id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/google/deepvariant/issues/849:267,energy efficiency,GPU,GPU,267,"Postprocess_variants.py ValueError: ptrue must be between zero and one: nan; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I have processed around 30 samples albeit having some issues with GPU, possibly due to nvidia driver / cuda version. However, recently postprocess has started stalling with the same error. Any help troubleshooting this would be greatly appreciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 202",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:575,energy efficiency,gpu,gpu,575,"Postprocess_variants.py ValueError: ptrue must be between zero and one: nan; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I have processed around 30 samples albeit having some issues with GPU, possibly due to nvidia driver / cuda version. However, recently postprocess has started stalling with the same error. Any help troubleshooting this would be greatly appreciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 202",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:963,energy efficiency,gpu,gpus,963,"Postprocess_variants.py ValueError: ptrue must be between zero and one: nan; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I have processed around 30 samples albeit having some issues with GPU, possibly due to nvidia driver / cuda version. However, recently postprocess has started stalling with the same error. Any help troubleshooting this would be greatly appreciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 202",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1005,energy efficiency,gpu,gpu,1005,"cess_variants.py ValueError: ptrue must be between zero and one: nan; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I have processed around 30 samples albeit having some issues with GPU, possibly due to nvidia driver / cuda version. However, recently postprocess has started stalling with the same error. Any help troubleshooting this would be greatly appreciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1038,energy efficiency,gpu,gpu,1038,"e must be between zero and one: nan; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I have processed around 30 samples albeit having some issues with GPU, possibly due to nvidia driver / cuda version. However, recently postprocess has started stalling with the same error. Any help troubleshooting this would be greatly appreciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/co",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1284,energy efficiency,cpu,cpus,1284,"o nvidia driver / cuda version. However, recently postprocess has started stalling with the same error. Any help troubleshooting this would be greatly appreciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operati",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:2038,energy efficiency,core,core,2038,"u /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. I0710 12:09:25.874185 139944337696576 postprocess_variants.py:1313] CVO sorting took 2.0161957065264384 minutes. I0710 12:09:25.874843 139944337696576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0710 12:09:25.874915 139944337696576 postprocess_variants.py:1318] Using 19 CPUs for parallelization of variant transformation. I0710 12:09:45.096508 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. multiprocessing.pool.RemoteTraceback:. """""". Traceback (most recent",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:2104,energy efficiency,optim,optimized,2104,"CA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. I0710 12:09:25.874185 139944337696576 postprocess_variants.py:1313] CVO sorting took 2.0161957065264384 minutes. I0710 12:09:25.874843 139944337696576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0710 12:09:25.874915 139944337696576 postprocess_variants.py:1318] Using 19 CPUs for parallelization of variant transformation. I0710 12:09:45.096508 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. multiprocessing.pool.RemoteTraceback:. """""". Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/pool.py"", line",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:2184,energy efficiency,CPU,CPU,2184,"ample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. I0710 12:09:25.874185 139944337696576 postprocess_variants.py:1313] CVO sorting took 2.0161957065264384 minutes. I0710 12:09:25.874843 139944337696576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0710 12:09:25.874915 139944337696576 postprocess_variants.py:1318] Using 19 CPUs for parallelization of variant transformation. I0710 12:09:45.096508 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. multiprocessing.pool.RemoteTraceback:. """""". Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 125, in worker. result = (True, func(*args, **kwds)). File ""/usr/lib/python3",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:2787,energy efficiency,CPU,CPUs,2787,"itions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. I0710 12:09:25.874185 139944337696576 postprocess_variants.py:1313] CVO sorting took 2.0161957065264384 minutes. I0710 12:09:25.874843 139944337696576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0710 12:09:25.874915 139944337696576 postprocess_variants.py:1318] Using 19 CPUs for parallelization of variant transformation. I0710 12:09:45.096508 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. multiprocessing.pool.RemoteTraceback:. """""". Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 125, in worker. result = (True, func(*args, **kwds)). File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 48, in mapstar. return list(map(*args)). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1125, in _mappable_transform_call_variant_group_to_output_variant. return _transform_call_variant_group_to_output_variant(**kwargs). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1036, in _transform_call_variant_group_to_output_variant. return add_call_to_variant(. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postproce",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:3876,energy efficiency,predict,predictions,3876,"rocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. multiprocessing.pool.RemoteTraceback:. """""". Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 125, in worker. result = (True, func(*args, **kwds)). File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 48, in mapstar. return list(map(*args)). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1125, in _mappable_transform_call_variant_group_to_output_variant. return _transform_call_variant_group_to_output_variant(**kwargs). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1036, in _transform_call_variant_group_to_output_variant. return add_call_to_variant(. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 434, in add_call_to_variant. gq, variant.quality = compute_quals(predictions, index). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 469, in compute_quals. genomics_math.ptrue_to_bounded_phred(predictions[prediction_index]). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/third_party/nucleus/util/genomics_math.py"", line 143, in ptrue_to_bounded_phred. raise ValueError('ptrue must be between zero and one: {}'.format(ptrue)). ValueError: ptrue must be between zero and one: nan. """""". The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_i47tupw0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:4067,energy efficiency,predict,predictions,4067,"on3.8/multiprocessing/pool.py"", line 125, in worker. result = (True, func(*args, **kwds)). File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 48, in mapstar. return list(map(*args)). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1125, in _mappable_transform_call_variant_group_to_output_variant. return _transform_call_variant_group_to_output_variant(**kwargs). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1036, in _transform_call_variant_group_to_output_variant. return add_call_to_variant(. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 434, in add_call_to_variant. gq, variant.quality = compute_quals(predictions, index). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 469, in compute_quals. genomics_math.ptrue_to_bounded_phred(predictions[prediction_index]). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/third_party/nucleus/util/genomics_math.py"", line 143, in ptrue_to_bounded_phred. raise ValueError('ptrue must be between zero and one: {}'.format(ptrue)). ValueError: ptrue must be between zero and one: nan. """""". The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1385, in main. tmp_variant_file = dump_variants_to_temp_file(variant_generator). File ""/tmp/Bazel.runfiles_i47tupw0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:309,integrability,version,version,309,"Postprocess_variants.py ValueError: ptrue must be between zero and one: nan; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I have processed around 30 samples albeit having some issues with GPU, possibly due to nvidia driver / cuda version. However, recently postprocess has started stalling with the same error. Any help troubleshooting this would be greatly appreciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 202",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:514,integrability,VERSION,VERSION,514,"Postprocess_variants.py ValueError: ptrue must be between zero and one: nan; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I have processed around 30 samples albeit having some issues with GPU, possibly due to nvidia driver / cuda version. However, recently postprocess has started stalling with the same error. Any help troubleshooting this would be greatly appreciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 202",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:548,integrability,version,version,548,"Postprocess_variants.py ValueError: ptrue must be between zero and one: nan; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I have processed around 30 samples albeit having some issues with GPU, possibly due to nvidia driver / cuda version. However, recently postprocess has started stalling with the same error. Any help troubleshooting this would be greatly appreciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 202",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1515,integrability,Version,Version,1515,"ON=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. I0710 12:09:25.874185 139944337696576",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:2663,integrability,Transform,Transforming,2663,"overned by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. I0710 12:09:25.874185 139944337696576 postprocess_variants.py:1313] CVO sorting took 2.0161957065264384 minutes. I0710 12:09:25.874843 139944337696576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0710 12:09:25.874915 139944337696576 postprocess_variants.py:1318] Using 19 CPUs for parallelization of variant transformation. I0710 12:09:45.096508 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. multiprocessing.pool.RemoteTraceback:. """""". Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 125, in worker. result = (True, func(*args, **kwds)). File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 48, in mapstar. return list(map(*args)). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1125, in _mappable_transform_call_variant_group_to_output_variant. return _transform_call_variant_group_to_output_variant(**kwargs). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1036, in _transform_call_variant_group_to_output_varian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:2823,integrability,transform,transformation,2823,"r.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. I0710 12:09:25.874185 139944337696576 postprocess_variants.py:1313] CVO sorting took 2.0161957065264384 minutes. I0710 12:09:25.874843 139944337696576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0710 12:09:25.874915 139944337696576 postprocess_variants.py:1318] Using 19 CPUs for parallelization of variant transformation. I0710 12:09:45.096508 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. multiprocessing.pool.RemoteTraceback:. """""". Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 125, in worker. result = (True, func(*args, **kwds)). File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 48, in mapstar. return list(map(*args)). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1125, in _mappable_transform_call_variant_group_to_output_variant. return _transform_call_variant_group_to_output_variant(**kwargs). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1036, in _transform_call_variant_group_to_output_variant. return add_call_to_variant(. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 434, in add_call_to",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:931,interoperability,share,share,931,"Postprocess_variants.py ValueError: ptrue must be between zero and one: nan; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I have processed around 30 samples albeit having some issues with GPU, possibly due to nvidia driver / cuda version. However, recently postprocess has started stalling with the same error. Any help troubleshooting this would be greatly appreciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 202",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:2043,interoperability,platform,platform,2043,"deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. I0710 12:09:25.874185 139944337696576 postprocess_variants.py:1313] CVO sorting took 2.0161957065264384 minutes. I0710 12:09:25.874843 139944337696576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0710 12:09:25.874915 139944337696576 postprocess_variants.py:1318] Using 19 CPUs for parallelization of variant transformation. I0710 12:09:45.096508 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. multiprocessing.pool.RemoteTraceback:. """""". Traceback (most recent call l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:2663,interoperability,Transform,Transforming,2663,"overned by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. I0710 12:09:25.874185 139944337696576 postprocess_variants.py:1313] CVO sorting took 2.0161957065264384 minutes. I0710 12:09:25.874843 139944337696576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0710 12:09:25.874915 139944337696576 postprocess_variants.py:1318] Using 19 CPUs for parallelization of variant transformation. I0710 12:09:45.096508 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. multiprocessing.pool.RemoteTraceback:. """""". Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 125, in worker. result = (True, func(*args, **kwds)). File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 48, in mapstar. return list(map(*args)). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1125, in _mappable_transform_call_variant_group_to_output_variant. return _transform_call_variant_group_to_output_variant(**kwargs). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1036, in _transform_call_variant_group_to_output_varian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:2823,interoperability,transform,transformation,2823,"r.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. I0710 12:09:25.874185 139944337696576 postprocess_variants.py:1313] CVO sorting took 2.0161957065264384 minutes. I0710 12:09:25.874843 139944337696576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0710 12:09:25.874915 139944337696576 postprocess_variants.py:1318] Using 19 CPUs for parallelization of variant transformation. I0710 12:09:45.096508 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. multiprocessing.pool.RemoteTraceback:. """""". Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 125, in worker. result = (True, func(*args, **kwds)). File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 48, in mapstar. return list(map(*args)). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1125, in _mappable_transform_call_variant_group_to_output_variant. return _transform_call_variant_group_to_output_variant(**kwargs). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1036, in _transform_call_variant_group_to_output_variant. return add_call_to_variant(. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 434, in add_call_to",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:4305,interoperability,format,format,4305,"_google_deepvariant/deepvariant/postprocess_variants.py"", line 1125, in _mappable_transform_call_variant_group_to_output_variant. return _transform_call_variant_group_to_output_variant(**kwargs). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1036, in _transform_call_variant_group_to_output_variant. return add_call_to_variant(. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 434, in add_call_to_variant. gq, variant.quality = compute_quals(predictions, index). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 469, in compute_quals. genomics_math.ptrue_to_bounded_phred(predictions[prediction_index]). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/third_party/nucleus/util/genomics_math.py"", line 143, in ptrue_to_bounded_phred. raise ValueError('ptrue must be between zero and one: {}'.format(ptrue)). ValueError: ptrue must be between zero and one: nan. """""". The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1385, in main. tmp_variant_file = dump_variants_to_temp_file(variant_generator). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1067, in dump_variants_to_temp_file. tfrecord.write_tfrecords(variant_protos, temp.name). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:309,modifiability,version,version,309,"Postprocess_variants.py ValueError: ptrue must be between zero and one: nan; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I have processed around 30 samples albeit having some issues with GPU, possibly due to nvidia driver / cuda version. However, recently postprocess has started stalling with the same error. Any help troubleshooting this would be greatly appreciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 202",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:514,modifiability,VERSION,VERSION,514,"Postprocess_variants.py ValueError: ptrue must be between zero and one: nan; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I have processed around 30 samples albeit having some issues with GPU, possibly due to nvidia driver / cuda version. However, recently postprocess has started stalling with the same error. Any help troubleshooting this would be greatly appreciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 202",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:548,modifiability,version,version,548,"Postprocess_variants.py ValueError: ptrue must be between zero and one: nan; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I have processed around 30 samples albeit having some issues with GPU, possibly due to nvidia driver / cuda version. However, recently postprocess has started stalling with the same error. Any help troubleshooting this would be greatly appreciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 202",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1193,modifiability,interm,intermediate,1193,". I have processed around 30 samples albeit having some issues with GPU, possibly due to nvidia driver / cuda version. However, recently postprocess has started stalling with the same error. Any help troubleshooting this would be greatly appreciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instruction",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1399,modifiability,interm,intermediate,1399,"eshooting this would be greatly appreciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1515,modifiability,Version,Version,1515,"ON=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. I0710 12:09:25.874185 139944337696576",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:4605,modifiability,modul,module,4605," line 1036, in _transform_call_variant_group_to_output_variant. return add_call_to_variant(. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 434, in add_call_to_variant. gq, variant.quality = compute_quals(predictions, index). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 469, in compute_quals. genomics_math.ptrue_to_bounded_phred(predictions[prediction_index]). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/third_party/nucleus/util/genomics_math.py"", line 143, in ptrue_to_bounded_phred. raise ValueError('ptrue must be between zero and one: {}'.format(ptrue)). ValueError: ptrue must be between zero and one: nan. """""". The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1385, in main. tmp_variant_file = dump_variants_to_temp_file(variant_generator). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1067, in dump_variants_to_temp_file. tfrecord.write_tfrecords(variant_protos, temp.name). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 190, in write_tfrecords. for proto in protos:. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 91, in maybe_resolve_conflicting_variants. for overlapping_candidates in _group_overlapping_variants(sorted_varia",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:267,performance,GPU,GPU,267,"Postprocess_variants.py ValueError: ptrue must be between zero and one: nan; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I have processed around 30 samples albeit having some issues with GPU, possibly due to nvidia driver / cuda version. However, recently postprocess has started stalling with the same error. Any help troubleshooting this would be greatly appreciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 202",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:383,performance,error,error,383,"Postprocess_variants.py ValueError: ptrue must be between zero and one: nan; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I have processed around 30 samples albeit having some issues with GPU, possibly due to nvidia driver / cuda version. However, recently postprocess has started stalling with the same error. Any help troubleshooting this would be greatly appreciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 202",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:575,performance,gpu,gpu,575,"Postprocess_variants.py ValueError: ptrue must be between zero and one: nan; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I have processed around 30 samples albeit having some issues with GPU, possibly due to nvidia driver / cuda version. However, recently postprocess has started stalling with the same error. Any help troubleshooting this would be greatly appreciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 202",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:963,performance,gpu,gpus,963,"Postprocess_variants.py ValueError: ptrue must be between zero and one: nan; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I have processed around 30 samples albeit having some issues with GPU, possibly due to nvidia driver / cuda version. However, recently postprocess has started stalling with the same error. Any help troubleshooting this would be greatly appreciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 202",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1005,performance,gpu,gpu,1005,"cess_variants.py ValueError: ptrue must be between zero and one: nan; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I have processed around 30 samples albeit having some issues with GPU, possibly due to nvidia driver / cuda version. However, recently postprocess has started stalling with the same error. Any help troubleshooting this would be greatly appreciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1038,performance,gpu,gpu,1038,"e must be between zero and one: nan; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I have processed around 30 samples albeit having some issues with GPU, possibly due to nvidia driver / cuda version. However, recently postprocess has started stalling with the same error. Any help troubleshooting this would be greatly appreciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/co",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1284,performance,cpu,cpus,1284,"o nvidia driver / cuda version. However, recently postprocess has started stalling with the same error. Any help troubleshooting this would be greatly appreciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operati",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1439,performance,Error,Error,1439,"ciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1655,performance,content,contents,1655," Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. I0710 12:09:25.874185 139944337696576 postprocess_variants.py:1313] CVO sorting took 2.0161957065264384 minutes. I0710 12:09:25.874843 139944337696576 postprocess_variants.py:13",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:2104,performance,optimiz,optimized,2104,"CA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. I0710 12:09:25.874185 139944337696576 postprocess_variants.py:1313] CVO sorting took 2.0161957065264384 minutes. I0710 12:09:25.874843 139944337696576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0710 12:09:25.874915 139944337696576 postprocess_variants.py:1318] Using 19 CPUs for parallelization of variant transformation. I0710 12:09:45.096508 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. multiprocessing.pool.RemoteTraceback:. """""". Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/pool.py"", line",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:2138,performance,Network,Network,2138,"lysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. I0710 12:09:25.874185 139944337696576 postprocess_variants.py:1313] CVO sorting took 2.0161957065264384 minutes. I0710 12:09:25.874843 139944337696576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0710 12:09:25.874915 139944337696576 postprocess_variants.py:1318] Using 19 CPUs for parallelization of variant transformation. I0710 12:09:45.096508 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. multiprocessing.pool.RemoteTraceback:. """""". Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 125, in worker. result = (True, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:2184,performance,CPU,CPU,2184,"ample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. I0710 12:09:25.874185 139944337696576 postprocess_variants.py:1313] CVO sorting took 2.0161957065264384 minutes. I0710 12:09:25.874843 139944337696576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0710 12:09:25.874915 139944337696576 postprocess_variants.py:1318] Using 19 CPUs for parallelization of variant transformation. I0710 12:09:45.096508 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. multiprocessing.pool.RemoteTraceback:. """""". Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 125, in worker. result = (True, func(*args, **kwds)). File ""/usr/lib/python3",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:2204,performance,perform,performance-critical,2204,"iants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. I0710 12:09:25.874185 139944337696576 postprocess_variants.py:1313] CVO sorting took 2.0161957065264384 minutes. I0710 12:09:25.874843 139944337696576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0710 12:09:25.874915 139944337696576 postprocess_variants.py:1318] Using 19 CPUs for parallelization of variant transformation. I0710 12:09:45.096508 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. multiprocessing.pool.RemoteTraceback:. """""". Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 125, in worker. result = (True, func(*args, **kwds)). File ""/usr/lib/python3.8/multiprocessing/pool.py"",",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:2787,performance,CPU,CPUs,2787,"itions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. I0710 12:09:25.874185 139944337696576 postprocess_variants.py:1313] CVO sorting took 2.0161957065264384 minutes. I0710 12:09:25.874843 139944337696576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0710 12:09:25.874915 139944337696576 postprocess_variants.py:1318] Using 19 CPUs for parallelization of variant transformation. I0710 12:09:45.096508 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. multiprocessing.pool.RemoteTraceback:. """""". Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 125, in worker. result = (True, func(*args, **kwds)). File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 48, in mapstar. return list(map(*args)). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1125, in _mappable_transform_call_variant_group_to_output_variant. return _transform_call_variant_group_to_output_variant(**kwargs). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1036, in _transform_call_variant_group_to_output_variant. return add_call_to_variant(. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postproce",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:2796,performance,parallel,parallelization,2796,"license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. I0710 12:09:25.874185 139944337696576 postprocess_variants.py:1313] CVO sorting took 2.0161957065264384 minutes. I0710 12:09:25.874843 139944337696576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0710 12:09:25.874915 139944337696576 postprocess_variants.py:1318] Using 19 CPUs for parallelization of variant transformation. I0710 12:09:45.096508 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. multiprocessing.pool.RemoteTraceback:. """""". Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 125, in worker. result = (True, func(*args, **kwds)). File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 48, in mapstar. return list(map(*args)). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1125, in _mappable_transform_call_variant_group_to_output_variant. return _transform_call_variant_group_to_output_variant(**kwargs). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1036, in _transform_call_variant_group_to_output_variant. return add_call_to_variant(. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1918,reliability,availab,available,1918,"ir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. I0710 12:09:25.874185 139944337696576 postprocess_variants.py:1313] CVO sorting took 2.0161957065264384 minutes. I0710 12:09:25.874843 139944337696576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0710 12:09:25.874915 139944337696576 postprocess_variants.py:1318] Using 19 CPUs for parallelization of variant transformation. I0710 12:09:45.096508 139944337696576 postprocess_variants.py:1211] Using sample nam",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:6056,reliability,Doe,Does,6056,"}'.format(ptrue)). ValueError: ptrue must be between zero and one: nan. """""". The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1385, in main. tmp_variant_file = dump_variants_to_temp_file(variant_generator). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1067, in dump_variants_to_temp_file. tfrecord.write_tfrecords(variant_protos, temp.name). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 190, in write_tfrecords. for proto in protos:. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 91, in maybe_resolve_conflicting_variants. for overlapping_candidates in _group_overlapping_variants(sorted_variants):. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 111, in _group_overlapping_variants. for variant in sorted_variants:. File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 420, in <genexpr>. return (item for chunk in result for item in chunk). File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 868, in next. raise value. ValueError: ptrue must be between zero and one: nan. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:383,safety,error,error,383,"Postprocess_variants.py ValueError: ptrue must be between zero and one: nan; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I have processed around 30 samples albeit having some issues with GPU, possibly due to nvidia driver / cuda version. However, recently postprocess has started stalling with the same error. Any help troubleshooting this would be greatly appreciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 202",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1439,safety,Error,Error,1439,"ciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1918,safety,avail,available,1918,"ir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. I0710 12:09:25.874185 139944337696576 postprocess_variants.py:1313] CVO sorting took 2.0161957065264384 minutes. I0710 12:09:25.874843 139944337696576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0710 12:09:25.874915 139944337696576 postprocess_variants.py:1318] Using 19 CPUs for parallelization of variant transformation. I0710 12:09:45.096508 139944337696576 postprocess_variants.py:1211] Using sample nam",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:3876,safety,predict,predictions,3876,"rocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. multiprocessing.pool.RemoteTraceback:. """""". Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 125, in worker. result = (True, func(*args, **kwds)). File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 48, in mapstar. return list(map(*args)). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1125, in _mappable_transform_call_variant_group_to_output_variant. return _transform_call_variant_group_to_output_variant(**kwargs). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1036, in _transform_call_variant_group_to_output_variant. return add_call_to_variant(. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 434, in add_call_to_variant. gq, variant.quality = compute_quals(predictions, index). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 469, in compute_quals. genomics_math.ptrue_to_bounded_phred(predictions[prediction_index]). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/third_party/nucleus/util/genomics_math.py"", line 143, in ptrue_to_bounded_phred. raise ValueError('ptrue must be between zero and one: {}'.format(ptrue)). ValueError: ptrue must be between zero and one: nan. """""". The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_i47tupw0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:4067,safety,predict,predictions,4067,"on3.8/multiprocessing/pool.py"", line 125, in worker. result = (True, func(*args, **kwds)). File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 48, in mapstar. return list(map(*args)). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1125, in _mappable_transform_call_variant_group_to_output_variant. return _transform_call_variant_group_to_output_variant(**kwargs). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1036, in _transform_call_variant_group_to_output_variant. return add_call_to_variant(. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 434, in add_call_to_variant. gq, variant.quality = compute_quals(predictions, index). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 469, in compute_quals. genomics_math.ptrue_to_bounded_phred(predictions[prediction_index]). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/third_party/nucleus/util/genomics_math.py"", line 143, in ptrue_to_bounded_phred. raise ValueError('ptrue must be between zero and one: {}'.format(ptrue)). ValueError: ptrue must be between zero and one: nan. """""". The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1385, in main. tmp_variant_file = dump_variants_to_temp_file(variant_generator). File ""/tmp/Bazel.runfiles_i47tupw0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:4389,safety,except,exception,4389,"sform_call_variant_group_to_output_variant. return _transform_call_variant_group_to_output_variant(**kwargs). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1036, in _transform_call_variant_group_to_output_variant. return add_call_to_variant(. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 434, in add_call_to_variant. gq, variant.quality = compute_quals(predictions, index). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 469, in compute_quals. genomics_math.ptrue_to_bounded_phred(predictions[prediction_index]). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/third_party/nucleus/util/genomics_math.py"", line 143, in ptrue_to_bounded_phred. raise ValueError('ptrue must be between zero and one: {}'.format(ptrue)). ValueError: ptrue must be between zero and one: nan. """""". The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1385, in main. tmp_variant_file = dump_variants_to_temp_file(variant_generator). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1067, in dump_variants_to_temp_file. tfrecord.write_tfrecords(variant_protos, temp.name). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 190, in write_tfrecords. for proto in protos:.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:4437,safety,except,exception,4437,"rn _transform_call_variant_group_to_output_variant(**kwargs). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1036, in _transform_call_variant_group_to_output_variant. return add_call_to_variant(. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 434, in add_call_to_variant. gq, variant.quality = compute_quals(predictions, index). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 469, in compute_quals. genomics_math.ptrue_to_bounded_phred(predictions[prediction_index]). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/third_party/nucleus/util/genomics_math.py"", line 143, in ptrue_to_bounded_phred. raise ValueError('ptrue must be between zero and one: {}'.format(ptrue)). ValueError: ptrue must be between zero and one: nan. """""". The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1385, in main. tmp_variant_file = dump_variants_to_temp_file(variant_generator). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1067, in dump_variants_to_temp_file. tfrecord.write_tfrecords(variant_protos, temp.name). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 190, in write_tfrecords. for proto in protos:. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:4605,safety,modul,module,4605," line 1036, in _transform_call_variant_group_to_output_variant. return add_call_to_variant(. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 434, in add_call_to_variant. gq, variant.quality = compute_quals(predictions, index). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 469, in compute_quals. genomics_math.ptrue_to_bounded_phred(predictions[prediction_index]). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/third_party/nucleus/util/genomics_math.py"", line 143, in ptrue_to_bounded_phred. raise ValueError('ptrue must be between zero and one: {}'.format(ptrue)). ValueError: ptrue must be between zero and one: nan. """""". The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1385, in main. tmp_variant_file = dump_variants_to_temp_file(variant_generator). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1067, in dump_variants_to_temp_file. tfrecord.write_tfrecords(variant_protos, temp.name). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 190, in write_tfrecords. for proto in protos:. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 91, in maybe_resolve_conflicting_variants. for overlapping_candidates in _group_overlapping_variants(sorted_varia",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:6077,safety,test,test,6077,"}'.format(ptrue)). ValueError: ptrue must be between zero and one: nan. """""". The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1385, in main. tmp_variant_file = dump_variants_to_temp_file(variant_generator). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1067, in dump_variants_to_temp_file. tfrecord.write_tfrecords(variant_protos, temp.name). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 190, in write_tfrecords. for proto in protos:. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 91, in maybe_resolve_conflicting_variants. for overlapping_candidates in _group_overlapping_variants(sorted_variants):. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 111, in _group_overlapping_variants. for variant in sorted_variants:. File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 420, in <genexpr>. return (item for chunk in result for item in chunk). File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 868, in next. raise value. ValueError: ptrue must be between zero and one: nan. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:6117,safety,test,test,6117,"}'.format(ptrue)). ValueError: ptrue must be between zero and one: nan. """""". The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1385, in main. tmp_variant_file = dump_variants_to_temp_file(variant_generator). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1067, in dump_variants_to_temp_file. tfrecord.write_tfrecords(variant_protos, temp.name). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 190, in write_tfrecords. for proto in protos:. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 91, in maybe_resolve_conflicting_variants. for overlapping_candidates in _group_overlapping_variants(sorted_variants):. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 111, in _group_overlapping_variants. for variant in sorted_variants:. File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 420, in <genexpr>. return (item for chunk in result for item in chunk). File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 868, in next. raise value. ValueError: ptrue must be between zero and one: nan. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:887,security,secur,security-opt,887,"Postprocess_variants.py ValueError: ptrue must be between zero and one: nan; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I have processed around 30 samples albeit having some issues with GPU, possibly due to nvidia driver / cuda version. However, recently postprocess has started stalling with the same error. Any help troubleshooting this would be greatly appreciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 202",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1668,security,govern,governed,1668,": (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. I0710 12:09:25.874185 139944337696576 postprocess_variants.py:1313] CVO sorting took 2.0161957065264384 minutes. I0710 12:09:25.874843 139944337696576 postprocess_variants.py:1316] Transform",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1918,security,availab,available,1918,"ir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. I0710 12:09:25.874185 139944337696576 postprocess_variants.py:1313] CVO sorting took 2.0161957065264384 minutes. I0710 12:09:25.874843 139944337696576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0710 12:09:25.874915 139944337696576 postprocess_variants.py:1318] Using 19 CPUs for parallelization of variant transformation. I0710 12:09:45.096508 139944337696576 postprocess_variants.py:1211] Using sample nam",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:2138,security,Network,Network,2138,"lysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. I0710 12:09:25.874185 139944337696576 postprocess_variants.py:1313] CVO sorting took 2.0161957065264384 minutes. I0710 12:09:25.874843 139944337696576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0710 12:09:25.874915 139944337696576 postprocess_variants.py:1318] Using 19 CPUs for parallelization of variant transformation. I0710 12:09:45.096508 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. multiprocessing.pool.RemoteTraceback:. """""". Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 125, in worker. result = (True, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:686,testability,instrument,instrument,686,"Postprocess_variants.py ValueError: ptrue must be between zero and one: nan; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I have processed around 30 samples albeit having some issues with GPU, possibly due to nvidia driver / cuda version. However, recently postprocess has started stalling with the same error. Any help troubleshooting this would be greatly appreciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 202",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:916,testability,hook,hooks-dir,916,"Postprocess_variants.py ValueError: ptrue must be between zero and one: nan; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I have processed around 30 samples albeit having some issues with GPU, possibly due to nvidia driver / cuda version. However, recently postprocess has started stalling with the same error. Any help troubleshooting this would be greatly appreciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 202",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:952,testability,hook,hooks,952,"Postprocess_variants.py ValueError: ptrue must be between zero and one: nan; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I have processed around 30 samples albeit having some issues with GPU, possibly due to nvidia driver / cuda version. However, recently postprocess has started stalling with the same error. Any help troubleshooting this would be greatly appreciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 202",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1445,testability,trace,trace,1445,"! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call_varia",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:3018,testability,Trace,Traceback,3018,": I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. I0710 12:09:25.874185 139944337696576 postprocess_variants.py:1313] CVO sorting took 2.0161957065264384 minutes. I0710 12:09:25.874843 139944337696576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0710 12:09:25.874915 139944337696576 postprocess_variants.py:1318] Using 19 CPUs for parallelization of variant transformation. I0710 12:09:45.096508 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. multiprocessing.pool.RemoteTraceback:. """""". Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 125, in worker. result = (True, func(*args, **kwds)). File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 48, in mapstar. return list(map(*args)). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1125, in _mappable_transform_call_variant_group_to_output_variant. return _transform_call_variant_group_to_output_variant(**kwargs). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1036, in _transform_call_variant_group_to_output_variant. return add_call_to_variant(. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 434, in add_call_to_variant. gq, variant.quality = compute_quals(predictions, index). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 469, in compute_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:4449,testability,Trace,Traceback,4449,"m_call_variant_group_to_output_variant(**kwargs). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1036, in _transform_call_variant_group_to_output_variant. return add_call_to_variant(. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 434, in add_call_to_variant. gq, variant.quality = compute_quals(predictions, index). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 469, in compute_quals. genomics_math.ptrue_to_bounded_phred(predictions[prediction_index]). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/third_party/nucleus/util/genomics_math.py"", line 143, in ptrue_to_bounded_phred. raise ValueError('ptrue must be between zero and one: {}'.format(ptrue)). ValueError: ptrue must be between zero and one: nan. """""". The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1385, in main. tmp_variant_file = dump_variants_to_temp_file(variant_generator). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1067, in dump_variants_to_temp_file. tfrecord.write_tfrecords(variant_protos, temp.name). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 190, in write_tfrecords. for proto in protos:. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:6077,testability,test,test,6077,"}'.format(ptrue)). ValueError: ptrue must be between zero and one: nan. """""". The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1385, in main. tmp_variant_file = dump_variants_to_temp_file(variant_generator). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1067, in dump_variants_to_temp_file. tfrecord.write_tfrecords(variant_protos, temp.name). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 190, in write_tfrecords. for proto in protos:. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 91, in maybe_resolve_conflicting_variants. for overlapping_candidates in _group_overlapping_variants(sorted_variants):. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 111, in _group_overlapping_variants. for variant in sorted_variants:. File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 420, in <genexpr>. return (item for chunk in result for item in chunk). File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 868, in next. raise value. ValueError: ptrue must be between zero and one: nan. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:6117,testability,test,test,6117,"}'.format(ptrue)). ValueError: ptrue must be between zero and one: nan. """""". The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1385, in main. tmp_variant_file = dump_variants_to_temp_file(variant_generator). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1067, in dump_variants_to_temp_file. tfrecord.write_tfrecords(variant_protos, temp.name). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 190, in write_tfrecords. for proto in protos:. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 91, in maybe_resolve_conflicting_variants. for overlapping_candidates in _group_overlapping_variants(sorted_variants):. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 111, in _group_overlapping_variants. for variant in sorted_variants:. File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 420, in <genexpr>. return (item for chunk in result for item in chunk). File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 868, in next. raise value. ValueError: ptrue must be between zero and one: nan. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:6291,testability,context,context,6291,"}'.format(ptrue)). ValueError: ptrue must be between zero and one: nan. """""". The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1385, in main. tmp_variant_file = dump_variants_to_temp_file(variant_generator). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1067, in dump_variants_to_temp_file. tfrecord.write_tfrecords(variant_protos, temp.name). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 190, in write_tfrecords. for proto in protos:. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 91, in maybe_resolve_conflicting_variants. for overlapping_candidates in _group_overlapping_variants(sorted_variants):. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 111, in _group_overlapping_variants. for variant in sorted_variants:. File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 420, in <genexpr>. return (item for chunk in result for item in chunk). File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 868, in next. raise value. ValueError: ptrue must be between zero and one: nan. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:383,usability,error,error,383,"Postprocess_variants.py ValueError: ptrue must be between zero and one: nan; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I have processed around 30 samples albeit having some issues with GPU, possibly due to nvidia driver / cuda version. However, recently postprocess has started stalling with the same error. Any help troubleshooting this would be greatly appreciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 202",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:394,usability,help,help,394,"Postprocess_variants.py ValueError: ptrue must be between zero and one: nan; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I have processed around 30 samples albeit having some issues with GPU, possibly due to nvidia driver / cuda version. However, recently postprocess has started stalling with the same error. Any help troubleshooting this would be greatly appreciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 202",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:853,usability,Command,Command,853,"Postprocess_variants.py ValueError: ptrue must be between zero and one: nan; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I have processed around 30 samples albeit having some issues with GPU, possibly due to nvidia driver / cuda version. However, recently postprocess has started stalling with the same error. Any help troubleshooting this would be greatly appreciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 202",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1439,usability,Error,Error,1439,"ciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1696,usability,Learn,Learning,1696,"ference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. I0710 12:09:25.874185 139944337696576 postprocess_variants.py:1313] CVO sorting took 2.0161957065264384 minutes. I0710 12:09:25.874843 139944337696576 postprocess_variants.py:1316] Transforming call_variants_output to ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1859,usability,learn,learning-container-license,1859,"run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. I0710 12:09:25.874185 139944337696576 postprocess_variants.py:1313] CVO sorting took 2.0161957065264384 minutes. I0710 12:09:25.874843 139944337696576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0710 12:09:25.874915 139944337696576 postprocess_variants.py:1318] Using 19 CPUs for parallelization of variant transformation. I0710 12:09:45.096508 13994433769",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:2204,usability,perform,performance-critical,2204,"iants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. I0710 12:09:25.874185 139944337696576 postprocess_variants.py:1313] CVO sorting took 2.0161957065264384 minutes. I0710 12:09:25.874843 139944337696576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0710 12:09:25.874915 139944337696576 postprocess_variants.py:1318] Using 19 CPUs for parallelization of variant transformation. I0710 12:09:45.096508 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. multiprocessing.pool.RemoteTraceback:. """""". Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 125, in worker. result = (True, func(*args, **kwds)). File ""/usr/lib/python3.8/multiprocessing/pool.py"",",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/850:107,availability,avail,available,107,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:131,availability,Operat,Operating,131,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:395,availability,down,downloads,395,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:90,deployability,log,logs,90,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:184,deployability,version,version,184,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:202,deployability,Instal,Installation,202,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:994,deployability,log,log,994,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:1064,deployability,log,log,1064,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:1085,deployability,log,log,1085,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:1155,deployability,log,log,1155,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:1183,deployability,log,log,1183,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:1260,deployability,log,log,1260,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:1284,deployability,log,log,1284,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:1357,deployability,log,log,1357,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:184,integrability,version,version,184,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:419,integrability,pub,public,419,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:184,modifiability,version,version,184,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:405,modifiability,pac,pacbcloud,405,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:729,modifiability,PAC,PACBIO,729,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:107,reliability,availab,available,107,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:90,safety,log,logs,90,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:107,safety,avail,available,107,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:351,safety,input,input,351,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:590,safety,input,input,590,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:599,safety,input,input,599,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:743,safety,input,input,743,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:771,safety,input,input,771,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:994,safety,log,log,994,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:1064,safety,log,log,1064,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:1085,safety,log,log,1085,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:1155,safety,log,log,1155,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:1183,safety,log,log,1183,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:1260,safety,log,log,1260,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:1284,safety,log,log,1284,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:1357,safety,log,log,1357,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:90,security,log,logs,90,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:107,security,availab,available,107,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:994,security,log,log,994,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:1064,security,log,log,1064,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:1085,security,log,log,1085,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:1155,security,log,log,1155,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:1183,security,log,log,1183,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:1260,security,log,log,1260,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:1284,security,log,log,1284,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:1357,security,log,log,1357,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:90,testability,log,logs,90,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:967,testability,context,context,967,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:994,testability,log,log,994,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:1064,testability,log,log,1064,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:1085,testability,log,log,1085,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:1155,testability,log,log,1155,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:1183,testability,log,log,1183,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:1260,testability,log,log,1260,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:1284,testability,log,log,1284,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:1357,testability,log,log,1357,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:351,usability,input,input,351,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:540,usability,Command,Command,540,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:590,usability,input,input,590,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:599,usability,input,input,599,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:743,usability,input,input,743,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:771,usability,input,input,771,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:1018,usability,user,user-attachments,1018,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:1109,usability,user,user-attachments,1109,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:1207,usability,user,user-attachments,1207,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/850:1308,usability,user,user-attachments,1308,"No vcf output after running; **Describe the issue:**. After running, no VCF is found, the logs however are available. **Setup**. - Operating system: ubuntu 22.04 (WSL2). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): docker. - Type of data: (I find variant only in chr17 for easier reading and faster speed). - input read: aligned HG004 to CHM13 (https://downloads.pacbcloud.com/public/revio/2022Q4/HG004-rep1/). - reference genome: CHM13 (https://github.com/marbl/CHM13). **Steps to reproduce:**. - Command:. `docker run --volume ""/root/deepvariant/input"":""/input"" --volume ""/root/deepvariant/output"":""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/chm13v2.0.fa --reads=/input/aligntest.bam --regions ""chr17"" --output_vcf=/output.vcf.gz --output_gvcf=/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results --logging_dir=/output`. . **Any additional context:**. [make_examples.log](https://github.com/user-attachments/files/16189177/make_examples.log). [call_variants.log](https://github.com/user-attachments/files/16189180/call_variants.log). [postprocess_variants.log](https://github.com/user-attachments/files/16189182/postprocess_variants.log). [vcf_stats_report.log](https://github.com/user-attachments/files/16189186/vcf_stats_report.log).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/850
https://github.com/google/deepvariant/issues/851:834,availability,error,error,834,"ValueError: Reference contigs span 3137161264 bases but only 63025520 bases (2.01%) were found in common among our input files. Check that the sources were created on a common genome reference build.; I want to use deepvariant only on ucsc_hg19's chr20. So I execute:. ```. docker run \. -v ""${PWD}"":""/input"" \. -v ""${PWD}/vg_deepvariant"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc_hg19.fa.gz \. --reads=/output/chr20_aln.sort.bam \. --regions ""chr20"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir. ```. My bam file is from vg, and I want to use deepvariant to call variant. I check the header of bam and reference, they are matching. The more detail error information:. `ValueError: Reference contigs span 3137161264 bases but only 63025520 bases (2.01%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrM"" is 16571 bp and IS MISSING, . ""chr1"" is 249250621 bp and IS MISSING, . ""chr2"" is 243199373 bp and IS MISSING, . ""chr3"" is 198022430 bp and IS MISSING, . ""chr4"" is 191154276 bp and IS MISSING, . ""chr5"" is 180915260 bp and IS MISSING, . ""chr6"" is 171115067 bp and IS MISSING, . ""chr7"" is 159138663 bp and IS MISSING, . ""chr8"" is 146364022 bp and IS MISSING, . ""chr9"" is 141213431 bp and IS MISSING, . ""chr10"" is 135534747 bp and IS MISSING, . ""chr11"" is 135006516 bp and IS MISSING, . ""chr12"" is 133851895 bp and IS MISSING, . ""chr13"" is 115169878 bp and IS MISSING, . ""chr14"" is 107349540 bp and IS MISSING, . ""chr15"" is 102531392 bp and IS MISSING, . ""chr16"" is 90354753 bp and IS MISSING, . ""chr17"" is 81195210 bp and IS MISSING, . ""chr18"" is 78077248 bp and IS MISSING, . ""chr19"" is 59128983 bp and IS MISSING, . ""chr20"" is 63025520 bp and matched, . ""chr21"" is 48129895 bp and IS MISSING, . ""chr22"" is 51304566 b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/851
https://github.com/google/deepvariant/issues/851:193,deployability,build,build,193,"ValueError: Reference contigs span 3137161264 bases but only 63025520 bases (2.01%) were found in common among our input files. Check that the sources were created on a common genome reference build.; I want to use deepvariant only on ucsc_hg19's chr20. So I execute:. ```. docker run \. -v ""${PWD}"":""/input"" \. -v ""${PWD}/vg_deepvariant"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc_hg19.fa.gz \. --reads=/output/chr20_aln.sort.bam \. --regions ""chr20"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir. ```. My bam file is from vg, and I want to use deepvariant to call variant. I check the header of bam and reference, they are matching. The more detail error information:. `ValueError: Reference contigs span 3137161264 bases but only 63025520 bases (2.01%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrM"" is 16571 bp and IS MISSING, . ""chr1"" is 249250621 bp and IS MISSING, . ""chr2"" is 243199373 bp and IS MISSING, . ""chr3"" is 198022430 bp and IS MISSING, . ""chr4"" is 191154276 bp and IS MISSING, . ""chr5"" is 180915260 bp and IS MISSING, . ""chr6"" is 171115067 bp and IS MISSING, . ""chr7"" is 159138663 bp and IS MISSING, . ""chr8"" is 146364022 bp and IS MISSING, . ""chr9"" is 141213431 bp and IS MISSING, . ""chr10"" is 135534747 bp and IS MISSING, . ""chr11"" is 135006516 bp and IS MISSING, . ""chr12"" is 133851895 bp and IS MISSING, . ""chr13"" is 115169878 bp and IS MISSING, . ""chr14"" is 107349540 bp and IS MISSING, . ""chr15"" is 102531392 bp and IS MISSING, . ""chr16"" is 90354753 bp and IS MISSING, . ""chr17"" is 81195210 bp and IS MISSING, . ""chr18"" is 78077248 bp and IS MISSING, . ""chr19"" is 59128983 bp and IS MISSING, . ""chr20"" is 63025520 bp and matched, . ""chr21"" is 48129895 bp and IS MISSING, . ""chr22"" is 51304566 b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/851
https://github.com/google/deepvariant/issues/851:1048,deployability,build,build,1048," but only 63025520 bases (2.01%) were found in common among our input files. Check that the sources were created on a common genome reference build.; I want to use deepvariant only on ucsc_hg19's chr20. So I execute:. ```. docker run \. -v ""${PWD}"":""/input"" \. -v ""${PWD}/vg_deepvariant"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc_hg19.fa.gz \. --reads=/output/chr20_aln.sort.bam \. --regions ""chr20"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir. ```. My bam file is from vg, and I want to use deepvariant to call variant. I check the header of bam and reference, they are matching. The more detail error information:. `ValueError: Reference contigs span 3137161264 bases but only 63025520 bases (2.01%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrM"" is 16571 bp and IS MISSING, . ""chr1"" is 249250621 bp and IS MISSING, . ""chr2"" is 243199373 bp and IS MISSING, . ""chr3"" is 198022430 bp and IS MISSING, . ""chr4"" is 191154276 bp and IS MISSING, . ""chr5"" is 180915260 bp and IS MISSING, . ""chr6"" is 171115067 bp and IS MISSING, . ""chr7"" is 159138663 bp and IS MISSING, . ""chr8"" is 146364022 bp and IS MISSING, . ""chr9"" is 141213431 bp and IS MISSING, . ""chr10"" is 135534747 bp and IS MISSING, . ""chr11"" is 135006516 bp and IS MISSING, . ""chr12"" is 133851895 bp and IS MISSING, . ""chr13"" is 115169878 bp and IS MISSING, . ""chr14"" is 107349540 bp and IS MISSING, . ""chr15"" is 102531392 bp and IS MISSING, . ""chr16"" is 90354753 bp and IS MISSING, . ""chr17"" is 81195210 bp and IS MISSING, . ""chr18"" is 78077248 bp and IS MISSING, . ""chr19"" is 59128983 bp and IS MISSING, . ""chr20"" is 63025520 bp and matched, . ""chr21"" is 48129895 bp and IS MISSING, . ""chr22"" is 51304566 bp and IS MISSING, . ""chrX"" is 155270560 bp and IS M",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/851
https://github.com/google/deepvariant/issues/851:834,performance,error,error,834,"ValueError: Reference contigs span 3137161264 bases but only 63025520 bases (2.01%) were found in common among our input files. Check that the sources were created on a common genome reference build.; I want to use deepvariant only on ucsc_hg19's chr20. So I execute:. ```. docker run \. -v ""${PWD}"":""/input"" \. -v ""${PWD}/vg_deepvariant"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc_hg19.fa.gz \. --reads=/output/chr20_aln.sort.bam \. --regions ""chr20"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir. ```. My bam file is from vg, and I want to use deepvariant to call variant. I check the header of bam and reference, they are matching. The more detail error information:. `ValueError: Reference contigs span 3137161264 bases but only 63025520 bases (2.01%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrM"" is 16571 bp and IS MISSING, . ""chr1"" is 249250621 bp and IS MISSING, . ""chr2"" is 243199373 bp and IS MISSING, . ""chr3"" is 198022430 bp and IS MISSING, . ""chr4"" is 191154276 bp and IS MISSING, . ""chr5"" is 180915260 bp and IS MISSING, . ""chr6"" is 171115067 bp and IS MISSING, . ""chr7"" is 159138663 bp and IS MISSING, . ""chr8"" is 146364022 bp and IS MISSING, . ""chr9"" is 141213431 bp and IS MISSING, . ""chr10"" is 135534747 bp and IS MISSING, . ""chr11"" is 135006516 bp and IS MISSING, . ""chr12"" is 133851895 bp and IS MISSING, . ""chr13"" is 115169878 bp and IS MISSING, . ""chr14"" is 107349540 bp and IS MISSING, . ""chr15"" is 102531392 bp and IS MISSING, . ""chr16"" is 90354753 bp and IS MISSING, . ""chr17"" is 81195210 bp and IS MISSING, . ""chr18"" is 78077248 bp and IS MISSING, . ""chr19"" is 59128983 bp and IS MISSING, . ""chr20"" is 63025520 bp and matched, . ""chr21"" is 48129895 bp and IS MISSING, . ""chr22"" is 51304566 b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/851
https://github.com/google/deepvariant/issues/851:115,safety,input,input,115,"ValueError: Reference contigs span 3137161264 bases but only 63025520 bases (2.01%) were found in common among our input files. Check that the sources were created on a common genome reference build.; I want to use deepvariant only on ucsc_hg19's chr20. So I execute:. ```. docker run \. -v ""${PWD}"":""/input"" \. -v ""${PWD}/vg_deepvariant"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc_hg19.fa.gz \. --reads=/output/chr20_aln.sort.bam \. --regions ""chr20"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir. ```. My bam file is from vg, and I want to use deepvariant to call variant. I check the header of bam and reference, they are matching. The more detail error information:. `ValueError: Reference contigs span 3137161264 bases but only 63025520 bases (2.01%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrM"" is 16571 bp and IS MISSING, . ""chr1"" is 249250621 bp and IS MISSING, . ""chr2"" is 243199373 bp and IS MISSING, . ""chr3"" is 198022430 bp and IS MISSING, . ""chr4"" is 191154276 bp and IS MISSING, . ""chr5"" is 180915260 bp and IS MISSING, . ""chr6"" is 171115067 bp and IS MISSING, . ""chr7"" is 159138663 bp and IS MISSING, . ""chr8"" is 146364022 bp and IS MISSING, . ""chr9"" is 141213431 bp and IS MISSING, . ""chr10"" is 135534747 bp and IS MISSING, . ""chr11"" is 135006516 bp and IS MISSING, . ""chr12"" is 133851895 bp and IS MISSING, . ""chr13"" is 115169878 bp and IS MISSING, . ""chr14"" is 107349540 bp and IS MISSING, . ""chr15"" is 102531392 bp and IS MISSING, . ""chr16"" is 90354753 bp and IS MISSING, . ""chr17"" is 81195210 bp and IS MISSING, . ""chr18"" is 78077248 bp and IS MISSING, . ""chr19"" is 59128983 bp and IS MISSING, . ""chr20"" is 63025520 bp and matched, . ""chr21"" is 48129895 bp and IS MISSING, . ""chr22"" is 51304566 b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/851
https://github.com/google/deepvariant/issues/851:302,safety,input,input,302,"ValueError: Reference contigs span 3137161264 bases but only 63025520 bases (2.01%) were found in common among our input files. Check that the sources were created on a common genome reference build.; I want to use deepvariant only on ucsc_hg19's chr20. So I execute:. ```. docker run \. -v ""${PWD}"":""/input"" \. -v ""${PWD}/vg_deepvariant"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc_hg19.fa.gz \. --reads=/output/chr20_aln.sort.bam \. --regions ""chr20"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir. ```. My bam file is from vg, and I want to use deepvariant to call variant. I check the header of bam and reference, they are matching. The more detail error information:. `ValueError: Reference contigs span 3137161264 bases but only 63025520 bases (2.01%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrM"" is 16571 bp and IS MISSING, . ""chr1"" is 249250621 bp and IS MISSING, . ""chr2"" is 243199373 bp and IS MISSING, . ""chr3"" is 198022430 bp and IS MISSING, . ""chr4"" is 191154276 bp and IS MISSING, . ""chr5"" is 180915260 bp and IS MISSING, . ""chr6"" is 171115067 bp and IS MISSING, . ""chr7"" is 159138663 bp and IS MISSING, . ""chr8"" is 146364022 bp and IS MISSING, . ""chr9"" is 141213431 bp and IS MISSING, . ""chr10"" is 135534747 bp and IS MISSING, . ""chr11"" is 135006516 bp and IS MISSING, . ""chr12"" is 133851895 bp and IS MISSING, . ""chr13"" is 115169878 bp and IS MISSING, . ""chr14"" is 107349540 bp and IS MISSING, . ""chr15"" is 102531392 bp and IS MISSING, . ""chr16"" is 90354753 bp and IS MISSING, . ""chr17"" is 81195210 bp and IS MISSING, . ""chr18"" is 78077248 bp and IS MISSING, . ""chr19"" is 59128983 bp and IS MISSING, . ""chr20"" is 63025520 bp and matched, . ""chr21"" is 48129895 bp and IS MISSING, . ""chr22"" is 51304566 b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/851
https://github.com/google/deepvariant/issues/851:458,safety,input,input,458,"ValueError: Reference contigs span 3137161264 bases but only 63025520 bases (2.01%) were found in common among our input files. Check that the sources were created on a common genome reference build.; I want to use deepvariant only on ucsc_hg19's chr20. So I execute:. ```. docker run \. -v ""${PWD}"":""/input"" \. -v ""${PWD}/vg_deepvariant"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc_hg19.fa.gz \. --reads=/output/chr20_aln.sort.bam \. --regions ""chr20"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir. ```. My bam file is from vg, and I want to use deepvariant to call variant. I check the header of bam and reference, they are matching. The more detail error information:. `ValueError: Reference contigs span 3137161264 bases but only 63025520 bases (2.01%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrM"" is 16571 bp and IS MISSING, . ""chr1"" is 249250621 bp and IS MISSING, . ""chr2"" is 243199373 bp and IS MISSING, . ""chr3"" is 198022430 bp and IS MISSING, . ""chr4"" is 191154276 bp and IS MISSING, . ""chr5"" is 180915260 bp and IS MISSING, . ""chr6"" is 171115067 bp and IS MISSING, . ""chr7"" is 159138663 bp and IS MISSING, . ""chr8"" is 146364022 bp and IS MISSING, . ""chr9"" is 141213431 bp and IS MISSING, . ""chr10"" is 135534747 bp and IS MISSING, . ""chr11"" is 135006516 bp and IS MISSING, . ""chr12"" is 133851895 bp and IS MISSING, . ""chr13"" is 115169878 bp and IS MISSING, . ""chr14"" is 107349540 bp and IS MISSING, . ""chr15"" is 102531392 bp and IS MISSING, . ""chr16"" is 90354753 bp and IS MISSING, . ""chr17"" is 81195210 bp and IS MISSING, . ""chr18"" is 78077248 bp and IS MISSING, . ""chr19"" is 59128983 bp and IS MISSING, . ""chr20"" is 63025520 bp and matched, . ""chr21"" is 48129895 bp and IS MISSING, . ""chr22"" is 51304566 b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/851
https://github.com/google/deepvariant/issues/851:834,safety,error,error,834,"ValueError: Reference contigs span 3137161264 bases but only 63025520 bases (2.01%) were found in common among our input files. Check that the sources were created on a common genome reference build.; I want to use deepvariant only on ucsc_hg19's chr20. So I execute:. ```. docker run \. -v ""${PWD}"":""/input"" \. -v ""${PWD}/vg_deepvariant"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc_hg19.fa.gz \. --reads=/output/chr20_aln.sort.bam \. --regions ""chr20"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir. ```. My bam file is from vg, and I want to use deepvariant to call variant. I check the header of bam and reference, they are matching. The more detail error information:. `ValueError: Reference contigs span 3137161264 bases but only 63025520 bases (2.01%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrM"" is 16571 bp and IS MISSING, . ""chr1"" is 249250621 bp and IS MISSING, . ""chr2"" is 243199373 bp and IS MISSING, . ""chr3"" is 198022430 bp and IS MISSING, . ""chr4"" is 191154276 bp and IS MISSING, . ""chr5"" is 180915260 bp and IS MISSING, . ""chr6"" is 171115067 bp and IS MISSING, . ""chr7"" is 159138663 bp and IS MISSING, . ""chr8"" is 146364022 bp and IS MISSING, . ""chr9"" is 141213431 bp and IS MISSING, . ""chr10"" is 135534747 bp and IS MISSING, . ""chr11"" is 135006516 bp and IS MISSING, . ""chr12"" is 133851895 bp and IS MISSING, . ""chr13"" is 115169878 bp and IS MISSING, . ""chr14"" is 107349540 bp and IS MISSING, . ""chr15"" is 102531392 bp and IS MISSING, . ""chr16"" is 90354753 bp and IS MISSING, . ""chr17"" is 81195210 bp and IS MISSING, . ""chr18"" is 78077248 bp and IS MISSING, . ""chr19"" is 59128983 bp and IS MISSING, . ""chr20"" is 63025520 bp and matched, . ""chr21"" is 48129895 bp and IS MISSING, . ""chr22"" is 51304566 b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/851
https://github.com/google/deepvariant/issues/851:970,safety,input,input,970,"ValueError: Reference contigs span 3137161264 bases but only 63025520 bases (2.01%) were found in common among our input files. Check that the sources were created on a common genome reference build.; I want to use deepvariant only on ucsc_hg19's chr20. So I execute:. ```. docker run \. -v ""${PWD}"":""/input"" \. -v ""${PWD}/vg_deepvariant"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc_hg19.fa.gz \. --reads=/output/chr20_aln.sort.bam \. --regions ""chr20"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir. ```. My bam file is from vg, and I want to use deepvariant to call variant. I check the header of bam and reference, they are matching. The more detail error information:. `ValueError: Reference contigs span 3137161264 bases but only 63025520 bases (2.01%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrM"" is 16571 bp and IS MISSING, . ""chr1"" is 249250621 bp and IS MISSING, . ""chr2"" is 243199373 bp and IS MISSING, . ""chr3"" is 198022430 bp and IS MISSING, . ""chr4"" is 191154276 bp and IS MISSING, . ""chr5"" is 180915260 bp and IS MISSING, . ""chr6"" is 171115067 bp and IS MISSING, . ""chr7"" is 159138663 bp and IS MISSING, . ""chr8"" is 146364022 bp and IS MISSING, . ""chr9"" is 141213431 bp and IS MISSING, . ""chr10"" is 135534747 bp and IS MISSING, . ""chr11"" is 135006516 bp and IS MISSING, . ""chr12"" is 133851895 bp and IS MISSING, . ""chr13"" is 115169878 bp and IS MISSING, . ""chr14"" is 107349540 bp and IS MISSING, . ""chr15"" is 102531392 bp and IS MISSING, . ""chr16"" is 90354753 bp and IS MISSING, . ""chr17"" is 81195210 bp and IS MISSING, . ""chr18"" is 78077248 bp and IS MISSING, . ""chr19"" is 59128983 bp and IS MISSING, . ""chr20"" is 63025520 bp and matched, . ""chr21"" is 48129895 bp and IS MISSING, . ""chr22"" is 51304566 b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/851
https://github.com/google/deepvariant/issues/851:115,usability,input,input,115,"ValueError: Reference contigs span 3137161264 bases but only 63025520 bases (2.01%) were found in common among our input files. Check that the sources were created on a common genome reference build.; I want to use deepvariant only on ucsc_hg19's chr20. So I execute:. ```. docker run \. -v ""${PWD}"":""/input"" \. -v ""${PWD}/vg_deepvariant"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc_hg19.fa.gz \. --reads=/output/chr20_aln.sort.bam \. --regions ""chr20"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir. ```. My bam file is from vg, and I want to use deepvariant to call variant. I check the header of bam and reference, they are matching. The more detail error information:. `ValueError: Reference contigs span 3137161264 bases but only 63025520 bases (2.01%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrM"" is 16571 bp and IS MISSING, . ""chr1"" is 249250621 bp and IS MISSING, . ""chr2"" is 243199373 bp and IS MISSING, . ""chr3"" is 198022430 bp and IS MISSING, . ""chr4"" is 191154276 bp and IS MISSING, . ""chr5"" is 180915260 bp and IS MISSING, . ""chr6"" is 171115067 bp and IS MISSING, . ""chr7"" is 159138663 bp and IS MISSING, . ""chr8"" is 146364022 bp and IS MISSING, . ""chr9"" is 141213431 bp and IS MISSING, . ""chr10"" is 135534747 bp and IS MISSING, . ""chr11"" is 135006516 bp and IS MISSING, . ""chr12"" is 133851895 bp and IS MISSING, . ""chr13"" is 115169878 bp and IS MISSING, . ""chr14"" is 107349540 bp and IS MISSING, . ""chr15"" is 102531392 bp and IS MISSING, . ""chr16"" is 90354753 bp and IS MISSING, . ""chr17"" is 81195210 bp and IS MISSING, . ""chr18"" is 78077248 bp and IS MISSING, . ""chr19"" is 59128983 bp and IS MISSING, . ""chr20"" is 63025520 bp and matched, . ""chr21"" is 48129895 bp and IS MISSING, . ""chr22"" is 51304566 b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/851
https://github.com/google/deepvariant/issues/851:302,usability,input,input,302,"ValueError: Reference contigs span 3137161264 bases but only 63025520 bases (2.01%) were found in common among our input files. Check that the sources were created on a common genome reference build.; I want to use deepvariant only on ucsc_hg19's chr20. So I execute:. ```. docker run \. -v ""${PWD}"":""/input"" \. -v ""${PWD}/vg_deepvariant"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc_hg19.fa.gz \. --reads=/output/chr20_aln.sort.bam \. --regions ""chr20"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir. ```. My bam file is from vg, and I want to use deepvariant to call variant. I check the header of bam and reference, they are matching. The more detail error information:. `ValueError: Reference contigs span 3137161264 bases but only 63025520 bases (2.01%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrM"" is 16571 bp and IS MISSING, . ""chr1"" is 249250621 bp and IS MISSING, . ""chr2"" is 243199373 bp and IS MISSING, . ""chr3"" is 198022430 bp and IS MISSING, . ""chr4"" is 191154276 bp and IS MISSING, . ""chr5"" is 180915260 bp and IS MISSING, . ""chr6"" is 171115067 bp and IS MISSING, . ""chr7"" is 159138663 bp and IS MISSING, . ""chr8"" is 146364022 bp and IS MISSING, . ""chr9"" is 141213431 bp and IS MISSING, . ""chr10"" is 135534747 bp and IS MISSING, . ""chr11"" is 135006516 bp and IS MISSING, . ""chr12"" is 133851895 bp and IS MISSING, . ""chr13"" is 115169878 bp and IS MISSING, . ""chr14"" is 107349540 bp and IS MISSING, . ""chr15"" is 102531392 bp and IS MISSING, . ""chr16"" is 90354753 bp and IS MISSING, . ""chr17"" is 81195210 bp and IS MISSING, . ""chr18"" is 78077248 bp and IS MISSING, . ""chr19"" is 59128983 bp and IS MISSING, . ""chr20"" is 63025520 bp and matched, . ""chr21"" is 48129895 bp and IS MISSING, . ""chr22"" is 51304566 b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/851
https://github.com/google/deepvariant/issues/851:458,usability,input,input,458,"ValueError: Reference contigs span 3137161264 bases but only 63025520 bases (2.01%) were found in common among our input files. Check that the sources were created on a common genome reference build.; I want to use deepvariant only on ucsc_hg19's chr20. So I execute:. ```. docker run \. -v ""${PWD}"":""/input"" \. -v ""${PWD}/vg_deepvariant"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc_hg19.fa.gz \. --reads=/output/chr20_aln.sort.bam \. --regions ""chr20"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir. ```. My bam file is from vg, and I want to use deepvariant to call variant. I check the header of bam and reference, they are matching. The more detail error information:. `ValueError: Reference contigs span 3137161264 bases but only 63025520 bases (2.01%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrM"" is 16571 bp and IS MISSING, . ""chr1"" is 249250621 bp and IS MISSING, . ""chr2"" is 243199373 bp and IS MISSING, . ""chr3"" is 198022430 bp and IS MISSING, . ""chr4"" is 191154276 bp and IS MISSING, . ""chr5"" is 180915260 bp and IS MISSING, . ""chr6"" is 171115067 bp and IS MISSING, . ""chr7"" is 159138663 bp and IS MISSING, . ""chr8"" is 146364022 bp and IS MISSING, . ""chr9"" is 141213431 bp and IS MISSING, . ""chr10"" is 135534747 bp and IS MISSING, . ""chr11"" is 135006516 bp and IS MISSING, . ""chr12"" is 133851895 bp and IS MISSING, . ""chr13"" is 115169878 bp and IS MISSING, . ""chr14"" is 107349540 bp and IS MISSING, . ""chr15"" is 102531392 bp and IS MISSING, . ""chr16"" is 90354753 bp and IS MISSING, . ""chr17"" is 81195210 bp and IS MISSING, . ""chr18"" is 78077248 bp and IS MISSING, . ""chr19"" is 59128983 bp and IS MISSING, . ""chr20"" is 63025520 bp and matched, . ""chr21"" is 48129895 bp and IS MISSING, . ""chr22"" is 51304566 b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/851
https://github.com/google/deepvariant/issues/851:834,usability,error,error,834,"ValueError: Reference contigs span 3137161264 bases but only 63025520 bases (2.01%) were found in common among our input files. Check that the sources were created on a common genome reference build.; I want to use deepvariant only on ucsc_hg19's chr20. So I execute:. ```. docker run \. -v ""${PWD}"":""/input"" \. -v ""${PWD}/vg_deepvariant"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc_hg19.fa.gz \. --reads=/output/chr20_aln.sort.bam \. --regions ""chr20"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir. ```. My bam file is from vg, and I want to use deepvariant to call variant. I check the header of bam and reference, they are matching. The more detail error information:. `ValueError: Reference contigs span 3137161264 bases but only 63025520 bases (2.01%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrM"" is 16571 bp and IS MISSING, . ""chr1"" is 249250621 bp and IS MISSING, . ""chr2"" is 243199373 bp and IS MISSING, . ""chr3"" is 198022430 bp and IS MISSING, . ""chr4"" is 191154276 bp and IS MISSING, . ""chr5"" is 180915260 bp and IS MISSING, . ""chr6"" is 171115067 bp and IS MISSING, . ""chr7"" is 159138663 bp and IS MISSING, . ""chr8"" is 146364022 bp and IS MISSING, . ""chr9"" is 141213431 bp and IS MISSING, . ""chr10"" is 135534747 bp and IS MISSING, . ""chr11"" is 135006516 bp and IS MISSING, . ""chr12"" is 133851895 bp and IS MISSING, . ""chr13"" is 115169878 bp and IS MISSING, . ""chr14"" is 107349540 bp and IS MISSING, . ""chr15"" is 102531392 bp and IS MISSING, . ""chr16"" is 90354753 bp and IS MISSING, . ""chr17"" is 81195210 bp and IS MISSING, . ""chr18"" is 78077248 bp and IS MISSING, . ""chr19"" is 59128983 bp and IS MISSING, . ""chr20"" is 63025520 bp and matched, . ""chr21"" is 48129895 bp and IS MISSING, . ""chr22"" is 51304566 b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/851
https://github.com/google/deepvariant/issues/851:970,usability,input,input,970,"ValueError: Reference contigs span 3137161264 bases but only 63025520 bases (2.01%) were found in common among our input files. Check that the sources were created on a common genome reference build.; I want to use deepvariant only on ucsc_hg19's chr20. So I execute:. ```. docker run \. -v ""${PWD}"":""/input"" \. -v ""${PWD}/vg_deepvariant"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc_hg19.fa.gz \. --reads=/output/chr20_aln.sort.bam \. --regions ""chr20"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir. ```. My bam file is from vg, and I want to use deepvariant to call variant. I check the header of bam and reference, they are matching. The more detail error information:. `ValueError: Reference contigs span 3137161264 bases but only 63025520 bases (2.01%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: . ""chrM"" is 16571 bp and IS MISSING, . ""chr1"" is 249250621 bp and IS MISSING, . ""chr2"" is 243199373 bp and IS MISSING, . ""chr3"" is 198022430 bp and IS MISSING, . ""chr4"" is 191154276 bp and IS MISSING, . ""chr5"" is 180915260 bp and IS MISSING, . ""chr6"" is 171115067 bp and IS MISSING, . ""chr7"" is 159138663 bp and IS MISSING, . ""chr8"" is 146364022 bp and IS MISSING, . ""chr9"" is 141213431 bp and IS MISSING, . ""chr10"" is 135534747 bp and IS MISSING, . ""chr11"" is 135006516 bp and IS MISSING, . ""chr12"" is 133851895 bp and IS MISSING, . ""chr13"" is 115169878 bp and IS MISSING, . ""chr14"" is 107349540 bp and IS MISSING, . ""chr15"" is 102531392 bp and IS MISSING, . ""chr16"" is 90354753 bp and IS MISSING, . ""chr17"" is 81195210 bp and IS MISSING, . ""chr18"" is 78077248 bp and IS MISSING, . ""chr19"" is 59128983 bp and IS MISSING, . ""chr20"" is 63025520 bp and matched, . ""chr21"" is 48129895 bp and IS MISSING, . ""chr22"" is 51304566 b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/851
https://github.com/google/deepvariant/issues/852:37,availability,down,download,37,"I read DeepVariant essay and want to download some data.; Hello, I read you essay ""A universal sNP and small-indel variant caller using deep neural networks"" in nature biotechnology. It's so good. I want to download the Platinum Genomes Project NA12878 data. I check it in the supplementary information. In supplementary note 11, there is a link[https://cloud.google.com/genomics/data/platinum-genomes.]( NA12878 Platinum Genomes BAM file). However, it's missing. So I want to ask if there is a new web that I can download it. Thank you!!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/852
https://github.com/google/deepvariant/issues/852:207,availability,down,download,207,"I read DeepVariant essay and want to download some data.; Hello, I read you essay ""A universal sNP and small-indel variant caller using deep neural networks"" in nature biotechnology. It's so good. I want to download the Platinum Genomes Project NA12878 data. I check it in the supplementary information. In supplementary note 11, there is a link[https://cloud.google.com/genomics/data/platinum-genomes.]( NA12878 Platinum Genomes BAM file). However, it's missing. So I want to ask if there is a new web that I can download it. Thank you!!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/852
https://github.com/google/deepvariant/issues/852:514,availability,down,download,514,"I read DeepVariant essay and want to download some data.; Hello, I read you essay ""A universal sNP and small-indel variant caller using deep neural networks"" in nature biotechnology. It's so good. I want to download the Platinum Genomes Project NA12878 data. I check it in the supplementary information. In supplementary note 11, there is a link[https://cloud.google.com/genomics/data/platinum-genomes.]( NA12878 Platinum Genomes BAM file). However, it's missing. So I want to ask if there is a new web that I can download it. Thank you!!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/852
https://github.com/google/deepvariant/issues/852:354,energy efficiency,cloud,cloud,354,"I read DeepVariant essay and want to download some data.; Hello, I read you essay ""A universal sNP and small-indel variant caller using deep neural networks"" in nature biotechnology. It's so good. I want to download the Platinum Genomes Project NA12878 data. I check it in the supplementary information. In supplementary note 11, there is a link[https://cloud.google.com/genomics/data/platinum-genomes.]( NA12878 Platinum Genomes BAM file). However, it's missing. So I want to ask if there is a new web that I can download it. Thank you!!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/852
https://github.com/google/deepvariant/issues/852:148,performance,network,networks,148,"I read DeepVariant essay and want to download some data.; Hello, I read you essay ""A universal sNP and small-indel variant caller using deep neural networks"" in nature biotechnology. It's so good. I want to download the Platinum Genomes Project NA12878 data. I check it in the supplementary information. In supplementary note 11, there is a link[https://cloud.google.com/genomics/data/platinum-genomes.]( NA12878 Platinum Genomes BAM file). However, it's missing. So I want to ask if there is a new web that I can download it. Thank you!!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/852
https://github.com/google/deepvariant/issues/852:148,security,network,networks,148,"I read DeepVariant essay and want to download some data.; Hello, I read you essay ""A universal sNP and small-indel variant caller using deep neural networks"" in nature biotechnology. It's so good. I want to download the Platinum Genomes Project NA12878 data. I check it in the supplementary information. In supplementary note 11, there is a link[https://cloud.google.com/genomics/data/platinum-genomes.]( NA12878 Platinum Genomes BAM file). However, it's missing. So I want to ask if there is a new web that I can download it. Thank you!!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/852
https://github.com/google/deepvariant/issues/853:0,availability,Error,Error,0,"Error while running tests on Calling variants in non-autosomal contigs; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am having some errors while fetching variants from chrX, Could you please have a look I added a error.txt file for reference. . Thank you. > INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chrX"" start: 14000 end: 15000. **Setup**. - Operating system:linux. - DeepVariant version:latest. - Installation method (Docker, built from source, etc.):udocker. - Type of data: test file for checking Calling variants in non-autosomal contigs [this](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-xy-calling-case-study.md). **Steps to reproduce:**. - Command:. BIN_VERSION=""1.6.1"". ```. REF=""GRCh38_no_alt_analysis_set.fasta"". BAM=""HG002.pfda_challenge.grch38.chrXY.bam"". THREADS=$(nproc). REGION=""chrX chrY"". HAPLOID_CONTIGS=""chrX,chrY"". PAR_BED=""GRCh38_PAR.bed"". udocker run \. -v ""${INPUT_DIR}"":""${INPUT_DIR}"" \. -v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ""${INPUT_DIR}/${REF}"" \. --reads ""${INPUT_DIR}/${BAM}"" \. --output_vcf ""${OUTPUT_DIR}/${OUTPUT_VCF}"" \. --output_gvcf ""${OUTPUT_DIR}/${OUTPUT_GVCF}"" \. --num_shards ""${THREADS}"" \. --haploid_contigs ""${HAPLOID_CONTIGS}"" \. --par_regions_bed ""${INPUT_DIR}/${PAR_BED}"" \. --regions ""${REGION}"" \. --intermediate_results_dir ""${OUTPUT_DIR}/${INTERMEDIATE_DIRECTORY}"" . ```. - Error trace: . . [error.txt](https://github.com/user-attachments/files/16281125/error.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:208,availability,error,errors,208,"Error while running tests on Calling variants in non-autosomal contigs; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am having some errors while fetching variants from chrX, Could you please have a look I added a error.txt file for reference. . Thank you. > INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chrX"" start: 14000 end: 15000. **Setup**. - Operating system:linux. - DeepVariant version:latest. - Installation method (Docker, built from source, etc.):udocker. - Type of data: test file for checking Calling variants in non-autosomal contigs [this](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-xy-calling-case-study.md). **Steps to reproduce:**. - Command:. BIN_VERSION=""1.6.1"". ```. REF=""GRCh38_no_alt_analysis_set.fasta"". BAM=""HG002.pfda_challenge.grch38.chrXY.bam"". THREADS=$(nproc). REGION=""chrX chrY"". HAPLOID_CONTIGS=""chrX,chrY"". PAR_BED=""GRCh38_PAR.bed"". udocker run \. -v ""${INPUT_DIR}"":""${INPUT_DIR}"" \. -v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ""${INPUT_DIR}/${REF}"" \. --reads ""${INPUT_DIR}/${BAM}"" \. --output_vcf ""${OUTPUT_DIR}/${OUTPUT_VCF}"" \. --output_gvcf ""${OUTPUT_DIR}/${OUTPUT_GVCF}"" \. --num_shards ""${THREADS}"" \. --haploid_contigs ""${HAPLOID_CONTIGS}"" \. --par_regions_bed ""${INPUT_DIR}/${PAR_BED}"" \. --regions ""${REGION}"" \. --intermediate_results_dir ""${OUTPUT_DIR}/${INTERMEDIATE_DIRECTORY}"" . ```. - Error trace: . . [error.txt](https://github.com/user-attachments/files/16281125/error.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:289,availability,error,error,289,"Error while running tests on Calling variants in non-autosomal contigs; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am having some errors while fetching variants from chrX, Could you please have a look I added a error.txt file for reference. . Thank you. > INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chrX"" start: 14000 end: 15000. **Setup**. - Operating system:linux. - DeepVariant version:latest. - Installation method (Docker, built from source, etc.):udocker. - Type of data: test file for checking Calling variants in non-autosomal contigs [this](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-xy-calling-case-study.md). **Steps to reproduce:**. - Command:. BIN_VERSION=""1.6.1"". ```. REF=""GRCh38_no_alt_analysis_set.fasta"". BAM=""HG002.pfda_challenge.grch38.chrXY.bam"". THREADS=$(nproc). REGION=""chrX chrY"". HAPLOID_CONTIGS=""chrX,chrY"". PAR_BED=""GRCh38_PAR.bed"". udocker run \. -v ""${INPUT_DIR}"":""${INPUT_DIR}"" \. -v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ""${INPUT_DIR}/${REF}"" \. --reads ""${INPUT_DIR}/${BAM}"" \. --output_vcf ""${OUTPUT_DIR}/${OUTPUT_VCF}"" \. --output_gvcf ""${OUTPUT_DIR}/${OUTPUT_GVCF}"" \. --num_shards ""${THREADS}"" \. --haploid_contigs ""${HAPLOID_CONTIGS}"" \. --par_regions_bed ""${INPUT_DIR}/${PAR_BED}"" \. --regions ""${REGION}"" \. --intermediate_results_dir ""${OUTPUT_DIR}/${INTERMEDIATE_DIRECTORY}"" . ```. - Error trace: . . [error.txt](https://github.com/user-attachments/files/16281125/error.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:438,availability,Operat,Operating,438,"Error while running tests on Calling variants in non-autosomal contigs; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am having some errors while fetching variants from chrX, Could you please have a look I added a error.txt file for reference. . Thank you. > INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chrX"" start: 14000 end: 15000. **Setup**. - Operating system:linux. - DeepVariant version:latest. - Installation method (Docker, built from source, etc.):udocker. - Type of data: test file for checking Calling variants in non-autosomal contigs [this](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-xy-calling-case-study.md). **Steps to reproduce:**. - Command:. BIN_VERSION=""1.6.1"". ```. REF=""GRCh38_no_alt_analysis_set.fasta"". BAM=""HG002.pfda_challenge.grch38.chrXY.bam"". THREADS=$(nproc). REGION=""chrX chrY"". HAPLOID_CONTIGS=""chrX,chrY"". PAR_BED=""GRCh38_PAR.bed"". udocker run \. -v ""${INPUT_DIR}"":""${INPUT_DIR}"" \. -v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ""${INPUT_DIR}/${REF}"" \. --reads ""${INPUT_DIR}/${BAM}"" \. --output_vcf ""${OUTPUT_DIR}/${OUTPUT_VCF}"" \. --output_gvcf ""${OUTPUT_DIR}/${OUTPUT_GVCF}"" \. --num_shards ""${THREADS}"" \. --haploid_contigs ""${HAPLOID_CONTIGS}"" \. --par_regions_bed ""${INPUT_DIR}/${PAR_BED}"" \. --regions ""${REGION}"" \. --intermediate_results_dir ""${OUTPUT_DIR}/${INTERMEDIATE_DIRECTORY}"" . ```. - Error trace: . . [error.txt](https://github.com/user-attachments/files/16281125/error.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:1550,availability,Error,Error,1550,"Error while running tests on Calling variants in non-autosomal contigs; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am having some errors while fetching variants from chrX, Could you please have a look I added a error.txt file for reference. . Thank you. > INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chrX"" start: 14000 end: 15000. **Setup**. - Operating system:linux. - DeepVariant version:latest. - Installation method (Docker, built from source, etc.):udocker. - Type of data: test file for checking Calling variants in non-autosomal contigs [this](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-xy-calling-case-study.md). **Steps to reproduce:**. - Command:. BIN_VERSION=""1.6.1"". ```. REF=""GRCh38_no_alt_analysis_set.fasta"". BAM=""HG002.pfda_challenge.grch38.chrXY.bam"". THREADS=$(nproc). REGION=""chrX chrY"". HAPLOID_CONTIGS=""chrX,chrY"". PAR_BED=""GRCh38_PAR.bed"". udocker run \. -v ""${INPUT_DIR}"":""${INPUT_DIR}"" \. -v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ""${INPUT_DIR}/${REF}"" \. --reads ""${INPUT_DIR}/${BAM}"" \. --output_vcf ""${OUTPUT_DIR}/${OUTPUT_VCF}"" \. --output_gvcf ""${OUTPUT_DIR}/${OUTPUT_GVCF}"" \. --num_shards ""${THREADS}"" \. --haploid_contigs ""${HAPLOID_CONTIGS}"" \. --par_regions_bed ""${INPUT_DIR}/${PAR_BED}"" \. --regions ""${REGION}"" \. --intermediate_results_dir ""${OUTPUT_DIR}/${INTERMEDIATE_DIRECTORY}"" . ```. - Error trace: . . [error.txt](https://github.com/user-attachments/files/16281125/error.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:1568,availability,error,error,1568,"Error while running tests on Calling variants in non-autosomal contigs; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am having some errors while fetching variants from chrX, Could you please have a look I added a error.txt file for reference. . Thank you. > INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chrX"" start: 14000 end: 15000. **Setup**. - Operating system:linux. - DeepVariant version:latest. - Installation method (Docker, built from source, etc.):udocker. - Type of data: test file for checking Calling variants in non-autosomal contigs [this](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-xy-calling-case-study.md). **Steps to reproduce:**. - Command:. BIN_VERSION=""1.6.1"". ```. REF=""GRCh38_no_alt_analysis_set.fasta"". BAM=""HG002.pfda_challenge.grch38.chrXY.bam"". THREADS=$(nproc). REGION=""chrX chrY"". HAPLOID_CONTIGS=""chrX,chrY"". PAR_BED=""GRCh38_PAR.bed"". udocker run \. -v ""${INPUT_DIR}"":""${INPUT_DIR}"" \. -v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ""${INPUT_DIR}/${REF}"" \. --reads ""${INPUT_DIR}/${BAM}"" \. --output_vcf ""${OUTPUT_DIR}/${OUTPUT_VCF}"" \. --output_gvcf ""${OUTPUT_DIR}/${OUTPUT_GVCF}"" \. --num_shards ""${THREADS}"" \. --haploid_contigs ""${HAPLOID_CONTIGS}"" \. --par_regions_bed ""${INPUT_DIR}/${PAR_BED}"" \. --regions ""${REGION}"" \. --intermediate_results_dir ""${OUTPUT_DIR}/${INTERMEDIATE_DIRECTORY}"" . ```. - Error trace: . . [error.txt](https://github.com/user-attachments/files/16281125/error.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:1630,availability,error,error,1630,"Error while running tests on Calling variants in non-autosomal contigs; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am having some errors while fetching variants from chrX, Could you please have a look I added a error.txt file for reference. . Thank you. > INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chrX"" start: 14000 end: 15000. **Setup**. - Operating system:linux. - DeepVariant version:latest. - Installation method (Docker, built from source, etc.):udocker. - Type of data: test file for checking Calling variants in non-autosomal contigs [this](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-xy-calling-case-study.md). **Steps to reproduce:**. - Command:. BIN_VERSION=""1.6.1"". ```. REF=""GRCh38_no_alt_analysis_set.fasta"". BAM=""HG002.pfda_challenge.grch38.chrXY.bam"". THREADS=$(nproc). REGION=""chrX chrY"". HAPLOID_CONTIGS=""chrX,chrY"". PAR_BED=""GRCh38_PAR.bed"". udocker run \. -v ""${INPUT_DIR}"":""${INPUT_DIR}"" \. -v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ""${INPUT_DIR}/${REF}"" \. --reads ""${INPUT_DIR}/${BAM}"" \. --output_vcf ""${OUTPUT_DIR}/${OUTPUT_VCF}"" \. --output_gvcf ""${OUTPUT_DIR}/${OUTPUT_GVCF}"" \. --num_shards ""${THREADS}"" \. --haploid_contigs ""${HAPLOID_CONTIGS}"" \. --par_regions_bed ""${INPUT_DIR}/${PAR_BED}"" \. --regions ""${REGION}"" \. --intermediate_results_dir ""${OUTPUT_DIR}/${INTERMEDIATE_DIRECTORY}"" . ```. - Error trace: . . [error.txt](https://github.com/user-attachments/files/16281125/error.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:476,deployability,version,version,476,"Error while running tests on Calling variants in non-autosomal contigs; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am having some errors while fetching variants from chrX, Could you please have a look I added a error.txt file for reference. . Thank you. > INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chrX"" start: 14000 end: 15000. **Setup**. - Operating system:linux. - DeepVariant version:latest. - Installation method (Docker, built from source, etc.):udocker. - Type of data: test file for checking Calling variants in non-autosomal contigs [this](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-xy-calling-case-study.md). **Steps to reproduce:**. - Command:. BIN_VERSION=""1.6.1"". ```. REF=""GRCh38_no_alt_analysis_set.fasta"". BAM=""HG002.pfda_challenge.grch38.chrXY.bam"". THREADS=$(nproc). REGION=""chrX chrY"". HAPLOID_CONTIGS=""chrX,chrY"". PAR_BED=""GRCh38_PAR.bed"". udocker run \. -v ""${INPUT_DIR}"":""${INPUT_DIR}"" \. -v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ""${INPUT_DIR}/${REF}"" \. --reads ""${INPUT_DIR}/${BAM}"" \. --output_vcf ""${OUTPUT_DIR}/${OUTPUT_VCF}"" \. --output_gvcf ""${OUTPUT_DIR}/${OUTPUT_GVCF}"" \. --num_shards ""${THREADS}"" \. --haploid_contigs ""${HAPLOID_CONTIGS}"" \. --par_regions_bed ""${INPUT_DIR}/${PAR_BED}"" \. --regions ""${REGION}"" \. --intermediate_results_dir ""${OUTPUT_DIR}/${INTERMEDIATE_DIRECTORY}"" . ```. - Error trace: . . [error.txt](https://github.com/user-attachments/files/16281125/error.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:494,deployability,Instal,Installation,494,"Error while running tests on Calling variants in non-autosomal contigs; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am having some errors while fetching variants from chrX, Could you please have a look I added a error.txt file for reference. . Thank you. > INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chrX"" start: 14000 end: 15000. **Setup**. - Operating system:linux. - DeepVariant version:latest. - Installation method (Docker, built from source, etc.):udocker. - Type of data: test file for checking Calling variants in non-autosomal contigs [this](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-xy-calling-case-study.md). **Steps to reproduce:**. - Command:. BIN_VERSION=""1.6.1"". ```. REF=""GRCh38_no_alt_analysis_set.fasta"". BAM=""HG002.pfda_challenge.grch38.chrXY.bam"". THREADS=$(nproc). REGION=""chrX chrY"". HAPLOID_CONTIGS=""chrX,chrY"". PAR_BED=""GRCh38_PAR.bed"". udocker run \. -v ""${INPUT_DIR}"":""${INPUT_DIR}"" \. -v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ""${INPUT_DIR}/${REF}"" \. --reads ""${INPUT_DIR}/${BAM}"" \. --output_vcf ""${OUTPUT_DIR}/${OUTPUT_VCF}"" \. --output_gvcf ""${OUTPUT_DIR}/${OUTPUT_GVCF}"" \. --num_shards ""${THREADS}"" \. --haploid_contigs ""${HAPLOID_CONTIGS}"" \. --par_regions_bed ""${INPUT_DIR}/${PAR_BED}"" \. --regions ""${REGION}"" \. --intermediate_results_dir ""${OUTPUT_DIR}/${INTERMEDIATE_DIRECTORY}"" . ```. - Error trace: . . [error.txt](https://github.com/user-attachments/files/16281125/error.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:476,integrability,version,version,476,"Error while running tests on Calling variants in non-autosomal contigs; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am having some errors while fetching variants from chrX, Could you please have a look I added a error.txt file for reference. . Thank you. > INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chrX"" start: 14000 end: 15000. **Setup**. - Operating system:linux. - DeepVariant version:latest. - Installation method (Docker, built from source, etc.):udocker. - Type of data: test file for checking Calling variants in non-autosomal contigs [this](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-xy-calling-case-study.md). **Steps to reproduce:**. - Command:. BIN_VERSION=""1.6.1"". ```. REF=""GRCh38_no_alt_analysis_set.fasta"". BAM=""HG002.pfda_challenge.grch38.chrXY.bam"". THREADS=$(nproc). REGION=""chrX chrY"". HAPLOID_CONTIGS=""chrX,chrY"". PAR_BED=""GRCh38_PAR.bed"". udocker run \. -v ""${INPUT_DIR}"":""${INPUT_DIR}"" \. -v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ""${INPUT_DIR}/${REF}"" \. --reads ""${INPUT_DIR}/${BAM}"" \. --output_vcf ""${OUTPUT_DIR}/${OUTPUT_VCF}"" \. --output_gvcf ""${OUTPUT_DIR}/${OUTPUT_GVCF}"" \. --num_shards ""${THREADS}"" \. --haploid_contigs ""${HAPLOID_CONTIGS}"" \. --par_regions_bed ""${INPUT_DIR}/${PAR_BED}"" \. --regions ""${REGION}"" \. --intermediate_results_dir ""${OUTPUT_DIR}/${INTERMEDIATE_DIRECTORY}"" . ```. - Error trace: . . [error.txt](https://github.com/user-attachments/files/16281125/error.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:476,modifiability,version,version,476,"Error while running tests on Calling variants in non-autosomal contigs; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am having some errors while fetching variants from chrX, Could you please have a look I added a error.txt file for reference. . Thank you. > INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chrX"" start: 14000 end: 15000. **Setup**. - Operating system:linux. - DeepVariant version:latest. - Installation method (Docker, built from source, etc.):udocker. - Type of data: test file for checking Calling variants in non-autosomal contigs [this](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-xy-calling-case-study.md). **Steps to reproduce:**. - Command:. BIN_VERSION=""1.6.1"". ```. REF=""GRCh38_no_alt_analysis_set.fasta"". BAM=""HG002.pfda_challenge.grch38.chrXY.bam"". THREADS=$(nproc). REGION=""chrX chrY"". HAPLOID_CONTIGS=""chrX,chrY"". PAR_BED=""GRCh38_PAR.bed"". udocker run \. -v ""${INPUT_DIR}"":""${INPUT_DIR}"" \. -v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ""${INPUT_DIR}/${REF}"" \. --reads ""${INPUT_DIR}/${BAM}"" \. --output_vcf ""${OUTPUT_DIR}/${OUTPUT_VCF}"" \. --output_gvcf ""${OUTPUT_DIR}/${OUTPUT_GVCF}"" \. --num_shards ""${THREADS}"" \. --haploid_contigs ""${HAPLOID_CONTIGS}"" \. --par_regions_bed ""${INPUT_DIR}/${PAR_BED}"" \. --regions ""${REGION}"" \. --intermediate_results_dir ""${OUTPUT_DIR}/${INTERMEDIATE_DIRECTORY}"" . ```. - Error trace: . . [error.txt](https://github.com/user-attachments/files/16281125/error.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:1161,modifiability,PAC,PACBIO,1161,"Error while running tests on Calling variants in non-autosomal contigs; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am having some errors while fetching variants from chrX, Could you please have a look I added a error.txt file for reference. . Thank you. > INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chrX"" start: 14000 end: 15000. **Setup**. - Operating system:linux. - DeepVariant version:latest. - Installation method (Docker, built from source, etc.):udocker. - Type of data: test file for checking Calling variants in non-autosomal contigs [this](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-xy-calling-case-study.md). **Steps to reproduce:**. - Command:. BIN_VERSION=""1.6.1"". ```. REF=""GRCh38_no_alt_analysis_set.fasta"". BAM=""HG002.pfda_challenge.grch38.chrXY.bam"". THREADS=$(nproc). REGION=""chrX chrY"". HAPLOID_CONTIGS=""chrX,chrY"". PAR_BED=""GRCh38_PAR.bed"". udocker run \. -v ""${INPUT_DIR}"":""${INPUT_DIR}"" \. -v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ""${INPUT_DIR}/${REF}"" \. --reads ""${INPUT_DIR}/${BAM}"" \. --output_vcf ""${OUTPUT_DIR}/${OUTPUT_VCF}"" \. --output_gvcf ""${OUTPUT_DIR}/${OUTPUT_GVCF}"" \. --num_shards ""${THREADS}"" \. --haploid_contigs ""${HAPLOID_CONTIGS}"" \. --par_regions_bed ""${INPUT_DIR}/${PAR_BED}"" \. --regions ""${REGION}"" \. --intermediate_results_dir ""${OUTPUT_DIR}/${INTERMEDIATE_DIRECTORY}"" . ```. - Error trace: . . [error.txt](https://github.com/user-attachments/files/16281125/error.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:0,performance,Error,Error,0,"Error while running tests on Calling variants in non-autosomal contigs; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am having some errors while fetching variants from chrX, Could you please have a look I added a error.txt file for reference. . Thank you. > INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chrX"" start: 14000 end: 15000. **Setup**. - Operating system:linux. - DeepVariant version:latest. - Installation method (Docker, built from source, etc.):udocker. - Type of data: test file for checking Calling variants in non-autosomal contigs [this](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-xy-calling-case-study.md). **Steps to reproduce:**. - Command:. BIN_VERSION=""1.6.1"". ```. REF=""GRCh38_no_alt_analysis_set.fasta"". BAM=""HG002.pfda_challenge.grch38.chrXY.bam"". THREADS=$(nproc). REGION=""chrX chrY"". HAPLOID_CONTIGS=""chrX,chrY"". PAR_BED=""GRCh38_PAR.bed"". udocker run \. -v ""${INPUT_DIR}"":""${INPUT_DIR}"" \. -v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ""${INPUT_DIR}/${REF}"" \. --reads ""${INPUT_DIR}/${BAM}"" \. --output_vcf ""${OUTPUT_DIR}/${OUTPUT_VCF}"" \. --output_gvcf ""${OUTPUT_DIR}/${OUTPUT_GVCF}"" \. --num_shards ""${THREADS}"" \. --haploid_contigs ""${HAPLOID_CONTIGS}"" \. --par_regions_bed ""${INPUT_DIR}/${PAR_BED}"" \. --regions ""${REGION}"" \. --intermediate_results_dir ""${OUTPUT_DIR}/${INTERMEDIATE_DIRECTORY}"" . ```. - Error trace: . . [error.txt](https://github.com/user-attachments/files/16281125/error.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:208,performance,error,errors,208,"Error while running tests on Calling variants in non-autosomal contigs; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am having some errors while fetching variants from chrX, Could you please have a look I added a error.txt file for reference. . Thank you. > INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chrX"" start: 14000 end: 15000. **Setup**. - Operating system:linux. - DeepVariant version:latest. - Installation method (Docker, built from source, etc.):udocker. - Type of data: test file for checking Calling variants in non-autosomal contigs [this](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-xy-calling-case-study.md). **Steps to reproduce:**. - Command:. BIN_VERSION=""1.6.1"". ```. REF=""GRCh38_no_alt_analysis_set.fasta"". BAM=""HG002.pfda_challenge.grch38.chrXY.bam"". THREADS=$(nproc). REGION=""chrX chrY"". HAPLOID_CONTIGS=""chrX,chrY"". PAR_BED=""GRCh38_PAR.bed"". udocker run \. -v ""${INPUT_DIR}"":""${INPUT_DIR}"" \. -v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ""${INPUT_DIR}/${REF}"" \. --reads ""${INPUT_DIR}/${BAM}"" \. --output_vcf ""${OUTPUT_DIR}/${OUTPUT_VCF}"" \. --output_gvcf ""${OUTPUT_DIR}/${OUTPUT_GVCF}"" \. --num_shards ""${THREADS}"" \. --haploid_contigs ""${HAPLOID_CONTIGS}"" \. --par_regions_bed ""${INPUT_DIR}/${PAR_BED}"" \. --regions ""${REGION}"" \. --intermediate_results_dir ""${OUTPUT_DIR}/${INTERMEDIATE_DIRECTORY}"" . ```. - Error trace: . . [error.txt](https://github.com/user-attachments/files/16281125/error.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:289,performance,error,error,289,"Error while running tests on Calling variants in non-autosomal contigs; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am having some errors while fetching variants from chrX, Could you please have a look I added a error.txt file for reference. . Thank you. > INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chrX"" start: 14000 end: 15000. **Setup**. - Operating system:linux. - DeepVariant version:latest. - Installation method (Docker, built from source, etc.):udocker. - Type of data: test file for checking Calling variants in non-autosomal contigs [this](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-xy-calling-case-study.md). **Steps to reproduce:**. - Command:. BIN_VERSION=""1.6.1"". ```. REF=""GRCh38_no_alt_analysis_set.fasta"". BAM=""HG002.pfda_challenge.grch38.chrXY.bam"". THREADS=$(nproc). REGION=""chrX chrY"". HAPLOID_CONTIGS=""chrX,chrY"". PAR_BED=""GRCh38_PAR.bed"". udocker run \. -v ""${INPUT_DIR}"":""${INPUT_DIR}"" \. -v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ""${INPUT_DIR}/${REF}"" \. --reads ""${INPUT_DIR}/${BAM}"" \. --output_vcf ""${OUTPUT_DIR}/${OUTPUT_VCF}"" \. --output_gvcf ""${OUTPUT_DIR}/${OUTPUT_GVCF}"" \. --num_shards ""${THREADS}"" \. --haploid_contigs ""${HAPLOID_CONTIGS}"" \. --par_regions_bed ""${INPUT_DIR}/${PAR_BED}"" \. --regions ""${REGION}"" \. --intermediate_results_dir ""${OUTPUT_DIR}/${INTERMEDIATE_DIRECTORY}"" . ```. - Error trace: . . [error.txt](https://github.com/user-attachments/files/16281125/error.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:1550,performance,Error,Error,1550,"Error while running tests on Calling variants in non-autosomal contigs; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am having some errors while fetching variants from chrX, Could you please have a look I added a error.txt file for reference. . Thank you. > INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chrX"" start: 14000 end: 15000. **Setup**. - Operating system:linux. - DeepVariant version:latest. - Installation method (Docker, built from source, etc.):udocker. - Type of data: test file for checking Calling variants in non-autosomal contigs [this](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-xy-calling-case-study.md). **Steps to reproduce:**. - Command:. BIN_VERSION=""1.6.1"". ```. REF=""GRCh38_no_alt_analysis_set.fasta"". BAM=""HG002.pfda_challenge.grch38.chrXY.bam"". THREADS=$(nproc). REGION=""chrX chrY"". HAPLOID_CONTIGS=""chrX,chrY"". PAR_BED=""GRCh38_PAR.bed"". udocker run \. -v ""${INPUT_DIR}"":""${INPUT_DIR}"" \. -v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ""${INPUT_DIR}/${REF}"" \. --reads ""${INPUT_DIR}/${BAM}"" \. --output_vcf ""${OUTPUT_DIR}/${OUTPUT_VCF}"" \. --output_gvcf ""${OUTPUT_DIR}/${OUTPUT_GVCF}"" \. --num_shards ""${THREADS}"" \. --haploid_contigs ""${HAPLOID_CONTIGS}"" \. --par_regions_bed ""${INPUT_DIR}/${PAR_BED}"" \. --regions ""${REGION}"" \. --intermediate_results_dir ""${OUTPUT_DIR}/${INTERMEDIATE_DIRECTORY}"" . ```. - Error trace: . . [error.txt](https://github.com/user-attachments/files/16281125/error.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:1568,performance,error,error,1568,"Error while running tests on Calling variants in non-autosomal contigs; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am having some errors while fetching variants from chrX, Could you please have a look I added a error.txt file for reference. . Thank you. > INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chrX"" start: 14000 end: 15000. **Setup**. - Operating system:linux. - DeepVariant version:latest. - Installation method (Docker, built from source, etc.):udocker. - Type of data: test file for checking Calling variants in non-autosomal contigs [this](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-xy-calling-case-study.md). **Steps to reproduce:**. - Command:. BIN_VERSION=""1.6.1"". ```. REF=""GRCh38_no_alt_analysis_set.fasta"". BAM=""HG002.pfda_challenge.grch38.chrXY.bam"". THREADS=$(nproc). REGION=""chrX chrY"". HAPLOID_CONTIGS=""chrX,chrY"". PAR_BED=""GRCh38_PAR.bed"". udocker run \. -v ""${INPUT_DIR}"":""${INPUT_DIR}"" \. -v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ""${INPUT_DIR}/${REF}"" \. --reads ""${INPUT_DIR}/${BAM}"" \. --output_vcf ""${OUTPUT_DIR}/${OUTPUT_VCF}"" \. --output_gvcf ""${OUTPUT_DIR}/${OUTPUT_GVCF}"" \. --num_shards ""${THREADS}"" \. --haploid_contigs ""${HAPLOID_CONTIGS}"" \. --par_regions_bed ""${INPUT_DIR}/${PAR_BED}"" \. --regions ""${REGION}"" \. --intermediate_results_dir ""${OUTPUT_DIR}/${INTERMEDIATE_DIRECTORY}"" . ```. - Error trace: . . [error.txt](https://github.com/user-attachments/files/16281125/error.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:1630,performance,error,error,1630,"Error while running tests on Calling variants in non-autosomal contigs; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am having some errors while fetching variants from chrX, Could you please have a look I added a error.txt file for reference. . Thank you. > INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chrX"" start: 14000 end: 15000. **Setup**. - Operating system:linux. - DeepVariant version:latest. - Installation method (Docker, built from source, etc.):udocker. - Type of data: test file for checking Calling variants in non-autosomal contigs [this](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-xy-calling-case-study.md). **Steps to reproduce:**. - Command:. BIN_VERSION=""1.6.1"". ```. REF=""GRCh38_no_alt_analysis_set.fasta"". BAM=""HG002.pfda_challenge.grch38.chrXY.bam"". THREADS=$(nproc). REGION=""chrX chrY"". HAPLOID_CONTIGS=""chrX,chrY"". PAR_BED=""GRCh38_PAR.bed"". udocker run \. -v ""${INPUT_DIR}"":""${INPUT_DIR}"" \. -v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ""${INPUT_DIR}/${REF}"" \. --reads ""${INPUT_DIR}/${BAM}"" \. --output_vcf ""${OUTPUT_DIR}/${OUTPUT_VCF}"" \. --output_gvcf ""${OUTPUT_DIR}/${OUTPUT_GVCF}"" \. --num_shards ""${THREADS}"" \. --haploid_contigs ""${HAPLOID_CONTIGS}"" \. --par_regions_bed ""${INPUT_DIR}/${PAR_BED}"" \. --regions ""${REGION}"" \. --intermediate_results_dir ""${OUTPUT_DIR}/${INTERMEDIATE_DIRECTORY}"" . ```. - Error trace: . . [error.txt](https://github.com/user-attachments/files/16281125/error.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:0,safety,Error,Error,0,"Error while running tests on Calling variants in non-autosomal contigs; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am having some errors while fetching variants from chrX, Could you please have a look I added a error.txt file for reference. . Thank you. > INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chrX"" start: 14000 end: 15000. **Setup**. - Operating system:linux. - DeepVariant version:latest. - Installation method (Docker, built from source, etc.):udocker. - Type of data: test file for checking Calling variants in non-autosomal contigs [this](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-xy-calling-case-study.md). **Steps to reproduce:**. - Command:. BIN_VERSION=""1.6.1"". ```. REF=""GRCh38_no_alt_analysis_set.fasta"". BAM=""HG002.pfda_challenge.grch38.chrXY.bam"". THREADS=$(nproc). REGION=""chrX chrY"". HAPLOID_CONTIGS=""chrX,chrY"". PAR_BED=""GRCh38_PAR.bed"". udocker run \. -v ""${INPUT_DIR}"":""${INPUT_DIR}"" \. -v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ""${INPUT_DIR}/${REF}"" \. --reads ""${INPUT_DIR}/${BAM}"" \. --output_vcf ""${OUTPUT_DIR}/${OUTPUT_VCF}"" \. --output_gvcf ""${OUTPUT_DIR}/${OUTPUT_GVCF}"" \. --num_shards ""${THREADS}"" \. --haploid_contigs ""${HAPLOID_CONTIGS}"" \. --par_regions_bed ""${INPUT_DIR}/${PAR_BED}"" \. --regions ""${REGION}"" \. --intermediate_results_dir ""${OUTPUT_DIR}/${INTERMEDIATE_DIRECTORY}"" . ```. - Error trace: . . [error.txt](https://github.com/user-attachments/files/16281125/error.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:20,safety,test,tests,20,"Error while running tests on Calling variants in non-autosomal contigs; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am having some errors while fetching variants from chrX, Could you please have a look I added a error.txt file for reference. . Thank you. > INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chrX"" start: 14000 end: 15000. **Setup**. - Operating system:linux. - DeepVariant version:latest. - Installation method (Docker, built from source, etc.):udocker. - Type of data: test file for checking Calling variants in non-autosomal contigs [this](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-xy-calling-case-study.md). **Steps to reproduce:**. - Command:. BIN_VERSION=""1.6.1"". ```. REF=""GRCh38_no_alt_analysis_set.fasta"". BAM=""HG002.pfda_challenge.grch38.chrXY.bam"". THREADS=$(nproc). REGION=""chrX chrY"". HAPLOID_CONTIGS=""chrX,chrY"". PAR_BED=""GRCh38_PAR.bed"". udocker run \. -v ""${INPUT_DIR}"":""${INPUT_DIR}"" \. -v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ""${INPUT_DIR}/${REF}"" \. --reads ""${INPUT_DIR}/${BAM}"" \. --output_vcf ""${OUTPUT_DIR}/${OUTPUT_VCF}"" \. --output_gvcf ""${OUTPUT_DIR}/${OUTPUT_GVCF}"" \. --num_shards ""${THREADS}"" \. --haploid_contigs ""${HAPLOID_CONTIGS}"" \. --par_regions_bed ""${INPUT_DIR}/${PAR_BED}"" \. --regions ""${REGION}"" \. --intermediate_results_dir ""${OUTPUT_DIR}/${INTERMEDIATE_DIRECTORY}"" . ```. - Error trace: . . [error.txt](https://github.com/user-attachments/files/16281125/error.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:208,safety,error,errors,208,"Error while running tests on Calling variants in non-autosomal contigs; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am having some errors while fetching variants from chrX, Could you please have a look I added a error.txt file for reference. . Thank you. > INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chrX"" start: 14000 end: 15000. **Setup**. - Operating system:linux. - DeepVariant version:latest. - Installation method (Docker, built from source, etc.):udocker. - Type of data: test file for checking Calling variants in non-autosomal contigs [this](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-xy-calling-case-study.md). **Steps to reproduce:**. - Command:. BIN_VERSION=""1.6.1"". ```. REF=""GRCh38_no_alt_analysis_set.fasta"". BAM=""HG002.pfda_challenge.grch38.chrXY.bam"". THREADS=$(nproc). REGION=""chrX chrY"". HAPLOID_CONTIGS=""chrX,chrY"". PAR_BED=""GRCh38_PAR.bed"". udocker run \. -v ""${INPUT_DIR}"":""${INPUT_DIR}"" \. -v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ""${INPUT_DIR}/${REF}"" \. --reads ""${INPUT_DIR}/${BAM}"" \. --output_vcf ""${OUTPUT_DIR}/${OUTPUT_VCF}"" \. --output_gvcf ""${OUTPUT_DIR}/${OUTPUT_GVCF}"" \. --num_shards ""${THREADS}"" \. --haploid_contigs ""${HAPLOID_CONTIGS}"" \. --par_regions_bed ""${INPUT_DIR}/${PAR_BED}"" \. --regions ""${REGION}"" \. --intermediate_results_dir ""${OUTPUT_DIR}/${INTERMEDIATE_DIRECTORY}"" . ```. - Error trace: . . [error.txt](https://github.com/user-attachments/files/16281125/error.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:289,safety,error,error,289,"Error while running tests on Calling variants in non-autosomal contigs; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am having some errors while fetching variants from chrX, Could you please have a look I added a error.txt file for reference. . Thank you. > INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chrX"" start: 14000 end: 15000. **Setup**. - Operating system:linux. - DeepVariant version:latest. - Installation method (Docker, built from source, etc.):udocker. - Type of data: test file for checking Calling variants in non-autosomal contigs [this](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-xy-calling-case-study.md). **Steps to reproduce:**. - Command:. BIN_VERSION=""1.6.1"". ```. REF=""GRCh38_no_alt_analysis_set.fasta"". BAM=""HG002.pfda_challenge.grch38.chrXY.bam"". THREADS=$(nproc). REGION=""chrX chrY"". HAPLOID_CONTIGS=""chrX,chrY"". PAR_BED=""GRCh38_PAR.bed"". udocker run \. -v ""${INPUT_DIR}"":""${INPUT_DIR}"" \. -v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ""${INPUT_DIR}/${REF}"" \. --reads ""${INPUT_DIR}/${BAM}"" \. --output_vcf ""${OUTPUT_DIR}/${OUTPUT_VCF}"" \. --output_gvcf ""${OUTPUT_DIR}/${OUTPUT_GVCF}"" \. --num_shards ""${THREADS}"" \. --haploid_contigs ""${HAPLOID_CONTIGS}"" \. --par_regions_bed ""${INPUT_DIR}/${PAR_BED}"" \. --regions ""${REGION}"" \. --intermediate_results_dir ""${OUTPUT_DIR}/${INTERMEDIATE_DIRECTORY}"" . ```. - Error trace: . . [error.txt](https://github.com/user-attachments/files/16281125/error.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:573,safety,test,test,573,"Error while running tests on Calling variants in non-autosomal contigs; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am having some errors while fetching variants from chrX, Could you please have a look I added a error.txt file for reference. . Thank you. > INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chrX"" start: 14000 end: 15000. **Setup**. - Operating system:linux. - DeepVariant version:latest. - Installation method (Docker, built from source, etc.):udocker. - Type of data: test file for checking Calling variants in non-autosomal contigs [this](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-xy-calling-case-study.md). **Steps to reproduce:**. - Command:. BIN_VERSION=""1.6.1"". ```. REF=""GRCh38_no_alt_analysis_set.fasta"". BAM=""HG002.pfda_challenge.grch38.chrXY.bam"". THREADS=$(nproc). REGION=""chrX chrY"". HAPLOID_CONTIGS=""chrX,chrY"". PAR_BED=""GRCh38_PAR.bed"". udocker run \. -v ""${INPUT_DIR}"":""${INPUT_DIR}"" \. -v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ""${INPUT_DIR}/${REF}"" \. --reads ""${INPUT_DIR}/${BAM}"" \. --output_vcf ""${OUTPUT_DIR}/${OUTPUT_VCF}"" \. --output_gvcf ""${OUTPUT_DIR}/${OUTPUT_GVCF}"" \. --num_shards ""${THREADS}"" \. --haploid_contigs ""${HAPLOID_CONTIGS}"" \. --par_regions_bed ""${INPUT_DIR}/${PAR_BED}"" \. --regions ""${REGION}"" \. --intermediate_results_dir ""${OUTPUT_DIR}/${INTERMEDIATE_DIRECTORY}"" . ```. - Error trace: . . [error.txt](https://github.com/user-attachments/files/16281125/error.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:1550,safety,Error,Error,1550,"Error while running tests on Calling variants in non-autosomal contigs; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am having some errors while fetching variants from chrX, Could you please have a look I added a error.txt file for reference. . Thank you. > INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chrX"" start: 14000 end: 15000. **Setup**. - Operating system:linux. - DeepVariant version:latest. - Installation method (Docker, built from source, etc.):udocker. - Type of data: test file for checking Calling variants in non-autosomal contigs [this](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-xy-calling-case-study.md). **Steps to reproduce:**. - Command:. BIN_VERSION=""1.6.1"". ```. REF=""GRCh38_no_alt_analysis_set.fasta"". BAM=""HG002.pfda_challenge.grch38.chrXY.bam"". THREADS=$(nproc). REGION=""chrX chrY"". HAPLOID_CONTIGS=""chrX,chrY"". PAR_BED=""GRCh38_PAR.bed"". udocker run \. -v ""${INPUT_DIR}"":""${INPUT_DIR}"" \. -v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ""${INPUT_DIR}/${REF}"" \. --reads ""${INPUT_DIR}/${BAM}"" \. --output_vcf ""${OUTPUT_DIR}/${OUTPUT_VCF}"" \. --output_gvcf ""${OUTPUT_DIR}/${OUTPUT_GVCF}"" \. --num_shards ""${THREADS}"" \. --haploid_contigs ""${HAPLOID_CONTIGS}"" \. --par_regions_bed ""${INPUT_DIR}/${PAR_BED}"" \. --regions ""${REGION}"" \. --intermediate_results_dir ""${OUTPUT_DIR}/${INTERMEDIATE_DIRECTORY}"" . ```. - Error trace: . . [error.txt](https://github.com/user-attachments/files/16281125/error.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:1568,safety,error,error,1568,"Error while running tests on Calling variants in non-autosomal contigs; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am having some errors while fetching variants from chrX, Could you please have a look I added a error.txt file for reference. . Thank you. > INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chrX"" start: 14000 end: 15000. **Setup**. - Operating system:linux. - DeepVariant version:latest. - Installation method (Docker, built from source, etc.):udocker. - Type of data: test file for checking Calling variants in non-autosomal contigs [this](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-xy-calling-case-study.md). **Steps to reproduce:**. - Command:. BIN_VERSION=""1.6.1"". ```. REF=""GRCh38_no_alt_analysis_set.fasta"". BAM=""HG002.pfda_challenge.grch38.chrXY.bam"". THREADS=$(nproc). REGION=""chrX chrY"". HAPLOID_CONTIGS=""chrX,chrY"". PAR_BED=""GRCh38_PAR.bed"". udocker run \. -v ""${INPUT_DIR}"":""${INPUT_DIR}"" \. -v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ""${INPUT_DIR}/${REF}"" \. --reads ""${INPUT_DIR}/${BAM}"" \. --output_vcf ""${OUTPUT_DIR}/${OUTPUT_VCF}"" \. --output_gvcf ""${OUTPUT_DIR}/${OUTPUT_GVCF}"" \. --num_shards ""${THREADS}"" \. --haploid_contigs ""${HAPLOID_CONTIGS}"" \. --par_regions_bed ""${INPUT_DIR}/${PAR_BED}"" \. --regions ""${REGION}"" \. --intermediate_results_dir ""${OUTPUT_DIR}/${INTERMEDIATE_DIRECTORY}"" . ```. - Error trace: . . [error.txt](https://github.com/user-attachments/files/16281125/error.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:1630,safety,error,error,1630,"Error while running tests on Calling variants in non-autosomal contigs; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am having some errors while fetching variants from chrX, Could you please have a look I added a error.txt file for reference. . Thank you. > INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chrX"" start: 14000 end: 15000. **Setup**. - Operating system:linux. - DeepVariant version:latest. - Installation method (Docker, built from source, etc.):udocker. - Type of data: test file for checking Calling variants in non-autosomal contigs [this](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-xy-calling-case-study.md). **Steps to reproduce:**. - Command:. BIN_VERSION=""1.6.1"". ```. REF=""GRCh38_no_alt_analysis_set.fasta"". BAM=""HG002.pfda_challenge.grch38.chrXY.bam"". THREADS=$(nproc). REGION=""chrX chrY"". HAPLOID_CONTIGS=""chrX,chrY"". PAR_BED=""GRCh38_PAR.bed"". udocker run \. -v ""${INPUT_DIR}"":""${INPUT_DIR}"" \. -v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ""${INPUT_DIR}/${REF}"" \. --reads ""${INPUT_DIR}/${BAM}"" \. --output_vcf ""${OUTPUT_DIR}/${OUTPUT_VCF}"" \. --output_gvcf ""${OUTPUT_DIR}/${OUTPUT_GVCF}"" \. --num_shards ""${THREADS}"" \. --haploid_contigs ""${HAPLOID_CONTIGS}"" \. --par_regions_bed ""${INPUT_DIR}/${PAR_BED}"" \. --regions ""${REGION}"" \. --intermediate_results_dir ""${OUTPUT_DIR}/${INTERMEDIATE_DIRECTORY}"" . ```. - Error trace: . . [error.txt](https://github.com/user-attachments/files/16281125/error.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:20,testability,test,tests,20,"Error while running tests on Calling variants in non-autosomal contigs; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am having some errors while fetching variants from chrX, Could you please have a look I added a error.txt file for reference. . Thank you. > INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chrX"" start: 14000 end: 15000. **Setup**. - Operating system:linux. - DeepVariant version:latest. - Installation method (Docker, built from source, etc.):udocker. - Type of data: test file for checking Calling variants in non-autosomal contigs [this](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-xy-calling-case-study.md). **Steps to reproduce:**. - Command:. BIN_VERSION=""1.6.1"". ```. REF=""GRCh38_no_alt_analysis_set.fasta"". BAM=""HG002.pfda_challenge.grch38.chrXY.bam"". THREADS=$(nproc). REGION=""chrX chrY"". HAPLOID_CONTIGS=""chrX,chrY"". PAR_BED=""GRCh38_PAR.bed"". udocker run \. -v ""${INPUT_DIR}"":""${INPUT_DIR}"" \. -v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ""${INPUT_DIR}/${REF}"" \. --reads ""${INPUT_DIR}/${BAM}"" \. --output_vcf ""${OUTPUT_DIR}/${OUTPUT_VCF}"" \. --output_gvcf ""${OUTPUT_DIR}/${OUTPUT_GVCF}"" \. --num_shards ""${THREADS}"" \. --haploid_contigs ""${HAPLOID_CONTIGS}"" \. --par_regions_bed ""${INPUT_DIR}/${PAR_BED}"" \. --regions ""${REGION}"" \. --intermediate_results_dir ""${OUTPUT_DIR}/${INTERMEDIATE_DIRECTORY}"" . ```. - Error trace: . . [error.txt](https://github.com/user-attachments/files/16281125/error.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:573,testability,test,test,573,"Error while running tests on Calling variants in non-autosomal contigs; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am having some errors while fetching variants from chrX, Could you please have a look I added a error.txt file for reference. . Thank you. > INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chrX"" start: 14000 end: 15000. **Setup**. - Operating system:linux. - DeepVariant version:latest. - Installation method (Docker, built from source, etc.):udocker. - Type of data: test file for checking Calling variants in non-autosomal contigs [this](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-xy-calling-case-study.md). **Steps to reproduce:**. - Command:. BIN_VERSION=""1.6.1"". ```. REF=""GRCh38_no_alt_analysis_set.fasta"". BAM=""HG002.pfda_challenge.grch38.chrXY.bam"". THREADS=$(nproc). REGION=""chrX chrY"". HAPLOID_CONTIGS=""chrX,chrY"". PAR_BED=""GRCh38_PAR.bed"". udocker run \. -v ""${INPUT_DIR}"":""${INPUT_DIR}"" \. -v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ""${INPUT_DIR}/${REF}"" \. --reads ""${INPUT_DIR}/${BAM}"" \. --output_vcf ""${OUTPUT_DIR}/${OUTPUT_VCF}"" \. --output_gvcf ""${OUTPUT_DIR}/${OUTPUT_GVCF}"" \. --num_shards ""${THREADS}"" \. --haploid_contigs ""${HAPLOID_CONTIGS}"" \. --par_regions_bed ""${INPUT_DIR}/${PAR_BED}"" \. --regions ""${REGION}"" \. --intermediate_results_dir ""${OUTPUT_DIR}/${INTERMEDIATE_DIRECTORY}"" . ```. - Error trace: . . [error.txt](https://github.com/user-attachments/files/16281125/error.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:1556,testability,trace,trace,1556,"Error while running tests on Calling variants in non-autosomal contigs; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am having some errors while fetching variants from chrX, Could you please have a look I added a error.txt file for reference. . Thank you. > INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chrX"" start: 14000 end: 15000. **Setup**. - Operating system:linux. - DeepVariant version:latest. - Installation method (Docker, built from source, etc.):udocker. - Type of data: test file for checking Calling variants in non-autosomal contigs [this](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-xy-calling-case-study.md). **Steps to reproduce:**. - Command:. BIN_VERSION=""1.6.1"". ```. REF=""GRCh38_no_alt_analysis_set.fasta"". BAM=""HG002.pfda_challenge.grch38.chrXY.bam"". THREADS=$(nproc). REGION=""chrX chrY"". HAPLOID_CONTIGS=""chrX,chrY"". PAR_BED=""GRCh38_PAR.bed"". udocker run \. -v ""${INPUT_DIR}"":""${INPUT_DIR}"" \. -v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ""${INPUT_DIR}/${REF}"" \. --reads ""${INPUT_DIR}/${BAM}"" \. --output_vcf ""${OUTPUT_DIR}/${OUTPUT_VCF}"" \. --output_gvcf ""${OUTPUT_DIR}/${OUTPUT_GVCF}"" \. --num_shards ""${THREADS}"" \. --haploid_contigs ""${HAPLOID_CONTIGS}"" \. --par_regions_bed ""${INPUT_DIR}/${PAR_BED}"" \. --regions ""${REGION}"" \. --intermediate_results_dir ""${OUTPUT_DIR}/${INTERMEDIATE_DIRECTORY}"" . ```. - Error trace: . . [error.txt](https://github.com/user-attachments/files/16281125/error.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:0,usability,Error,Error,0,"Error while running tests on Calling variants in non-autosomal contigs; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am having some errors while fetching variants from chrX, Could you please have a look I added a error.txt file for reference. . Thank you. > INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chrX"" start: 14000 end: 15000. **Setup**. - Operating system:linux. - DeepVariant version:latest. - Installation method (Docker, built from source, etc.):udocker. - Type of data: test file for checking Calling variants in non-autosomal contigs [this](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-xy-calling-case-study.md). **Steps to reproduce:**. - Command:. BIN_VERSION=""1.6.1"". ```. REF=""GRCh38_no_alt_analysis_set.fasta"". BAM=""HG002.pfda_challenge.grch38.chrXY.bam"". THREADS=$(nproc). REGION=""chrX chrY"". HAPLOID_CONTIGS=""chrX,chrY"". PAR_BED=""GRCh38_PAR.bed"". udocker run \. -v ""${INPUT_DIR}"":""${INPUT_DIR}"" \. -v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ""${INPUT_DIR}/${REF}"" \. --reads ""${INPUT_DIR}/${BAM}"" \. --output_vcf ""${OUTPUT_DIR}/${OUTPUT_VCF}"" \. --output_gvcf ""${OUTPUT_DIR}/${OUTPUT_GVCF}"" \. --num_shards ""${THREADS}"" \. --haploid_contigs ""${HAPLOID_CONTIGS}"" \. --par_regions_bed ""${INPUT_DIR}/${PAR_BED}"" \. --regions ""${REGION}"" \. --intermediate_results_dir ""${OUTPUT_DIR}/${INTERMEDIATE_DIRECTORY}"" . ```. - Error trace: . . [error.txt](https://github.com/user-attachments/files/16281125/error.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:208,usability,error,errors,208,"Error while running tests on Calling variants in non-autosomal contigs; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am having some errors while fetching variants from chrX, Could you please have a look I added a error.txt file for reference. . Thank you. > INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chrX"" start: 14000 end: 15000. **Setup**. - Operating system:linux. - DeepVariant version:latest. - Installation method (Docker, built from source, etc.):udocker. - Type of data: test file for checking Calling variants in non-autosomal contigs [this](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-xy-calling-case-study.md). **Steps to reproduce:**. - Command:. BIN_VERSION=""1.6.1"". ```. REF=""GRCh38_no_alt_analysis_set.fasta"". BAM=""HG002.pfda_challenge.grch38.chrXY.bam"". THREADS=$(nproc). REGION=""chrX chrY"". HAPLOID_CONTIGS=""chrX,chrY"". PAR_BED=""GRCh38_PAR.bed"". udocker run \. -v ""${INPUT_DIR}"":""${INPUT_DIR}"" \. -v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ""${INPUT_DIR}/${REF}"" \. --reads ""${INPUT_DIR}/${BAM}"" \. --output_vcf ""${OUTPUT_DIR}/${OUTPUT_VCF}"" \. --output_gvcf ""${OUTPUT_DIR}/${OUTPUT_GVCF}"" \. --num_shards ""${THREADS}"" \. --haploid_contigs ""${HAPLOID_CONTIGS}"" \. --par_regions_bed ""${INPUT_DIR}/${PAR_BED}"" \. --regions ""${REGION}"" \. --intermediate_results_dir ""${OUTPUT_DIR}/${INTERMEDIATE_DIRECTORY}"" . ```. - Error trace: . . [error.txt](https://github.com/user-attachments/files/16281125/error.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:289,usability,error,error,289,"Error while running tests on Calling variants in non-autosomal contigs; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am having some errors while fetching variants from chrX, Could you please have a look I added a error.txt file for reference. . Thank you. > INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chrX"" start: 14000 end: 15000. **Setup**. - Operating system:linux. - DeepVariant version:latest. - Installation method (Docker, built from source, etc.):udocker. - Type of data: test file for checking Calling variants in non-autosomal contigs [this](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-xy-calling-case-study.md). **Steps to reproduce:**. - Command:. BIN_VERSION=""1.6.1"". ```. REF=""GRCh38_no_alt_analysis_set.fasta"". BAM=""HG002.pfda_challenge.grch38.chrXY.bam"". THREADS=$(nproc). REGION=""chrX chrY"". HAPLOID_CONTIGS=""chrX,chrY"". PAR_BED=""GRCh38_PAR.bed"". udocker run \. -v ""${INPUT_DIR}"":""${INPUT_DIR}"" \. -v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ""${INPUT_DIR}/${REF}"" \. --reads ""${INPUT_DIR}/${BAM}"" \. --output_vcf ""${OUTPUT_DIR}/${OUTPUT_VCF}"" \. --output_gvcf ""${OUTPUT_DIR}/${OUTPUT_GVCF}"" \. --num_shards ""${THREADS}"" \. --haploid_contigs ""${HAPLOID_CONTIGS}"" \. --par_regions_bed ""${INPUT_DIR}/${PAR_BED}"" \. --regions ""${REGION}"" \. --intermediate_results_dir ""${OUTPUT_DIR}/${INTERMEDIATE_DIRECTORY}"" . ```. - Error trace: . . [error.txt](https://github.com/user-attachments/files/16281125/error.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:766,usability,Command,Command,766,"Error while running tests on Calling variants in non-autosomal contigs; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am having some errors while fetching variants from chrX, Could you please have a look I added a error.txt file for reference. . Thank you. > INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chrX"" start: 14000 end: 15000. **Setup**. - Operating system:linux. - DeepVariant version:latest. - Installation method (Docker, built from source, etc.):udocker. - Type of data: test file for checking Calling variants in non-autosomal contigs [this](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-xy-calling-case-study.md). **Steps to reproduce:**. - Command:. BIN_VERSION=""1.6.1"". ```. REF=""GRCh38_no_alt_analysis_set.fasta"". BAM=""HG002.pfda_challenge.grch38.chrXY.bam"". THREADS=$(nproc). REGION=""chrX chrY"". HAPLOID_CONTIGS=""chrX,chrY"". PAR_BED=""GRCh38_PAR.bed"". udocker run \. -v ""${INPUT_DIR}"":""${INPUT_DIR}"" \. -v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ""${INPUT_DIR}/${REF}"" \. --reads ""${INPUT_DIR}/${BAM}"" \. --output_vcf ""${OUTPUT_DIR}/${OUTPUT_VCF}"" \. --output_gvcf ""${OUTPUT_DIR}/${OUTPUT_GVCF}"" \. --num_shards ""${THREADS}"" \. --haploid_contigs ""${HAPLOID_CONTIGS}"" \. --par_regions_bed ""${INPUT_DIR}/${PAR_BED}"" \. --regions ""${REGION}"" \. --intermediate_results_dir ""${OUTPUT_DIR}/${INTERMEDIATE_DIRECTORY}"" . ```. - Error trace: . . [error.txt](https://github.com/user-attachments/files/16281125/error.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:1550,usability,Error,Error,1550,"Error while running tests on Calling variants in non-autosomal contigs; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am having some errors while fetching variants from chrX, Could you please have a look I added a error.txt file for reference. . Thank you. > INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chrX"" start: 14000 end: 15000. **Setup**. - Operating system:linux. - DeepVariant version:latest. - Installation method (Docker, built from source, etc.):udocker. - Type of data: test file for checking Calling variants in non-autosomal contigs [this](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-xy-calling-case-study.md). **Steps to reproduce:**. - Command:. BIN_VERSION=""1.6.1"". ```. REF=""GRCh38_no_alt_analysis_set.fasta"". BAM=""HG002.pfda_challenge.grch38.chrXY.bam"". THREADS=$(nproc). REGION=""chrX chrY"". HAPLOID_CONTIGS=""chrX,chrY"". PAR_BED=""GRCh38_PAR.bed"". udocker run \. -v ""${INPUT_DIR}"":""${INPUT_DIR}"" \. -v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ""${INPUT_DIR}/${REF}"" \. --reads ""${INPUT_DIR}/${BAM}"" \. --output_vcf ""${OUTPUT_DIR}/${OUTPUT_VCF}"" \. --output_gvcf ""${OUTPUT_DIR}/${OUTPUT_GVCF}"" \. --num_shards ""${THREADS}"" \. --haploid_contigs ""${HAPLOID_CONTIGS}"" \. --par_regions_bed ""${INPUT_DIR}/${PAR_BED}"" \. --regions ""${REGION}"" \. --intermediate_results_dir ""${OUTPUT_DIR}/${INTERMEDIATE_DIRECTORY}"" . ```. - Error trace: . . [error.txt](https://github.com/user-attachments/files/16281125/error.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:1568,usability,error,error,1568,"Error while running tests on Calling variants in non-autosomal contigs; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am having some errors while fetching variants from chrX, Could you please have a look I added a error.txt file for reference. . Thank you. > INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chrX"" start: 14000 end: 15000. **Setup**. - Operating system:linux. - DeepVariant version:latest. - Installation method (Docker, built from source, etc.):udocker. - Type of data: test file for checking Calling variants in non-autosomal contigs [this](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-xy-calling-case-study.md). **Steps to reproduce:**. - Command:. BIN_VERSION=""1.6.1"". ```. REF=""GRCh38_no_alt_analysis_set.fasta"". BAM=""HG002.pfda_challenge.grch38.chrXY.bam"". THREADS=$(nproc). REGION=""chrX chrY"". HAPLOID_CONTIGS=""chrX,chrY"". PAR_BED=""GRCh38_PAR.bed"". udocker run \. -v ""${INPUT_DIR}"":""${INPUT_DIR}"" \. -v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ""${INPUT_DIR}/${REF}"" \. --reads ""${INPUT_DIR}/${BAM}"" \. --output_vcf ""${OUTPUT_DIR}/${OUTPUT_VCF}"" \. --output_gvcf ""${OUTPUT_DIR}/${OUTPUT_GVCF}"" \. --num_shards ""${THREADS}"" \. --haploid_contigs ""${HAPLOID_CONTIGS}"" \. --par_regions_bed ""${INPUT_DIR}/${PAR_BED}"" \. --regions ""${REGION}"" \. --intermediate_results_dir ""${OUTPUT_DIR}/${INTERMEDIATE_DIRECTORY}"" . ```. - Error trace: . . [error.txt](https://github.com/user-attachments/files/16281125/error.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:1598,usability,user,user-attachments,1598,"Error while running tests on Calling variants in non-autosomal contigs; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am having some errors while fetching variants from chrX, Could you please have a look I added a error.txt file for reference. . Thank you. > INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chrX"" start: 14000 end: 15000. **Setup**. - Operating system:linux. - DeepVariant version:latest. - Installation method (Docker, built from source, etc.):udocker. - Type of data: test file for checking Calling variants in non-autosomal contigs [this](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-xy-calling-case-study.md). **Steps to reproduce:**. - Command:. BIN_VERSION=""1.6.1"". ```. REF=""GRCh38_no_alt_analysis_set.fasta"". BAM=""HG002.pfda_challenge.grch38.chrXY.bam"". THREADS=$(nproc). REGION=""chrX chrY"". HAPLOID_CONTIGS=""chrX,chrY"". PAR_BED=""GRCh38_PAR.bed"". udocker run \. -v ""${INPUT_DIR}"":""${INPUT_DIR}"" \. -v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ""${INPUT_DIR}/${REF}"" \. --reads ""${INPUT_DIR}/${BAM}"" \. --output_vcf ""${OUTPUT_DIR}/${OUTPUT_VCF}"" \. --output_gvcf ""${OUTPUT_DIR}/${OUTPUT_GVCF}"" \. --num_shards ""${THREADS}"" \. --haploid_contigs ""${HAPLOID_CONTIGS}"" \. --par_regions_bed ""${INPUT_DIR}/${PAR_BED}"" \. --regions ""${REGION}"" \. --intermediate_results_dir ""${OUTPUT_DIR}/${INTERMEDIATE_DIRECTORY}"" . ```. - Error trace: . . [error.txt](https://github.com/user-attachments/files/16281125/error.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:1630,usability,error,error,1630,"Error while running tests on Calling variants in non-autosomal contigs; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am having some errors while fetching variants from chrX, Could you please have a look I added a error.txt file for reference. . Thank you. > INVALID_ARGUMENT: Couldn't fetch bases for reference_name: ""chrX"" start: 14000 end: 15000. **Setup**. - Operating system:linux. - DeepVariant version:latest. - Installation method (Docker, built from source, etc.):udocker. - Type of data: test file for checking Calling variants in non-autosomal contigs [this](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-xy-calling-case-study.md). **Steps to reproduce:**. - Command:. BIN_VERSION=""1.6.1"". ```. REF=""GRCh38_no_alt_analysis_set.fasta"". BAM=""HG002.pfda_challenge.grch38.chrXY.bam"". THREADS=$(nproc). REGION=""chrX chrY"". HAPLOID_CONTIGS=""chrX,chrY"". PAR_BED=""GRCh38_PAR.bed"". udocker run \. -v ""${INPUT_DIR}"":""${INPUT_DIR}"" \. -v ""${OUTPUT_DIR}"":""${OUTPUT_DIR}"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ""${INPUT_DIR}/${REF}"" \. --reads ""${INPUT_DIR}/${BAM}"" \. --output_vcf ""${OUTPUT_DIR}/${OUTPUT_VCF}"" \. --output_gvcf ""${OUTPUT_DIR}/${OUTPUT_GVCF}"" \. --num_shards ""${THREADS}"" \. --haploid_contigs ""${HAPLOID_CONTIGS}"" \. --par_regions_bed ""${INPUT_DIR}/${PAR_BED}"" \. --regions ""${REGION}"" \. --intermediate_results_dir ""${OUTPUT_DIR}/${INTERMEDIATE_DIRECTORY}"" . ```. - Error trace: . . [error.txt](https://github.com/user-attachments/files/16281125/error.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/854:275,availability,error,error,275,"Memory issue while running deepvariant_1.6.0.sif with ONT_R104 ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. Python encountered a MemoryError, no matter how much we increase the memory allocation the error exists. **Setup**. - Operating system:. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): apptainer pull docker://google/deepvariant:""1.6.1"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) bam files, ONT. **Steps to reproduce:**. - Command: . apptainer exec --bind /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint /work/XXXX/ls6/deepvariant/deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant --model_type ONT_R104 --ref /work/XXXX/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/XXXX/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --output_vcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.vcf.gz --output_gvcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.g.vcf.gz --num_shards 64 --logging_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/ --intermediate_results_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_goog",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:302,availability,Operat,Operating,302,"Memory issue while running deepvariant_1.6.0.sif with ONT_R104 ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. Python encountered a MemoryError, no matter how much we increase the memory allocation the error exists. **Setup**. - Operating system:. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): apptainer pull docker://google/deepvariant:""1.6.1"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) bam files, ONT. **Steps to reproduce:**. - Command: . apptainer exec --bind /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint /work/XXXX/ls6/deepvariant/deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant --model_type ONT_R104 --ref /work/XXXX/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/XXXX/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --output_vcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.vcf.gz --output_gvcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.g.vcf.gz --num_shards 64 --logging_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/ --intermediate_results_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_goog",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:1310,availability,Error,Error,1310,"ystem:. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): apptainer pull docker://google/deepvariant:""1.6.1"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) bam files, ONT. **Steps to reproduce:**. - Command: . apptainer exec --bind /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint /work/XXXX/ls6/deepvariant/deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant --model_type ONT_R104 --ref /work/XXXX/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/XXXX/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --output_vcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.vcf.gz --output_gvcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.g.vcf.gz --num_shards 64 --logging_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/ --intermediate_results_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__ini",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:15685,availability,error,error,15685, --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 39. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 52. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 57. real	0m4.925s. user	0m4.781s. sys	0m19.092s. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Did not face this error in DeepVariant version: 1.5.0.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:335,deployability,version,version,335,"Memory issue while running deepvariant_1.6.0.sif with ONT_R104 ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. Python encountered a MemoryError, no matter how much we increase the memory allocation the error exists. **Setup**. - Operating system:. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): apptainer pull docker://google/deepvariant:""1.6.1"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) bam files, ONT. **Steps to reproduce:**. - Command: . apptainer exec --bind /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint /work/XXXX/ls6/deepvariant/deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant --model_type ONT_R104 --ref /work/XXXX/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/XXXX/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --output_vcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.vcf.gz --output_gvcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.g.vcf.gz --num_shards 64 --logging_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/ --intermediate_results_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_goog",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:353,deployability,Instal,Installation,353,"Memory issue while running deepvariant_1.6.0.sif with ONT_R104 ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. Python encountered a MemoryError, no matter how much we increase the memory allocation the error exists. **Setup**. - Operating system:. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): apptainer pull docker://google/deepvariant:""1.6.1"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) bam files, ONT. **Steps to reproduce:**. - Command: . apptainer exec --bind /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint /work/XXXX/ls6/deepvariant/deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant --model_type ONT_R104 --ref /work/XXXX/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/XXXX/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --output_vcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.vcf.gz --output_gvcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.g.vcf.gz --num_shards 64 --logging_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/ --intermediate_results_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_goog",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:1372,deployability,fail,failed,1372,"ocker, built from source, etc.): apptainer pull docker://google/deepvariant:""1.6.1"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) bam files, ONT. **Steps to reproduce:**. - Command: . apptainer exec --bind /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint /work/XXXX/ls6/deepvariant/deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant --model_type ONT_R104 --ref /work/XXXX/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/XXXX/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --output_vcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.vcf.gz --output_gvcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.g.vcf.gz --num_shards 64 --logging_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/ --intermediate_results_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/u",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:1543,deployability,instal,installed,1543,"e the case studies?) bam files, ONT. **Steps to reproduce:**. - Command: . apptainer exec --bind /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint /work/XXXX/ls6/deepvariant/deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant --model_type ONT_R104 --ref /work/XXXX/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/XXXX/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --output_vcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.vcf.gz --output_gvcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.g.vcf.gz --num_shards 64 --logging_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/ --intermediate_results_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pick",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:1657,deployability,fail,failed,1657,"NT_WGS/HH/FL9-1_deepvaraint /work/XXXX/ls6/deepvariant/deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant --model_type ONT_R104 --ref /work/XXXX/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/XXXX/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --output_vcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.vcf.gz --output_gvcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.g.vcf.gz --num_shards 64 --logging_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/ --intermediate_results_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:1828,deployability,instal,installed,1828,"38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/XXXX/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --output_vcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.vcf.gz --output_gvcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.g.vcf.gz --num_shards 64 --logging_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/ --intermediate_results_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:2059,deployability,modul,module,2059,"9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.g.vcf.gz --num_shards 64 --logging_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/ --intermediate_results_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:2228,deployability,modul,module,2228,"/scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:2336,deployability,modul,module,2336," . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:2453,deployability,modul,module,2453,". 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_an",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:2568,deployability,modul,module,2568,"rl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootst",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:2781,deployability,fail,failed,2781,",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:2970,deployability,modul,module,2970,"_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:3139,deployability,modul,module,3139,"cqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:3247,deployability,modul,module,3247,"as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:3360,deployability,modul,module,3360,"om. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 144, in <module>. from . import lib. File ""/usr/local/lib/python3.8/dist-packages/numpy/lib/__init__.py"", line 34,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:3981,deployability,modul,module,3981,"deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 144, in <module>. from . import lib. File ""/usr/local/lib/python3.8/dist-packages/numpy/lib/__init__.py"", line 34, in <module>. from . import polynomial. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:4150,deployability,modul,module,4150,"t numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 144, in <module>. from . import lib. File ""/usr/local/lib/python3.8/dist-packages/numpy/lib/__init__.py"", line 34, in <module>. from . import polynomial. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:4258,deployability,modul,module,4258,". import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 144, in <module>. from . import lib. File ""/usr/local/lib/python3.8/dist-packages/numpy/lib/__init__.py"", line 34, in <module>. from . import polynomial. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:4368,deployability,modul,module,4368,"om . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 144, in <module>. from . import lib. File ""/usr/local/lib/python3.8/dist-packages/numpy/lib/__init__.py"", line 34, in <module>. from . import polynomial. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. F",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:4987,deployability,modul,module,4987,"from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 144, in <module>. from . import lib. File ""/usr/local/lib/python3.8/dist-packages/numpy/lib/__init__.py"", line 34, in <module>. from . import polynomial. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/versi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:5156,deployability,modul,module,5156,"import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 144, in <module>. from . import lib. File ""/usr/local/lib/python3.8/dist-packages/numpy/lib/__init__.py"", line 34, in <module>. from . import polynomial. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _reg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:5321,deployability,modul,module,5321,"ckages/numpy/lib/__init__.py"", line 34, in <module>. from . import polynomial. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p =",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:5482,deployability,modul,module,5482,"mportlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:5668,deployability,modul,module,5668,"n exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_comp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:5820,deployability,modul,module,5820,"ta. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:5907,deployability,modul,module,5907,"/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:5985,deployability,version,version,5985,"dule>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:6012,deployability,modul,module,6012,"port make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/pytho",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:6027,deployability,Version,Version,6027,"es_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:6120,deployability,version,version,6120,"examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryEr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:6146,deployability,Version,Version,6146,", in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recen",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:7276,deployability,modul,module,7276,"/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 151, in <module>. from . import polynomial. File ""/usr/local/lib/python3.8/dist-packages/numpy/polynomial/__init__.py"", line 120, in <module>. from .hermite_e import HermiteE. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_ex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:7445,deployability,modul,module,7445,". File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 151, in <module>. from . import polynomial. File ""/usr/local/lib/python3.8/dist-packages/numpy/polynomial/__init__.py"", line 120, in <module>. from .hermite_e import HermiteE. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_example",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:7553,deployability,modul,module,7553,"b/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 151, in <module>. from . import polynomial. File ""/usr/local/lib/python3.8/dist-packages/numpy/polynomial/__init__.py"", line 120, in <module>. from .hermite_e import HermiteE. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmd",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:7678,deployability,modul,module,7678,"ine 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 151, in <module>. from . import polynomial. File ""/usr/local/lib/python3.8/dist-packages/numpy/polynomial/__init__.py"", line 120, in <module>. from .hermite_e import HermiteE. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:8304,deployability,modul,module,8304,"t make_examples_core. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 151, in <module>. from . import polynomial. File ""/usr/local/lib/python3.8/dist-packages/numpy/polynomial/__init__.py"", line 120, in <module>. from .hermite_e import HermiteE. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/pytho",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:8473,deployability,modul,module,8473,"le ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 151, in <module>. from . import polynomial. File ""/usr/local/lib/python3.8/dist-packages/numpy/polynomial/__init__.py"", line 120, in <module>. from .hermite_e import HermiteE. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_ve",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:8638,deployability,modul,module,8638,"lynomial/__init__.py"", line 120, in <module>. from .hermite_e import HermiteE. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:8799,deployability,modul,module,8799,"mportlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:8985,deployability,modul,module,8985,"n exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:9137,deployability,modul,module,9137,"ta. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). Fi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:9224,deployability,modul,module,9224,"/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], fl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:9276,deployability,version,version,9276,"mples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:9356,deployability,version,version,9356,"e ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:9383,deployability,modul,module,9383,"gmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/pytho",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:9398,deployability,Version,Version,9398,"om_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:9491,deployability,version,version,9491,"ant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryEr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:9517,deployability,Version,Version,9517,"y. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recen",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:10647,deployability,modul,module,10647,"/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 57, in <module>. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1037, in get_data. MemoryError. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:10816,deployability,modul,module,10816,". File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 57, in <module>. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1037, in get_data. MemoryError. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:10924,deployability,modul,module,10924,"b/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 57, in <module>. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1037, in get_data. MemoryError. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:11016,deployability,modul,module,11016,"/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 57, in <module>. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1037, in get_data. MemoryError. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mappi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:11481,deployability,fail,failed,11481,"e. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 57, in <module>. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1037, in get_data. MemoryError. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 22. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:12264,deployability,fail,failed,12264,"ap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1037, in get_data. MemoryError. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 22. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 24. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:13047,deployability,fail,failed,13047,elds --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 22. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 24. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 39. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:13830,deployability,fail,failed,13830,elds --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 24. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 39. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 52. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:14613,deployability,fail,failed,14613,elds --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 39. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 52. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 57. real	0m4.925s. user	0m4.781s. sys	0m19.092s. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by u,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:15706,deployability,version,version,15706, --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 39. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 52. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 57. real	0m4.925s. user	0m4.781s. sys	0m19.092s. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Did not face this error in DeepVariant version: 1.5.0.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:260,energy efficiency,alloc,allocation,260,"Memory issue while running deepvariant_1.6.0.sif with ONT_R104 ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. Python encountered a MemoryError, no matter how much we increase the memory allocation the error exists. **Setup**. - Operating system:. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): apptainer pull docker://google/deepvariant:""1.6.1"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) bam files, ONT. **Steps to reproduce:**. - Command: . apptainer exec --bind /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint /work/XXXX/ls6/deepvariant/deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant --model_type ONT_R104 --ref /work/XXXX/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/XXXX/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --output_vcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.vcf.gz --output_gvcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.g.vcf.gz --num_shards 64 --logging_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/ --intermediate_results_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_goog",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:3270,energy efficiency,core,core,3270,"l/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 144, in <module>. from ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:3327,energy efficiency,core,core,3327,"2, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 144, in <module>. from . import lib. File ""/usr/local/lib/python3.8/dist-package",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:10984,energy efficiency,core,core,10984,"e(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 57, in <module>. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1037, in get_data. MemoryError. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:335,integrability,version,version,335,"Memory issue while running deepvariant_1.6.0.sif with ONT_R104 ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. Python encountered a MemoryError, no matter how much we increase the memory allocation the error exists. **Setup**. - Operating system:. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): apptainer pull docker://google/deepvariant:""1.6.1"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) bam files, ONT. **Steps to reproduce:**. - Command: . apptainer exec --bind /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint /work/XXXX/ls6/deepvariant/deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant --model_type ONT_R104 --ref /work/XXXX/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/XXXX/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --output_vcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.vcf.gz --output_gvcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.g.vcf.gz --num_shards 64 --logging_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/ --intermediate_results_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_goog",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:5985,integrability,version,version,5985,"dule>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:6027,integrability,Version,Version,6027,"es_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:6120,integrability,version,version,6120,"examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryEr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:6146,integrability,Version,Version,6146,", in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recen",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:9276,integrability,version,version,9276,"mples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:9356,integrability,version,version,9356,"e ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:9398,integrability,Version,Version,9398,"om_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:9491,integrability,version,version,9491,"ant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryEr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:9517,integrability,Version,Version,9517,"y. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recen",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:15706,integrability,version,version,15706, --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 39. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 52. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 57. real	0m4.925s. user	0m4.781s. sys	0m19.092s. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Did not face this error in DeepVariant version: 1.5.0.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:640,interoperability,bind,bind,640,"Memory issue while running deepvariant_1.6.0.sif with ONT_R104 ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. Python encountered a MemoryError, no matter how much we increase the memory allocation the error exists. **Setup**. - Operating system:. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): apptainer pull docker://google/deepvariant:""1.6.1"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) bam files, ONT. **Steps to reproduce:**. - Command: . apptainer exec --bind /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint /work/XXXX/ls6/deepvariant/deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant --model_type ONT_R104 --ref /work/XXXX/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/XXXX/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --output_vcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.vcf.gz --output_gvcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.g.vcf.gz --num_shards 64 --logging_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/ --intermediate_results_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_goog",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:1604,interoperability,standard,standard,1604,". - Command: . apptainer exec --bind /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint /work/XXXX/ls6/deepvariant/deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant --model_type ONT_R104 --ref /work/XXXX/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/XXXX/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --output_vcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.vcf.gz --output_gvcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.g.vcf.gz --num_shards 64 --logging_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/ --intermediate_results_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:1889,interoperability,standard,standard,1889,"/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --output_vcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.vcf.gz --output_gvcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.g.vcf.gz --num_shards 64 --logging_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/ --intermediate_results_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:2808,interoperability,share,shared,2808,"re supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:335,modifiability,version,version,335,"Memory issue while running deepvariant_1.6.0.sif with ONT_R104 ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. Python encountered a MemoryError, no matter how much we increase the memory allocation the error exists. **Setup**. - Operating system:. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): apptainer pull docker://google/deepvariant:""1.6.1"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) bam files, ONT. **Steps to reproduce:**. - Command: . apptainer exec --bind /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint /work/XXXX/ls6/deepvariant/deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant --model_type ONT_R104 --ref /work/XXXX/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/XXXX/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --output_vcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.vcf.gz --output_gvcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.g.vcf.gz --num_shards 64 --logging_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/ --intermediate_results_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_goog",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:640,modifiability,bind,bind,640,"Memory issue while running deepvariant_1.6.0.sif with ONT_R104 ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. Python encountered a MemoryError, no matter how much we increase the memory allocation the error exists. **Setup**. - Operating system:. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): apptainer pull docker://google/deepvariant:""1.6.1"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) bam files, ONT. **Steps to reproduce:**. - Command: . apptainer exec --bind /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint /work/XXXX/ls6/deepvariant/deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant --model_type ONT_R104 --ref /work/XXXX/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/XXXX/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --output_vcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.vcf.gz --output_gvcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.g.vcf.gz --num_shards 64 --logging_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/ --intermediate_results_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_goog",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:2059,modifiability,modul,module,2059,"9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.g.vcf.gz --num_shards 64 --logging_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/ --intermediate_results_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:2228,modifiability,modul,module,2228,"/scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:2293,modifiability,pac,packages,2293,"e_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:2336,modifiability,modul,module,2336," . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:2403,modifiability,pac,packages,2403," that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<fro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:2453,modifiability,modul,module,2453,". 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_an",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:2521,modifiability,pac,packages,2521,"are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:2568,modifiability,modul,module,2568,"rl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootst",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:2709,modifiability,pac,packages,2709,"tings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:2970,modifiability,modul,module,2970,"_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:3139,modifiability,modul,module,3139,"cqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:3204,modifiability,pac,packages,3204,"e.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:3247,modifiability,modul,module,3247,"as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:3312,modifiability,pac,packages,3312,".py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 144, in <module>. from . import lib. File ""/usr/local/lib/python3.8",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:3360,modifiability,modul,module,3360,"om. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 144, in <module>. from . import lib. File ""/usr/local/lib/python3.8/dist-packages/numpy/lib/__init__.py"", line 34,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:3981,modifiability,modul,module,3981,"deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 144, in <module>. from . import lib. File ""/usr/local/lib/python3.8/dist-packages/numpy/lib/__init__.py"", line 34, in <module>. from . import polynomial. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:4150,modifiability,modul,module,4150,"t numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 144, in <module>. from . import lib. File ""/usr/local/lib/python3.8/dist-packages/numpy/lib/__init__.py"", line 34, in <module>. from . import polynomial. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:4215,modifiability,pac,packages,4215,"__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 144, in <module>. from . import lib. File ""/usr/local/lib/python3.8/dist-packages/numpy/lib/__init__.py"", line 34, in <module>. from . import polynomial. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/B",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:4258,modifiability,modul,module,4258,". import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 144, in <module>. from . import lib. File ""/usr/local/lib/python3.8/dist-packages/numpy/lib/__init__.py"", line 34, in <module>. from . import polynomial. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:4322,modifiability,pac,packages,4322,"/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 144, in <module>. from . import lib. File ""/usr/local/lib/python3.8/dist-packages/numpy/lib/__init__.py"", line 34, in <module>. from . import polynomial. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <modul",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:4368,modifiability,modul,module,4368,"om . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 144, in <module>. from . import lib. File ""/usr/local/lib/python3.8/dist-packages/numpy/lib/__init__.py"", line 34, in <module>. from . import polynomial. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. F",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:4987,modifiability,modul,module,4987,"from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 144, in <module>. from . import lib. File ""/usr/local/lib/python3.8/dist-packages/numpy/lib/__init__.py"", line 34, in <module>. from . import polynomial. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/versi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:5156,modifiability,modul,module,5156,"import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 144, in <module>. from . import lib. File ""/usr/local/lib/python3.8/dist-packages/numpy/lib/__init__.py"", line 34, in <module>. from . import polynomial. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _reg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:5321,modifiability,modul,module,5321,"ckages/numpy/lib/__init__.py"", line 34, in <module>. from . import polynomial. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p =",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:5482,modifiability,modul,module,5482,"mportlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:5668,modifiability,modul,module,5668,"n exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_comp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:5768,modifiability,pac,packages,5768,"portlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:5820,modifiability,modul,module,5820,"ta. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:5857,modifiability,pac,packages,5857,"t call last):. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:5907,modifiability,modul,module,5907,"/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:5944,modifiability,pac,packages,5944,"ariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:5975,modifiability,pac,packaging,5975,"8, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, to",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:5985,modifiability,version,version,5985,"dule>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:6012,modifiability,modul,module,6012,"port make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/pytho",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:6027,modifiability,Version,Version,6027,"es_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:6079,modifiability,pac,packages,6079,"/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = byte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:6110,modifiability,pac,packaging,6110,"ant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:6120,modifiability,version,version,6120,"examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryEr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:6146,modifiability,Version,Version,6146,", in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recen",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:7276,modifiability,modul,module,7276,"/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 151, in <module>. from . import polynomial. File ""/usr/local/lib/python3.8/dist-packages/numpy/polynomial/__init__.py"", line 120, in <module>. from .hermite_e import HermiteE. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_ex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:7445,modifiability,modul,module,7445,". File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 151, in <module>. from . import polynomial. File ""/usr/local/lib/python3.8/dist-packages/numpy/polynomial/__init__.py"", line 120, in <module>. from .hermite_e import HermiteE. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_example",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:7510,modifiability,pac,packages,7510,"ompile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 151, in <module>. from . import polynomial. File ""/usr/local/lib/python3.8/dist-packages/numpy/polynomial/__init__.py"", line 120, in <module>. from .hermite_e import HermiteE. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:7553,modifiability,modul,module,7553,"b/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 151, in <module>. from . import polynomial. File ""/usr/local/lib/python3.8/dist-packages/numpy/polynomial/__init__.py"", line 120, in <module>. from .hermite_e import HermiteE. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmd",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:7624,modifiability,pac,packages,7624,", flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 151, in <module>. from . import polynomial. File ""/usr/local/lib/python3.8/dist-packages/numpy/polynomial/__init__.py"", line 120, in <module>. from .hermite_e import HermiteE. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:7678,modifiability,modul,module,7678,"ine 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 151, in <module>. from . import polynomial. File ""/usr/local/lib/python3.8/dist-packages/numpy/polynomial/__init__.py"", line 120, in <module>. from .hermite_e import HermiteE. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:8304,modifiability,modul,module,8304,"t make_examples_core. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 151, in <module>. from . import polynomial. File ""/usr/local/lib/python3.8/dist-packages/numpy/polynomial/__init__.py"", line 120, in <module>. from .hermite_e import HermiteE. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/pytho",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:8473,modifiability,modul,module,8473,"le ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 151, in <module>. from . import polynomial. File ""/usr/local/lib/python3.8/dist-packages/numpy/polynomial/__init__.py"", line 120, in <module>. from .hermite_e import HermiteE. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_ve",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:8638,modifiability,modul,module,8638,"lynomial/__init__.py"", line 120, in <module>. from .hermite_e import HermiteE. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:8799,modifiability,modul,module,8799,"mportlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:8985,modifiability,modul,module,8985,"n exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:9085,modifiability,pac,packages,9085,"portlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:9137,modifiability,modul,module,9137,"ta. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). Fi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:9174,modifiability,pac,packages,9174,"t call last):. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:9224,modifiability,modul,module,9224,"/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], fl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:9266,modifiability,pac,packaging,9266,"/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:9276,modifiability,version,version,9276,"mples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:9315,modifiability,pac,packages,9315,"eepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:9346,modifiability,pac,packaging,9346,"core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, to",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:9356,modifiability,version,version,9356,"e ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:9383,modifiability,modul,module,9383,"gmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/pytho",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:9398,modifiability,Version,Version,9398,"om_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:9450,modifiability,pac,packages,9450,".py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = byte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:9481,modifiability,pac,packaging,9481," deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:9491,modifiability,version,version,9491,"ant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryEr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:9517,modifiability,Version,Version,9517,"y. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recen",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:10647,modifiability,modul,module,10647,"/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 57, in <module>. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1037, in get_data. MemoryError. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:10816,modifiability,modul,module,10816,". File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 57, in <module>. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1037, in get_data. MemoryError. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:10881,modifiability,pac,packages,10881,"ompile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 57, in <module>. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1037, in get_data. MemoryError. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/095",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:10924,modifiability,modul,module,10924,"b/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 57, in <module>. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1037, in get_data. MemoryError. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:10969,modifiability,pac,packages,10969,"pile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 57, in <module>. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1037, in get_data. MemoryError. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@6",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:11016,modifiability,modul,module,11016,"/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 57, in <module>. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1037, in get_data. MemoryError. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mappi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:15706,modifiability,version,version,15706, --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 39. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 52. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 57. real	0m4.925s. user	0m4.781s. sys	0m19.092s. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Did not face this error in DeepVariant version: 1.5.0.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:0,performance,Memor,Memory,0,"Memory issue while running deepvariant_1.6.0.sif with ONT_R104 ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. Python encountered a MemoryError, no matter how much we increase the memory allocation the error exists. **Setup**. - Operating system:. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): apptainer pull docker://google/deepvariant:""1.6.1"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) bam files, ONT. **Steps to reproduce:**. - Command: . apptainer exec --bind /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint /work/XXXX/ls6/deepvariant/deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant --model_type ONT_R104 --ref /work/XXXX/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/XXXX/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --output_vcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.vcf.gz --output_gvcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.g.vcf.gz --num_shards 64 --logging_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/ --intermediate_results_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_goog",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:205,performance,Memor,MemoryError,205,"Memory issue while running deepvariant_1.6.0.sif with ONT_R104 ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. Python encountered a MemoryError, no matter how much we increase the memory allocation the error exists. **Setup**. - Operating system:. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): apptainer pull docker://google/deepvariant:""1.6.1"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) bam files, ONT. **Steps to reproduce:**. - Command: . apptainer exec --bind /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint /work/XXXX/ls6/deepvariant/deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant --model_type ONT_R104 --ref /work/XXXX/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/XXXX/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --output_vcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.vcf.gz --output_gvcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.g.vcf.gz --num_shards 64 --logging_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/ --intermediate_results_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_goog",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:253,performance,memor,memory,253,"Memory issue while running deepvariant_1.6.0.sif with ONT_R104 ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. Python encountered a MemoryError, no matter how much we increase the memory allocation the error exists. **Setup**. - Operating system:. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): apptainer pull docker://google/deepvariant:""1.6.1"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) bam files, ONT. **Steps to reproduce:**. - Command: . apptainer exec --bind /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint /work/XXXX/ls6/deepvariant/deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant --model_type ONT_R104 --ref /work/XXXX/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/XXXX/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --output_vcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.vcf.gz --output_gvcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.g.vcf.gz --num_shards 64 --logging_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/ --intermediate_results_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_goog",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:275,performance,error,error,275,"Memory issue while running deepvariant_1.6.0.sif with ONT_R104 ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. Python encountered a MemoryError, no matter how much we increase the memory allocation the error exists. **Setup**. - Operating system:. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): apptainer pull docker://google/deepvariant:""1.6.1"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) bam files, ONT. **Steps to reproduce:**. - Command: . apptainer exec --bind /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint /work/XXXX/ls6/deepvariant/deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant --model_type ONT_R104 --ref /work/XXXX/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/XXXX/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --output_vcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.vcf.gz --output_gvcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.g.vcf.gz --num_shards 64 --logging_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/ --intermediate_results_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_goog",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:1310,performance,Error,Error,1310,"ystem:. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): apptainer pull docker://google/deepvariant:""1.6.1"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) bam files, ONT. **Steps to reproduce:**. - Command: . apptainer exec --bind /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint /work/XXXX/ls6/deepvariant/deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant --model_type ONT_R104 --ref /work/XXXX/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/XXXX/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --output_vcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.vcf.gz --output_gvcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.g.vcf.gz --num_shards 64 --logging_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/ --intermediate_results_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__ini",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:3821,performance,Memor,MemoryError,3821,"eback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 144, in <module>. from . import lib. File ""/usr/local/lib/python3.8/dist-packages/numpy/lib/__init__.py"", line 34, in <module>. from . import polynomial. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:4827,performance,Memor,MemoryError,4827," Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 144, in <module>. from . import lib. File ""/usr/local/lib/python3.8/dist-packages/numpy/lib/__init__.py"", line 34, in <module>. from . import polynomial. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:7116,performance,Memor,MemoryError,7116,"rsion.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 151, in <module>. from . import polynomial. File ""/usr/local/lib/python3.8/dist-packages/numpy/polynomial/__init__.py"", line 120, in <module>. from .hermite_e import HermiteE. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", li",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:8144,performance,Memor,MemoryError,8144,"t call last):. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 151, in <module>. from . import polynomial. File ""/usr/local/lib/python3.8/dist-packages/numpy/polynomial/__init__.py"", line 120, in <module>. from .hermite_e import HermiteE. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:10487,performance,Memor,MemoryError,10487,"rsion.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 57, in <module>. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1037, in get_data. MemoryError. parallel: This job failed:. /op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:11449,performance,Memor,MemoryError,11449,"(charmap) # should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 57, in <module>. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1037, in get_data. MemoryError. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 22. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:11462,performance,parallel,parallel,11462," should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 57, in <module>. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1037, in get_data. MemoryError. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 22. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:12245,performance,parallel,parallel,12245,"importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1037, in get_data. MemoryError. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 22. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 24. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:13028,performance,parallel,parallel,13028,--parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 22. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 24. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 39. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr1,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:13811,performance,parallel,parallel,13811,--parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 24. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 39. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 52. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr1,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:14594,performance,parallel,parallel,14594,--parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 39. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 52. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 57. real	0m4.925s. user	0m4.781s. sys	0m19.092s. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reprod,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:15685,performance,error,error,15685, --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 39. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 52. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 57. real	0m4.925s. user	0m4.781s. sys	0m19.092s. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Did not face this error in DeepVariant version: 1.5.0.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:1372,reliability,fail,failed,1372,"ocker, built from source, etc.): apptainer pull docker://google/deepvariant:""1.6.1"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) bam files, ONT. **Steps to reproduce:**. - Command: . apptainer exec --bind /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint /work/XXXX/ls6/deepvariant/deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant --model_type ONT_R104 --ref /work/XXXX/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/XXXX/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --output_vcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.vcf.gz --output_gvcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.g.vcf.gz --num_shards 64 --logging_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/ --intermediate_results_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/u",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:1657,reliability,fail,failed,1657,"NT_WGS/HH/FL9-1_deepvaraint /work/XXXX/ls6/deepvariant/deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant --model_type ONT_R104 --ref /work/XXXX/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/XXXX/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --output_vcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.vcf.gz --output_gvcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.g.vcf.gz --num_shards 64 --logging_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/ --intermediate_results_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:2781,reliability,fail,failed,2781,",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:11481,reliability,fail,failed,11481,"e. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 57, in <module>. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1037, in get_data. MemoryError. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 22. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:12264,reliability,fail,failed,12264,"ap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1037, in get_data. MemoryError. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 22. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 24. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:13047,reliability,fail,failed,13047,elds --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 22. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 24. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 39. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:13830,reliability,fail,failed,13830,elds --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 24. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 39. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 52. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:14613,reliability,fail,failed,14613,elds --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 39. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 52. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 57. real	0m4.925s. user	0m4.781s. sys	0m19.092s. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by u,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:15424,reliability,Doe,Does,15424, --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 39. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 52. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 57. real	0m4.925s. user	0m4.781s. sys	0m19.092s. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Did not face this error in DeepVariant version: 1.5.0.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:275,safety,error,error,275,"Memory issue while running deepvariant_1.6.0.sif with ONT_R104 ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. Python encountered a MemoryError, no matter how much we increase the memory allocation the error exists. **Setup**. - Operating system:. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): apptainer pull docker://google/deepvariant:""1.6.1"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) bam files, ONT. **Steps to reproduce:**. - Command: . apptainer exec --bind /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint /work/XXXX/ls6/deepvariant/deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant --model_type ONT_R104 --ref /work/XXXX/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/XXXX/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --output_vcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.vcf.gz --output_gvcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.g.vcf.gz --num_shards 64 --logging_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/ --intermediate_results_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_goog",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:1310,safety,Error,Error,1310,"ystem:. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): apptainer pull docker://google/deepvariant:""1.6.1"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) bam files, ONT. **Steps to reproduce:**. - Command: . apptainer exec --bind /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint /work/XXXX/ls6/deepvariant/deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant --model_type ONT_R104 --ref /work/XXXX/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/XXXX/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --output_vcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.vcf.gz --output_gvcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.g.vcf.gz --num_shards 64 --logging_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/ --intermediate_results_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__ini",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:2059,safety,modul,module,2059,"9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.g.vcf.gz --num_shards 64 --logging_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/ --intermediate_results_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:2228,safety,modul,module,2228,"/scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:2336,safety,modul,module,2336," . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:2453,safety,modul,module,2453,". 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_an",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:2568,safety,modul,module,2568,"rl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootst",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:2970,safety,modul,module,2970,"_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:3139,safety,modul,module,3139,"cqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:3247,safety,modul,module,3247,"as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:3360,safety,modul,module,3360,"om. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 144, in <module>. from . import lib. File ""/usr/local/lib/python3.8/dist-packages/numpy/lib/__init__.py"", line 34,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:3981,safety,modul,module,3981,"deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 144, in <module>. from . import lib. File ""/usr/local/lib/python3.8/dist-packages/numpy/lib/__init__.py"", line 34, in <module>. from . import polynomial. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:4150,safety,modul,module,4150,"t numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 144, in <module>. from . import lib. File ""/usr/local/lib/python3.8/dist-packages/numpy/lib/__init__.py"", line 34, in <module>. from . import polynomial. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:4258,safety,modul,module,4258,". import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 144, in <module>. from . import lib. File ""/usr/local/lib/python3.8/dist-packages/numpy/lib/__init__.py"", line 34, in <module>. from . import polynomial. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:4368,safety,modul,module,4368,"om . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 144, in <module>. from . import lib. File ""/usr/local/lib/python3.8/dist-packages/numpy/lib/__init__.py"", line 34, in <module>. from . import polynomial. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. F",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:4987,safety,modul,module,4987,"from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 144, in <module>. from . import lib. File ""/usr/local/lib/python3.8/dist-packages/numpy/lib/__init__.py"", line 34, in <module>. from . import polynomial. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/versi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:5156,safety,modul,module,5156,"import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 144, in <module>. from . import lib. File ""/usr/local/lib/python3.8/dist-packages/numpy/lib/__init__.py"", line 34, in <module>. from . import polynomial. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _reg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:5321,safety,modul,module,5321,"ckages/numpy/lib/__init__.py"", line 34, in <module>. from . import polynomial. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p =",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:5482,safety,modul,module,5482,"mportlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:5668,safety,modul,module,5668,"n exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_comp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:5820,safety,modul,module,5820,"ta. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:5907,safety,modul,module,5907,"/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:6012,safety,modul,module,6012,"port make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/pytho",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:7276,safety,modul,module,7276,"/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 151, in <module>. from . import polynomial. File ""/usr/local/lib/python3.8/dist-packages/numpy/polynomial/__init__.py"", line 120, in <module>. from .hermite_e import HermiteE. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_ex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:7445,safety,modul,module,7445,". File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 151, in <module>. from . import polynomial. File ""/usr/local/lib/python3.8/dist-packages/numpy/polynomial/__init__.py"", line 120, in <module>. from .hermite_e import HermiteE. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_example",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:7553,safety,modul,module,7553,"b/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 151, in <module>. from . import polynomial. File ""/usr/local/lib/python3.8/dist-packages/numpy/polynomial/__init__.py"", line 120, in <module>. from .hermite_e import HermiteE. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmd",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:7678,safety,modul,module,7678,"ine 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 151, in <module>. from . import polynomial. File ""/usr/local/lib/python3.8/dist-packages/numpy/polynomial/__init__.py"", line 120, in <module>. from .hermite_e import HermiteE. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:8304,safety,modul,module,8304,"t make_examples_core. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 151, in <module>. from . import polynomial. File ""/usr/local/lib/python3.8/dist-packages/numpy/polynomial/__init__.py"", line 120, in <module>. from .hermite_e import HermiteE. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/pytho",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:8473,safety,modul,module,8473,"le ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 151, in <module>. from . import polynomial. File ""/usr/local/lib/python3.8/dist-packages/numpy/polynomial/__init__.py"", line 120, in <module>. from .hermite_e import HermiteE. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_ve",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:8638,safety,modul,module,8638,"lynomial/__init__.py"", line 120, in <module>. from .hermite_e import HermiteE. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:8799,safety,modul,module,8799,"mportlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:8985,safety,modul,module,8985,"n exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:9137,safety,modul,module,9137,"ta. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). Fi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:9224,safety,modul,module,9224,"/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], fl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:9383,safety,modul,module,9383,"gmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/python3/dist-packages/pkg_resources/__init__.py"", line 82, in <module>. __import__('pkg_resources.extern.packaging.version'). File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 191, in <module>. class Version(_BaseVersion):. File ""/usr/lib/python3/dist-packages/pkg_resources/_vendor/packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/pytho",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:10647,safety,modul,module,10647,"/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 57, in <module>. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1037, in get_data. MemoryError. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:10816,safety,modul,module,10816,". File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 57, in <module>. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1037, in get_data. MemoryError. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:10924,safety,modul,module,10924,"b/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 57, in <module>. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1037, in get_data. MemoryError. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:11016,safety,modul,module,11016,"/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 57, in <module>. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1037, in get_data. MemoryError. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mappi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:15445,safety,test,test,15445, --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 39. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 52. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 57. real	0m4.925s. user	0m4.781s. sys	0m19.092s. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Did not face this error in DeepVariant version: 1.5.0.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:15481,safety,test,test,15481, --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 39. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 52. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 57. real	0m4.925s. user	0m4.781s. sys	0m19.092s. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Did not face this error in DeepVariant version: 1.5.0.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:15685,safety,error,error,15685, --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 39. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 52. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 57. real	0m4.925s. user	0m4.781s. sys	0m19.092s. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Did not face this error in DeepVariant version: 1.5.0.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:7106,security,hash,hashable,7106,"packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 151, in <module>. from . import polynomial. File ""/usr/local/lib/python3.8/dist-packages/numpy/polynomial/__init__.py"", line 120, in <module>. from .hermite_e import HermiteE. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_ex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:10477,security,hash,hashable,10477,"packaging/version.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 57, in <module>. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1037, in get_data. MemoryError. parallel: This job ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:488,testability,instrument,instrument,488,"Memory issue while running deepvariant_1.6.0.sif with ONT_R104 ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. Python encountered a MemoryError, no matter how much we increase the memory allocation the error exists. **Setup**. - Operating system:. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): apptainer pull docker://google/deepvariant:""1.6.1"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) bam files, ONT. **Steps to reproduce:**. - Command: . apptainer exec --bind /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint /work/XXXX/ls6/deepvariant/deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant --model_type ONT_R104 --ref /work/XXXX/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/XXXX/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --output_vcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.vcf.gz --output_gvcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.g.vcf.gz --num_shards 64 --logging_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/ --intermediate_results_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_goog",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:1316,testability,trace,trace,1316,". - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): apptainer pull docker://google/deepvariant:""1.6.1"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) bam files, ONT. **Steps to reproduce:**. - Command: . apptainer exec --bind /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint /work/XXXX/ls6/deepvariant/deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant --model_type ONT_R104 --ref /work/XXXX/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/XXXX/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --output_vcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.vcf.gz --output_gvcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.g.vcf.gz --num_shards 64 --logging_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/ --intermediate_results_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:1912,testability,Trace,Traceback,1912,"chr10.bam --output_vcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.vcf.gz --output_gvcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.g.vcf.gz --num_shards 64 --logging_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/ --intermediate_results_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_dee",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:2823,testability,Trace,Traceback,2823,"installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared object. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:3834,testability,Trace,Traceback,3834,"recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 144, in <module>. from . import lib. File ""/usr/local/lib/python3.8/dist-packages/numpy/lib/__init__.py"", line 34, in <module>. from . import polynomial. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:4840,testability,Trace,Traceback,4840,"most recent call last):. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 144, in <module>. from . import lib. File ""/usr/local/lib/python3.8/dist-packages/numpy/lib/__init__.py"", line 34, in <module>. from . import polynomial. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:7129,testability,Trace,Traceback,7129,"ine 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 151, in <module>. from . import polynomial. File ""/usr/local/lib/python3.8/dist-packages/numpy/polynomial/__init__.py"", line 120, in <module>. from .hermite_e import HermiteE. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:8157,testability,Trace,Traceback,8157,":. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 151, in <module>. from . import polynomial. File ""/usr/local/lib/python3.8/dist-packages/numpy/polynomial/__init__.py"", line 120, in <module>. from .hermite_e import HermiteE. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File ""/usr/lib/p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:10500,testability,Trace,Traceback,10500,"ine 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 57, in <module>. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1037, in get_data. MemoryError. parallel: This job failed:. /opt/deepvarian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:15445,testability,test,test,15445, --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 39. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 52. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 57. real	0m4.925s. user	0m4.781s. sys	0m19.092s. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Did not face this error in DeepVariant version: 1.5.0.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:15481,testability,test,test,15481, --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 39. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 52. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 57. real	0m4.925s. user	0m4.781s. sys	0m19.092s. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Did not face this error in DeepVariant version: 1.5.0.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:15655,testability,context,context,15655, --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 39. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 52. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 57. real	0m4.925s. user	0m4.781s. sys	0m19.092s. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Did not face this error in DeepVariant version: 1.5.0.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:0,usability,Memor,Memory,0,"Memory issue while running deepvariant_1.6.0.sif with ONT_R104 ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. Python encountered a MemoryError, no matter how much we increase the memory allocation the error exists. **Setup**. - Operating system:. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): apptainer pull docker://google/deepvariant:""1.6.1"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) bam files, ONT. **Steps to reproduce:**. - Command: . apptainer exec --bind /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint /work/XXXX/ls6/deepvariant/deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant --model_type ONT_R104 --ref /work/XXXX/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/XXXX/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --output_vcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.vcf.gz --output_gvcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.g.vcf.gz --num_shards 64 --logging_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/ --intermediate_results_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_goog",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:205,usability,Memor,MemoryError,205,"Memory issue while running deepvariant_1.6.0.sif with ONT_R104 ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. Python encountered a MemoryError, no matter how much we increase the memory allocation the error exists. **Setup**. - Operating system:. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): apptainer pull docker://google/deepvariant:""1.6.1"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) bam files, ONT. **Steps to reproduce:**. - Command: . apptainer exec --bind /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint /work/XXXX/ls6/deepvariant/deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant --model_type ONT_R104 --ref /work/XXXX/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/XXXX/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --output_vcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.vcf.gz --output_gvcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.g.vcf.gz --num_shards 64 --logging_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/ --intermediate_results_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_goog",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:253,usability,memor,memory,253,"Memory issue while running deepvariant_1.6.0.sif with ONT_R104 ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. Python encountered a MemoryError, no matter how much we increase the memory allocation the error exists. **Setup**. - Operating system:. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): apptainer pull docker://google/deepvariant:""1.6.1"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) bam files, ONT. **Steps to reproduce:**. - Command: . apptainer exec --bind /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint /work/XXXX/ls6/deepvariant/deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant --model_type ONT_R104 --ref /work/XXXX/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/XXXX/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --output_vcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.vcf.gz --output_gvcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.g.vcf.gz --num_shards 64 --logging_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/ --intermediate_results_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_goog",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:275,usability,error,error,275,"Memory issue while running deepvariant_1.6.0.sif with ONT_R104 ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. Python encountered a MemoryError, no matter how much we increase the memory allocation the error exists. **Setup**. - Operating system:. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): apptainer pull docker://google/deepvariant:""1.6.1"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) bam files, ONT. **Steps to reproduce:**. - Command: . apptainer exec --bind /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint /work/XXXX/ls6/deepvariant/deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant --model_type ONT_R104 --ref /work/XXXX/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/XXXX/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --output_vcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.vcf.gz --output_gvcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.g.vcf.gz --num_shards 64 --logging_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/ --intermediate_results_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_goog",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:612,usability,Command,Command,612,"Memory issue while running deepvariant_1.6.0.sif with ONT_R104 ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. Python encountered a MemoryError, no matter how much we increase the memory allocation the error exists. **Setup**. - Operating system:. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): apptainer pull docker://google/deepvariant:""1.6.1"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) bam files, ONT. **Steps to reproduce:**. - Command: . apptainer exec --bind /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint /work/XXXX/ls6/deepvariant/deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant --model_type ONT_R104 --ref /work/XXXX/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/XXXX/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --output_vcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.vcf.gz --output_gvcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.g.vcf.gz --num_shards 64 --logging_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/ --intermediate_results_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_goog",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:1310,usability,Error,Error,1310,"ystem:. - DeepVariant version: 1.6.0. - Installation method (Docker, built from source, etc.): apptainer pull docker://google/deepvariant:""1.6.1"". - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) bam files, ONT. **Steps to reproduce:**. - Command: . apptainer exec --bind /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint /work/XXXX/ls6/deepvariant/deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant --model_type ONT_R104 --ref /work/XXXX/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/XXXX/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --output_vcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.vcf.gz --output_gvcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.g.vcf.gz --num_shards 64 --logging_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/ --intermediate_results_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__ini",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:1529,usability,support,supported,1529," that is unlike the case studies?) bam files, ONT. **Steps to reproduce:**. - Command: . apptainer exec --bind /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint /work/XXXX/ls6/deepvariant/deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant --model_type ONT_R104 --ref /work/XXXX/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/XXXX/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --output_vcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.vcf.gz --output_gvcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.g.vcf.gz --num_shards 64 --logging_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/ --intermediate_results_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/nump",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:1814,usability,support,supported,1814,"ommon/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/XXXX/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --output_vcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.vcf.gz --output_gvcf /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/FL9-1_chr10.output.g.vcf.gz --num_shards 64 --logging_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/ --intermediate_results_dir /scratch/XXXX/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results. - Error trace: (if applicable). . perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). perl: warning: Setting locale failed. perl: warning: Please check that your locale settings:. 	LANGUAGE = (unset),. 	LC_ALL = (unset),. 	LC_CTYPE = ""C.UTF-8"",. 	LANG = ""en_US.UTF-8"". are supported and installed on your system. perl: warning: Falling back to the standard locale (""C""). Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2p_bcqtz/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 152, in <module>. from . import random. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/__init__.py"", line 180, in <module>. from . import _pickle. File ""/usr/local/lib/python3.8/dist-packages/numpy/random/_pickle.py"", line 1, in <module>. from .mtrand import RandomState. File ""mtrand.pyx"", line 1, in init numpy.random.mtrand. ImportError: /usr/local/lib/python3.8/dist-packages/numpy/random/_bounded_integers.cpython-38-x86_64-linux-gnu.so: failed to map segment from shared obje",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:3821,usability,Memor,MemoryError,3821,"eback (most recent call last):. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_rd22bn15/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. from . import core. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 101, in <module>. from . import _add_newdocs. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 144, in <module>. from . import lib. File ""/usr/local/lib/python3.8/dist-packages/numpy/lib/__init__.py"", line 34, in <module>. from . import polynomial. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:4827,usability,Memor,MemoryError,4827," Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles__l7njte_/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 144, in <module>. from . import lib. File ""/usr/local/lib/python3.8/dist-packages/numpy/lib/__init__.py"", line 34, in <module>. from . import polynomial. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_2dnpe5cn/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:7116,usability,Memor,MemoryError,7116,"rsion.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 151, in <module>. from . import polynomial. File ""/usr/local/lib/python3.8/dist-packages/numpy/polynomial/__init__.py"", line 120, in <module>. from .hermite_e import HermiteE. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", li",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:8144,usability,Memor,MemoryError,8144,"t call last):. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_3qjgcvn2/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 151, in <module>. from . import polynomial. File ""/usr/local/lib/python3.8/dist-packages/numpy/polynomial/__init__.py"", line 120, in <module>. from .hermite_e import HermiteE. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1038, in get_data. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 46, in <module>. from deepvariant import allele_frequency. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/deepvariant/allele_frequency.py"", line 36, in <module>. from third_party.nucleus.io import vcf. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 83, in <module>. from third_party.nucleus.protos import variants_pb2. File ""/tmp/Bazel.runfiles_chdgmdtc/runfiles/com_google_deepvariant/third_party/nucleus/protos/variants_pb2.py"", line 7, in <module>. from google.protobuf import descriptor as _descriptor. File ""/usr/local/lib/python3.8/dist-packages/google/protobuf/__init__.py"", line 37, in <module>. File",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:10487,usability,Memor,MemoryError,10487,"rsion.py"", line 193, in Version. _regex = re.compile(. File ""/usr/lib/python3.8/re.py"", line 252, in compile. return _compile(pattern, flags). File ""/usr/lib/python3.8/re.py"", line 304, in _compile. p = sre_compile.compile(pattern, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 768, in compile. code = _code(p, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 607, in _code. _compile(code, p.data, flags). File ""/usr/lib/python3.8/sre_compile.py"", line 156, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 168, in _compile. _compile(code, p, _combine_flags(flags, add_flags, del_flags)). File ""/usr/lib/python3.8/sre_compile.py"", line 148, in _compile. _compile(code, av[2], flags). File ""/usr/lib/python3.8/sre_compile.py"", line 120, in _compile. charset, hascased = _optimize_charset(av, iscased, tolower, fixes). File ""/usr/lib/python3.8/sre_compile.py"", line 389, in _optimize_charset. charmap = bytes(charmap) # should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 57, in <module>. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1037, in get_data. MemoryError. parallel: This job failed:. /op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:11449,usability,Memor,MemoryError,11449,"(charmap) # should be hashable. MemoryError. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 38, in <module>. from deepvariant import make_examples_core. File ""/tmp/Bazel.runfiles_wycra2sl/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 43, in <module>. import numpy as np. File ""/usr/local/lib/python3.8/dist-packages/numpy/__init__.py"", line 141, in <module>. File ""/usr/local/lib/python3.8/dist-packages/numpy/core/__init__.py"", line 57, in <module>. File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load. File ""<frozen importlib._bootstrap>"", line 975, in _find_and_load_unlocked. File ""<frozen importlib._bootstrap>"", line 671, in _load_unlocked. File ""<frozen importlib._bootstrap_external>"", line 844, in exec_module. File ""<frozen importlib._bootstrap_external>"", line 939, in get_code. File ""<frozen importlib._bootstrap_external>"", line 1037, in get_data. MemoryError. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 22. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:15392,usability,user,user,15392, --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 39. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 52. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 57. real	0m4.925s. user	0m4.781s. sys	0m19.092s. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Did not face this error in DeepVariant version: 1.5.0.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:15685,usability,error,error,15685, --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 39. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 52. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/09505/s223885/data/common/human/hg38bundle/Homo_sapiens_assembly38.fasta --reads /scratch/09505/s223885/ONT_WGS/HH/FL9-1/FL9-1.chr10.bam --examples /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/make_examples.tfrecord@64.gz --add_hp_channel --alt_aligned_pileup diff_channels --gvcf /scratch/09505/s223885/ONT_WGS/HH/FL9-1_deepvaraint/FL9-1/chr10/intermediate_results/gvcf.tfrecord@64.gz --max_reads_per_partition 600 --min_mapping_quality 5 --parse_sam_aux_fields --partition_size 25000 --phase_reads --pileup_image_width 199 --norealign_reads --sort_by_haplotypes --track_ref_reads --vsc_min_fraction_indels 0.12 --vsc_min_fraction_snps 0.08 --task 57. real	0m4.925s. user	0m4.781s. sys	0m19.092s. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Did not face this error in DeepVariant version: 1.5.0.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/855:313,availability,Operat,Operating,313,"Program always run; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**: YES. **Describe the issue:** . 1. When the input sequence (fastq) matches the reference sequence, the program will keep running. 2. Sequence obtain from data generation tools. (dwgsim) . **Setup**. - Operating system: Red Hat Enterprise Linux release 8.6 (Ootpa). - DeepVariant version: deepvariant1.6.0.sif. - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). GRCh38| (Sequence obtain from data generation tools. (dwgsim) length,8-9kB, 150bp, PE, sequence may the same as reference sequence) . **Steps to reproduce:**. - Command: . time singularity run ~/singularity/deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${bamSavePath}/${name}.sorted.bam \. --output_vcf ${vcf} \. --output_gvcf ${outputPath}/vcf/${name}/${name}.g.vcf.gz \. --num_shards $(nproc) \. --regions ${BED} \. --sample_name ${name} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"" . - Error trace: (if applicable). I0729 14:44:37.339473 140223721211712 make_examples_core.py:301] Task 0/4: Preparing inputs. I0729 14:44:37.339473 140478861559616 make_examples_core.py:301] Task 3/4: Preparing inputs. I0729 14:44:37.350302 140710547908416 make_examples_core.py:301] Task 1/4: Preparing inputs. I0729 14:44:37.339477 139779121772352 make_examples_core.py:301] Task 2/4: Preparing inputs. I0729 14:44:37.476220 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.485832 140223721211712 make_examples_core.py:301] Task 0/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:1221,availability,Error,Error,1221,"ill keep running. 2. Sequence obtain from data generation tools. (dwgsim) . **Setup**. - Operating system: Red Hat Enterprise Linux release 8.6 (Ootpa). - DeepVariant version: deepvariant1.6.0.sif. - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). GRCh38| (Sequence obtain from data generation tools. (dwgsim) length,8-9kB, 150bp, PE, sequence may the same as reference sequence) . **Steps to reproduce:**. - Command: . time singularity run ~/singularity/deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${bamSavePath}/${name}.sorted.bam \. --output_vcf ${vcf} \. --output_gvcf ${outputPath}/vcf/${name}/${name}.g.vcf.gz \. --num_shards $(nproc) \. --regions ${BED} \. --sample_name ${name} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"" . - Error trace: (if applicable). I0729 14:44:37.339473 140223721211712 make_examples_core.py:301] Task 0/4: Preparing inputs. I0729 14:44:37.339473 140478861559616 make_examples_core.py:301] Task 3/4: Preparing inputs. I0729 14:44:37.350302 140710547908416 make_examples_core.py:301] Task 1/4: Preparing inputs. I0729 14:44:37.339477 139779121772352 make_examples_core.py:301] Task 2/4: Preparing inputs. I0729 14:44:37.476220 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.485832 140223721211712 make_examples_core.py:301] Task 0/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0729 14:44:37.533100 140223721211712 genomics_reader.py:222] Reading /lustre/home/acct-m",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:11591,availability,checkpoint,checkpoint,11591,".899687 140710547908416 make_examples_core.py:301] Task 1/4: Found 0 candidate variants. I0729 14:44:37.899752 140710547908416 make_examples_core.py:301] Task 1/4: Created 0 examples. I0729 14:44:37.893192 139779121772352 make_examples_core.py:301] Task 2/4: Writing example info to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00002-of-00004.gz.example_info.json. I0729 14:44:37.893293 139779121772352 make_examples_core.py:2958] example_shape = None. I0729 14:44:37.893665 139779121772352 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0729 14:44:37.894033 139779121772352 make_examples_core.py:301] Task 2/4: Found 0 candidate variants. I0729 14:44:37.894105 139779121772352 make_examples_core.py:301] Task 2/4: Created 0 examples. real	0m4.791s. user	0m11.503s. sys	0m2.085s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpkcjcf0p_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wes"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0729 14:44:41.088234 139722246891328 call_variants.py:471] Total 1 writing processes started. W0729 14:44:41.090612 139722246891328 call_variants.py:482] Unable to read any records from /tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz. Output will contain zero records. I0729 14:44:41.091079 139722246891328 call_variants.py:623] Complete: call_variants. **Does the quick start test work on your system?**. yes. **Any additional context:**. Some samples work fine",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:11824,availability,mainten,maintenance,11824,"e.py:301] Task 1/4: Found 0 candidate variants. I0729 14:44:37.899752 140710547908416 make_examples_core.py:301] Task 1/4: Created 0 examples. I0729 14:44:37.893192 139779121772352 make_examples_core.py:301] Task 2/4: Writing example info to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00002-of-00004.gz.example_info.json. I0729 14:44:37.893293 139779121772352 make_examples_core.py:2958] example_shape = None. I0729 14:44:37.893665 139779121772352 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0729 14:44:37.894033 139779121772352 make_examples_core.py:301] Task 2/4: Found 0 candidate variants. I0729 14:44:37.894105 139779121772352 make_examples_core.py:301] Task 2/4: Created 0 examples. real	0m4.791s. user	0m11.503s. sys	0m2.085s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpkcjcf0p_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wes"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0729 14:44:41.088234 139722246891328 call_variants.py:471] Total 1 writing processes started. W0729 14:44:41.090612 139722246891328 call_variants.py:482] Unable to read any records from /tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz. Output will contain zero records. I0729 14:44:41.091079 139722246891328 call_variants.py:623] Complete: call_variants. **Does the quick start test work on your system?**. yes. **Any additional context:**. Some samples work fine, some very similar samples keep running.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:11908,availability,down,downstream,11908,"e.py:301] Task 1/4: Found 0 candidate variants. I0729 14:44:37.899752 140710547908416 make_examples_core.py:301] Task 1/4: Created 0 examples. I0729 14:44:37.893192 139779121772352 make_examples_core.py:301] Task 2/4: Writing example info to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00002-of-00004.gz.example_info.json. I0729 14:44:37.893293 139779121772352 make_examples_core.py:2958] example_shape = None. I0729 14:44:37.893665 139779121772352 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0729 14:44:37.894033 139779121772352 make_examples_core.py:301] Task 2/4: Found 0 candidate variants. I0729 14:44:37.894105 139779121772352 make_examples_core.py:301] Task 2/4: Created 0 examples. real	0m4.791s. user	0m11.503s. sys	0m2.085s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpkcjcf0p_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wes"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0729 14:44:41.088234 139722246891328 call_variants.py:471] Total 1 writing processes started. W0729 14:44:41.090612 139722246891328 call_variants.py:482] Unable to read any records from /tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz. Output will contain zero records. I0729 14:44:41.091079 139722246891328 call_variants.py:623] Complete: call_variants. **Does the quick start test work on your system?**. yes. **Any additional context:**. Some samples work fine, some very similar samples keep running.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:356,deployability,releas,release,356,"Program always run; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**: YES. **Describe the issue:** . 1. When the input sequence (fastq) matches the reference sequence, the program will keep running. 2. Sequence obtain from data generation tools. (dwgsim) . **Setup**. - Operating system: Red Hat Enterprise Linux release 8.6 (Ootpa). - DeepVariant version: deepvariant1.6.0.sif. - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). GRCh38| (Sequence obtain from data generation tools. (dwgsim) length,8-9kB, 150bp, PE, sequence may the same as reference sequence) . **Steps to reproduce:**. - Command: . time singularity run ~/singularity/deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${bamSavePath}/${name}.sorted.bam \. --output_vcf ${vcf} \. --output_gvcf ${outputPath}/vcf/${name}/${name}.g.vcf.gz \. --num_shards $(nproc) \. --regions ${BED} \. --sample_name ${name} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"" . - Error trace: (if applicable). I0729 14:44:37.339473 140223721211712 make_examples_core.py:301] Task 0/4: Preparing inputs. I0729 14:44:37.339473 140478861559616 make_examples_core.py:301] Task 3/4: Preparing inputs. I0729 14:44:37.350302 140710547908416 make_examples_core.py:301] Task 1/4: Preparing inputs. I0729 14:44:37.339477 139779121772352 make_examples_core.py:301] Task 2/4: Preparing inputs. I0729 14:44:37.476220 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.485832 140223721211712 make_examples_core.py:301] Task 0/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:391,deployability,version,version,391,"Program always run; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**: YES. **Describe the issue:** . 1. When the input sequence (fastq) matches the reference sequence, the program will keep running. 2. Sequence obtain from data generation tools. (dwgsim) . **Setup**. - Operating system: Red Hat Enterprise Linux release 8.6 (Ootpa). - DeepVariant version: deepvariant1.6.0.sif. - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). GRCh38| (Sequence obtain from data generation tools. (dwgsim) length,8-9kB, 150bp, PE, sequence may the same as reference sequence) . **Steps to reproduce:**. - Command: . time singularity run ~/singularity/deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${bamSavePath}/${name}.sorted.bam \. --output_vcf ${vcf} \. --output_gvcf ${outputPath}/vcf/${name}/${name}.g.vcf.gz \. --num_shards $(nproc) \. --regions ${BED} \. --sample_name ${name} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"" . - Error trace: (if applicable). I0729 14:44:37.339473 140223721211712 make_examples_core.py:301] Task 0/4: Preparing inputs. I0729 14:44:37.339473 140478861559616 make_examples_core.py:301] Task 3/4: Preparing inputs. I0729 14:44:37.350302 140710547908416 make_examples_core.py:301] Task 1/4: Preparing inputs. I0729 14:44:37.339477 139779121772352 make_examples_core.py:301] Task 2/4: Preparing inputs. I0729 14:44:37.476220 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.485832 140223721211712 make_examples_core.py:301] Task 0/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:424,deployability,Instal,Installation,424,"Program always run; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**: YES. **Describe the issue:** . 1. When the input sequence (fastq) matches the reference sequence, the program will keep running. 2. Sequence obtain from data generation tools. (dwgsim) . **Setup**. - Operating system: Red Hat Enterprise Linux release 8.6 (Ootpa). - DeepVariant version: deepvariant1.6.0.sif. - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). GRCh38| (Sequence obtain from data generation tools. (dwgsim) length,8-9kB, 150bp, PE, sequence may the same as reference sequence) . **Steps to reproduce:**. - Command: . time singularity run ~/singularity/deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${bamSavePath}/${name}.sorted.bam \. --output_vcf ${vcf} \. --output_gvcf ${outputPath}/vcf/${name}/${name}.g.vcf.gz \. --num_shards $(nproc) \. --regions ${BED} \. --sample_name ${name} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"" . - Error trace: (if applicable). I0729 14:44:37.339473 140223721211712 make_examples_core.py:301] Task 0/4: Preparing inputs. I0729 14:44:37.339473 140478861559616 make_examples_core.py:301] Task 3/4: Preparing inputs. I0729 14:44:37.350302 140710547908416 make_examples_core.py:301] Task 1/4: Preparing inputs. I0729 14:44:37.339477 139779121772352 make_examples_core.py:301] Task 2/4: Preparing inputs. I0729 14:44:37.476220 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.485832 140223721211712 make_examples_core.py:301] Task 0/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:11840,deployability,releas,release,11840,"e.py:301] Task 1/4: Found 0 candidate variants. I0729 14:44:37.899752 140710547908416 make_examples_core.py:301] Task 1/4: Created 0 examples. I0729 14:44:37.893192 139779121772352 make_examples_core.py:301] Task 2/4: Writing example info to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00002-of-00004.gz.example_info.json. I0729 14:44:37.893293 139779121772352 make_examples_core.py:2958] example_shape = None. I0729 14:44:37.893665 139779121772352 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0729 14:44:37.894033 139779121772352 make_examples_core.py:301] Task 2/4: Found 0 candidate variants. I0729 14:44:37.894105 139779121772352 make_examples_core.py:301] Task 2/4: Created 0 examples. real	0m4.791s. user	0m11.503s. sys	0m2.085s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpkcjcf0p_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wes"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0729 14:44:41.088234 139722246891328 call_variants.py:471] Total 1 writing processes started. W0729 14:44:41.090612 139722246891328 call_variants.py:482] Unable to read any records from /tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz. Output will contain zero records. I0729 14:44:41.091079 139722246891328 call_variants.py:623] Complete: call_variants. **Does the quick start test work on your system?**. yes. **Any additional context:**. Some samples work fine, some very similar samples keep running.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:11937,deployability,depend,dependencies,11937,"e.py:301] Task 1/4: Found 0 candidate variants. I0729 14:44:37.899752 140710547908416 make_examples_core.py:301] Task 1/4: Created 0 examples. I0729 14:44:37.893192 139779121772352 make_examples_core.py:301] Task 2/4: Writing example info to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00002-of-00004.gz.example_info.json. I0729 14:44:37.893293 139779121772352 make_examples_core.py:2958] example_shape = None. I0729 14:44:37.893665 139779121772352 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0729 14:44:37.894033 139779121772352 make_examples_core.py:301] Task 2/4: Found 0 candidate variants. I0729 14:44:37.894105 139779121772352 make_examples_core.py:301] Task 2/4: Created 0 examples. real	0m4.791s. user	0m11.503s. sys	0m2.085s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpkcjcf0p_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wes"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0729 14:44:41.088234 139722246891328 call_variants.py:471] Total 1 writing processes started. W0729 14:44:41.090612 139722246891328 call_variants.py:482] Unable to read any records from /tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz. Output will contain zero records. I0729 14:44:41.091079 139722246891328 call_variants.py:623] Complete: call_variants. **Does the quick start test work on your system?**. yes. **Any additional context:**. Some samples work fine, some very similar samples keep running.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:12381,deployability,contain,contain,12381,"e.py:301] Task 1/4: Found 0 candidate variants. I0729 14:44:37.899752 140710547908416 make_examples_core.py:301] Task 1/4: Created 0 examples. I0729 14:44:37.893192 139779121772352 make_examples_core.py:301] Task 2/4: Writing example info to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00002-of-00004.gz.example_info.json. I0729 14:44:37.893293 139779121772352 make_examples_core.py:2958] example_shape = None. I0729 14:44:37.893665 139779121772352 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0729 14:44:37.894033 139779121772352 make_examples_core.py:301] Task 2/4: Found 0 candidate variants. I0729 14:44:37.894105 139779121772352 make_examples_core.py:301] Task 2/4: Created 0 examples. real	0m4.791s. user	0m11.503s. sys	0m2.085s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpkcjcf0p_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wes"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0729 14:44:41.088234 139722246891328 call_variants.py:471] Total 1 writing processes started. W0729 14:44:41.090612 139722246891328 call_variants.py:482] Unable to read any records from /tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz. Output will contain zero records. I0729 14:44:41.091079 139722246891328 call_variants.py:623] Complete: call_variants. **Does the quick start test work on your system?**. yes. **Any additional context:**. Some samples work fine, some very similar samples keep running.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:11608,energy efficiency,model,models,11608,"47908416 make_examples_core.py:301] Task 1/4: Found 0 candidate variants. I0729 14:44:37.899752 140710547908416 make_examples_core.py:301] Task 1/4: Created 0 examples. I0729 14:44:37.893192 139779121772352 make_examples_core.py:301] Task 2/4: Writing example info to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00002-of-00004.gz.example_info.json. I0729 14:44:37.893293 139779121772352 make_examples_core.py:2958] example_shape = None. I0729 14:44:37.893665 139779121772352 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0729 14:44:37.894033 139779121772352 make_examples_core.py:301] Task 2/4: Found 0 candidate variants. I0729 14:44:37.894105 139779121772352 make_examples_core.py:301] Task 2/4: Created 0 examples. real	0m4.791s. user	0m11.503s. sys	0m2.085s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpkcjcf0p_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wes"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0729 14:44:41.088234 139722246891328 call_variants.py:471] Total 1 writing processes started. W0729 14:44:41.090612 139722246891328 call_variants.py:482] Unable to read any records from /tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz. Output will contain zero records. I0729 14:44:41.091079 139722246891328 call_variants.py:623] Complete: call_variants. **Does the quick start test work on your system?**. yes. **Any additional context:**. Some samples work fine, some very sim",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:391,integrability,version,version,391,"Program always run; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**: YES. **Describe the issue:** . 1. When the input sequence (fastq) matches the reference sequence, the program will keep running. 2. Sequence obtain from data generation tools. (dwgsim) . **Setup**. - Operating system: Red Hat Enterprise Linux release 8.6 (Ootpa). - DeepVariant version: deepvariant1.6.0.sif. - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). GRCh38| (Sequence obtain from data generation tools. (dwgsim) length,8-9kB, 150bp, PE, sequence may the same as reference sequence) . **Steps to reproduce:**. - Command: . time singularity run ~/singularity/deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${bamSavePath}/${name}.sorted.bam \. --output_vcf ${vcf} \. --output_gvcf ${outputPath}/vcf/${name}/${name}.g.vcf.gz \. --num_shards $(nproc) \. --regions ${BED} \. --sample_name ${name} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"" . - Error trace: (if applicable). I0729 14:44:37.339473 140223721211712 make_examples_core.py:301] Task 0/4: Preparing inputs. I0729 14:44:37.339473 140478861559616 make_examples_core.py:301] Task 3/4: Preparing inputs. I0729 14:44:37.350302 140710547908416 make_examples_core.py:301] Task 1/4: Preparing inputs. I0729 14:44:37.339477 139779121772352 make_examples_core.py:301] Task 2/4: Preparing inputs. I0729 14:44:37.476220 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.485832 140223721211712 make_examples_core.py:301] Task 0/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:11937,integrability,depend,dependencies,11937,"e.py:301] Task 1/4: Found 0 candidate variants. I0729 14:44:37.899752 140710547908416 make_examples_core.py:301] Task 1/4: Created 0 examples. I0729 14:44:37.893192 139779121772352 make_examples_core.py:301] Task 2/4: Writing example info to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00002-of-00004.gz.example_info.json. I0729 14:44:37.893293 139779121772352 make_examples_core.py:2958] example_shape = None. I0729 14:44:37.893665 139779121772352 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0729 14:44:37.894033 139779121772352 make_examples_core.py:301] Task 2/4: Found 0 candidate variants. I0729 14:44:37.894105 139779121772352 make_examples_core.py:301] Task 2/4: Created 0 examples. real	0m4.791s. user	0m11.503s. sys	0m2.085s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpkcjcf0p_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wes"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0729 14:44:41.088234 139722246891328 call_variants.py:471] Total 1 writing processes started. W0729 14:44:41.090612 139722246891328 call_variants.py:482] Unable to read any records from /tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz. Output will contain zero records. I0729 14:44:41.091079 139722246891328 call_variants.py:623] Complete: call_variants. **Does the quick start test work on your system?**. yes. **Any additional context:**. Some samples work fine, some very similar samples keep running.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:11961,integrability,repositor,repositories,11961,"e.py:301] Task 1/4: Found 0 candidate variants. I0729 14:44:37.899752 140710547908416 make_examples_core.py:301] Task 1/4: Created 0 examples. I0729 14:44:37.893192 139779121772352 make_examples_core.py:301] Task 2/4: Writing example info to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00002-of-00004.gz.example_info.json. I0729 14:44:37.893293 139779121772352 make_examples_core.py:2958] example_shape = None. I0729 14:44:37.893665 139779121772352 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0729 14:44:37.894033 139779121772352 make_examples_core.py:301] Task 2/4: Found 0 candidate variants. I0729 14:44:37.894105 139779121772352 make_examples_core.py:301] Task 2/4: Created 0 examples. real	0m4.791s. user	0m11.503s. sys	0m2.085s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpkcjcf0p_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wes"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0729 14:44:41.088234 139722246891328 call_variants.py:471] Total 1 writing processes started. W0729 14:44:41.090612 139722246891328 call_variants.py:482] Unable to read any records from /tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz. Output will contain zero records. I0729 14:44:41.091079 139722246891328 call_variants.py:623] Complete: call_variants. **Does the quick start test work on your system?**. yes. **Any additional context:**. Some samples work fine, some very similar samples keep running.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:11961,interoperability,repositor,repositories,11961,"e.py:301] Task 1/4: Found 0 candidate variants. I0729 14:44:37.899752 140710547908416 make_examples_core.py:301] Task 1/4: Created 0 examples. I0729 14:44:37.893192 139779121772352 make_examples_core.py:301] Task 2/4: Writing example info to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00002-of-00004.gz.example_info.json. I0729 14:44:37.893293 139779121772352 make_examples_core.py:2958] example_shape = None. I0729 14:44:37.893665 139779121772352 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0729 14:44:37.894033 139779121772352 make_examples_core.py:301] Task 2/4: Found 0 candidate variants. I0729 14:44:37.894105 139779121772352 make_examples_core.py:301] Task 2/4: Created 0 examples. real	0m4.791s. user	0m11.503s. sys	0m2.085s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpkcjcf0p_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wes"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0729 14:44:41.088234 139722246891328 call_variants.py:471] Total 1 writing processes started. W0729 14:44:41.090612 139722246891328 call_variants.py:482] Unable to read any records from /tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz. Output will contain zero records. I0729 14:44:41.091079 139722246891328 call_variants.py:623] Complete: call_variants. **Does the quick start test work on your system?**. yes. **Any additional context:**. Some samples work fine, some very similar samples keep running.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:391,modifiability,version,version,391,"Program always run; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**: YES. **Describe the issue:** . 1. When the input sequence (fastq) matches the reference sequence, the program will keep running. 2. Sequence obtain from data generation tools. (dwgsim) . **Setup**. - Operating system: Red Hat Enterprise Linux release 8.6 (Ootpa). - DeepVariant version: deepvariant1.6.0.sif. - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). GRCh38| (Sequence obtain from data generation tools. (dwgsim) length,8-9kB, 150bp, PE, sequence may the same as reference sequence) . **Steps to reproduce:**. - Command: . time singularity run ~/singularity/deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${bamSavePath}/${name}.sorted.bam \. --output_vcf ${vcf} \. --output_gvcf ${outputPath}/vcf/${name}/${name}.g.vcf.gz \. --num_shards $(nproc) \. --regions ${BED} \. --sample_name ${name} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"" . - Error trace: (if applicable). I0729 14:44:37.339473 140223721211712 make_examples_core.py:301] Task 0/4: Preparing inputs. I0729 14:44:37.339473 140478861559616 make_examples_core.py:301] Task 3/4: Preparing inputs. I0729 14:44:37.350302 140710547908416 make_examples_core.py:301] Task 1/4: Preparing inputs. I0729 14:44:37.339477 139779121772352 make_examples_core.py:301] Task 2/4: Preparing inputs. I0729 14:44:37.476220 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.485832 140223721211712 make_examples_core.py:301] Task 0/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:2482,modifiability,deco,decode,2482,"les_core.py:301] Task 1/4: Preparing inputs. I0729 14:44:37.339477 139779121772352 make_examples_core.py:301] Task 2/4: Preparing inputs. I0729 14:44:37.476220 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.485832 140223721211712 make_examples_core.py:301] Task 0/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0729 14:44:37.533100 140223721211712 genomics_reader.py:222] Reading /lustre/home/acct-medfzx/medfzx-lkw/project/CAH/data/BED/cah_noname.bed with NativeBedReader. I0729 14:44:37.541654 140223721211712 make_examples_core.py:301] Task 0/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0729 14:44:37.543606 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.620779 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.620978 140223721211712 make_examples_core.py:301] Task 0/4: Writing gvcf records to /tmp/tmpkcjcf0p_/gvcf.tfrecord-00000-of-00004.gz. I0729 14:44:37.621363 140223721211712 make_examples_core.py:301] Task 0/4: Writing examples to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00000-of-00004.gz. I0729 14:44:37.621420 140223721211712 make_examples_core.py:301] Task 0/4: Overhead for preparing inputs: 0 seconds. I0729 14:44:37.652796 140223721211712 make_examples_core.py:301] Task 0/4: 0 candidates (0 examples) [0.03s elapsed]. I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:4343,modifiability,deco,decode,4343," inputs: 0 seconds. I0729 14:44:37.652796 140223721211712 make_examples_core.py:301] Task 0/4: 0 candidates (0 examples) [0.03s elapsed]. I0729 14:44:37.476214 140478861559616 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.485823 140478861559616 make_examples_core.py:301] Task 3/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0729 14:44:37.533152 140478861559616 genomics_reader.py:222] Reading /lustre/home/acct-medfzx/medfzx-lkw/project/CAH/data/BED/cah_noname.bed with NativeBedReader. I0729 14:44:37.541796 140478861559616 make_examples_core.py:301] Task 3/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0729 14:44:37.543756 140478861559616 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.619259 140478861559616 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.619429 140478861559616 make_examples_core.py:301] Task 3/4: Writing gvcf records to /tmp/tmpkcjcf0p_/gvcf.tfrecord-00003-of-00004.gz. I0729 14:44:37.619812 140478861559616 make_examples_core.py:301] Task 3/4: Writing examples to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00003-of-00004.gz. I0729 14:44:37.619867 140478861559616 make_examples_core.py:301] Task 3/4: Overhead for preparing inputs: 0 seconds. I0729 14:44:37.653389 140478861559616 make_examples_core.py:301] Task 3/4: 0 candidates (0 examples) [0.03s elapsed]. I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:6204,modifiability,deco,decode,6204," inputs: 0 seconds. I0729 14:44:37.653389 140478861559616 make_examples_core.py:301] Task 3/4: 0 candidates (0 examples) [0.03s elapsed]. I0729 14:44:37.476402 140710547908416 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.486019 140710547908416 make_examples_core.py:301] Task 1/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0729 14:44:37.533221 140710547908416 genomics_reader.py:222] Reading /lustre/home/acct-medfzx/medfzx-lkw/project/CAH/data/BED/cah_noname.bed with NativeBedReader. I0729 14:44:37.541869 140710547908416 make_examples_core.py:301] Task 1/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0729 14:44:37.543881 140710547908416 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.619640 140710547908416 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.619808 140710547908416 make_examples_core.py:301] Task 1/4: Writing gvcf records to /tmp/tmpkcjcf0p_/gvcf.tfrecord-00001-of-00004.gz. I0729 14:44:37.620180 140710547908416 make_examples_core.py:301] Task 1/4: Writing examples to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00001-of-00004.gz. I0729 14:44:37.620236 140710547908416 make_examples_core.py:301] Task 1/4: Overhead for preparing inputs: 0 seconds. I0729 14:44:37.652904 140710547908416 make_examples_core.py:301] Task 1/4: 0 candidates (0 examples) [0.03s elapsed]. I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:8065,modifiability,deco,decode,8065," inputs: 0 seconds. I0729 14:44:37.652904 140710547908416 make_examples_core.py:301] Task 1/4: 0 candidates (0 examples) [0.03s elapsed]. I0729 14:44:37.476840 139779121772352 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.486504 139779121772352 make_examples_core.py:301] Task 2/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0729 14:44:37.533215 139779121772352 genomics_reader.py:222] Reading /lustre/home/acct-medfzx/medfzx-lkw/project/CAH/data/BED/cah_noname.bed with NativeBedReader. I0729 14:44:37.541668 139779121772352 make_examples_core.py:301] Task 2/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0729 14:44:37.543754 139779121772352 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.624524 139779121772352 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.624701 139779121772352 make_examples_core.py:301] Task 2/4: Writing gvcf records to /tmp/tmpkcjcf0p_/gvcf.tfrecord-00002-of-00004.gz. I0729 14:44:37.625109 139779121772352 make_examples_core.py:301] Task 2/4: Writing examples to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00002-of-00004.gz. I0729 14:44:37.625170 139779121772352 make_examples_core.py:301] Task 2/4: Overhead for preparing inputs: 0 seconds. I0729 14:44:37.653617 139779121772352 make_examples_core.py:301] Task 2/4: 0 candidates (0 examples) [0.03s elapsed]. I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:11651,modifiability,pac,packages,11651,"e.py:301] Task 1/4: Found 0 candidate variants. I0729 14:44:37.899752 140710547908416 make_examples_core.py:301] Task 1/4: Created 0 examples. I0729 14:44:37.893192 139779121772352 make_examples_core.py:301] Task 2/4: Writing example info to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00002-of-00004.gz.example_info.json. I0729 14:44:37.893293 139779121772352 make_examples_core.py:2958] example_shape = None. I0729 14:44:37.893665 139779121772352 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0729 14:44:37.894033 139779121772352 make_examples_core.py:301] Task 2/4: Found 0 candidate variants. I0729 14:44:37.894105 139779121772352 make_examples_core.py:301] Task 2/4: Created 0 examples. real	0m4.791s. user	0m11.503s. sys	0m2.085s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpkcjcf0p_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wes"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0729 14:44:41.088234 139722246891328 call_variants.py:471] Total 1 writing processes started. W0729 14:44:41.090612 139722246891328 call_variants.py:482] Unable to read any records from /tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz. Output will contain zero records. I0729 14:44:41.091079 139722246891328 call_variants.py:623] Complete: call_variants. **Does the quick start test work on your system?**. yes. **Any additional context:**. Some samples work fine, some very similar samples keep running.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:11937,modifiability,depend,dependencies,11937,"e.py:301] Task 1/4: Found 0 candidate variants. I0729 14:44:37.899752 140710547908416 make_examples_core.py:301] Task 1/4: Created 0 examples. I0729 14:44:37.893192 139779121772352 make_examples_core.py:301] Task 2/4: Writing example info to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00002-of-00004.gz.example_info.json. I0729 14:44:37.893293 139779121772352 make_examples_core.py:2958] example_shape = None. I0729 14:44:37.893665 139779121772352 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0729 14:44:37.894033 139779121772352 make_examples_core.py:301] Task 2/4: Found 0 candidate variants. I0729 14:44:37.894105 139779121772352 make_examples_core.py:301] Task 2/4: Created 0 examples. real	0m4.791s. user	0m11.503s. sys	0m2.085s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpkcjcf0p_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wes"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0729 14:44:41.088234 139722246891328 call_variants.py:471] Total 1 writing processes started. W0729 14:44:41.090612 139722246891328 call_variants.py:482] Unable to read any records from /tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz. Output will contain zero records. I0729 14:44:41.091079 139722246891328 call_variants.py:623] Complete: call_variants. **Does the quick start test work on your system?**. yes. **Any additional context:**. Some samples work fine, some very similar samples keep running.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:775,performance,time,time,775,"Program always run; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**: YES. **Describe the issue:** . 1. When the input sequence (fastq) matches the reference sequence, the program will keep running. 2. Sequence obtain from data generation tools. (dwgsim) . **Setup**. - Operating system: Red Hat Enterprise Linux release 8.6 (Ootpa). - DeepVariant version: deepvariant1.6.0.sif. - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). GRCh38| (Sequence obtain from data generation tools. (dwgsim) length,8-9kB, 150bp, PE, sequence may the same as reference sequence) . **Steps to reproduce:**. - Command: . time singularity run ~/singularity/deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${bamSavePath}/${name}.sorted.bam \. --output_vcf ${vcf} \. --output_gvcf ${outputPath}/vcf/${name}/${name}.g.vcf.gz \. --num_shards $(nproc) \. --regions ${BED} \. --sample_name ${name} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"" . - Error trace: (if applicable). I0729 14:44:37.339473 140223721211712 make_examples_core.py:301] Task 0/4: Preparing inputs. I0729 14:44:37.339473 140478861559616 make_examples_core.py:301] Task 3/4: Preparing inputs. I0729 14:44:37.350302 140710547908416 make_examples_core.py:301] Task 1/4: Preparing inputs. I0729 14:44:37.339477 139779121772352 make_examples_core.py:301] Task 2/4: Preparing inputs. I0729 14:44:37.476220 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.485832 140223721211712 make_examples_core.py:301] Task 0/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:1221,performance,Error,Error,1221,"ill keep running. 2. Sequence obtain from data generation tools. (dwgsim) . **Setup**. - Operating system: Red Hat Enterprise Linux release 8.6 (Ootpa). - DeepVariant version: deepvariant1.6.0.sif. - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). GRCh38| (Sequence obtain from data generation tools. (dwgsim) length,8-9kB, 150bp, PE, sequence may the same as reference sequence) . **Steps to reproduce:**. - Command: . time singularity run ~/singularity/deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${bamSavePath}/${name}.sorted.bam \. --output_vcf ${vcf} \. --output_gvcf ${outputPath}/vcf/${name}/${name}.g.vcf.gz \. --num_shards $(nproc) \. --regions ${BED} \. --sample_name ${name} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"" . - Error trace: (if applicable). I0729 14:44:37.339473 140223721211712 make_examples_core.py:301] Task 0/4: Preparing inputs. I0729 14:44:37.339473 140478861559616 make_examples_core.py:301] Task 3/4: Preparing inputs. I0729 14:44:37.350302 140710547908416 make_examples_core.py:301] Task 1/4: Preparing inputs. I0729 14:44:37.339477 139779121772352 make_examples_core.py:301] Task 2/4: Preparing inputs. I0729 14:44:37.476220 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.485832 140223721211712 make_examples_core.py:301] Task 0/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0729 14:44:37.533100 140223721211712 genomics_reader.py:222] Reading /lustre/home/acct-m",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:3324,performance,Overhead,Overhead,3324,"21211712 make_examples_core.py:301] Task 0/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0729 14:44:37.543606 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.620779 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.620978 140223721211712 make_examples_core.py:301] Task 0/4: Writing gvcf records to /tmp/tmpkcjcf0p_/gvcf.tfrecord-00000-of-00004.gz. I0729 14:44:37.621363 140223721211712 make_examples_core.py:301] Task 0/4: Writing examples to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00000-of-00004.gz. I0729 14:44:37.621420 140223721211712 make_examples_core.py:301] Task 0/4: Overhead for preparing inputs: 0 seconds. I0729 14:44:37.652796 140223721211712 make_examples_core.py:301] Task 0/4: 0 candidates (0 examples) [0.03s elapsed]. I0729 14:44:37.476214 140478861559616 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.485823 140478861559616 make_examples_core.py:301] Task 3/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0729 14:44:37.533152 140478861559616 genomics_reader.py:222] Reading /lustre/home/acct-medfzx/medfzx-lkw/project/CAH/data/BED/cah_noname.bed with NativeBedReader. I0729 14:44:37.541796 140478861559616 make_examples_core.py:301] Task 3/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, not",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:5185,performance,Overhead,Overhead,5185,"61559616 make_examples_core.py:301] Task 3/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0729 14:44:37.543756 140478861559616 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.619259 140478861559616 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.619429 140478861559616 make_examples_core.py:301] Task 3/4: Writing gvcf records to /tmp/tmpkcjcf0p_/gvcf.tfrecord-00003-of-00004.gz. I0729 14:44:37.619812 140478861559616 make_examples_core.py:301] Task 3/4: Writing examples to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00003-of-00004.gz. I0729 14:44:37.619867 140478861559616 make_examples_core.py:301] Task 3/4: Overhead for preparing inputs: 0 seconds. I0729 14:44:37.653389 140478861559616 make_examples_core.py:301] Task 3/4: 0 candidates (0 examples) [0.03s elapsed]. I0729 14:44:37.476402 140710547908416 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.486019 140710547908416 make_examples_core.py:301] Task 1/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0729 14:44:37.533221 140710547908416 genomics_reader.py:222] Reading /lustre/home/acct-medfzx/medfzx-lkw/project/CAH/data/BED/cah_noname.bed with NativeBedReader. I0729 14:44:37.541869 140710547908416 make_examples_core.py:301] Task 1/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, not",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:7046,performance,Overhead,Overhead,7046,"47908416 make_examples_core.py:301] Task 1/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0729 14:44:37.543881 140710547908416 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.619640 140710547908416 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.619808 140710547908416 make_examples_core.py:301] Task 1/4: Writing gvcf records to /tmp/tmpkcjcf0p_/gvcf.tfrecord-00001-of-00004.gz. I0729 14:44:37.620180 140710547908416 make_examples_core.py:301] Task 1/4: Writing examples to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00001-of-00004.gz. I0729 14:44:37.620236 140710547908416 make_examples_core.py:301] Task 1/4: Overhead for preparing inputs: 0 seconds. I0729 14:44:37.652904 140710547908416 make_examples_core.py:301] Task 1/4: 0 candidates (0 examples) [0.03s elapsed]. I0729 14:44:37.476840 139779121772352 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.486504 139779121772352 make_examples_core.py:301] Task 2/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0729 14:44:37.533215 139779121772352 genomics_reader.py:222] Reading /lustre/home/acct-medfzx/medfzx-lkw/project/CAH/data/BED/cah_noname.bed with NativeBedReader. I0729 14:44:37.541668 139779121772352 make_examples_core.py:301] Task 2/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, not",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:8907,performance,Overhead,Overhead,8907,"21772352 make_examples_core.py:301] Task 2/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0729 14:44:37.543754 139779121772352 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.624524 139779121772352 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.624701 139779121772352 make_examples_core.py:301] Task 2/4: Writing gvcf records to /tmp/tmpkcjcf0p_/gvcf.tfrecord-00002-of-00004.gz. I0729 14:44:37.625109 139779121772352 make_examples_core.py:301] Task 2/4: Writing examples to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00002-of-00004.gz. I0729 14:44:37.625170 139779121772352 make_examples_core.py:301] Task 2/4: Overhead for preparing inputs: 0 seconds. I0729 14:44:37.653617 139779121772352 make_examples_core.py:301] Task 2/4: 0 candidates (0 examples) [0.03s elapsed]. I0729 14:44:37.898170 140223721211712 make_examples_core.py:301] Task 0/4: Writing example info to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00000-of-00004.gz.example_info.json. I0729 14:44:37.898274 140223721211712 make_examples_core.py:2958] example_shape = None. I0729 14:44:37.898649 140223721211712 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0729 14:44:37.899018 140223721211712 make_examples_core.py:301] Task 0/4: Found 0 candidate variants. I0729 14:44:37.899082 140223721211712 make_examples_core.py:301] Task 0/4: Created 0 examples. I0729 14:44:37.898826 140478861559616 make_examples_core.py:301] Task 3/4: Writing example info to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00003-of-00004.gz.example_info.json. I0729 14:44:37.898957 140478861559616 make_examples_core.py:2958] example_shape = None. I0729 14:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:11429,performance,time,time,11429,"mples_core.py:2958] example_shape = None. I0729 14:44:37.899351 140710547908416 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0729 14:44:37.899687 140710547908416 make_examples_core.py:301] Task 1/4: Found 0 candidate variants. I0729 14:44:37.899752 140710547908416 make_examples_core.py:301] Task 1/4: Created 0 examples. I0729 14:44:37.893192 139779121772352 make_examples_core.py:301] Task 2/4: Writing example info to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00002-of-00004.gz.example_info.json. I0729 14:44:37.893293 139779121772352 make_examples_core.py:2958] example_shape = None. I0729 14:44:37.893665 139779121772352 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0729 14:44:37.894033 139779121772352 make_examples_core.py:301] Task 2/4: Found 0 candidate variants. I0729 14:44:37.894105 139779121772352 make_examples_core.py:301] Task 2/4: Created 0 examples. real	0m4.791s. user	0m11.503s. sys	0m2.085s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpkcjcf0p_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wes"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0729 14:44:41.088234 139722246891328 call_variants.py:471] Total 1 writing processes started. W0729 14:44:41.090612 139722246891328 call_variants.py:482] Unable to read any records from /tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz. Output will contain zero records. I0729 14:44:41.091079 139722",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:11591,reliability,checkpoint,checkpoint,11591,".899687 140710547908416 make_examples_core.py:301] Task 1/4: Found 0 candidate variants. I0729 14:44:37.899752 140710547908416 make_examples_core.py:301] Task 1/4: Created 0 examples. I0729 14:44:37.893192 139779121772352 make_examples_core.py:301] Task 2/4: Writing example info to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00002-of-00004.gz.example_info.json. I0729 14:44:37.893293 139779121772352 make_examples_core.py:2958] example_shape = None. I0729 14:44:37.893665 139779121772352 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0729 14:44:37.894033 139779121772352 make_examples_core.py:301] Task 2/4: Found 0 candidate variants. I0729 14:44:37.894105 139779121772352 make_examples_core.py:301] Task 2/4: Created 0 examples. real	0m4.791s. user	0m11.503s. sys	0m2.085s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpkcjcf0p_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wes"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0729 14:44:41.088234 139722246891328 call_variants.py:471] Total 1 writing processes started. W0729 14:44:41.090612 139722246891328 call_variants.py:482] Unable to read any records from /tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz. Output will contain zero records. I0729 14:44:41.091079 139722246891328 call_variants.py:623] Complete: call_variants. **Does the quick start test work on your system?**. yes. **Any additional context:**. Some samples work fine",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:11824,reliability,mainten,maintenance,11824,"e.py:301] Task 1/4: Found 0 candidate variants. I0729 14:44:37.899752 140710547908416 make_examples_core.py:301] Task 1/4: Created 0 examples. I0729 14:44:37.893192 139779121772352 make_examples_core.py:301] Task 2/4: Writing example info to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00002-of-00004.gz.example_info.json. I0729 14:44:37.893293 139779121772352 make_examples_core.py:2958] example_shape = None. I0729 14:44:37.893665 139779121772352 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0729 14:44:37.894033 139779121772352 make_examples_core.py:301] Task 2/4: Found 0 candidate variants. I0729 14:44:37.894105 139779121772352 make_examples_core.py:301] Task 2/4: Created 0 examples. real	0m4.791s. user	0m11.503s. sys	0m2.085s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpkcjcf0p_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wes"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0729 14:44:41.088234 139722246891328 call_variants.py:471] Total 1 writing processes started. W0729 14:44:41.090612 139722246891328 call_variants.py:482] Unable to read any records from /tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz. Output will contain zero records. I0729 14:44:41.091079 139722246891328 call_variants.py:623] Complete: call_variants. **Does the quick start test work on your system?**. yes. **Any additional context:**. Some samples work fine, some very similar samples keep running.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:12490,reliability,Doe,Does,12490,"e.py:301] Task 1/4: Found 0 candidate variants. I0729 14:44:37.899752 140710547908416 make_examples_core.py:301] Task 1/4: Created 0 examples. I0729 14:44:37.893192 139779121772352 make_examples_core.py:301] Task 2/4: Writing example info to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00002-of-00004.gz.example_info.json. I0729 14:44:37.893293 139779121772352 make_examples_core.py:2958] example_shape = None. I0729 14:44:37.893665 139779121772352 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0729 14:44:37.894033 139779121772352 make_examples_core.py:301] Task 2/4: Found 0 candidate variants. I0729 14:44:37.894105 139779121772352 make_examples_core.py:301] Task 2/4: Created 0 examples. real	0m4.791s. user	0m11.503s. sys	0m2.085s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpkcjcf0p_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wes"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0729 14:44:41.088234 139722246891328 call_variants.py:471] Total 1 writing processes started. W0729 14:44:41.090612 139722246891328 call_variants.py:482] Unable to read any records from /tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz. Output will contain zero records. I0729 14:44:41.091079 139722246891328 call_variants.py:623] Complete: call_variants. **Does the quick start test work on your system?**. yes. **Any additional context:**. Some samples work fine, some very similar samples keep running.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:156,safety,input,input,156,"Program always run; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**: YES. **Describe the issue:** . 1. When the input sequence (fastq) matches the reference sequence, the program will keep running. 2. Sequence obtain from data generation tools. (dwgsim) . **Setup**. - Operating system: Red Hat Enterprise Linux release 8.6 (Ootpa). - DeepVariant version: deepvariant1.6.0.sif. - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). GRCh38| (Sequence obtain from data generation tools. (dwgsim) length,8-9kB, 150bp, PE, sequence may the same as reference sequence) . **Steps to reproduce:**. - Command: . time singularity run ~/singularity/deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${bamSavePath}/${name}.sorted.bam \. --output_vcf ${vcf} \. --output_gvcf ${outputPath}/vcf/${name}/${name}.g.vcf.gz \. --num_shards $(nproc) \. --regions ${BED} \. --sample_name ${name} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"" . - Error trace: (if applicable). I0729 14:44:37.339473 140223721211712 make_examples_core.py:301] Task 0/4: Preparing inputs. I0729 14:44:37.339473 140478861559616 make_examples_core.py:301] Task 3/4: Preparing inputs. I0729 14:44:37.350302 140710547908416 make_examples_core.py:301] Task 1/4: Preparing inputs. I0729 14:44:37.339477 139779121772352 make_examples_core.py:301] Task 2/4: Preparing inputs. I0729 14:44:37.476220 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.485832 140223721211712 make_examples_core.py:301] Task 0/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:1221,safety,Error,Error,1221,"ill keep running. 2. Sequence obtain from data generation tools. (dwgsim) . **Setup**. - Operating system: Red Hat Enterprise Linux release 8.6 (Ootpa). - DeepVariant version: deepvariant1.6.0.sif. - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). GRCh38| (Sequence obtain from data generation tools. (dwgsim) length,8-9kB, 150bp, PE, sequence may the same as reference sequence) . **Steps to reproduce:**. - Command: . time singularity run ~/singularity/deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${bamSavePath}/${name}.sorted.bam \. --output_vcf ${vcf} \. --output_gvcf ${outputPath}/vcf/${name}/${name}.g.vcf.gz \. --num_shards $(nproc) \. --regions ${BED} \. --sample_name ${name} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"" . - Error trace: (if applicable). I0729 14:44:37.339473 140223721211712 make_examples_core.py:301] Task 0/4: Preparing inputs. I0729 14:44:37.339473 140478861559616 make_examples_core.py:301] Task 3/4: Preparing inputs. I0729 14:44:37.350302 140710547908416 make_examples_core.py:301] Task 1/4: Preparing inputs. I0729 14:44:37.339477 139779121772352 make_examples_core.py:301] Task 2/4: Preparing inputs. I0729 14:44:37.476220 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.485832 140223721211712 make_examples_core.py:301] Task 0/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0729 14:44:37.533100 140223721211712 genomics_reader.py:222] Reading /lustre/home/acct-m",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:1336,safety,input,inputs,1336,"Enterprise Linux release 8.6 (Ootpa). - DeepVariant version: deepvariant1.6.0.sif. - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). GRCh38| (Sequence obtain from data generation tools. (dwgsim) length,8-9kB, 150bp, PE, sequence may the same as reference sequence) . **Steps to reproduce:**. - Command: . time singularity run ~/singularity/deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${bamSavePath}/${name}.sorted.bam \. --output_vcf ${vcf} \. --output_gvcf ${outputPath}/vcf/${name}/${name}.g.vcf.gz \. --num_shards $(nproc) \. --regions ${BED} \. --sample_name ${name} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"" . - Error trace: (if applicable). I0729 14:44:37.339473 140223721211712 make_examples_core.py:301] Task 0/4: Preparing inputs. I0729 14:44:37.339473 140478861559616 make_examples_core.py:301] Task 3/4: Preparing inputs. I0729 14:44:37.350302 140710547908416 make_examples_core.py:301] Task 1/4: Preparing inputs. I0729 14:44:37.339477 139779121772352 make_examples_core.py:301] Task 2/4: Preparing inputs. I0729 14:44:37.476220 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.485832 140223721211712 make_examples_core.py:301] Task 0/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0729 14:44:37.533100 140223721211712 genomics_reader.py:222] Reading /lustre/home/acct-medfzx/medfzx-lkw/project/CAH/data/BED/cah_noname.bed with NativeBedReader. I0729 14:44:37.541654 140223721211712 ma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:1429,safety,input,inputs,1429,"tion method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). GRCh38| (Sequence obtain from data generation tools. (dwgsim) length,8-9kB, 150bp, PE, sequence may the same as reference sequence) . **Steps to reproduce:**. - Command: . time singularity run ~/singularity/deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${bamSavePath}/${name}.sorted.bam \. --output_vcf ${vcf} \. --output_gvcf ${outputPath}/vcf/${name}/${name}.g.vcf.gz \. --num_shards $(nproc) \. --regions ${BED} \. --sample_name ${name} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"" . - Error trace: (if applicable). I0729 14:44:37.339473 140223721211712 make_examples_core.py:301] Task 0/4: Preparing inputs. I0729 14:44:37.339473 140478861559616 make_examples_core.py:301] Task 3/4: Preparing inputs. I0729 14:44:37.350302 140710547908416 make_examples_core.py:301] Task 1/4: Preparing inputs. I0729 14:44:37.339477 139779121772352 make_examples_core.py:301] Task 2/4: Preparing inputs. I0729 14:44:37.476220 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.485832 140223721211712 make_examples_core.py:301] Task 0/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0729 14:44:37.533100 140223721211712 genomics_reader.py:222] Reading /lustre/home/acct-medfzx/medfzx-lkw/project/CAH/data/BED/cah_noname.bed with NativeBedReader. I0729 14:44:37.541654 140223721211712 make_examples_core.py:301] Task 0/4: Starting from v0.9.0, --use_ref_for_cram is default to tru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:1522,safety,input,inputs,1522,"ument, reference genome, anything special that is unlike the case studies?). GRCh38| (Sequence obtain from data generation tools. (dwgsim) length,8-9kB, 150bp, PE, sequence may the same as reference sequence) . **Steps to reproduce:**. - Command: . time singularity run ~/singularity/deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${bamSavePath}/${name}.sorted.bam \. --output_vcf ${vcf} \. --output_gvcf ${outputPath}/vcf/${name}/${name}.g.vcf.gz \. --num_shards $(nproc) \. --regions ${BED} \. --sample_name ${name} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"" . - Error trace: (if applicable). I0729 14:44:37.339473 140223721211712 make_examples_core.py:301] Task 0/4: Preparing inputs. I0729 14:44:37.339473 140478861559616 make_examples_core.py:301] Task 3/4: Preparing inputs. I0729 14:44:37.350302 140710547908416 make_examples_core.py:301] Task 1/4: Preparing inputs. I0729 14:44:37.339477 139779121772352 make_examples_core.py:301] Task 2/4: Preparing inputs. I0729 14:44:37.476220 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.485832 140223721211712 make_examples_core.py:301] Task 0/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0729 14:44:37.533100 140223721211712 genomics_reader.py:222] Reading /lustre/home/acct-medfzx/medfzx-lkw/project/CAH/data/BED/cah_noname.bed with NativeBedReader. I0729 14:44:37.541654 140223721211712 make_examples_core.py:301] Task 0/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:1615,safety,input,inputs,1615,"e obtain from data generation tools. (dwgsim) length,8-9kB, 150bp, PE, sequence may the same as reference sequence) . **Steps to reproduce:**. - Command: . time singularity run ~/singularity/deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${bamSavePath}/${name}.sorted.bam \. --output_vcf ${vcf} \. --output_gvcf ${outputPath}/vcf/${name}/${name}.g.vcf.gz \. --num_shards $(nproc) \. --regions ${BED} \. --sample_name ${name} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"" . - Error trace: (if applicable). I0729 14:44:37.339473 140223721211712 make_examples_core.py:301] Task 0/4: Preparing inputs. I0729 14:44:37.339473 140478861559616 make_examples_core.py:301] Task 3/4: Preparing inputs. I0729 14:44:37.350302 140710547908416 make_examples_core.py:301] Task 1/4: Preparing inputs. I0729 14:44:37.339477 139779121772352 make_examples_core.py:301] Task 2/4: Preparing inputs. I0729 14:44:37.476220 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.485832 140223721211712 make_examples_core.py:301] Task 0/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0729 14:44:37.533100 140223721211712 genomics_reader.py:222] Reading /lustre/home/acct-medfzx/medfzx-lkw/project/CAH/data/BED/cah_noname.bed with NativeBedReader. I0729 14:44:37.541654 140223721211712 make_examples_core.py:301] Task 0/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0729 14:44:37.543606 140223721211712 genomics_reader.py:222] Reading result/s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:2457,safety,input,input,2457,"40710547908416 make_examples_core.py:301] Task 1/4: Preparing inputs. I0729 14:44:37.339477 139779121772352 make_examples_core.py:301] Task 2/4: Preparing inputs. I0729 14:44:37.476220 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.485832 140223721211712 make_examples_core.py:301] Task 0/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0729 14:44:37.533100 140223721211712 genomics_reader.py:222] Reading /lustre/home/acct-medfzx/medfzx-lkw/project/CAH/data/BED/cah_noname.bed with NativeBedReader. I0729 14:44:37.541654 140223721211712 make_examples_core.py:301] Task 0/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0729 14:44:37.543606 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.620779 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.620978 140223721211712 make_examples_core.py:301] Task 0/4: Writing gvcf records to /tmp/tmpkcjcf0p_/gvcf.tfrecord-00000-of-00004.gz. I0729 14:44:37.621363 140223721211712 make_examples_core.py:301] Task 0/4: Writing examples to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00000-of-00004.gz. I0729 14:44:37.621420 140223721211712 make_examples_core.py:301] Task 0/4: Overhead for preparing inputs: 0 seconds. I0729 14:44:37.652796 140223721211712 make_examples_core.py:301] Task 0/4: 0 candidates (0 exa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:3347,safety,input,inputs,3347,"_core.py:301] Task 0/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0729 14:44:37.543606 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.620779 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.620978 140223721211712 make_examples_core.py:301] Task 0/4: Writing gvcf records to /tmp/tmpkcjcf0p_/gvcf.tfrecord-00000-of-00004.gz. I0729 14:44:37.621363 140223721211712 make_examples_core.py:301] Task 0/4: Writing examples to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00000-of-00004.gz. I0729 14:44:37.621420 140223721211712 make_examples_core.py:301] Task 0/4: Overhead for preparing inputs: 0 seconds. I0729 14:44:37.652796 140223721211712 make_examples_core.py:301] Task 0/4: 0 candidates (0 examples) [0.03s elapsed]. I0729 14:44:37.476214 140478861559616 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.485823 140478861559616 make_examples_core.py:301] Task 3/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0729 14:44:37.533152 140478861559616 genomics_reader.py:222] Reading /lustre/home/acct-medfzx/medfzx-lkw/project/CAH/data/BED/cah_noname.bed with NativeBedReader. I0729 14:44:37.541796 140478861559616 make_examples_core.py:301] Task 3/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:4318,safety,input,input,4318,"4: Overhead for preparing inputs: 0 seconds. I0729 14:44:37.652796 140223721211712 make_examples_core.py:301] Task 0/4: 0 candidates (0 examples) [0.03s elapsed]. I0729 14:44:37.476214 140478861559616 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.485823 140478861559616 make_examples_core.py:301] Task 3/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0729 14:44:37.533152 140478861559616 genomics_reader.py:222] Reading /lustre/home/acct-medfzx/medfzx-lkw/project/CAH/data/BED/cah_noname.bed with NativeBedReader. I0729 14:44:37.541796 140478861559616 make_examples_core.py:301] Task 3/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0729 14:44:37.543756 140478861559616 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.619259 140478861559616 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.619429 140478861559616 make_examples_core.py:301] Task 3/4: Writing gvcf records to /tmp/tmpkcjcf0p_/gvcf.tfrecord-00003-of-00004.gz. I0729 14:44:37.619812 140478861559616 make_examples_core.py:301] Task 3/4: Writing examples to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00003-of-00004.gz. I0729 14:44:37.619867 140478861559616 make_examples_core.py:301] Task 3/4: Overhead for preparing inputs: 0 seconds. I0729 14:44:37.653389 140478861559616 make_examples_core.py:301] Task 3/4: 0 candidates (0 exa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:5208,safety,input,inputs,5208,"_core.py:301] Task 3/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0729 14:44:37.543756 140478861559616 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.619259 140478861559616 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.619429 140478861559616 make_examples_core.py:301] Task 3/4: Writing gvcf records to /tmp/tmpkcjcf0p_/gvcf.tfrecord-00003-of-00004.gz. I0729 14:44:37.619812 140478861559616 make_examples_core.py:301] Task 3/4: Writing examples to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00003-of-00004.gz. I0729 14:44:37.619867 140478861559616 make_examples_core.py:301] Task 3/4: Overhead for preparing inputs: 0 seconds. I0729 14:44:37.653389 140478861559616 make_examples_core.py:301] Task 3/4: 0 candidates (0 examples) [0.03s elapsed]. I0729 14:44:37.476402 140710547908416 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.486019 140710547908416 make_examples_core.py:301] Task 1/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0729 14:44:37.533221 140710547908416 genomics_reader.py:222] Reading /lustre/home/acct-medfzx/medfzx-lkw/project/CAH/data/BED/cah_noname.bed with NativeBedReader. I0729 14:44:37.541869 140710547908416 make_examples_core.py:301] Task 1/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:6179,safety,input,input,6179,"4: Overhead for preparing inputs: 0 seconds. I0729 14:44:37.653389 140478861559616 make_examples_core.py:301] Task 3/4: 0 candidates (0 examples) [0.03s elapsed]. I0729 14:44:37.476402 140710547908416 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.486019 140710547908416 make_examples_core.py:301] Task 1/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0729 14:44:37.533221 140710547908416 genomics_reader.py:222] Reading /lustre/home/acct-medfzx/medfzx-lkw/project/CAH/data/BED/cah_noname.bed with NativeBedReader. I0729 14:44:37.541869 140710547908416 make_examples_core.py:301] Task 1/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0729 14:44:37.543881 140710547908416 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.619640 140710547908416 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.619808 140710547908416 make_examples_core.py:301] Task 1/4: Writing gvcf records to /tmp/tmpkcjcf0p_/gvcf.tfrecord-00001-of-00004.gz. I0729 14:44:37.620180 140710547908416 make_examples_core.py:301] Task 1/4: Writing examples to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00001-of-00004.gz. I0729 14:44:37.620236 140710547908416 make_examples_core.py:301] Task 1/4: Overhead for preparing inputs: 0 seconds. I0729 14:44:37.652904 140710547908416 make_examples_core.py:301] Task 1/4: 0 candidates (0 exa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:7069,safety,input,inputs,7069,"_core.py:301] Task 1/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0729 14:44:37.543881 140710547908416 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.619640 140710547908416 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.619808 140710547908416 make_examples_core.py:301] Task 1/4: Writing gvcf records to /tmp/tmpkcjcf0p_/gvcf.tfrecord-00001-of-00004.gz. I0729 14:44:37.620180 140710547908416 make_examples_core.py:301] Task 1/4: Writing examples to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00001-of-00004.gz. I0729 14:44:37.620236 140710547908416 make_examples_core.py:301] Task 1/4: Overhead for preparing inputs: 0 seconds. I0729 14:44:37.652904 140710547908416 make_examples_core.py:301] Task 1/4: 0 candidates (0 examples) [0.03s elapsed]. I0729 14:44:37.476840 139779121772352 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.486504 139779121772352 make_examples_core.py:301] Task 2/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0729 14:44:37.533215 139779121772352 genomics_reader.py:222] Reading /lustre/home/acct-medfzx/medfzx-lkw/project/CAH/data/BED/cah_noname.bed with NativeBedReader. I0729 14:44:37.541668 139779121772352 make_examples_core.py:301] Task 2/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:8040,safety,input,input,8040,"4: Overhead for preparing inputs: 0 seconds. I0729 14:44:37.652904 140710547908416 make_examples_core.py:301] Task 1/4: 0 candidates (0 examples) [0.03s elapsed]. I0729 14:44:37.476840 139779121772352 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.486504 139779121772352 make_examples_core.py:301] Task 2/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0729 14:44:37.533215 139779121772352 genomics_reader.py:222] Reading /lustre/home/acct-medfzx/medfzx-lkw/project/CAH/data/BED/cah_noname.bed with NativeBedReader. I0729 14:44:37.541668 139779121772352 make_examples_core.py:301] Task 2/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0729 14:44:37.543754 139779121772352 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.624524 139779121772352 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.624701 139779121772352 make_examples_core.py:301] Task 2/4: Writing gvcf records to /tmp/tmpkcjcf0p_/gvcf.tfrecord-00002-of-00004.gz. I0729 14:44:37.625109 139779121772352 make_examples_core.py:301] Task 2/4: Writing examples to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00002-of-00004.gz. I0729 14:44:37.625170 139779121772352 make_examples_core.py:301] Task 2/4: Overhead for preparing inputs: 0 seconds. I0729 14:44:37.653617 139779121772352 make_examples_core.py:301] Task 2/4: 0 candidates (0 exa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:8930,safety,input,inputs,8930,"_core.py:301] Task 2/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0729 14:44:37.543754 139779121772352 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.624524 139779121772352 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.624701 139779121772352 make_examples_core.py:301] Task 2/4: Writing gvcf records to /tmp/tmpkcjcf0p_/gvcf.tfrecord-00002-of-00004.gz. I0729 14:44:37.625109 139779121772352 make_examples_core.py:301] Task 2/4: Writing examples to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00002-of-00004.gz. I0729 14:44:37.625170 139779121772352 make_examples_core.py:301] Task 2/4: Overhead for preparing inputs: 0 seconds. I0729 14:44:37.653617 139779121772352 make_examples_core.py:301] Task 2/4: 0 candidates (0 examples) [0.03s elapsed]. I0729 14:44:37.898170 140223721211712 make_examples_core.py:301] Task 0/4: Writing example info to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00000-of-00004.gz.example_info.json. I0729 14:44:37.898274 140223721211712 make_examples_core.py:2958] example_shape = None. I0729 14:44:37.898649 140223721211712 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0729 14:44:37.899018 140223721211712 make_examples_core.py:301] Task 0/4: Found 0 candidate variants. I0729 14:44:37.899082 140223721211712 make_examples_core.py:301] Task 0/4: Created 0 examples. I0729 14:44:37.898826 140478861559616 make_examples_core.py:301] Task 3/4: Writing example info to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00003-of-00004.gz.example_info.json. I0729 14:44:37.898957 140478861559616 make_examples_core.py:2958] example_shape = None. I0729 14:44:37.899326 140478861",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:11937,safety,depend,dependencies,11937,"e.py:301] Task 1/4: Found 0 candidate variants. I0729 14:44:37.899752 140710547908416 make_examples_core.py:301] Task 1/4: Created 0 examples. I0729 14:44:37.893192 139779121772352 make_examples_core.py:301] Task 2/4: Writing example info to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00002-of-00004.gz.example_info.json. I0729 14:44:37.893293 139779121772352 make_examples_core.py:2958] example_shape = None. I0729 14:44:37.893665 139779121772352 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0729 14:44:37.894033 139779121772352 make_examples_core.py:301] Task 2/4: Found 0 candidate variants. I0729 14:44:37.894105 139779121772352 make_examples_core.py:301] Task 2/4: Created 0 examples. real	0m4.791s. user	0m11.503s. sys	0m2.085s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpkcjcf0p_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wes"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0729 14:44:41.088234 139722246891328 call_variants.py:471] Total 1 writing processes started. W0729 14:44:41.090612 139722246891328 call_variants.py:482] Unable to read any records from /tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz. Output will contain zero records. I0729 14:44:41.091079 139722246891328 call_variants.py:623] Complete: call_variants. **Does the quick start test work on your system?**. yes. **Any additional context:**. Some samples work fine, some very similar samples keep running.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:12463,safety,Compl,Complete,12463,"e.py:301] Task 1/4: Found 0 candidate variants. I0729 14:44:37.899752 140710547908416 make_examples_core.py:301] Task 1/4: Created 0 examples. I0729 14:44:37.893192 139779121772352 make_examples_core.py:301] Task 2/4: Writing example info to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00002-of-00004.gz.example_info.json. I0729 14:44:37.893293 139779121772352 make_examples_core.py:2958] example_shape = None. I0729 14:44:37.893665 139779121772352 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0729 14:44:37.894033 139779121772352 make_examples_core.py:301] Task 2/4: Found 0 candidate variants. I0729 14:44:37.894105 139779121772352 make_examples_core.py:301] Task 2/4: Created 0 examples. real	0m4.791s. user	0m11.503s. sys	0m2.085s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpkcjcf0p_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wes"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0729 14:44:41.088234 139722246891328 call_variants.py:471] Total 1 writing processes started. W0729 14:44:41.090612 139722246891328 call_variants.py:482] Unable to read any records from /tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz. Output will contain zero records. I0729 14:44:41.091079 139722246891328 call_variants.py:623] Complete: call_variants. **Does the quick start test work on your system?**. yes. **Any additional context:**. Some samples work fine, some very similar samples keep running.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:12511,safety,test,test,12511,"e.py:301] Task 1/4: Found 0 candidate variants. I0729 14:44:37.899752 140710547908416 make_examples_core.py:301] Task 1/4: Created 0 examples. I0729 14:44:37.893192 139779121772352 make_examples_core.py:301] Task 2/4: Writing example info to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00002-of-00004.gz.example_info.json. I0729 14:44:37.893293 139779121772352 make_examples_core.py:2958] example_shape = None. I0729 14:44:37.893665 139779121772352 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0729 14:44:37.894033 139779121772352 make_examples_core.py:301] Task 2/4: Found 0 candidate variants. I0729 14:44:37.894105 139779121772352 make_examples_core.py:301] Task 2/4: Created 0 examples. real	0m4.791s. user	0m11.503s. sys	0m2.085s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpkcjcf0p_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wes"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0729 14:44:41.088234 139722246891328 call_variants.py:471] Total 1 writing processes started. W0729 14:44:41.090612 139722246891328 call_variants.py:482] Unable to read any records from /tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz. Output will contain zero records. I0729 14:44:41.091079 139722246891328 call_variants.py:623] Complete: call_variants. **Does the quick start test work on your system?**. yes. **Any additional context:**. Some samples work fine, some very similar samples keep running.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:11608,security,model,models,11608,"47908416 make_examples_core.py:301] Task 1/4: Found 0 candidate variants. I0729 14:44:37.899752 140710547908416 make_examples_core.py:301] Task 1/4: Created 0 examples. I0729 14:44:37.893192 139779121772352 make_examples_core.py:301] Task 2/4: Writing example info to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00002-of-00004.gz.example_info.json. I0729 14:44:37.893293 139779121772352 make_examples_core.py:2958] example_shape = None. I0729 14:44:37.893665 139779121772352 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0729 14:44:37.894033 139779121772352 make_examples_core.py:301] Task 2/4: Found 0 candidate variants. I0729 14:44:37.894105 139779121772352 make_examples_core.py:301] Task 2/4: Created 0 examples. real	0m4.791s. user	0m11.503s. sys	0m2.085s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpkcjcf0p_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wes"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0729 14:44:41.088234 139722246891328 call_variants.py:471] Total 1 writing processes started. W0729 14:44:41.090612 139722246891328 call_variants.py:482] Unable to read any records from /tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz. Output will contain zero records. I0729 14:44:41.091079 139722246891328 call_variants.py:623] Complete: call_variants. **Does the quick start test work on your system?**. yes. **Any additional context:**. Some samples work fine, some very sim",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:11901,security,modif,modify,11901,"e.py:301] Task 1/4: Found 0 candidate variants. I0729 14:44:37.899752 140710547908416 make_examples_core.py:301] Task 1/4: Created 0 examples. I0729 14:44:37.893192 139779121772352 make_examples_core.py:301] Task 2/4: Writing example info to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00002-of-00004.gz.example_info.json. I0729 14:44:37.893293 139779121772352 make_examples_core.py:2958] example_shape = None. I0729 14:44:37.893665 139779121772352 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0729 14:44:37.894033 139779121772352 make_examples_core.py:301] Task 2/4: Found 0 candidate variants. I0729 14:44:37.894105 139779121772352 make_examples_core.py:301] Task 2/4: Created 0 examples. real	0m4.791s. user	0m11.503s. sys	0m2.085s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpkcjcf0p_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wes"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0729 14:44:41.088234 139722246891328 call_variants.py:471] Total 1 writing processes started. W0729 14:44:41.090612 139722246891328 call_variants.py:482] Unable to read any records from /tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz. Output will contain zero records. I0729 14:44:41.091079 139722246891328 call_variants.py:623] Complete: call_variants. **Does the quick start test work on your system?**. yes. **Any additional context:**. Some samples work fine, some very similar samples keep running.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:12463,security,Compl,Complete,12463,"e.py:301] Task 1/4: Found 0 candidate variants. I0729 14:44:37.899752 140710547908416 make_examples_core.py:301] Task 1/4: Created 0 examples. I0729 14:44:37.893192 139779121772352 make_examples_core.py:301] Task 2/4: Writing example info to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00002-of-00004.gz.example_info.json. I0729 14:44:37.893293 139779121772352 make_examples_core.py:2958] example_shape = None. I0729 14:44:37.893665 139779121772352 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0729 14:44:37.894033 139779121772352 make_examples_core.py:301] Task 2/4: Found 0 candidate variants. I0729 14:44:37.894105 139779121772352 make_examples_core.py:301] Task 2/4: Created 0 examples. real	0m4.791s. user	0m11.503s. sys	0m2.085s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpkcjcf0p_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wes"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0729 14:44:41.088234 139722246891328 call_variants.py:471] Total 1 writing processes started. W0729 14:44:41.090612 139722246891328 call_variants.py:482] Unable to read any records from /tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz. Output will contain zero records. I0729 14:44:41.091079 139722246891328 call_variants.py:623] Complete: call_variants. **Does the quick start test work on your system?**. yes. **Any additional context:**. Some samples work fine, some very similar samples keep running.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:520,testability,instrument,instrument,520,"Program always run; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**: YES. **Describe the issue:** . 1. When the input sequence (fastq) matches the reference sequence, the program will keep running. 2. Sequence obtain from data generation tools. (dwgsim) . **Setup**. - Operating system: Red Hat Enterprise Linux release 8.6 (Ootpa). - DeepVariant version: deepvariant1.6.0.sif. - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). GRCh38| (Sequence obtain from data generation tools. (dwgsim) length,8-9kB, 150bp, PE, sequence may the same as reference sequence) . **Steps to reproduce:**. - Command: . time singularity run ~/singularity/deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${bamSavePath}/${name}.sorted.bam \. --output_vcf ${vcf} \. --output_gvcf ${outputPath}/vcf/${name}/${name}.g.vcf.gz \. --num_shards $(nproc) \. --regions ${BED} \. --sample_name ${name} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"" . - Error trace: (if applicable). I0729 14:44:37.339473 140223721211712 make_examples_core.py:301] Task 0/4: Preparing inputs. I0729 14:44:37.339473 140478861559616 make_examples_core.py:301] Task 3/4: Preparing inputs. I0729 14:44:37.350302 140710547908416 make_examples_core.py:301] Task 1/4: Preparing inputs. I0729 14:44:37.339477 139779121772352 make_examples_core.py:301] Task 2/4: Preparing inputs. I0729 14:44:37.476220 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.485832 140223721211712 make_examples_core.py:301] Task 0/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:1227,testability,trace,trace,1227,"ep running. 2. Sequence obtain from data generation tools. (dwgsim) . **Setup**. - Operating system: Red Hat Enterprise Linux release 8.6 (Ootpa). - DeepVariant version: deepvariant1.6.0.sif. - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). GRCh38| (Sequence obtain from data generation tools. (dwgsim) length,8-9kB, 150bp, PE, sequence may the same as reference sequence) . **Steps to reproduce:**. - Command: . time singularity run ~/singularity/deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${bamSavePath}/${name}.sorted.bam \. --output_vcf ${vcf} \. --output_gvcf ${outputPath}/vcf/${name}/${name}.g.vcf.gz \. --num_shards $(nproc) \. --regions ${BED} \. --sample_name ${name} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"" . - Error trace: (if applicable). I0729 14:44:37.339473 140223721211712 make_examples_core.py:301] Task 0/4: Preparing inputs. I0729 14:44:37.339473 140478861559616 make_examples_core.py:301] Task 3/4: Preparing inputs. I0729 14:44:37.350302 140710547908416 make_examples_core.py:301] Task 1/4: Preparing inputs. I0729 14:44:37.339477 139779121772352 make_examples_core.py:301] Task 2/4: Preparing inputs. I0729 14:44:37.476220 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.485832 140223721211712 make_examples_core.py:301] Task 0/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0729 14:44:37.533100 140223721211712 genomics_reader.py:222] Reading /lustre/home/acct-medfzx/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:11861,testability,plan,planned,11861,"e.py:301] Task 1/4: Found 0 candidate variants. I0729 14:44:37.899752 140710547908416 make_examples_core.py:301] Task 1/4: Created 0 examples. I0729 14:44:37.893192 139779121772352 make_examples_core.py:301] Task 2/4: Writing example info to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00002-of-00004.gz.example_info.json. I0729 14:44:37.893293 139779121772352 make_examples_core.py:2958] example_shape = None. I0729 14:44:37.893665 139779121772352 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0729 14:44:37.894033 139779121772352 make_examples_core.py:301] Task 2/4: Found 0 candidate variants. I0729 14:44:37.894105 139779121772352 make_examples_core.py:301] Task 2/4: Created 0 examples. real	0m4.791s. user	0m11.503s. sys	0m2.085s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpkcjcf0p_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wes"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0729 14:44:41.088234 139722246891328 call_variants.py:471] Total 1 writing processes started. W0729 14:44:41.090612 139722246891328 call_variants.py:482] Unable to read any records from /tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz. Output will contain zero records. I0729 14:44:41.091079 139722246891328 call_variants.py:623] Complete: call_variants. **Does the quick start test work on your system?**. yes. **Any additional context:**. Some samples work fine, some very similar samples keep running.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:11937,testability,depend,dependencies,11937,"e.py:301] Task 1/4: Found 0 candidate variants. I0729 14:44:37.899752 140710547908416 make_examples_core.py:301] Task 1/4: Created 0 examples. I0729 14:44:37.893192 139779121772352 make_examples_core.py:301] Task 2/4: Writing example info to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00002-of-00004.gz.example_info.json. I0729 14:44:37.893293 139779121772352 make_examples_core.py:2958] example_shape = None. I0729 14:44:37.893665 139779121772352 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0729 14:44:37.894033 139779121772352 make_examples_core.py:301] Task 2/4: Found 0 candidate variants. I0729 14:44:37.894105 139779121772352 make_examples_core.py:301] Task 2/4: Created 0 examples. real	0m4.791s. user	0m11.503s. sys	0m2.085s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpkcjcf0p_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wes"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0729 14:44:41.088234 139722246891328 call_variants.py:471] Total 1 writing processes started. W0729 14:44:41.090612 139722246891328 call_variants.py:482] Unable to read any records from /tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz. Output will contain zero records. I0729 14:44:41.091079 139722246891328 call_variants.py:623] Complete: call_variants. **Does the quick start test work on your system?**. yes. **Any additional context:**. Some samples work fine, some very similar samples keep running.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:12511,testability,test,test,12511,"e.py:301] Task 1/4: Found 0 candidate variants. I0729 14:44:37.899752 140710547908416 make_examples_core.py:301] Task 1/4: Created 0 examples. I0729 14:44:37.893192 139779121772352 make_examples_core.py:301] Task 2/4: Writing example info to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00002-of-00004.gz.example_info.json. I0729 14:44:37.893293 139779121772352 make_examples_core.py:2958] example_shape = None. I0729 14:44:37.893665 139779121772352 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0729 14:44:37.894033 139779121772352 make_examples_core.py:301] Task 2/4: Found 0 candidate variants. I0729 14:44:37.894105 139779121772352 make_examples_core.py:301] Task 2/4: Created 0 examples. real	0m4.791s. user	0m11.503s. sys	0m2.085s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpkcjcf0p_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wes"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0729 14:44:41.088234 139722246891328 call_variants.py:471] Total 1 writing processes started. W0729 14:44:41.090612 139722246891328 call_variants.py:482] Unable to read any records from /tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz. Output will contain zero records. I0729 14:44:41.091079 139722246891328 call_variants.py:623] Complete: call_variants. **Does the quick start test work on your system?**. yes. **Any additional context:**. Some samples work fine, some very similar samples keep running.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:12562,testability,context,context,12562,"e.py:301] Task 1/4: Found 0 candidate variants. I0729 14:44:37.899752 140710547908416 make_examples_core.py:301] Task 1/4: Created 0 examples. I0729 14:44:37.893192 139779121772352 make_examples_core.py:301] Task 2/4: Writing example info to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00002-of-00004.gz.example_info.json. I0729 14:44:37.893293 139779121772352 make_examples_core.py:2958] example_shape = None. I0729 14:44:37.893665 139779121772352 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0729 14:44:37.894033 139779121772352 make_examples_core.py:301] Task 2/4: Found 0 candidate variants. I0729 14:44:37.894105 139779121772352 make_examples_core.py:301] Task 2/4: Created 0 examples. real	0m4.791s. user	0m11.503s. sys	0m2.085s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpkcjcf0p_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wes"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0729 14:44:41.088234 139722246891328 call_variants.py:471] Total 1 writing processes started. W0729 14:44:41.090612 139722246891328 call_variants.py:482] Unable to read any records from /tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz. Output will contain zero records. I0729 14:44:41.091079 139722246891328 call_variants.py:623] Complete: call_variants. **Does the quick start test work on your system?**. yes. **Any additional context:**. Some samples work fine, some very similar samples keep running.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:156,usability,input,input,156,"Program always run; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**: YES. **Describe the issue:** . 1. When the input sequence (fastq) matches the reference sequence, the program will keep running. 2. Sequence obtain from data generation tools. (dwgsim) . **Setup**. - Operating system: Red Hat Enterprise Linux release 8.6 (Ootpa). - DeepVariant version: deepvariant1.6.0.sif. - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). GRCh38| (Sequence obtain from data generation tools. (dwgsim) length,8-9kB, 150bp, PE, sequence may the same as reference sequence) . **Steps to reproduce:**. - Command: . time singularity run ~/singularity/deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${bamSavePath}/${name}.sorted.bam \. --output_vcf ${vcf} \. --output_gvcf ${outputPath}/vcf/${name}/${name}.g.vcf.gz \. --num_shards $(nproc) \. --regions ${BED} \. --sample_name ${name} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"" . - Error trace: (if applicable). I0729 14:44:37.339473 140223721211712 make_examples_core.py:301] Task 0/4: Preparing inputs. I0729 14:44:37.339473 140478861559616 make_examples_core.py:301] Task 3/4: Preparing inputs. I0729 14:44:37.350302 140710547908416 make_examples_core.py:301] Task 1/4: Preparing inputs. I0729 14:44:37.339477 139779121772352 make_examples_core.py:301] Task 2/4: Preparing inputs. I0729 14:44:37.476220 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.485832 140223721211712 make_examples_core.py:301] Task 0/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:282,usability,tool,tools,282,"Program always run; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**: YES. **Describe the issue:** . 1. When the input sequence (fastq) matches the reference sequence, the program will keep running. 2. Sequence obtain from data generation tools. (dwgsim) . **Setup**. - Operating system: Red Hat Enterprise Linux release 8.6 (Ootpa). - DeepVariant version: deepvariant1.6.0.sif. - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). GRCh38| (Sequence obtain from data generation tools. (dwgsim) length,8-9kB, 150bp, PE, sequence may the same as reference sequence) . **Steps to reproduce:**. - Command: . time singularity run ~/singularity/deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${bamSavePath}/${name}.sorted.bam \. --output_vcf ${vcf} \. --output_gvcf ${outputPath}/vcf/${name}/${name}.g.vcf.gz \. --num_shards $(nproc) \. --regions ${BED} \. --sample_name ${name} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"" . - Error trace: (if applicable). I0729 14:44:37.339473 140223721211712 make_examples_core.py:301] Task 0/4: Preparing inputs. I0729 14:44:37.339473 140478861559616 make_examples_core.py:301] Task 3/4: Preparing inputs. I0729 14:44:37.350302 140710547908416 make_examples_core.py:301] Task 1/4: Preparing inputs. I0729 14:44:37.339477 139779121772352 make_examples_core.py:301] Task 2/4: Preparing inputs. I0729 14:44:37.476220 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.485832 140223721211712 make_examples_core.py:301] Task 0/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:648,usability,tool,tools,648,"Program always run; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**: YES. **Describe the issue:** . 1. When the input sequence (fastq) matches the reference sequence, the program will keep running. 2. Sequence obtain from data generation tools. (dwgsim) . **Setup**. - Operating system: Red Hat Enterprise Linux release 8.6 (Ootpa). - DeepVariant version: deepvariant1.6.0.sif. - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). GRCh38| (Sequence obtain from data generation tools. (dwgsim) length,8-9kB, 150bp, PE, sequence may the same as reference sequence) . **Steps to reproduce:**. - Command: . time singularity run ~/singularity/deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${bamSavePath}/${name}.sorted.bam \. --output_vcf ${vcf} \. --output_gvcf ${outputPath}/vcf/${name}/${name}.g.vcf.gz \. --num_shards $(nproc) \. --regions ${BED} \. --sample_name ${name} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"" . - Error trace: (if applicable). I0729 14:44:37.339473 140223721211712 make_examples_core.py:301] Task 0/4: Preparing inputs. I0729 14:44:37.339473 140478861559616 make_examples_core.py:301] Task 3/4: Preparing inputs. I0729 14:44:37.350302 140710547908416 make_examples_core.py:301] Task 1/4: Preparing inputs. I0729 14:44:37.339477 139779121772352 make_examples_core.py:301] Task 2/4: Preparing inputs. I0729 14:44:37.476220 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.485832 140223721211712 make_examples_core.py:301] Task 0/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:764,usability,Command,Command,764,"Program always run; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**: YES. **Describe the issue:** . 1. When the input sequence (fastq) matches the reference sequence, the program will keep running. 2. Sequence obtain from data generation tools. (dwgsim) . **Setup**. - Operating system: Red Hat Enterprise Linux release 8.6 (Ootpa). - DeepVariant version: deepvariant1.6.0.sif. - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). GRCh38| (Sequence obtain from data generation tools. (dwgsim) length,8-9kB, 150bp, PE, sequence may the same as reference sequence) . **Steps to reproduce:**. - Command: . time singularity run ~/singularity/deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${bamSavePath}/${name}.sorted.bam \. --output_vcf ${vcf} \. --output_gvcf ${outputPath}/vcf/${name}/${name}.g.vcf.gz \. --num_shards $(nproc) \. --regions ${BED} \. --sample_name ${name} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"" . - Error trace: (if applicable). I0729 14:44:37.339473 140223721211712 make_examples_core.py:301] Task 0/4: Preparing inputs. I0729 14:44:37.339473 140478861559616 make_examples_core.py:301] Task 3/4: Preparing inputs. I0729 14:44:37.350302 140710547908416 make_examples_core.py:301] Task 1/4: Preparing inputs. I0729 14:44:37.339477 139779121772352 make_examples_core.py:301] Task 2/4: Preparing inputs. I0729 14:44:37.476220 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.485832 140223721211712 make_examples_core.py:301] Task 0/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:1221,usability,Error,Error,1221,"ill keep running. 2. Sequence obtain from data generation tools. (dwgsim) . **Setup**. - Operating system: Red Hat Enterprise Linux release 8.6 (Ootpa). - DeepVariant version: deepvariant1.6.0.sif. - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). GRCh38| (Sequence obtain from data generation tools. (dwgsim) length,8-9kB, 150bp, PE, sequence may the same as reference sequence) . **Steps to reproduce:**. - Command: . time singularity run ~/singularity/deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${bamSavePath}/${name}.sorted.bam \. --output_vcf ${vcf} \. --output_gvcf ${outputPath}/vcf/${name}/${name}.g.vcf.gz \. --num_shards $(nproc) \. --regions ${BED} \. --sample_name ${name} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"" . - Error trace: (if applicable). I0729 14:44:37.339473 140223721211712 make_examples_core.py:301] Task 0/4: Preparing inputs. I0729 14:44:37.339473 140478861559616 make_examples_core.py:301] Task 3/4: Preparing inputs. I0729 14:44:37.350302 140710547908416 make_examples_core.py:301] Task 1/4: Preparing inputs. I0729 14:44:37.339477 139779121772352 make_examples_core.py:301] Task 2/4: Preparing inputs. I0729 14:44:37.476220 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.485832 140223721211712 make_examples_core.py:301] Task 0/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0729 14:44:37.533100 140223721211712 genomics_reader.py:222] Reading /lustre/home/acct-m",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:1336,usability,input,inputs,1336,"Enterprise Linux release 8.6 (Ootpa). - DeepVariant version: deepvariant1.6.0.sif. - Installation method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). GRCh38| (Sequence obtain from data generation tools. (dwgsim) length,8-9kB, 150bp, PE, sequence may the same as reference sequence) . **Steps to reproduce:**. - Command: . time singularity run ~/singularity/deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${bamSavePath}/${name}.sorted.bam \. --output_vcf ${vcf} \. --output_gvcf ${outputPath}/vcf/${name}/${name}.g.vcf.gz \. --num_shards $(nproc) \. --regions ${BED} \. --sample_name ${name} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"" . - Error trace: (if applicable). I0729 14:44:37.339473 140223721211712 make_examples_core.py:301] Task 0/4: Preparing inputs. I0729 14:44:37.339473 140478861559616 make_examples_core.py:301] Task 3/4: Preparing inputs. I0729 14:44:37.350302 140710547908416 make_examples_core.py:301] Task 1/4: Preparing inputs. I0729 14:44:37.339477 139779121772352 make_examples_core.py:301] Task 2/4: Preparing inputs. I0729 14:44:37.476220 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.485832 140223721211712 make_examples_core.py:301] Task 0/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0729 14:44:37.533100 140223721211712 genomics_reader.py:222] Reading /lustre/home/acct-medfzx/medfzx-lkw/project/CAH/data/BED/cah_noname.bed with NativeBedReader. I0729 14:44:37.541654 140223721211712 ma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:1429,usability,input,inputs,1429,"tion method (Docker, built from source, etc.): singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). GRCh38| (Sequence obtain from data generation tools. (dwgsim) length,8-9kB, 150bp, PE, sequence may the same as reference sequence) . **Steps to reproduce:**. - Command: . time singularity run ~/singularity/deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${bamSavePath}/${name}.sorted.bam \. --output_vcf ${vcf} \. --output_gvcf ${outputPath}/vcf/${name}/${name}.g.vcf.gz \. --num_shards $(nproc) \. --regions ${BED} \. --sample_name ${name} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"" . - Error trace: (if applicable). I0729 14:44:37.339473 140223721211712 make_examples_core.py:301] Task 0/4: Preparing inputs. I0729 14:44:37.339473 140478861559616 make_examples_core.py:301] Task 3/4: Preparing inputs. I0729 14:44:37.350302 140710547908416 make_examples_core.py:301] Task 1/4: Preparing inputs. I0729 14:44:37.339477 139779121772352 make_examples_core.py:301] Task 2/4: Preparing inputs. I0729 14:44:37.476220 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.485832 140223721211712 make_examples_core.py:301] Task 0/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0729 14:44:37.533100 140223721211712 genomics_reader.py:222] Reading /lustre/home/acct-medfzx/medfzx-lkw/project/CAH/data/BED/cah_noname.bed with NativeBedReader. I0729 14:44:37.541654 140223721211712 make_examples_core.py:301] Task 0/4: Starting from v0.9.0, --use_ref_for_cram is default to tru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:1522,usability,input,inputs,1522,"ument, reference genome, anything special that is unlike the case studies?). GRCh38| (Sequence obtain from data generation tools. (dwgsim) length,8-9kB, 150bp, PE, sequence may the same as reference sequence) . **Steps to reproduce:**. - Command: . time singularity run ~/singularity/deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${bamSavePath}/${name}.sorted.bam \. --output_vcf ${vcf} \. --output_gvcf ${outputPath}/vcf/${name}/${name}.g.vcf.gz \. --num_shards $(nproc) \. --regions ${BED} \. --sample_name ${name} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"" . - Error trace: (if applicable). I0729 14:44:37.339473 140223721211712 make_examples_core.py:301] Task 0/4: Preparing inputs. I0729 14:44:37.339473 140478861559616 make_examples_core.py:301] Task 3/4: Preparing inputs. I0729 14:44:37.350302 140710547908416 make_examples_core.py:301] Task 1/4: Preparing inputs. I0729 14:44:37.339477 139779121772352 make_examples_core.py:301] Task 2/4: Preparing inputs. I0729 14:44:37.476220 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.485832 140223721211712 make_examples_core.py:301] Task 0/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0729 14:44:37.533100 140223721211712 genomics_reader.py:222] Reading /lustre/home/acct-medfzx/medfzx-lkw/project/CAH/data/BED/cah_noname.bed with NativeBedReader. I0729 14:44:37.541654 140223721211712 make_examples_core.py:301] Task 0/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:1615,usability,input,inputs,1615,"e obtain from data generation tools. (dwgsim) length,8-9kB, 150bp, PE, sequence may the same as reference sequence) . **Steps to reproduce:**. - Command: . time singularity run ~/singularity/deepvariant.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref ${ref} \. --reads ${bamSavePath}/${name}.sorted.bam \. --output_vcf ${vcf} \. --output_gvcf ${outputPath}/vcf/${name}/${name}.g.vcf.gz \. --num_shards $(nproc) \. --regions ${BED} \. --sample_name ${name} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"" . - Error trace: (if applicable). I0729 14:44:37.339473 140223721211712 make_examples_core.py:301] Task 0/4: Preparing inputs. I0729 14:44:37.339473 140478861559616 make_examples_core.py:301] Task 3/4: Preparing inputs. I0729 14:44:37.350302 140710547908416 make_examples_core.py:301] Task 1/4: Preparing inputs. I0729 14:44:37.339477 139779121772352 make_examples_core.py:301] Task 2/4: Preparing inputs. I0729 14:44:37.476220 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.485832 140223721211712 make_examples_core.py:301] Task 0/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0729 14:44:37.533100 140223721211712 genomics_reader.py:222] Reading /lustre/home/acct-medfzx/medfzx-lkw/project/CAH/data/BED/cah_noname.bed with NativeBedReader. I0729 14:44:37.541654 140223721211712 make_examples_core.py:301] Task 0/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0729 14:44:37.543606 140223721211712 genomics_reader.py:222] Reading result/s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:2457,usability,input,input,2457,"40710547908416 make_examples_core.py:301] Task 1/4: Preparing inputs. I0729 14:44:37.339477 139779121772352 make_examples_core.py:301] Task 2/4: Preparing inputs. I0729 14:44:37.476220 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.485832 140223721211712 make_examples_core.py:301] Task 0/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0729 14:44:37.533100 140223721211712 genomics_reader.py:222] Reading /lustre/home/acct-medfzx/medfzx-lkw/project/CAH/data/BED/cah_noname.bed with NativeBedReader. I0729 14:44:37.541654 140223721211712 make_examples_core.py:301] Task 0/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0729 14:44:37.543606 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.620779 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.620978 140223721211712 make_examples_core.py:301] Task 0/4: Writing gvcf records to /tmp/tmpkcjcf0p_/gvcf.tfrecord-00000-of-00004.gz. I0729 14:44:37.621363 140223721211712 make_examples_core.py:301] Task 0/4: Writing examples to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00000-of-00004.gz. I0729 14:44:37.621420 140223721211712 make_examples_core.py:301] Task 0/4: Overhead for preparing inputs: 0 seconds. I0729 14:44:37.652796 140223721211712 make_examples_core.py:301] Task 0/4: 0 candidates (0 exa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:3347,usability,input,inputs,3347,"_core.py:301] Task 0/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0729 14:44:37.543606 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.620779 140223721211712 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.620978 140223721211712 make_examples_core.py:301] Task 0/4: Writing gvcf records to /tmp/tmpkcjcf0p_/gvcf.tfrecord-00000-of-00004.gz. I0729 14:44:37.621363 140223721211712 make_examples_core.py:301] Task 0/4: Writing examples to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00000-of-00004.gz. I0729 14:44:37.621420 140223721211712 make_examples_core.py:301] Task 0/4: Overhead for preparing inputs: 0 seconds. I0729 14:44:37.652796 140223721211712 make_examples_core.py:301] Task 0/4: 0 candidates (0 examples) [0.03s elapsed]. I0729 14:44:37.476214 140478861559616 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.485823 140478861559616 make_examples_core.py:301] Task 3/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0729 14:44:37.533152 140478861559616 genomics_reader.py:222] Reading /lustre/home/acct-medfzx/medfzx-lkw/project/CAH/data/BED/cah_noname.bed with NativeBedReader. I0729 14:44:37.541796 140478861559616 make_examples_core.py:301] Task 3/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:4318,usability,input,input,4318,"4: Overhead for preparing inputs: 0 seconds. I0729 14:44:37.652796 140223721211712 make_examples_core.py:301] Task 0/4: 0 candidates (0 examples) [0.03s elapsed]. I0729 14:44:37.476214 140478861559616 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.485823 140478861559616 make_examples_core.py:301] Task 3/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0729 14:44:37.533152 140478861559616 genomics_reader.py:222] Reading /lustre/home/acct-medfzx/medfzx-lkw/project/CAH/data/BED/cah_noname.bed with NativeBedReader. I0729 14:44:37.541796 140478861559616 make_examples_core.py:301] Task 3/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0729 14:44:37.543756 140478861559616 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.619259 140478861559616 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.619429 140478861559616 make_examples_core.py:301] Task 3/4: Writing gvcf records to /tmp/tmpkcjcf0p_/gvcf.tfrecord-00003-of-00004.gz. I0729 14:44:37.619812 140478861559616 make_examples_core.py:301] Task 3/4: Writing examples to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00003-of-00004.gz. I0729 14:44:37.619867 140478861559616 make_examples_core.py:301] Task 3/4: Overhead for preparing inputs: 0 seconds. I0729 14:44:37.653389 140478861559616 make_examples_core.py:301] Task 3/4: 0 candidates (0 exa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:5208,usability,input,inputs,5208,"_core.py:301] Task 3/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0729 14:44:37.543756 140478861559616 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.619259 140478861559616 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.619429 140478861559616 make_examples_core.py:301] Task 3/4: Writing gvcf records to /tmp/tmpkcjcf0p_/gvcf.tfrecord-00003-of-00004.gz. I0729 14:44:37.619812 140478861559616 make_examples_core.py:301] Task 3/4: Writing examples to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00003-of-00004.gz. I0729 14:44:37.619867 140478861559616 make_examples_core.py:301] Task 3/4: Overhead for preparing inputs: 0 seconds. I0729 14:44:37.653389 140478861559616 make_examples_core.py:301] Task 3/4: 0 candidates (0 examples) [0.03s elapsed]. I0729 14:44:37.476402 140710547908416 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.486019 140710547908416 make_examples_core.py:301] Task 1/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0729 14:44:37.533221 140710547908416 genomics_reader.py:222] Reading /lustre/home/acct-medfzx/medfzx-lkw/project/CAH/data/BED/cah_noname.bed with NativeBedReader. I0729 14:44:37.541869 140710547908416 make_examples_core.py:301] Task 1/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:6179,usability,input,input,6179,"4: Overhead for preparing inputs: 0 seconds. I0729 14:44:37.653389 140478861559616 make_examples_core.py:301] Task 3/4: 0 candidates (0 examples) [0.03s elapsed]. I0729 14:44:37.476402 140710547908416 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.486019 140710547908416 make_examples_core.py:301] Task 1/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0729 14:44:37.533221 140710547908416 genomics_reader.py:222] Reading /lustre/home/acct-medfzx/medfzx-lkw/project/CAH/data/BED/cah_noname.bed with NativeBedReader. I0729 14:44:37.541869 140710547908416 make_examples_core.py:301] Task 1/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0729 14:44:37.543881 140710547908416 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.619640 140710547908416 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.619808 140710547908416 make_examples_core.py:301] Task 1/4: Writing gvcf records to /tmp/tmpkcjcf0p_/gvcf.tfrecord-00001-of-00004.gz. I0729 14:44:37.620180 140710547908416 make_examples_core.py:301] Task 1/4: Writing examples to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00001-of-00004.gz. I0729 14:44:37.620236 140710547908416 make_examples_core.py:301] Task 1/4: Overhead for preparing inputs: 0 seconds. I0729 14:44:37.652904 140710547908416 make_examples_core.py:301] Task 1/4: 0 candidates (0 exa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:7069,usability,input,inputs,7069,"_core.py:301] Task 1/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0729 14:44:37.543881 140710547908416 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.619640 140710547908416 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.619808 140710547908416 make_examples_core.py:301] Task 1/4: Writing gvcf records to /tmp/tmpkcjcf0p_/gvcf.tfrecord-00001-of-00004.gz. I0729 14:44:37.620180 140710547908416 make_examples_core.py:301] Task 1/4: Writing examples to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00001-of-00004.gz. I0729 14:44:37.620236 140710547908416 make_examples_core.py:301] Task 1/4: Overhead for preparing inputs: 0 seconds. I0729 14:44:37.652904 140710547908416 make_examples_core.py:301] Task 1/4: 0 candidates (0 examples) [0.03s elapsed]. I0729 14:44:37.476840 139779121772352 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.486504 139779121772352 make_examples_core.py:301] Task 2/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0729 14:44:37.533215 139779121772352 genomics_reader.py:222] Reading /lustre/home/acct-medfzx/medfzx-lkw/project/CAH/data/BED/cah_noname.bed with NativeBedReader. I0729 14:44:37.541668 139779121772352 make_examples_core.py:301] Task 2/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:8040,usability,input,input,8040,"4: Overhead for preparing inputs: 0 seconds. I0729 14:44:37.652904 140710547908416 make_examples_core.py:301] Task 1/4: 0 candidates (0 examples) [0.03s elapsed]. I0729 14:44:37.476840 139779121772352 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.486504 139779121772352 make_examples_core.py:301] Task 2/4: Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0729 14:44:37.533215 139779121772352 genomics_reader.py:222] Reading /lustre/home/acct-medfzx/medfzx-lkw/project/CAH/data/BED/cah_noname.bed with NativeBedReader. I0729 14:44:37.541668 139779121772352 make_examples_core.py:301] Task 2/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0729 14:44:37.543754 139779121772352 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.624524 139779121772352 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.624701 139779121772352 make_examples_core.py:301] Task 2/4: Writing gvcf records to /tmp/tmpkcjcf0p_/gvcf.tfrecord-00002-of-00004.gz. I0729 14:44:37.625109 139779121772352 make_examples_core.py:301] Task 2/4: Writing examples to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00002-of-00004.gz. I0729 14:44:37.625170 139779121772352 make_examples_core.py:301] Task 2/4: Overhead for preparing inputs: 0 seconds. I0729 14:44:37.653617 139779121772352 make_examples_core.py:301] Task 2/4: 0 candidates (0 exa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:8930,usability,input,inputs,8930,"_core.py:301] Task 2/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0729 14:44:37.543754 139779121772352 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.624524 139779121772352 genomics_reader.py:222] Reading result/simulate_A/bam/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585/chr6_CYP21A2_CYP21A1P__A_Q_8845_R_8585.sorted.bam with NativeSamReader. I0729 14:44:37.624701 139779121772352 make_examples_core.py:301] Task 2/4: Writing gvcf records to /tmp/tmpkcjcf0p_/gvcf.tfrecord-00002-of-00004.gz. I0729 14:44:37.625109 139779121772352 make_examples_core.py:301] Task 2/4: Writing examples to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00002-of-00004.gz. I0729 14:44:37.625170 139779121772352 make_examples_core.py:301] Task 2/4: Overhead for preparing inputs: 0 seconds. I0729 14:44:37.653617 139779121772352 make_examples_core.py:301] Task 2/4: 0 candidates (0 examples) [0.03s elapsed]. I0729 14:44:37.898170 140223721211712 make_examples_core.py:301] Task 0/4: Writing example info to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00000-of-00004.gz.example_info.json. I0729 14:44:37.898274 140223721211712 make_examples_core.py:2958] example_shape = None. I0729 14:44:37.898649 140223721211712 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0729 14:44:37.899018 140223721211712 make_examples_core.py:301] Task 0/4: Found 0 candidate variants. I0729 14:44:37.899082 140223721211712 make_examples_core.py:301] Task 0/4: Created 0 examples. I0729 14:44:37.898826 140478861559616 make_examples_core.py:301] Task 3/4: Writing example info to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00003-of-00004.gz.example_info.json. I0729 14:44:37.898957 140478861559616 make_examples_core.py:2958] example_shape = None. I0729 14:44:37.899326 140478861",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:11366,usability,user,user,11366,"ample_info.json. I0729 14:44:37.898977 140710547908416 make_examples_core.py:2958] example_shape = None. I0729 14:44:37.899351 140710547908416 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0729 14:44:37.899687 140710547908416 make_examples_core.py:301] Task 1/4: Found 0 candidate variants. I0729 14:44:37.899752 140710547908416 make_examples_core.py:301] Task 1/4: Created 0 examples. I0729 14:44:37.893192 139779121772352 make_examples_core.py:301] Task 2/4: Writing example info to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00002-of-00004.gz.example_info.json. I0729 14:44:37.893293 139779121772352 make_examples_core.py:2958] example_shape = None. I0729 14:44:37.893665 139779121772352 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0729 14:44:37.894033 139779121772352 make_examples_core.py:301] Task 2/4: Found 0 candidate variants. I0729 14:44:37.894105 139779121772352 make_examples_core.py:301] Task 2/4: Created 0 examples. real	0m4.791s. user	0m11.503s. sys	0m2.085s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpkcjcf0p_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wes"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0729 14:44:41.088234 139722246891328 call_variants.py:471] Total 1 writing processes started. W0729 14:44:41.090612 139722246891328 call_variants.py:482] Unable to read any records from /tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:11414,usability,command,command,11414,"8416 make_examples_core.py:2958] example_shape = None. I0729 14:44:37.899351 140710547908416 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0729 14:44:37.899687 140710547908416 make_examples_core.py:301] Task 1/4: Found 0 candidate variants. I0729 14:44:37.899752 140710547908416 make_examples_core.py:301] Task 1/4: Created 0 examples. I0729 14:44:37.893192 139779121772352 make_examples_core.py:301] Task 2/4: Writing example info to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00002-of-00004.gz.example_info.json. I0729 14:44:37.893293 139779121772352 make_examples_core.py:2958] example_shape = None. I0729 14:44:37.893665 139779121772352 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0729 14:44:37.894033 139779121772352 make_examples_core.py:301] Task 2/4: Found 0 candidate variants. I0729 14:44:37.894105 139779121772352 make_examples_core.py:301] Task 2/4: Created 0 examples. real	0m4.791s. user	0m11.503s. sys	0m2.085s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpkcjcf0p_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wes"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0729 14:44:41.088234 139722246891328 call_variants.py:471] Total 1 writing processes started. W0729 14:44:41.090612 139722246891328 call_variants.py:482] Unable to read any records from /tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz. Output will contain zero records. I0729 14:44:41.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:11703,usability,User,UserWarning,11703,"e.py:301] Task 1/4: Found 0 candidate variants. I0729 14:44:37.899752 140710547908416 make_examples_core.py:301] Task 1/4: Created 0 examples. I0729 14:44:37.893192 139779121772352 make_examples_core.py:301] Task 2/4: Writing example info to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00002-of-00004.gz.example_info.json. I0729 14:44:37.893293 139779121772352 make_examples_core.py:2958] example_shape = None. I0729 14:44:37.893665 139779121772352 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0729 14:44:37.894033 139779121772352 make_examples_core.py:301] Task 2/4: Found 0 candidate variants. I0729 14:44:37.894105 139779121772352 make_examples_core.py:301] Task 2/4: Created 0 examples. real	0m4.791s. user	0m11.503s. sys	0m2.085s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpkcjcf0p_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wes"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0729 14:44:41.088234 139722246891328 call_variants.py:471] Total 1 writing processes started. W0729 14:44:41.090612 139722246891328 call_variants.py:482] Unable to read any records from /tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz. Output will contain zero records. I0729 14:44:41.091079 139722246891328 call_variants.py:623] Complete: call_variants. **Does the quick start test work on your system?**. yes. **Any additional context:**. Some samples work fine, some very similar samples keep running.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:11816,usability,minim,minimal,11816,"e.py:301] Task 1/4: Found 0 candidate variants. I0729 14:44:37.899752 140710547908416 make_examples_core.py:301] Task 1/4: Created 0 examples. I0729 14:44:37.893192 139779121772352 make_examples_core.py:301] Task 2/4: Writing example info to /tmp/tmpkcjcf0p_/make_examples.tfrecord-00002-of-00004.gz.example_info.json. I0729 14:44:37.893293 139779121772352 make_examples_core.py:2958] example_shape = None. I0729 14:44:37.893665 139779121772352 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0729 14:44:37.894033 139779121772352 make_examples_core.py:301] Task 2/4: Found 0 candidate variants. I0729 14:44:37.894105 139779121772352 make_examples_core.py:301] Task 2/4: Created 0 examples. real	0m4.791s. user	0m11.503s. sys	0m2.085s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpkcjcf0p_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/wes"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0729 14:44:41.088234 139722246891328 call_variants.py:471] Total 1 writing processes started. W0729 14:44:41.090612 139722246891328 call_variants.py:482] Unable to read any records from /tmp/tmpkcjcf0p_/make_examples.tfrecord@4.gz. Output will contain zero records. I0729 14:44:41.091079 139722246891328 call_variants.py:623] Complete: call_variants. **Does the quick start test work on your system?**. yes. **Any additional context:**. Some samples work fine, some very similar samples keep running.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/856:20,availability,slo,slow,20,"DeepVariant running slow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). Hello All,. I have been testing ONT datasets on the HPC cluster to benchmark and optimize them. While using the mapped ONT BAM files from the HG002 and HG003 datasets from the UCSC studies, I observed that DeepVariant gets stuck at the make_examples stage. Even after 24 hours, it remains in the same stage which is unsual. I would appreciate your input on this issue. **Setup**. - Operating system: Linux, HPC cluster. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . -ONT : https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam. reference -hg38 . **Steps to reproduce:**. - Command: . apptainer exec . --bind Deepvariant/HG002_HG003_1.5.0 deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant . --model_type ONT_R104 . --ref Homo_sapiens_assembly38.fasta . --reads HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam . --output_vcf HG002_chr1.output.vcf.gz . --output_gvcf HG002_chr1.output.g.vcf.gz . --regions chr1 --num_shards 56 --logging_dir chr1 . --intermediate_results_dir chr1/intermediate_results . - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, it did work. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:258,availability,cluster,cluster,258,"DeepVariant running slow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). Hello All,. I have been testing ONT datasets on the HPC cluster to benchmark and optimize them. While using the mapped ONT BAM files from the HG002 and HG003 datasets from the UCSC studies, I observed that DeepVariant gets stuck at the make_examples stage. Even after 24 hours, it remains in the same stage which is unsual. I would appreciate your input on this issue. **Setup**. - Operating system: Linux, HPC cluster. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . -ONT : https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam. reference -hg38 . **Steps to reproduce:**. - Command: . apptainer exec . --bind Deepvariant/HG002_HG003_1.5.0 deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant . --model_type ONT_R104 . --ref Homo_sapiens_assembly38.fasta . --reads HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam . --output_vcf HG002_chr1.output.vcf.gz . --output_gvcf HG002_chr1.output.g.vcf.gz . --regions chr1 --num_shards 56 --logging_dir chr1 . --intermediate_results_dir chr1/intermediate_results . - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, it did work. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:584,availability,Operat,Operating,584,"DeepVariant running slow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). Hello All,. I have been testing ONT datasets on the HPC cluster to benchmark and optimize them. While using the mapped ONT BAM files from the HG002 and HG003 datasets from the UCSC studies, I observed that DeepVariant gets stuck at the make_examples stage. Even after 24 hours, it remains in the same stage which is unsual. I would appreciate your input on this issue. **Setup**. - Operating system: Linux, HPC cluster. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . -ONT : https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam. reference -hg38 . **Steps to reproduce:**. - Command: . apptainer exec . --bind Deepvariant/HG002_HG003_1.5.0 deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant . --model_type ONT_R104 . --ref Homo_sapiens_assembly38.fasta . --reads HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam . --output_vcf HG002_chr1.output.vcf.gz . --output_gvcf HG002_chr1.output.g.vcf.gz . --regions chr1 --num_shards 56 --logging_dir chr1 . --intermediate_results_dir chr1/intermediate_results . - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, it did work. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:613,availability,cluster,cluster,613,"DeepVariant running slow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). Hello All,. I have been testing ONT datasets on the HPC cluster to benchmark and optimize them. While using the mapped ONT BAM files from the HG002 and HG003 datasets from the UCSC studies, I observed that DeepVariant gets stuck at the make_examples stage. Even after 24 hours, it remains in the same stage which is unsual. I would appreciate your input on this issue. **Setup**. - Operating system: Linux, HPC cluster. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . -ONT : https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam. reference -hg38 . **Steps to reproduce:**. - Command: . apptainer exec . --bind Deepvariant/HG002_HG003_1.5.0 deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant . --model_type ONT_R104 . --ref Homo_sapiens_assembly38.fasta . --reads HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam . --output_vcf HG002_chr1.output.vcf.gz . --output_gvcf HG002_chr1.output.g.vcf.gz . --regions chr1 --num_shards 56 --logging_dir chr1 . --intermediate_results_dir chr1/intermediate_results . - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, it did work. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:1489,availability,Error,Error,1489,"DeepVariant running slow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). Hello All,. I have been testing ONT datasets on the HPC cluster to benchmark and optimize them. While using the mapped ONT BAM files from the HG002 and HG003 datasets from the UCSC studies, I observed that DeepVariant gets stuck at the make_examples stage. Even after 24 hours, it remains in the same stage which is unsual. I would appreciate your input on this issue. **Setup**. - Operating system: Linux, HPC cluster. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . -ONT : https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam. reference -hg38 . **Steps to reproduce:**. - Command: . apptainer exec . --bind Deepvariant/HG002_HG003_1.5.0 deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant . --model_type ONT_R104 . --ref Homo_sapiens_assembly38.fasta . --reads HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam . --output_vcf HG002_chr1.output.vcf.gz . --output_gvcf HG002_chr1.output.g.vcf.gz . --regions chr1 --num_shards 56 --logging_dir chr1 . --intermediate_results_dir chr1/intermediate_results . - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, it did work. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:258,deployability,cluster,cluster,258,"DeepVariant running slow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). Hello All,. I have been testing ONT datasets on the HPC cluster to benchmark and optimize them. While using the mapped ONT BAM files from the HG002 and HG003 datasets from the UCSC studies, I observed that DeepVariant gets stuck at the make_examples stage. Even after 24 hours, it remains in the same stage which is unsual. I would appreciate your input on this issue. **Setup**. - Operating system: Linux, HPC cluster. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . -ONT : https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam. reference -hg38 . **Steps to reproduce:**. - Command: . apptainer exec . --bind Deepvariant/HG002_HG003_1.5.0 deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant . --model_type ONT_R104 . --ref Homo_sapiens_assembly38.fasta . --reads HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam . --output_vcf HG002_chr1.output.vcf.gz . --output_gvcf HG002_chr1.output.g.vcf.gz . --regions chr1 --num_shards 56 --logging_dir chr1 . --intermediate_results_dir chr1/intermediate_results . - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, it did work. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:394,deployability,observ,observed,394,"DeepVariant running slow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). Hello All,. I have been testing ONT datasets on the HPC cluster to benchmark and optimize them. While using the mapped ONT BAM files from the HG002 and HG003 datasets from the UCSC studies, I observed that DeepVariant gets stuck at the make_examples stage. Even after 24 hours, it remains in the same stage which is unsual. I would appreciate your input on this issue. **Setup**. - Operating system: Linux, HPC cluster. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . -ONT : https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam. reference -hg38 . **Steps to reproduce:**. - Command: . apptainer exec . --bind Deepvariant/HG002_HG003_1.5.0 deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant . --model_type ONT_R104 . --ref Homo_sapiens_assembly38.fasta . --reads HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam . --output_vcf HG002_chr1.output.vcf.gz . --output_gvcf HG002_chr1.output.g.vcf.gz . --regions chr1 --num_shards 56 --logging_dir chr1 . --intermediate_results_dir chr1/intermediate_results . - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, it did work. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:452,deployability,stage,stage,452,"DeepVariant running slow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). Hello All,. I have been testing ONT datasets on the HPC cluster to benchmark and optimize them. While using the mapped ONT BAM files from the HG002 and HG003 datasets from the UCSC studies, I observed that DeepVariant gets stuck at the make_examples stage. Even after 24 hours, it remains in the same stage which is unsual. I would appreciate your input on this issue. **Setup**. - Operating system: Linux, HPC cluster. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . -ONT : https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam. reference -hg38 . **Steps to reproduce:**. - Command: . apptainer exec . --bind Deepvariant/HG002_HG003_1.5.0 deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant . --model_type ONT_R104 . --ref Homo_sapiens_assembly38.fasta . --reads HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam . --output_vcf HG002_chr1.output.vcf.gz . --output_gvcf HG002_chr1.output.g.vcf.gz . --regions chr1 --num_shards 56 --logging_dir chr1 . --intermediate_results_dir chr1/intermediate_results . - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, it did work. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:503,deployability,stage,stage,503,"DeepVariant running slow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). Hello All,. I have been testing ONT datasets on the HPC cluster to benchmark and optimize them. While using the mapped ONT BAM files from the HG002 and HG003 datasets from the UCSC studies, I observed that DeepVariant gets stuck at the make_examples stage. Even after 24 hours, it remains in the same stage which is unsual. I would appreciate your input on this issue. **Setup**. - Operating system: Linux, HPC cluster. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . -ONT : https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam. reference -hg38 . **Steps to reproduce:**. - Command: . apptainer exec . --bind Deepvariant/HG002_HG003_1.5.0 deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant . --model_type ONT_R104 . --ref Homo_sapiens_assembly38.fasta . --reads HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam . --output_vcf HG002_chr1.output.vcf.gz . --output_gvcf HG002_chr1.output.g.vcf.gz . --regions chr1 --num_shards 56 --logging_dir chr1 . --intermediate_results_dir chr1/intermediate_results . - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, it did work. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:613,deployability,cluster,cluster,613,"DeepVariant running slow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). Hello All,. I have been testing ONT datasets on the HPC cluster to benchmark and optimize them. While using the mapped ONT BAM files from the HG002 and HG003 datasets from the UCSC studies, I observed that DeepVariant gets stuck at the make_examples stage. Even after 24 hours, it remains in the same stage which is unsual. I would appreciate your input on this issue. **Setup**. - Operating system: Linux, HPC cluster. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . -ONT : https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam. reference -hg38 . **Steps to reproduce:**. - Command: . apptainer exec . --bind Deepvariant/HG002_HG003_1.5.0 deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant . --model_type ONT_R104 . --ref Homo_sapiens_assembly38.fasta . --reads HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam . --output_vcf HG002_chr1.output.vcf.gz . --output_gvcf HG002_chr1.output.g.vcf.gz . --regions chr1 --num_shards 56 --logging_dir chr1 . --intermediate_results_dir chr1/intermediate_results . - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, it did work. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:636,deployability,version,version,636,"DeepVariant running slow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). Hello All,. I have been testing ONT datasets on the HPC cluster to benchmark and optimize them. While using the mapped ONT BAM files from the HG002 and HG003 datasets from the UCSC studies, I observed that DeepVariant gets stuck at the make_examples stage. Even after 24 hours, it remains in the same stage which is unsual. I would appreciate your input on this issue. **Setup**. - Operating system: Linux, HPC cluster. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . -ONT : https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam. reference -hg38 . **Steps to reproduce:**. - Command: . apptainer exec . --bind Deepvariant/HG002_HG003_1.5.0 deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant . --model_type ONT_R104 . --ref Homo_sapiens_assembly38.fasta . --reads HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam . --output_vcf HG002_chr1.output.vcf.gz . --output_gvcf HG002_chr1.output.g.vcf.gz . --regions chr1 --num_shards 56 --logging_dir chr1 . --intermediate_results_dir chr1/intermediate_results . - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, it did work. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:654,deployability,Instal,Installation,654,"DeepVariant running slow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). Hello All,. I have been testing ONT datasets on the HPC cluster to benchmark and optimize them. While using the mapped ONT BAM files from the HG002 and HG003 datasets from the UCSC studies, I observed that DeepVariant gets stuck at the make_examples stage. Even after 24 hours, it remains in the same stage which is unsual. I would appreciate your input on this issue. **Setup**. - Operating system: Linux, HPC cluster. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . -ONT : https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam. reference -hg38 . **Steps to reproduce:**. - Command: . apptainer exec . --bind Deepvariant/HG002_HG003_1.5.0 deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant . --model_type ONT_R104 . --ref Homo_sapiens_assembly38.fasta . --reads HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam . --output_vcf HG002_chr1.output.vcf.gz . --output_gvcf HG002_chr1.output.g.vcf.gz . --regions chr1 --num_shards 56 --logging_dir chr1 . --intermediate_results_dir chr1/intermediate_results . - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, it did work. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:283,energy efficiency,optim,optimize,283,"DeepVariant running slow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). Hello All,. I have been testing ONT datasets on the HPC cluster to benchmark and optimize them. While using the mapped ONT BAM files from the HG002 and HG003 datasets from the UCSC studies, I observed that DeepVariant gets stuck at the make_examples stage. Even after 24 hours, it remains in the same stage which is unsual. I would appreciate your input on this issue. **Setup**. - Operating system: Linux, HPC cluster. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . -ONT : https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam. reference -hg38 . **Steps to reproduce:**. - Command: . apptainer exec . --bind Deepvariant/HG002_HG003_1.5.0 deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant . --model_type ONT_R104 . --ref Homo_sapiens_assembly38.fasta . --reads HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam . --output_vcf HG002_chr1.output.vcf.gz . --output_gvcf HG002_chr1.output.g.vcf.gz . --regions chr1 --num_shards 56 --logging_dir chr1 . --intermediate_results_dir chr1/intermediate_results . - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, it did work. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:636,integrability,version,version,636,"DeepVariant running slow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). Hello All,. I have been testing ONT datasets on the HPC cluster to benchmark and optimize them. While using the mapped ONT BAM files from the HG002 and HG003 datasets from the UCSC studies, I observed that DeepVariant gets stuck at the make_examples stage. Even after 24 hours, it remains in the same stage which is unsual. I would appreciate your input on this issue. **Setup**. - Operating system: Linux, HPC cluster. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . -ONT : https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam. reference -hg38 . **Steps to reproduce:**. - Command: . apptainer exec . --bind Deepvariant/HG002_HG003_1.5.0 deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant . --model_type ONT_R104 . --ref Homo_sapiens_assembly38.fasta . --reads HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam . --output_vcf HG002_chr1.output.vcf.gz . --output_gvcf HG002_chr1.output.g.vcf.gz . --regions chr1 --num_shards 56 --logging_dir chr1 . --intermediate_results_dir chr1/intermediate_results . - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, it did work. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:1084,interoperability,bind,bind,1084,"DeepVariant running slow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). Hello All,. I have been testing ONT datasets on the HPC cluster to benchmark and optimize them. While using the mapped ONT BAM files from the HG002 and HG003 datasets from the UCSC studies, I observed that DeepVariant gets stuck at the make_examples stage. Even after 24 hours, it remains in the same stage which is unsual. I would appreciate your input on this issue. **Setup**. - Operating system: Linux, HPC cluster. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . -ONT : https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam. reference -hg38 . **Steps to reproduce:**. - Command: . apptainer exec . --bind Deepvariant/HG002_HG003_1.5.0 deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant . --model_type ONT_R104 . --ref Homo_sapiens_assembly38.fasta . --reads HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam . --output_vcf HG002_chr1.output.vcf.gz . --output_gvcf HG002_chr1.output.g.vcf.gz . --regions chr1 --num_shards 56 --logging_dir chr1 . --intermediate_results_dir chr1/intermediate_results . - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, it did work. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:636,modifiability,version,version,636,"DeepVariant running slow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). Hello All,. I have been testing ONT datasets on the HPC cluster to benchmark and optimize them. While using the mapped ONT BAM files from the HG002 and HG003 datasets from the UCSC studies, I observed that DeepVariant gets stuck at the make_examples stage. Even after 24 hours, it remains in the same stage which is unsual. I would appreciate your input on this issue. **Setup**. - Operating system: Linux, HPC cluster. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . -ONT : https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam. reference -hg38 . **Steps to reproduce:**. - Command: . apptainer exec . --bind Deepvariant/HG002_HG003_1.5.0 deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant . --model_type ONT_R104 . --ref Homo_sapiens_assembly38.fasta . --reads HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam . --output_vcf HG002_chr1.output.vcf.gz . --output_gvcf HG002_chr1.output.g.vcf.gz . --regions chr1 --num_shards 56 --logging_dir chr1 . --intermediate_results_dir chr1/intermediate_results . - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, it did work. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:1084,modifiability,bind,bind,1084,"DeepVariant running slow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). Hello All,. I have been testing ONT datasets on the HPC cluster to benchmark and optimize them. While using the mapped ONT BAM files from the HG002 and HG003 datasets from the UCSC studies, I observed that DeepVariant gets stuck at the make_examples stage. Even after 24 hours, it remains in the same stage which is unsual. I would appreciate your input on this issue. **Setup**. - Operating system: Linux, HPC cluster. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . -ONT : https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam. reference -hg38 . **Steps to reproduce:**. - Command: . apptainer exec . --bind Deepvariant/HG002_HG003_1.5.0 deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant . --model_type ONT_R104 . --ref Homo_sapiens_assembly38.fasta . --reads HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam . --output_vcf HG002_chr1.output.vcf.gz . --output_gvcf HG002_chr1.output.g.vcf.gz . --regions chr1 --num_shards 56 --logging_dir chr1 . --intermediate_results_dir chr1/intermediate_results . - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, it did work. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:283,performance,optimiz,optimize,283,"DeepVariant running slow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). Hello All,. I have been testing ONT datasets on the HPC cluster to benchmark and optimize them. While using the mapped ONT BAM files from the HG002 and HG003 datasets from the UCSC studies, I observed that DeepVariant gets stuck at the make_examples stage. Even after 24 hours, it remains in the same stage which is unsual. I would appreciate your input on this issue. **Setup**. - Operating system: Linux, HPC cluster. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . -ONT : https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam. reference -hg38 . **Steps to reproduce:**. - Command: . apptainer exec . --bind Deepvariant/HG002_HG003_1.5.0 deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant . --model_type ONT_R104 . --ref Homo_sapiens_assembly38.fasta . --reads HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam . --output_vcf HG002_chr1.output.vcf.gz . --output_gvcf HG002_chr1.output.g.vcf.gz . --regions chr1 --num_shards 56 --logging_dir chr1 . --intermediate_results_dir chr1/intermediate_results . - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, it did work. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:1489,performance,Error,Error,1489,"DeepVariant running slow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). Hello All,. I have been testing ONT datasets on the HPC cluster to benchmark and optimize them. While using the mapped ONT BAM files from the HG002 and HG003 datasets from the UCSC studies, I observed that DeepVariant gets stuck at the make_examples stage. Even after 24 hours, it remains in the same stage which is unsual. I would appreciate your input on this issue. **Setup**. - Operating system: Linux, HPC cluster. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . -ONT : https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam. reference -hg38 . **Steps to reproduce:**. - Command: . apptainer exec . --bind Deepvariant/HG002_HG003_1.5.0 deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant . --model_type ONT_R104 . --ref Homo_sapiens_assembly38.fasta . --reads HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam . --output_vcf HG002_chr1.output.vcf.gz . --output_gvcf HG002_chr1.output.g.vcf.gz . --regions chr1 --num_shards 56 --logging_dir chr1 . --intermediate_results_dir chr1/intermediate_results . - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, it did work. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:20,reliability,slo,slow,20,"DeepVariant running slow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). Hello All,. I have been testing ONT datasets on the HPC cluster to benchmark and optimize them. While using the mapped ONT BAM files from the HG002 and HG003 datasets from the UCSC studies, I observed that DeepVariant gets stuck at the make_examples stage. Even after 24 hours, it remains in the same stage which is unsual. I would appreciate your input on this issue. **Setup**. - Operating system: Linux, HPC cluster. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . -ONT : https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam. reference -hg38 . **Steps to reproduce:**. - Command: . apptainer exec . --bind Deepvariant/HG002_HG003_1.5.0 deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant . --model_type ONT_R104 . --ref Homo_sapiens_assembly38.fasta . --reads HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam . --output_vcf HG002_chr1.output.vcf.gz . --output_gvcf HG002_chr1.output.g.vcf.gz . --regions chr1 --num_shards 56 --logging_dir chr1 . --intermediate_results_dir chr1/intermediate_results . - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, it did work. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:1521,reliability,Doe,Does,1521,"DeepVariant running slow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). Hello All,. I have been testing ONT datasets on the HPC cluster to benchmark and optimize them. While using the mapped ONT BAM files from the HG002 and HG003 datasets from the UCSC studies, I observed that DeepVariant gets stuck at the make_examples stage. Even after 24 hours, it remains in the same stage which is unsual. I would appreciate your input on this issue. **Setup**. - Operating system: Linux, HPC cluster. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . -ONT : https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam. reference -hg38 . **Steps to reproduce:**. - Command: . apptainer exec . --bind Deepvariant/HG002_HG003_1.5.0 deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant . --model_type ONT_R104 . --ref Homo_sapiens_assembly38.fasta . --reads HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam . --output_vcf HG002_chr1.output.vcf.gz . --output_gvcf HG002_chr1.output.g.vcf.gz . --regions chr1 --num_shards 56 --logging_dir chr1 . --intermediate_results_dir chr1/intermediate_results . - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, it did work. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:226,safety,test,testing,226,"DeepVariant running slow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). Hello All,. I have been testing ONT datasets on the HPC cluster to benchmark and optimize them. While using the mapped ONT BAM files from the HG002 and HG003 datasets from the UCSC studies, I observed that DeepVariant gets stuck at the make_examples stage. Even after 24 hours, it remains in the same stage which is unsual. I would appreciate your input on this issue. **Setup**. - Operating system: Linux, HPC cluster. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . -ONT : https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam. reference -hg38 . **Steps to reproduce:**. - Command: . apptainer exec . --bind Deepvariant/HG002_HG003_1.5.0 deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant . --model_type ONT_R104 . --ref Homo_sapiens_assembly38.fasta . --reads HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam . --output_vcf HG002_chr1.output.vcf.gz . --output_gvcf HG002_chr1.output.g.vcf.gz . --regions chr1 --num_shards 56 --logging_dir chr1 . --intermediate_results_dir chr1/intermediate_results . - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, it did work. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:550,safety,input,input,550,"DeepVariant running slow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). Hello All,. I have been testing ONT datasets on the HPC cluster to benchmark and optimize them. While using the mapped ONT BAM files from the HG002 and HG003 datasets from the UCSC studies, I observed that DeepVariant gets stuck at the make_examples stage. Even after 24 hours, it remains in the same stage which is unsual. I would appreciate your input on this issue. **Setup**. - Operating system: Linux, HPC cluster. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . -ONT : https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam. reference -hg38 . **Steps to reproduce:**. - Command: . apptainer exec . --bind Deepvariant/HG002_HG003_1.5.0 deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant . --model_type ONT_R104 . --ref Homo_sapiens_assembly38.fasta . --reads HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam . --output_vcf HG002_chr1.output.vcf.gz . --output_gvcf HG002_chr1.output.g.vcf.gz . --regions chr1 --num_shards 56 --logging_dir chr1 . --intermediate_results_dir chr1/intermediate_results . - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, it did work. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:1489,safety,Error,Error,1489,"DeepVariant running slow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). Hello All,. I have been testing ONT datasets on the HPC cluster to benchmark and optimize them. While using the mapped ONT BAM files from the HG002 and HG003 datasets from the UCSC studies, I observed that DeepVariant gets stuck at the make_examples stage. Even after 24 hours, it remains in the same stage which is unsual. I would appreciate your input on this issue. **Setup**. - Operating system: Linux, HPC cluster. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . -ONT : https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam. reference -hg38 . **Steps to reproduce:**. - Command: . apptainer exec . --bind Deepvariant/HG002_HG003_1.5.0 deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant . --model_type ONT_R104 . --ref Homo_sapiens_assembly38.fasta . --reads HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam . --output_vcf HG002_chr1.output.vcf.gz . --output_gvcf HG002_chr1.output.g.vcf.gz . --regions chr1 --num_shards 56 --logging_dir chr1 . --intermediate_results_dir chr1/intermediate_results . - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, it did work. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:1542,safety,test,test,1542,"DeepVariant running slow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). Hello All,. I have been testing ONT datasets on the HPC cluster to benchmark and optimize them. While using the mapped ONT BAM files from the HG002 and HG003 datasets from the UCSC studies, I observed that DeepVariant gets stuck at the make_examples stage. Even after 24 hours, it remains in the same stage which is unsual. I would appreciate your input on this issue. **Setup**. - Operating system: Linux, HPC cluster. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . -ONT : https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam. reference -hg38 . **Steps to reproduce:**. - Command: . apptainer exec . --bind Deepvariant/HG002_HG003_1.5.0 deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant . --model_type ONT_R104 . --ref Homo_sapiens_assembly38.fasta . --reads HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam . --output_vcf HG002_chr1.output.vcf.gz . --output_gvcf HG002_chr1.output.g.vcf.gz . --regions chr1 --num_shards 56 --logging_dir chr1 . --intermediate_results_dir chr1/intermediate_results . - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, it did work. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:1578,safety,test,test,1578,"DeepVariant running slow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). Hello All,. I have been testing ONT datasets on the HPC cluster to benchmark and optimize them. While using the mapped ONT BAM files from the HG002 and HG003 datasets from the UCSC studies, I observed that DeepVariant gets stuck at the make_examples stage. Even after 24 hours, it remains in the same stage which is unsual. I would appreciate your input on this issue. **Setup**. - Operating system: Linux, HPC cluster. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . -ONT : https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam. reference -hg38 . **Steps to reproduce:**. - Command: . apptainer exec . --bind Deepvariant/HG002_HG003_1.5.0 deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant . --model_type ONT_R104 . --ref Homo_sapiens_assembly38.fasta . --reads HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam . --output_vcf HG002_chr1.output.vcf.gz . --output_gvcf HG002_chr1.output.g.vcf.gz . --regions chr1 --num_shards 56 --logging_dir chr1 . --intermediate_results_dir chr1/intermediate_results . - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, it did work. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:226,testability,test,testing,226,"DeepVariant running slow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). Hello All,. I have been testing ONT datasets on the HPC cluster to benchmark and optimize them. While using the mapped ONT BAM files from the HG002 and HG003 datasets from the UCSC studies, I observed that DeepVariant gets stuck at the make_examples stage. Even after 24 hours, it remains in the same stage which is unsual. I would appreciate your input on this issue. **Setup**. - Operating system: Linux, HPC cluster. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . -ONT : https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam. reference -hg38 . **Steps to reproduce:**. - Command: . apptainer exec . --bind Deepvariant/HG002_HG003_1.5.0 deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant . --model_type ONT_R104 . --ref Homo_sapiens_assembly38.fasta . --reads HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam . --output_vcf HG002_chr1.output.vcf.gz . --output_gvcf HG002_chr1.output.g.vcf.gz . --regions chr1 --num_shards 56 --logging_dir chr1 . --intermediate_results_dir chr1/intermediate_results . - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, it did work. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:394,testability,observ,observed,394,"DeepVariant running slow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). Hello All,. I have been testing ONT datasets on the HPC cluster to benchmark and optimize them. While using the mapped ONT BAM files from the HG002 and HG003 datasets from the UCSC studies, I observed that DeepVariant gets stuck at the make_examples stage. Even after 24 hours, it remains in the same stage which is unsual. I would appreciate your input on this issue. **Setup**. - Operating system: Linux, HPC cluster. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . -ONT : https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam. reference -hg38 . **Steps to reproduce:**. - Command: . apptainer exec . --bind Deepvariant/HG002_HG003_1.5.0 deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant . --model_type ONT_R104 . --ref Homo_sapiens_assembly38.fasta . --reads HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam . --output_vcf HG002_chr1.output.vcf.gz . --output_gvcf HG002_chr1.output.g.vcf.gz . --regions chr1 --num_shards 56 --logging_dir chr1 . --intermediate_results_dir chr1/intermediate_results . - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, it did work. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:750,testability,instrument,instrument,750,"DeepVariant running slow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). Hello All,. I have been testing ONT datasets on the HPC cluster to benchmark and optimize them. While using the mapped ONT BAM files from the HG002 and HG003 datasets from the UCSC studies, I observed that DeepVariant gets stuck at the make_examples stage. Even after 24 hours, it remains in the same stage which is unsual. I would appreciate your input on this issue. **Setup**. - Operating system: Linux, HPC cluster. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . -ONT : https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam. reference -hg38 . **Steps to reproduce:**. - Command: . apptainer exec . --bind Deepvariant/HG002_HG003_1.5.0 deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant . --model_type ONT_R104 . --ref Homo_sapiens_assembly38.fasta . --reads HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam . --output_vcf HG002_chr1.output.vcf.gz . --output_gvcf HG002_chr1.output.g.vcf.gz . --regions chr1 --num_shards 56 --logging_dir chr1 . --intermediate_results_dir chr1/intermediate_results . - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, it did work. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:852,testability,trace,trace,852,"DeepVariant running slow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). Hello All,. I have been testing ONT datasets on the HPC cluster to benchmark and optimize them. While using the mapped ONT BAM files from the HG002 and HG003 datasets from the UCSC studies, I observed that DeepVariant gets stuck at the make_examples stage. Even after 24 hours, it remains in the same stage which is unsual. I would appreciate your input on this issue. **Setup**. - Operating system: Linux, HPC cluster. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . -ONT : https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam. reference -hg38 . **Steps to reproduce:**. - Command: . apptainer exec . --bind Deepvariant/HG002_HG003_1.5.0 deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant . --model_type ONT_R104 . --ref Homo_sapiens_assembly38.fasta . --reads HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam . --output_vcf HG002_chr1.output.vcf.gz . --output_gvcf HG002_chr1.output.g.vcf.gz . --regions chr1 --num_shards 56 --logging_dir chr1 . --intermediate_results_dir chr1/intermediate_results . - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, it did work. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:1495,testability,trace,trace,1495,"DeepVariant running slow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). Hello All,. I have been testing ONT datasets on the HPC cluster to benchmark and optimize them. While using the mapped ONT BAM files from the HG002 and HG003 datasets from the UCSC studies, I observed that DeepVariant gets stuck at the make_examples stage. Even after 24 hours, it remains in the same stage which is unsual. I would appreciate your input on this issue. **Setup**. - Operating system: Linux, HPC cluster. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . -ONT : https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam. reference -hg38 . **Steps to reproduce:**. - Command: . apptainer exec . --bind Deepvariant/HG002_HG003_1.5.0 deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant . --model_type ONT_R104 . --ref Homo_sapiens_assembly38.fasta . --reads HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam . --output_vcf HG002_chr1.output.vcf.gz . --output_gvcf HG002_chr1.output.g.vcf.gz . --regions chr1 --num_shards 56 --logging_dir chr1 . --intermediate_results_dir chr1/intermediate_results . - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, it did work. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:1542,testability,test,test,1542,"DeepVariant running slow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). Hello All,. I have been testing ONT datasets on the HPC cluster to benchmark and optimize them. While using the mapped ONT BAM files from the HG002 and HG003 datasets from the UCSC studies, I observed that DeepVariant gets stuck at the make_examples stage. Even after 24 hours, it remains in the same stage which is unsual. I would appreciate your input on this issue. **Setup**. - Operating system: Linux, HPC cluster. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . -ONT : https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam. reference -hg38 . **Steps to reproduce:**. - Command: . apptainer exec . --bind Deepvariant/HG002_HG003_1.5.0 deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant . --model_type ONT_R104 . --ref Homo_sapiens_assembly38.fasta . --reads HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam . --output_vcf HG002_chr1.output.vcf.gz . --output_gvcf HG002_chr1.output.g.vcf.gz . --regions chr1 --num_shards 56 --logging_dir chr1 . --intermediate_results_dir chr1/intermediate_results . - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, it did work. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:1578,testability,test,test,1578,"DeepVariant running slow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). Hello All,. I have been testing ONT datasets on the HPC cluster to benchmark and optimize them. While using the mapped ONT BAM files from the HG002 and HG003 datasets from the UCSC studies, I observed that DeepVariant gets stuck at the make_examples stage. Even after 24 hours, it remains in the same stage which is unsual. I would appreciate your input on this issue. **Setup**. - Operating system: Linux, HPC cluster. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . -ONT : https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam. reference -hg38 . **Steps to reproduce:**. - Command: . apptainer exec . --bind Deepvariant/HG002_HG003_1.5.0 deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant . --model_type ONT_R104 . --ref Homo_sapiens_assembly38.fasta . --reads HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam . --output_vcf HG002_chr1.output.vcf.gz . --output_gvcf HG002_chr1.output.g.vcf.gz . --regions chr1 --num_shards 56 --logging_dir chr1 . --intermediate_results_dir chr1/intermediate_results . - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, it did work. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:1770,testability,context,context,1770,"DeepVariant running slow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). Hello All,. I have been testing ONT datasets on the HPC cluster to benchmark and optimize them. While using the mapped ONT BAM files from the HG002 and HG003 datasets from the UCSC studies, I observed that DeepVariant gets stuck at the make_examples stage. Even after 24 hours, it remains in the same stage which is unsual. I would appreciate your input on this issue. **Setup**. - Operating system: Linux, HPC cluster. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . -ONT : https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam. reference -hg38 . **Steps to reproduce:**. - Command: . apptainer exec . --bind Deepvariant/HG002_HG003_1.5.0 deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant . --model_type ONT_R104 . --ref Homo_sapiens_assembly38.fasta . --reads HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam . --output_vcf HG002_chr1.output.vcf.gz . --output_gvcf HG002_chr1.output.g.vcf.gz . --regions chr1 --num_shards 56 --logging_dir chr1 . --intermediate_results_dir chr1/intermediate_results . - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, it did work. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:148,usability,clear,clear,148,"DeepVariant running slow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). Hello All,. I have been testing ONT datasets on the HPC cluster to benchmark and optimize them. While using the mapped ONT BAM files from the HG002 and HG003 datasets from the UCSC studies, I observed that DeepVariant gets stuck at the make_examples stage. Even after 24 hours, it remains in the same stage which is unsual. I would appreciate your input on this issue. **Setup**. - Operating system: Linux, HPC cluster. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . -ONT : https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam. reference -hg38 . **Steps to reproduce:**. - Command: . apptainer exec . --bind Deepvariant/HG002_HG003_1.5.0 deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant . --model_type ONT_R104 . --ref Homo_sapiens_assembly38.fasta . --reads HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam . --output_vcf HG002_chr1.output.vcf.gz . --output_gvcf HG002_chr1.output.g.vcf.gz . --regions chr1 --num_shards 56 --logging_dir chr1 . --intermediate_results_dir chr1/intermediate_results . - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, it did work. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:550,usability,input,input,550,"DeepVariant running slow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). Hello All,. I have been testing ONT datasets on the HPC cluster to benchmark and optimize them. While using the mapped ONT BAM files from the HG002 and HG003 datasets from the UCSC studies, I observed that DeepVariant gets stuck at the make_examples stage. Even after 24 hours, it remains in the same stage which is unsual. I would appreciate your input on this issue. **Setup**. - Operating system: Linux, HPC cluster. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . -ONT : https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam. reference -hg38 . **Steps to reproduce:**. - Command: . apptainer exec . --bind Deepvariant/HG002_HG003_1.5.0 deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant . --model_type ONT_R104 . --ref Homo_sapiens_assembly38.fasta . --reads HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam . --output_vcf HG002_chr1.output.vcf.gz . --output_gvcf HG002_chr1.output.g.vcf.gz . --regions chr1 --num_shards 56 --logging_dir chr1 . --intermediate_results_dir chr1/intermediate_results . - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, it did work. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:1054,usability,Command,Command,1054,"DeepVariant running slow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). Hello All,. I have been testing ONT datasets on the HPC cluster to benchmark and optimize them. While using the mapped ONT BAM files from the HG002 and HG003 datasets from the UCSC studies, I observed that DeepVariant gets stuck at the make_examples stage. Even after 24 hours, it remains in the same stage which is unsual. I would appreciate your input on this issue. **Setup**. - Operating system: Linux, HPC cluster. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . -ONT : https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam. reference -hg38 . **Steps to reproduce:**. - Command: . apptainer exec . --bind Deepvariant/HG002_HG003_1.5.0 deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant . --model_type ONT_R104 . --ref Homo_sapiens_assembly38.fasta . --reads HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam . --output_vcf HG002_chr1.output.vcf.gz . --output_gvcf HG002_chr1.output.g.vcf.gz . --regions chr1 --num_shards 56 --logging_dir chr1 . --intermediate_results_dir chr1/intermediate_results . - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, it did work. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:1489,usability,Error,Error,1489,"DeepVariant running slow; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). Hello All,. I have been testing ONT datasets on the HPC cluster to benchmark and optimize them. While using the mapped ONT BAM files from the HG002 and HG003 datasets from the UCSC studies, I observed that DeepVariant gets stuck at the make_examples stage. Even after 24 hours, it remains in the same stage which is unsual. I would appreciate your input on this issue. **Setup**. - Operating system: Linux, HPC cluster. - DeepVariant version: 1.5.0. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) . -ONT : https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/UCSC_Ultralong_OxfordNanopore_Promethion/HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam. reference -hg38 . **Steps to reproduce:**. - Command: . apptainer exec . --bind Deepvariant/HG002_HG003_1.5.0 deepvariant_1.5.0.sif /opt/deepvariant/bin/run_deepvariant . --model_type ONT_R104 . --ref Homo_sapiens_assembly38.fasta . --reads HG002_GRCh38_ONT-UL_UCSC_20200508.phased.bam . --output_vcf HG002_chr1.output.vcf.gz . --output_gvcf HG002_chr1.output.g.vcf.gz . --regions chr1 --num_shards 56 --logging_dir chr1 . --intermediate_results_dir chr1/intermediate_results . - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, it did work. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/857:59,availability,restor,restored,59,"AssertionError: Some objects had attributes which were not restored:; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:YES. **Describe the issue:**. When Running deep variant wes mode, there arised an assetion error when loading the weights of the model. **Setup**. - Operating system:Linux . - DeepVariant version:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:253,availability,error,error,253,"AssertionError: Some objects had attributes which were not restored:; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:YES. **Describe the issue:**. When Running deep variant wes mode, there arised an assetion error when loading the weights of the model. **Setup**. - Operating system:Linux . - DeepVariant version:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:311,availability,Operat,Operating,311,"AssertionError: Some objects had attributes which were not restored:; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:YES. **Describe the issue:**. When Running deep variant wes mode, there arised an assetion error when loading the weights of the model. **Setup**. - Operating system:Linux . - DeepVariant version:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1054,availability,Error,Error,1054,"t restored:; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:YES. **Describe the issue:**. When Running deep variant wes mode, there arised an assetion error when loading the weights of the model. **Setup**. - Operating system:Linux . - DeepVariant version:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1170,availability,checkpoint,checkpoint,1170,"be the issue:**. When Running deep variant wes mode, there arised an assetion error when loading the weights of the model. **Setup**. - Operating system:Linux . - DeepVariant version:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-bas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1181,availability,checkpoint,checkpoint,1181,"e:**. When Running deep variant wes mode, there arised an assetion error when loading the weights of the model. **Setup**. - Operating system:Linux . - DeepVariant version:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1255,availability,checkpoint,checkpoint,1255,"hen loading the weights of the model. **Setup**. - Operating system:Linux . - DeepVariant version:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1266,availability,checkpoint,checkpoint,1266," the weights of the model. **Setup**. - Operating system:Linux . - DeepVariant version:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1361,availability,Restor,Restoring,1361," Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-enc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1399,availability,checkpoint,checkpoint,1399,"om source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the obje",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1433,availability,restor,restore,1433,"ype of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1539,availability,restor,restore,1539," **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1636,availability,checkpoint,checkpoints,1636,"ant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1769,availability,checkpoint,checkpoint,1769,"are/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1915,availability,checkpoint,checkpoint,1915,"xamples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(ma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1926,availability,checkpoint,checkpoint,1926,"ra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:2000,availability,checkpoint,checkpoint,2000,"${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvar",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:2011,availability,checkpoint,checkpoint,2011,"/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_v",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:2106,availability,Restor,Restoring,2106,"m /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:2144,availability,checkpoint,checkpoint,2144,"es/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_v",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:2178,availability,restor,restore,2178,"heckpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_va",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:2284,availability,restor,restore,2284,"ted and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:2381,availability,checkpoint,checkpoints,2381,"train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) fr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:2514,availability,checkpoint,checkpoint,2514,"e. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. ra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:3459,availability,checkpoint,checkpoint,3459,"sr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:3470,availability,checkpoint,checkpoint,3470,"sr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:3599,availability,restor,restored,3599,"sr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:350,deployability,version,version,350,"AssertionError: Some objects had attributes which were not restored:; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:YES. **Describe the issue:**. When Running deep variant wes mode, there arised an assetion error when loading the weights of the model. **Setup**. - Operating system:Linux . - DeepVariant version:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:367,deployability,Instal,Installation,367,"AssertionError: Some objects had attributes which were not restored:; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:YES. **Describe the issue:**. When Running deep variant wes mode, there arised an assetion error when loading the weights of the model. **Setup**. - Operating system:Linux . - DeepVariant version:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1324,deployability,version,version,1324,"Linux . - DeepVariant version:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is cal",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1350,deployability,updat,updating,1350,"ion:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. P",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1441,deployability,API,API,1441," data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the obje",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1598,deployability,build,building,1598,"run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:2069,deployability,version,version,2069,"plicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tm",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:2095,deployability,updat,updating,2095,"nsorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:2186,deployability,API,API,2186,"int.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_variants",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:2343,deployability,build,building,2343,"or updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:2688,deployability,modul,module,2688,"he object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . ```. **Does the quick start test work on your system?**. Please test with https:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:264,energy efficiency,load,loading,264,"AssertionError: Some objects had attributes which were not restored:; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:YES. **Describe the issue:**. When Running deep variant wes mode, there arised an assetion error when loading the weights of the model. **Setup**. - Operating system:Linux . - DeepVariant version:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:291,energy efficiency,model,model,291,"AssertionError: Some objects had attributes which were not restored:; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:YES. **Describe the issue:**. When Running deep variant wes mode, there arised an assetion error when loading the weights of the model. **Setup**. - Operating system:Linux . - DeepVariant version:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:786,energy efficiency,model,model,786,"AssertionError: Some objects had attributes which were not restored:; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:YES. **Describe the issue:**. When Running deep variant wes mode, there arised an assetion error when loading the weights of the model. **Setup**. - Operating system:Linux . - DeepVariant version:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:792,energy efficiency,model,model,792,"AssertionError: Some objects had attributes which were not restored:; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:YES. **Describe the issue:**. When Running deep variant wes mode, there arised an assetion error when loading the weights of the model. **Setup**. - Operating system:Linux . - DeepVariant version:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:3190,energy efficiency,model,model,3190,"sr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:350,integrability,version,version,350,"AssertionError: Some objects had attributes which were not restored:; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:YES. **Describe the issue:**. When Running deep variant wes mode, there arised an assetion error when loading the weights of the model. **Setup**. - Operating system:Linux . - DeepVariant version:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1324,integrability,version,version,1324,"Linux . - DeepVariant version:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is cal",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1441,integrability,API,API,1441," data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the obje",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1732,integrability,messag,message,1732,"ized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:2069,integrability,version,version,2069,"plicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tm",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:2186,integrability,API,API,2186,"int.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_variants",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:2477,integrability,messag,message,2477,"h variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1441,interoperability,API,API,1441," data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the obje",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1668,interoperability,format,format,1668,"iant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1732,interoperability,messag,message,1732,"ized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:2186,interoperability,API,API,2186,"int.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_variants",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:2413,interoperability,format,format,2413,"the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:2477,interoperability,messag,message,2477,"h variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:350,modifiability,version,version,350,"AssertionError: Some objects had attributes which were not restored:; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:YES. **Describe the issue:**. When Running deep variant wes mode, there arised an assetion error when loading the weights of the model. **Setup**. - Operating system:Linux . - DeepVariant version:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1143,modifiability,pac,packages,1143,"/docs/FAQ.md**:YES. **Describe the issue:**. When Running deep variant wes mode, there arised an assetion error when loading the weights of the model. **Setup**. - Operating system:Linux . - DeepVariant version:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver che",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1324,modifiability,version,version,1324,"Linux . - DeepVariant version:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is cal",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1483,modifiability,variab,variables,1483,"me, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1888,modifiability,pac,packages,1888," --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 25",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:2069,modifiability,version,version,2069,"plicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tm",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:2228,modifiability,variab,variables,2228,"rom tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_variants. model.load_weights(checkpoint_path).expect_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:2688,modifiability,modul,module,2688,"he object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . ```. **Does the quick start test work on your system?**. Please test with https:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:3280,modifiability,pac,packages,3280,"sr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:3432,modifiability,pac,packages,3432,"sr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:253,performance,error,error,253,"AssertionError: Some objects had attributes which were not restored:; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:YES. **Describe the issue:**. When Running deep variant wes mode, there arised an assetion error when loading the weights of the model. **Setup**. - Operating system:Linux . - DeepVariant version:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:264,performance,load,loading,264,"AssertionError: Some objects had attributes which were not restored:; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:YES. **Describe the issue:**. When Running deep variant wes mode, there arised an assetion error when loading the weights of the model. **Setup**. - Operating system:Linux . - DeepVariant version:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1054,performance,Error,Error,1054,"t restored:; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:YES. **Describe the issue:**. When Running deep variant wes mode, there arised an assetion error when loading the weights of the model. **Setup**. - Operating system:Linux . - DeepVariant version:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1569,performance,time,time,1569,"Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call las",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:2314,performance,time,time,2314," future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:59,reliability,restor,restored,59,"AssertionError: Some objects had attributes which were not restored:; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:YES. **Describe the issue:**. When Running deep variant wes mode, there arised an assetion error when loading the weights of the model. **Setup**. - Operating system:Linux . - DeepVariant version:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1170,reliability,checkpoint,checkpoint,1170,"be the issue:**. When Running deep variant wes mode, there arised an assetion error when loading the weights of the model. **Setup**. - Operating system:Linux . - DeepVariant version:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-bas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1181,reliability,checkpoint,checkpoint,1181,"e:**. When Running deep variant wes mode, there arised an assetion error when loading the weights of the model. **Setup**. - Operating system:Linux . - DeepVariant version:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1255,reliability,checkpoint,checkpoint,1255,"hen loading the weights of the model. **Setup**. - Operating system:Linux . - DeepVariant version:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1266,reliability,checkpoint,checkpoint,1266," the weights of the model. **Setup**. - Operating system:Linux . - DeepVariant version:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1361,reliability,Restor,Restoring,1361," Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-enc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1399,reliability,checkpoint,checkpoint,1399,"om source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the obje",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1433,reliability,restor,restore,1433,"ype of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1539,reliability,restor,restore,1539," **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1636,reliability,checkpoint,checkpoints,1636,"ant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1769,reliability,checkpoint,checkpoint,1769,"are/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1915,reliability,checkpoint,checkpoint,1915,"xamples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(ma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1926,reliability,checkpoint,checkpoint,1926,"ra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:2000,reliability,checkpoint,checkpoint,2000,"${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvar",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:2011,reliability,checkpoint,checkpoint,2011,"/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_v",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:2106,reliability,Restor,Restoring,2106,"m /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:2144,reliability,checkpoint,checkpoint,2144,"es/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_v",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:2178,reliability,restor,restore,2178,"heckpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_va",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:2284,reliability,restor,restore,2284,"ted and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:2381,reliability,checkpoint,checkpoints,2381,"train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) fr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:2514,reliability,checkpoint,checkpoint,2514,"e. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. ra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:3459,reliability,checkpoint,checkpoint,3459,"sr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:3470,reliability,checkpoint,checkpoint,3470,"sr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:3599,reliability,restor,restored,3599,"sr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:3618,reliability,Doe,Does,3618,"sr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:253,safety,error,error,253,"AssertionError: Some objects had attributes which were not restored:; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:YES. **Describe the issue:**. When Running deep variant wes mode, there arised an assetion error when loading the weights of the model. **Setup**. - Operating system:Linux . - DeepVariant version:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1054,safety,Error,Error,1054,"t restored:; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:YES. **Describe the issue:**. When Running deep variant wes mode, there arised an assetion error when loading the weights of the model. **Setup**. - Operating system:Linux . - DeepVariant version:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1350,safety,updat,updating,1350,"ion:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. P",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:2095,safety,updat,updating,2095,"nsorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:2688,safety,modul,module,2688,"he object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . ```. **Does the quick start test work on your system?**. Please test with https:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:3639,safety,test,test,3639,"sr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:3675,safety,test,test,3675,"sr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:291,security,model,model,291,"AssertionError: Some objects had attributes which were not restored:; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:YES. **Describe the issue:**. When Running deep variant wes mode, there arised an assetion error when loading the weights of the model. **Setup**. - Operating system:Linux . - DeepVariant version:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:786,security,model,model,786,"AssertionError: Some objects had attributes which were not restored:; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:YES. **Describe the issue:**. When Running deep variant wes mode, there arised an assetion error when loading the weights of the model. **Setup**. - Operating system:Linux . - DeepVariant version:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:792,security,model,model,792,"AssertionError: Some objects had attributes which were not restored:; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:YES. **Describe the issue:**. When Running deep variant wes mode, there arised an assetion error when loading the weights of the model. **Setup**. - Operating system:Linux . - DeepVariant version:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1350,security,updat,updating,1350,"ion:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. P",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:2095,security,updat,updating,2095,"nsorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:3190,security,model,model,3190,"sr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:0,testability,Assert,AssertionError,0,"AssertionError: Some objects had attributes which were not restored:; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:YES. **Describe the issue:**. When Running deep variant wes mode, there arised an assetion error when loading the weights of the model. **Setup**. - Operating system:Linux . - DeepVariant version:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:462,testability,instrument,instrument,462,"AssertionError: Some objects had attributes which were not restored:; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:YES. **Describe the issue:**. When Running deep variant wes mode, there arised an assetion error when loading the weights of the model. **Setup**. - Operating system:Linux . - DeepVariant version:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1060,testability,trace,trace,1060,"ored:; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:YES. **Describe the issue:**. When Running deep variant wes mode, there arised an assetion error when loading the weights of the model. **Setup**. - Operating system:Linux . - DeepVariant version:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:2540,testability,Trace,Traceback,2540,"e ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. Asser",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:3523,testability,Assert,AssertionError,3523,"sr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:3540,testability,Assert,AssertionError,3540,"sr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:3639,testability,test,test,3639,"sr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:3675,testability,test,test,3675,"sr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:3849,testability,context,context,3849,"sr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:253,usability,error,error,253,"AssertionError: Some objects had attributes which were not restored:; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:YES. **Describe the issue:**. When Running deep variant wes mode, there arised an assetion error when loading the weights of the model. **Setup**. - Operating system:Linux . - DeepVariant version:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:571,usability,Command,Command,571,"AssertionError: Some objects had attributes which were not restored:; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:YES. **Describe the issue:**. When Running deep variant wes mode, there arised an assetion error when loading the weights of the model. **Setup**. - Operating system:Linux . - DeepVariant version:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1054,usability,Error,Error,1054,"t restored:; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:YES. **Describe the issue:**. When Running deep variant wes mode, there arised an assetion error when loading the weights of the model. **Setup**. - Operating system:Linux . - DeepVariant version:1.6.1. - Installation method (Docker, built from source, etc.):Singularity. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. ```. DV=""singularity run /autofs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:1608,usability,Prefer,Prefer,1608,"fs/bal34/xyu/softwares/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant "". ${DV} \. --model_type=WES \. --customized_model=/autofs/bal34/xyu/run_software/dv_illu/model/model.ckpt \. --ref ${REF_FILE_PATH} \. --reads {1} \. --output_vcf ${BASE_DIR}/{2}/output.vcf.gz \. --num_shards 30 \. --make_examples_extra_args=""split_skip_reads=true,channels=''"" \. --intermediate_results_dir ${BASE_DIR}/{2}/intermediate_results_dir. ```. - Error trace: (if applicable). ```. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:2353,usability,Prefer,Prefer,2353,"ng:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0731 11:52:32.961261 140355267913536 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_rw0m5gar/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 640, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/858:280,deployability,continu,continue,280,"I have a question about training DeepVariant.; If I wanna train a customer DeepVariant on my own WGS data. I have two ideas:. 1. Create training dataset(such as chr1-chr19) and train the model on each chr1 one by one independently(It means train a model on chr1 firstly, and then continue to train on chr2). 2. Create training dataset on all chr(chr1-chr19), shuffle the dataset and training. Which way is deepvariant? In addition, I wanna to train a clean DeepVariant(Only train on my own data, is it work?). Thanks and except for you reply!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/858
https://github.com/google/deepvariant/issues/858:187,energy efficiency,model,model,187,"I have a question about training DeepVariant.; If I wanna train a customer DeepVariant on my own WGS data. I have two ideas:. 1. Create training dataset(such as chr1-chr19) and train the model on each chr1 one by one independently(It means train a model on chr1 firstly, and then continue to train on chr2). 2. Create training dataset on all chr(chr1-chr19), shuffle the dataset and training. Which way is deepvariant? In addition, I wanna to train a clean DeepVariant(Only train on my own data, is it work?). Thanks and except for you reply!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/858
https://github.com/google/deepvariant/issues/858:248,energy efficiency,model,model,248,"I have a question about training DeepVariant.; If I wanna train a customer DeepVariant on my own WGS data. I have two ideas:. 1. Create training dataset(such as chr1-chr19) and train the model on each chr1 one by one independently(It means train a model on chr1 firstly, and then continue to train on chr2). 2. Create training dataset on all chr(chr1-chr19), shuffle the dataset and training. Which way is deepvariant? In addition, I wanna to train a clean DeepVariant(Only train on my own data, is it work?). Thanks and except for you reply!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/858
https://github.com/google/deepvariant/issues/858:521,safety,except,except,521,"I have a question about training DeepVariant.; If I wanna train a customer DeepVariant on my own WGS data. I have two ideas:. 1. Create training dataset(such as chr1-chr19) and train the model on each chr1 one by one independently(It means train a model on chr1 firstly, and then continue to train on chr2). 2. Create training dataset on all chr(chr1-chr19), shuffle the dataset and training. Which way is deepvariant? In addition, I wanna to train a clean DeepVariant(Only train on my own data, is it work?). Thanks and except for you reply!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/858
https://github.com/google/deepvariant/issues/858:187,security,model,model,187,"I have a question about training DeepVariant.; If I wanna train a customer DeepVariant on my own WGS data. I have two ideas:. 1. Create training dataset(such as chr1-chr19) and train the model on each chr1 one by one independently(It means train a model on chr1 firstly, and then continue to train on chr2). 2. Create training dataset on all chr(chr1-chr19), shuffle the dataset and training. Which way is deepvariant? In addition, I wanna to train a clean DeepVariant(Only train on my own data, is it work?). Thanks and except for you reply!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/858
https://github.com/google/deepvariant/issues/858:248,security,model,model,248,"I have a question about training DeepVariant.; If I wanna train a customer DeepVariant on my own WGS data. I have two ideas:. 1. Create training dataset(such as chr1-chr19) and train the model on each chr1 one by one independently(It means train a model on chr1 firstly, and then continue to train on chr2). 2. Create training dataset on all chr(chr1-chr19), shuffle the dataset and training. Which way is deepvariant? In addition, I wanna to train a clean DeepVariant(Only train on my own data, is it work?). Thanks and except for you reply!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/858
https://github.com/google/deepvariant/issues/858:66,usability,custom,customer,66,"I have a question about training DeepVariant.; If I wanna train a customer DeepVariant on my own WGS data. I have two ideas:. 1. Create training dataset(such as chr1-chr19) and train the model on each chr1 one by one independently(It means train a model on chr1 firstly, and then continue to train on chr2). 2. Create training dataset on all chr(chr1-chr19), shuffle the dataset and training. Which way is deepvariant? In addition, I wanna to train a clean DeepVariant(Only train on my own data, is it work?). Thanks and except for you reply!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/858
https://github.com/google/deepvariant/issues/859:105,availability,error,error,105,"Source code compilation of DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:1946,availability,avail,available,1946,"infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:2200,availability,error,error,2200,"ata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:2230,availability,error,error,2230,"-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you con",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:8091,availability,Error,Error,8091,"the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. ------------------------------------------------------------. . _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned. Processing numpy/random/_bounded_integers.pxd.in. Processing numpy/random/_common.pyx. Processing numpy/random/_philox.pyx. Traceback (most recent call last):. File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 235, in <module>. main(). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 231, in main. find_process_files(root_dir). File ""/tmp/pip-install-u4pd848o",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:8273,availability,state,state,8273," you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. ------------------------------------------------------------. . _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned. Processing numpy/random/_bounded_integers.pxd.in. Processing numpy/random/_common.pyx. Processing numpy/random/_philox.pyx. Traceback (most recent call last):. File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 235, in <module>. main(). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 231, in main. find_process_files(root_dir). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 222, in find_process_files. process(root_dir, fromfile, tofile, function, hash_db). File ""/tmp/pip-install-u4pd848o/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:11243,availability,error,error,11243,"ook_input['kwargs']). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:11317,availability,error,error,11317,"endor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. jaxlib 0.4.31 pypi_0 pypi. ld_impl_linux-64 2.38 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:11366,availability,error,error,11366,", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. jaxlib 0.4.31 pypi_0 pypi. ld_impl_linux-64 2.38 h1181459_1 . libffi 3.4.4 h6a678d5_1 . libgcc-ng ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:12571,availability,servic,service,12571,. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. jaxlib 0.4.31 pypi_0 pypi. ld_impl_linux-64 2.38 h1181459_1 . libffi 3.4.4 h6a678d5_1 . libgcc-ng 11.2.0 h1234567_1 . libgomp 11.2.0 h1234567_1 . libstdcxx-ng 11.2.0 h1234567_1 . libuuid 1.41.5 h5eee18b_0 . markdown-it-py 3.0.0 pypi_0 pypi. mdurl 0.1.2 pypi_0 pypi. mkl 2023.1.0 h213fc3f_46344 . mkl-service 2.4.0 py310h5eee18b_1 . mkl_fft 1.3.8 py310h5eee18b_0 . mkl_random 1.2.4 py310hdb19cb5_0 . ml-collections 0.1.1 pypi_0 pypi. ml-dtypes 0.4.0 pypi_0 pypi. mock 5.1.0 pypi_0 pypi. msgpack 1.0.8 pypi_0 pypi. ncurses 6.4 h6a678d5_0 . nest-asyncio 1.6.0 pypi_0 pypi. numpy 1.24.3 py310h5f9d8c6_1 . numpy-base 1.24.3 py310hb5e798b_1 . openssl 3.0.14 h5eee18b_0 . opt-einsum 3.3.0 pypi_0 pypi. optax 0.2.3 pypi_0 pypi. orbax-checkpoint 0.5.23 pypi_0 pypi. packaging 24.1 pypi_0 pypi. pip 24.0 py310h06a4308_0 . protobuf 3.13.0 pypi_0 pypi. pygments 2.18.0 pypi_0 pypi. python 3.10.14 h955ad1f_1 . pyyaml 6.0.1 pypi_0 pypi. readline 8.2 h5eee18b_0 . rich 13.7.1 pypi_0 pypi. scipy 1.14.0 pypi_0 pypi. setuptools 69.5.1 py310h06a4308_0 . six 1.16.0 pypi_0 pypi. sortedcontainers 2.1.0 pypi_0 pypi. sqlite 3.45.3 h5eee18b_0 . tbb 2021.8.0 hdb19cb5_0 . tensorstore 0.1.64 pypi_0 pypi. tf-slim 1.1.0 pypi_0 pypi. tk 8.6.14 h39e8969_0 . toolz 0.12.1 pypi_0 pypi. typing-extensions 4.12.2 pypi_0 pypi. tzdata 2,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:12997,availability,checkpoint,checkpoint,12997,rsion Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. jaxlib 0.4.31 pypi_0 pypi. ld_impl_linux-64 2.38 h1181459_1 . libffi 3.4.4 h6a678d5_1 . libgcc-ng 11.2.0 h1234567_1 . libgomp 11.2.0 h1234567_1 . libstdcxx-ng 11.2.0 h1234567_1 . libuuid 1.41.5 h5eee18b_0 . markdown-it-py 3.0.0 pypi_0 pypi. mdurl 0.1.2 pypi_0 pypi. mkl 2023.1.0 h213fc3f_46344 . mkl-service 2.4.0 py310h5eee18b_1 . mkl_fft 1.3.8 py310h5eee18b_0 . mkl_random 1.2.4 py310hdb19cb5_0 . ml-collections 0.1.1 pypi_0 pypi. ml-dtypes 0.4.0 pypi_0 pypi. mock 5.1.0 pypi_0 pypi. msgpack 1.0.8 pypi_0 pypi. ncurses 6.4 h6a678d5_0 . nest-asyncio 1.6.0 pypi_0 pypi. numpy 1.24.3 py310h5f9d8c6_1 . numpy-base 1.24.3 py310hb5e798b_1 . openssl 3.0.14 h5eee18b_0 . opt-einsum 3.3.0 pypi_0 pypi. optax 0.2.3 pypi_0 pypi. orbax-checkpoint 0.5.23 pypi_0 pypi. packaging 24.1 pypi_0 pypi. pip 24.0 py310h06a4308_0 . protobuf 3.13.0 pypi_0 pypi. pygments 2.18.0 pypi_0 pypi. python 3.10.14 h955ad1f_1 . pyyaml 6.0.1 pypi_0 pypi. readline 8.2 h5eee18b_0 . rich 13.7.1 pypi_0 pypi. scipy 1.14.0 pypi_0 pypi. setuptools 69.5.1 py310h06a4308_0 . six 1.16.0 pypi_0 pypi. sortedcontainers 2.1.0 pypi_0 pypi. sqlite 3.45.3 h5eee18b_0 . tbb 2021.8.0 hdb19cb5_0 . tensorstore 0.1.64 pypi_0 pypi. tf-slim 1.1.0 pypi_0 pypi. tk 8.6.14 h39e8969_0 . toolz 0.12.1 pypi_0 pypi. typing-extensions 4.12.2 pypi_0 pypi. tzdata 2024a h04d1e81_0 . wheel 0.43.0 py310h06a4308_0 . wrapt 1.16.0 pypi_0 pypi. xz 5.4.6 h5eee18b_1 . zipp 3.19.2 pypi_0 pypi. zlib 1.2.13 h5eee18b_1 .,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:13456,availability,sli,slim,13456,rsion Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. jaxlib 0.4.31 pypi_0 pypi. ld_impl_linux-64 2.38 h1181459_1 . libffi 3.4.4 h6a678d5_1 . libgcc-ng 11.2.0 h1234567_1 . libgomp 11.2.0 h1234567_1 . libstdcxx-ng 11.2.0 h1234567_1 . libuuid 1.41.5 h5eee18b_0 . markdown-it-py 3.0.0 pypi_0 pypi. mdurl 0.1.2 pypi_0 pypi. mkl 2023.1.0 h213fc3f_46344 . mkl-service 2.4.0 py310h5eee18b_1 . mkl_fft 1.3.8 py310h5eee18b_0 . mkl_random 1.2.4 py310hdb19cb5_0 . ml-collections 0.1.1 pypi_0 pypi. ml-dtypes 0.4.0 pypi_0 pypi. mock 5.1.0 pypi_0 pypi. msgpack 1.0.8 pypi_0 pypi. ncurses 6.4 h6a678d5_0 . nest-asyncio 1.6.0 pypi_0 pypi. numpy 1.24.3 py310h5f9d8c6_1 . numpy-base 1.24.3 py310hb5e798b_1 . openssl 3.0.14 h5eee18b_0 . opt-einsum 3.3.0 pypi_0 pypi. optax 0.2.3 pypi_0 pypi. orbax-checkpoint 0.5.23 pypi_0 pypi. packaging 24.1 pypi_0 pypi. pip 24.0 py310h06a4308_0 . protobuf 3.13.0 pypi_0 pypi. pygments 2.18.0 pypi_0 pypi. python 3.10.14 h955ad1f_1 . pyyaml 6.0.1 pypi_0 pypi. readline 8.2 h5eee18b_0 . rich 13.7.1 pypi_0 pypi. scipy 1.14.0 pypi_0 pypi. setuptools 69.5.1 py310h06a4308_0 . six 1.16.0 pypi_0 pypi. sortedcontainers 2.1.0 pypi_0 pypi. sqlite 3.45.3 h5eee18b_0 . tbb 2021.8.0 hdb19cb5_0 . tensorstore 0.1.64 pypi_0 pypi. tf-slim 1.1.0 pypi_0 pypi. tk 8.6.14 h39e8969_0 . toolz 0.12.1 pypi_0 pypi. typing-extensions 4.12.2 pypi_0 pypi. tzdata 2024a h04d1e81_0 . wheel 0.43.0 py310h06a4308_0 . wrapt 1.16.0 pypi_0 pypi. xz 5.4.6 h5eee18b_1 . zipp 3.19.2 pypi_0 pypi. zlib 1.2.13 h5eee18b_1 .,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:39,deployability,fail,failed,39,"Source code compilation of DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:59,deployability,version,version,59,"Source code compilation of DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:228,deployability,version,versions,228,"Source code compilation of DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:286,deployability,build,build-prereq,286,"Source code compilation of DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:441,deployability,Stage,Stage,441,"Source code compilation of DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:448,deployability,Instal,Install,448,"Source code compilation of DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:626,deployability,Stage,Stage,626,"Source code compilation of DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:700,deployability,Stage,Stage,700,"Source code compilation of DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:707,deployability,Updat,Update,707,"Source code compilation of DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:783,deployability,Stage,Stage,783,"Source code compilation of DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:805,deployability,Instal,Install,805,"Source code compilation of DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:918,deployability,Stage,Stage,918,"Source code compilation of DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:925,deployability,Instal,Install,925,"Source code compilation of DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:951,deployability,infrastructur,infrastructure,951,"Source code compilation of DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:1266,deployability,Instal,Installing,1266,"e persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:1349,deployability,instal,installed,1349,"u 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:1530,deployability,instal,installed,1530,"buntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:1673,deployability,manag,manager,1673," 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Decl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:1928,deployability,releas,release,1928," python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. De",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:1983,deployability,updat,update,1983," Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:2000,deployability,instal,install,2000,"Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:2010,deployability,upgrad,upgrade,2010,"eed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure yo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:2157,deployability,Stage,Stage,2157,"sing cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always requi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:2164,deployability,Instal,Install,2164,"hed pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the G",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:8814,deployability,instal,install-,8814," function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. ------------------------------------------------------------. . _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned. Processing numpy/random/_bounded_integers.pxd.in. Processing numpy/random/_common.pyx. Processing numpy/random/_philox.pyx. Traceback (most recent call last):. File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 235, in <module>. main(). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 231, in main. find_process_files(root_dir). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 222, in find_process_files. process(root_dir, fromfile, tofile, function, hash_db). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 188, in process. processor_function(fromfile, tofile). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 77, in process_pyx. subprocess.check_call(. File ""/public/home/zhanghl3/miniconda3/envs/deepvariant/lib/python3.10/subprocess.py"", line 369, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '['/public/home/zhanghl3/miniconda3/envs/deepvariant/bin/python3', '-m', 'cython', '-3', '",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:8905,deployability,modul,module,8905,"r calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. ------------------------------------------------------------. . _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned. Processing numpy/random/_bounded_integers.pxd.in. Processing numpy/random/_common.pyx. Processing numpy/random/_philox.pyx. Traceback (most recent call last):. File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 235, in <module>. main(). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 231, in main. find_process_files(root_dir). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 222, in find_process_files. process(root_dir, fromfile, tofile, function, hash_db). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 188, in process. processor_function(fromfile, tofile). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 77, in process_pyx. subprocess.check_call(. File ""/public/home/zhanghl3/miniconda3/envs/deepvariant/lib/python3.10/subprocess.py"", line 369, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '['/public/home/zhanghl3/miniconda3/envs/deepvariant/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_philox.c', '_philox.pyx']' returned non-zero exit status 1. Cythoniz",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:8937,deployability,instal,install-,8937,"e the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. ------------------------------------------------------------. . _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned. Processing numpy/random/_bounded_integers.pxd.in. Processing numpy/random/_common.pyx. Processing numpy/random/_philox.pyx. Traceback (most recent call last):. File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 235, in <module>. main(). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 231, in main. find_process_files(root_dir). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 222, in find_process_files. process(root_dir, fromfile, tofile, function, hash_db). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 188, in process. processor_function(fromfile, tofile). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 77, in process_pyx. subprocess.check_call(. File ""/public/home/zhanghl3/miniconda3/envs/deepvariant/lib/python3.10/subprocess.py"", line 369, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '['/public/home/zhanghl3/miniconda3/envs/deepvariant/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_philox.c', '_philox.pyx']' returned non-zero exit status 1. Cythonizing sources. Traceback (most rece",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:9078,deployability,instal,install-,9078,"tions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. ------------------------------------------------------------. . _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned. Processing numpy/random/_bounded_integers.pxd.in. Processing numpy/random/_common.pyx. Processing numpy/random/_philox.pyx. Traceback (most recent call last):. File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 235, in <module>. main(). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 231, in main. find_process_files(root_dir). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 222, in find_process_files. process(root_dir, fromfile, tofile, function, hash_db). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 188, in process. processor_function(fromfile, tofile). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 77, in process_pyx. subprocess.check_call(. File ""/public/home/zhanghl3/miniconda3/envs/deepvariant/lib/python3.10/subprocess.py"", line 369, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '['/public/home/zhanghl3/miniconda3/envs/deepvariant/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_philox.c', '_philox.pyx']' returned non-zero exit status 1. Cythonizing sources. Traceback (most recent call last):. File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 353, in <module>.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:9259,deployability,instal,install-,9259,"f._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. ------------------------------------------------------------. . _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned. Processing numpy/random/_bounded_integers.pxd.in. Processing numpy/random/_common.pyx. Processing numpy/random/_philox.pyx. Traceback (most recent call last):. File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 235, in <module>. main(). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 231, in main. find_process_files(root_dir). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 222, in find_process_files. process(root_dir, fromfile, tofile, function, hash_db). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 188, in process. processor_function(fromfile, tofile). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 77, in process_pyx. subprocess.check_call(. File ""/public/home/zhanghl3/miniconda3/envs/deepvariant/lib/python3.10/subprocess.py"", line 369, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '['/public/home/zhanghl3/miniconda3/envs/deepvariant/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_philox.c', '_philox.pyx']' returned non-zero exit status 1. Cythonizing sources. Traceback (most recent call last):. File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 353, in <module>. main(). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 335, in main. json_out['return_val'] = hook(**hook_input['kwargs",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:9411,deployability,instal,install-,9411," _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned. Processing numpy/random/_bounded_integers.pxd.in. Processing numpy/random/_common.pyx. Processing numpy/random/_philox.pyx. Traceback (most recent call last):. File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 235, in <module>. main(). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 231, in main. find_process_files(root_dir). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 222, in find_process_files. process(root_dir, fromfile, tofile, function, hash_db). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 188, in process. processor_function(fromfile, tofile). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 77, in process_pyx. subprocess.check_call(. File ""/public/home/zhanghl3/miniconda3/envs/deepvariant/lib/python3.10/subprocess.py"", line 369, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '['/public/home/zhanghl3/miniconda3/envs/deepvariant/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_philox.c', '_philox.pyx']' returned non-zero exit status 1. Cythonizing sources. Traceback (most recent call last):. File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 353, in <module>. main(). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 335, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_whee",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:9825,deployability,fail,fail,9825,"48o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 235, in <module>. main(). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 231, in main. find_process_files(root_dir). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 222, in find_process_files. process(root_dir, fromfile, tofile, function, hash_db). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 188, in process. processor_function(fromfile, tofile). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 77, in process_pyx. subprocess.check_call(. File ""/public/home/zhanghl3/miniconda3/envs/deepvariant/lib/python3.10/subprocess.py"", line 369, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '['/public/home/zhanghl3/miniconda3/envs/deepvariant/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_philox.c', '_philox.pyx']' returned non-zero exit status 1. Cythonizing sources. Traceback (most recent call last):. File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 353, in <module>. main(). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 335, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:10074,deployability,modul,module,10074,"-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 222, in find_process_files. process(root_dir, fromfile, tofile, function, hash_db). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 188, in process. processor_function(fromfile, tofile). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 77, in process_pyx. subprocess.check_call(. File ""/public/home/zhanghl3/miniconda3/envs/deepvariant/lib/python3.10/subprocess.py"", line 369, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '['/public/home/zhanghl3/miniconda3/envs/deepvariant/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_philox.c', '_philox.pyx']' returned non-zero exit status 1. Cythonizing sources. Traceback (most recent call last):. File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 353, in <module>. main(). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 335, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:10483,deployability,build,build-env-,10483,"line 77, in process_pyx. subprocess.check_call(. File ""/public/home/zhanghl3/miniconda3/envs/deepvariant/lib/python3.10/subprocess.py"", line 369, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '['/public/home/zhanghl3/miniconda3/envs/deepvariant/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_philox.c', '_philox.pyx']' returned non-zero exit status 1. Cythonizing sources. Traceback (most recent call last):. File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 353, in <module>. main(). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 335, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:10646,deployability,build,build-env-,10646,"ise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '['/public/home/zhanghl3/miniconda3/envs/deepvariant/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_philox.c', '_philox.pyx']' returned non-zero exit status 1. Cythonizing sources. Traceback (most recent call last):. File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 353, in <module>. main(). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 335, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # pack",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:10800,deployability,build,build-env-,10800,"hon', '-3', '--fast-fail', '-o', '_philox.c', '_philox.pyx']' returned non-zero exit status 1. Cythonizing sources. Traceback (most recent call last):. File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 353, in <module>. main(). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 335, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:10987,deployability,modul,module,10987,"ite-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 353, in <module>. main(). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 335, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:11162,deployability,fail,failed,11162,"_in_process/_in_process.py"", line 335, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 py",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:11205,deployability,fail,failed,11205,"ain. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:11344,deployability,fail,failed,11344,"rocess/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. jaxlib 0.4.31 pypi_0 pypi. ld_impl_linux-64 2.38 h1181459_1 . libffi 3.4.4 h",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:11598,deployability,contain,contains,11598,"ild_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. jaxlib 0.4.31 pypi_0 pypi. ld_impl_linux-64 2.38 h1181459_1 . libffi 3.4.4 h6a678d5_1 . libgcc-ng 11.2.0 h1234567_1 . libgomp 11.2.0 h1234567_1 . libstdcxx-ng 11.2.0 h1234567_1 . libuuid 1.41.5 h5eee18b_0 . markdown-it-py 3.0.0 pypi_0 pypi. mdurl 0.1.2 pypi_0 pypi. mkl 2023.1.0 h213fc3f_46344 . mkl-service 2.4.0 py310h5eee18b_1 .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:11719,deployability,Version,Version,11719,".py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. jaxlib 0.4.31 pypi_0 pypi. ld_impl_linux-64 2.38 h1181459_1 . libffi 3.4.4 h6a678d5_1 . libgcc-ng 11.2.0 h1234567_1 . libgomp 11.2.0 h1234567_1 . libstdcxx-ng 11.2.0 h1234567_1 . libuuid 1.41.5 h5eee18b_0 . markdown-it-py 3.0.0 pypi_0 pypi. mdurl 0.1.2 pypi_0 pypi. mkl 2023.1.0 h213fc3f_46344 . mkl-service 2.4.0 py310h5eee18b_1 . mkl_fft 1.3.8 py310h5eee18b_0 . mkl_random 1.2.4 py310hdb19cb5_0 . ml-collections 0.1.1 pypi_0 pypi. ml-dtypes 0.4.0 pyp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:11727,deployability,Build,Build,11727,"ine 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. jaxlib 0.4.31 pypi_0 pypi. ld_impl_linux-64 2.38 h1181459_1 . libffi 3.4.4 h6a678d5_1 . libgcc-ng 11.2.0 h1234567_1 . libgomp 11.2.0 h1234567_1 . libstdcxx-ng 11.2.0 h1234567_1 . libuuid 1.41.5 h5eee18b_0 . markdown-it-py 3.0.0 pypi_0 pypi. mdurl 0.1.2 pypi_0 pypi. mkl 2023.1.0 h213fc3f_46344 . mkl-service 2.4.0 py310h5eee18b_1 . mkl_fft 1.3.8 py310h5eee18b_0 . mkl_random 1.2.4 py310hdb19cb5_0 . ml-collections 0.1.1 pypi_0 pypi. ml-dtypes 0.4.0 pypi_0 pyp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:12147,deployability,resourc,resources,12147,"cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. jaxlib 0.4.31 pypi_0 pypi. ld_impl_linux-64 2.38 h1181459_1 . libffi 3.4.4 h6a678d5_1 . libgcc-ng 11.2.0 h1234567_1 . libgomp 11.2.0 h1234567_1 . libstdcxx-ng 11.2.0 h1234567_1 . libuuid 1.41.5 h5eee18b_0 . markdown-it-py 3.0.0 pypi_0 pypi. mdurl 0.1.2 pypi_0 pypi. mkl 2023.1.0 h213fc3f_46344 . mkl-service 2.4.0 py310h5eee18b_1 . mkl_fft 1.3.8 py310h5eee18b_0 . mkl_random 1.2.4 py310hdb19cb5_0 . ml-collections 0.1.1 pypi_0 pypi. ml-dtypes 0.4.0 pypi_0 pypi. mock 5.1.0 pypi_0 pypi. msgpack 1.0.8 pypi_0 pypi. ncurses 6.4 h6a678d5_0 . nest-asyncio 1.6.0 pypi_0 pypi. numpy 1.24.3 py310h5f9d8c6_1 . numpy-base 1.24.3 py310hb5e798b_1 . openssl 3.0.14 h5eee18b_0 . opt-einsum 3.3.0 pypi_0 pypi. optax 0.2.3 pypi_0 pypi. orbax-checkpoint 0.5.23 pypi_0 pypi. packaging 24.1 pypi_0 pypi. pip 24.0 py310h06a4308_0 . protobuf 3.13.0 pypi_0 pypi. pygments 2.18.0 pypi_0 pypi. python 3.10",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:12571,deployability,servic,service,12571,. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. jaxlib 0.4.31 pypi_0 pypi. ld_impl_linux-64 2.38 h1181459_1 . libffi 3.4.4 h6a678d5_1 . libgcc-ng 11.2.0 h1234567_1 . libgomp 11.2.0 h1234567_1 . libstdcxx-ng 11.2.0 h1234567_1 . libuuid 1.41.5 h5eee18b_0 . markdown-it-py 3.0.0 pypi_0 pypi. mdurl 0.1.2 pypi_0 pypi. mkl 2023.1.0 h213fc3f_46344 . mkl-service 2.4.0 py310h5eee18b_1 . mkl_fft 1.3.8 py310h5eee18b_0 . mkl_random 1.2.4 py310hdb19cb5_0 . ml-collections 0.1.1 pypi_0 pypi. ml-dtypes 0.4.0 pypi_0 pypi. mock 5.1.0 pypi_0 pypi. msgpack 1.0.8 pypi_0 pypi. ncurses 6.4 h6a678d5_0 . nest-asyncio 1.6.0 pypi_0 pypi. numpy 1.24.3 py310h5f9d8c6_1 . numpy-base 1.24.3 py310hb5e798b_1 . openssl 3.0.14 h5eee18b_0 . opt-einsum 3.3.0 pypi_0 pypi. optax 0.2.3 pypi_0 pypi. orbax-checkpoint 0.5.23 pypi_0 pypi. packaging 24.1 pypi_0 pypi. pip 24.0 py310h06a4308_0 . protobuf 3.13.0 pypi_0 pypi. pygments 2.18.0 pypi_0 pypi. python 3.10.14 h955ad1f_1 . pyyaml 6.0.1 pypi_0 pypi. readline 8.2 h5eee18b_0 . rich 13.7.1 pypi_0 pypi. scipy 1.14.0 pypi_0 pypi. setuptools 69.5.1 py310h06a4308_0 . six 1.16.0 pypi_0 pypi. sortedcontainers 2.1.0 pypi_0 pypi. sqlite 3.45.3 h5eee18b_0 . tbb 2021.8.0 hdb19cb5_0 . tensorstore 0.1.64 pypi_0 pypi. tf-slim 1.1.0 pypi_0 pypi. tk 8.6.14 h39e8969_0 . toolz 0.12.1 pypi_0 pypi. typing-extensions 4.12.2 pypi_0 pypi. tzdata 2,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:374,energy efficiency,Load,Load,374,"Source code compilation of DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:559,energy efficiency,Load,Load,559,"Source code compilation of DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:1033,energy efficiency,Current,Current,1033,"t failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:1673,energy efficiency,manag,manager,1673," 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Decl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:12147,energy efficiency,resourc,resources,12147,"cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. jaxlib 0.4.31 pypi_0 pypi. ld_impl_linux-64 2.38 h1181459_1 . libffi 3.4.4 h6a678d5_1 . libgcc-ng 11.2.0 h1234567_1 . libgomp 11.2.0 h1234567_1 . libstdcxx-ng 11.2.0 h1234567_1 . libuuid 1.41.5 h5eee18b_0 . markdown-it-py 3.0.0 pypi_0 pypi. mdurl 0.1.2 pypi_0 pypi. mkl 2023.1.0 h213fc3f_46344 . mkl-service 2.4.0 py310h5eee18b_1 . mkl_fft 1.3.8 py310h5eee18b_0 . mkl_random 1.2.4 py310hdb19cb5_0 . ml-collections 0.1.1 pypi_0 pypi. ml-dtypes 0.4.0 pypi_0 pypi. mock 5.1.0 pypi_0 pypi. msgpack 1.0.8 pypi_0 pypi. ncurses 6.4 h6a678d5_0 . nest-asyncio 1.6.0 pypi_0 pypi. numpy 1.24.3 py310h5f9d8c6_1 . numpy-base 1.24.3 py310hb5e798b_1 . openssl 3.0.14 h5eee18b_0 . opt-einsum 3.3.0 pypi_0 pypi. optax 0.2.3 pypi_0 pypi. orbax-checkpoint 0.5.23 pypi_0 pypi. packaging 24.1 pypi_0 pypi. pip 24.0 py310h06a4308_0 . protobuf 3.13.0 pypi_0 pypi. pygments 2.18.0 pypi_0 pypi. python 3.10",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:59,integrability,version,version,59,"Source code compilation of DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:228,integrability,version,versions,228,"Source code compilation of DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:2207,integrability,sub,subprocess-exited-with-error,2207,"g cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:8273,integrability,state,state,8273," you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. ------------------------------------------------------------. . _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned. Processing numpy/random/_bounded_integers.pxd.in. Processing numpy/random/_common.pyx. Processing numpy/random/_philox.pyx. Traceback (most recent call last):. File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 235, in <module>. main(). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 231, in main. find_process_files(root_dir). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 222, in find_process_files. process(root_dir, fromfile, tofile, function, hash_db). File ""/tmp/pip-install-u4pd848o/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:9513,integrability,sub,subprocess,9513,") noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned. Processing numpy/random/_bounded_integers.pxd.in. Processing numpy/random/_common.pyx. Processing numpy/random/_philox.pyx. Traceback (most recent call last):. File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 235, in <module>. main(). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 231, in main. find_process_files(root_dir). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 222, in find_process_files. process(root_dir, fromfile, tofile, function, hash_db). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 188, in process. processor_function(fromfile, tofile). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 77, in process_pyx. subprocess.check_call(. File ""/public/home/zhanghl3/miniconda3/envs/deepvariant/lib/python3.10/subprocess.py"", line 369, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '['/public/home/zhanghl3/miniconda3/envs/deepvariant/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_philox.c', '_philox.pyx']' returned non-zero exit status 1. Cythonizing sources. Traceback (most recent call last):. File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 353, in <module>. main(). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 335, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:9544,integrability,pub,public,9544,"values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned. Processing numpy/random/_bounded_integers.pxd.in. Processing numpy/random/_common.pyx. Processing numpy/random/_philox.pyx. Traceback (most recent call last):. File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 235, in <module>. main(). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 231, in main. find_process_files(root_dir). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 222, in find_process_files. process(root_dir, fromfile, tofile, function, hash_db). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 188, in process. processor_function(fromfile, tofile). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 77, in process_pyx. subprocess.check_call(. File ""/public/home/zhanghl3/miniconda3/envs/deepvariant/lib/python3.10/subprocess.py"", line 369, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '['/public/home/zhanghl3/miniconda3/envs/deepvariant/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_philox.c', '_philox.pyx']' returned non-zero exit status 1. Cythonizing sources. Traceback (most recent call last):. File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 353, in <module>. main(). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 335, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptoo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:9608,integrability,sub,subprocess,9608,"the value being assigned. Processing numpy/random/_bounded_integers.pxd.in. Processing numpy/random/_common.pyx. Processing numpy/random/_philox.pyx. Traceback (most recent call last):. File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 235, in <module>. main(). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 231, in main. find_process_files(root_dir). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 222, in find_process_files. process(root_dir, fromfile, tofile, function, hash_db). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 188, in process. processor_function(fromfile, tofile). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 77, in process_pyx. subprocess.check_call(. File ""/public/home/zhanghl3/miniconda3/envs/deepvariant/lib/python3.10/subprocess.py"", line 369, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '['/public/home/zhanghl3/miniconda3/envs/deepvariant/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_philox.c', '_philox.pyx']' returned non-zero exit status 1. Cythonizing sources. Traceback (most recent call last):. File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 353, in <module>. main(). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 335, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:9689,integrability,sub,subprocess,9689,"ssing numpy/random/_common.pyx. Processing numpy/random/_philox.pyx. Traceback (most recent call last):. File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 235, in <module>. main(). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 231, in main. find_process_files(root_dir). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 222, in find_process_files. process(root_dir, fromfile, tofile, function, hash_db). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 188, in process. processor_function(fromfile, tofile). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 77, in process_pyx. subprocess.check_call(. File ""/public/home/zhanghl3/miniconda3/envs/deepvariant/lib/python3.10/subprocess.py"", line 369, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '['/public/home/zhanghl3/miniconda3/envs/deepvariant/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_philox.c', '_philox.pyx']' returned non-zero exit status 1. Cythonizing sources. Traceback (most recent call last):. File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 353, in <module>. main(). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 335, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:9732,integrability,pub,public,9732,"g numpy/random/_philox.pyx. Traceback (most recent call last):. File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 235, in <module>. main(). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 231, in main. find_process_files(root_dir). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 222, in find_process_files. process(root_dir, fromfile, tofile, function, hash_db). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 188, in process. processor_function(fromfile, tofile). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 77, in process_pyx. subprocess.check_call(. File ""/public/home/zhanghl3/miniconda3/envs/deepvariant/lib/python3.10/subprocess.py"", line 369, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '['/public/home/zhanghl3/miniconda3/envs/deepvariant/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_philox.c', '_philox.pyx']' returned non-zero exit status 1. Cythonizing sources. Traceback (most recent call last):. File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 353, in <module>. main(). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 335, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:11267,integrability,sub,subprocess,11267," ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. j",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:11719,integrability,Version,Version,11719,".py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. jaxlib 0.4.31 pypi_0 pypi. ld_impl_linux-64 2.38 h1181459_1 . libffi 3.4.4 h6a678d5_1 . libgcc-ng 11.2.0 h1234567_1 . libgomp 11.2.0 h1234567_1 . libstdcxx-ng 11.2.0 h1234567_1 . libuuid 1.41.5 h5eee18b_0 . markdown-it-py 3.0.0 pypi_0 pypi. mdurl 0.1.2 pypi_0 pypi. mkl 2023.1.0 h213fc3f_46344 . mkl-service 2.4.0 py310h5eee18b_1 . mkl_fft 1.3.8 py310h5eee18b_0 . mkl_random 1.2.4 py310hdb19cb5_0 . ml-collections 0.1.1 pypi_0 pypi. ml-dtypes 0.4.0 pyp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:12571,integrability,servic,service,12571,. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. jaxlib 0.4.31 pypi_0 pypi. ld_impl_linux-64 2.38 h1181459_1 . libffi 3.4.4 h6a678d5_1 . libgcc-ng 11.2.0 h1234567_1 . libgomp 11.2.0 h1234567_1 . libstdcxx-ng 11.2.0 h1234567_1 . libuuid 1.41.5 h5eee18b_0 . markdown-it-py 3.0.0 pypi_0 pypi. mdurl 0.1.2 pypi_0 pypi. mkl 2023.1.0 h213fc3f_46344 . mkl-service 2.4.0 py310h5eee18b_1 . mkl_fft 1.3.8 py310h5eee18b_0 . mkl_random 1.2.4 py310hdb19cb5_0 . ml-collections 0.1.1 pypi_0 pypi. ml-dtypes 0.4.0 pypi_0 pypi. mock 5.1.0 pypi_0 pypi. msgpack 1.0.8 pypi_0 pypi. ncurses 6.4 h6a678d5_0 . nest-asyncio 1.6.0 pypi_0 pypi. numpy 1.24.3 py310h5f9d8c6_1 . numpy-base 1.24.3 py310hb5e798b_1 . openssl 3.0.14 h5eee18b_0 . opt-einsum 3.3.0 pypi_0 pypi. optax 0.2.3 pypi_0 pypi. orbax-checkpoint 0.5.23 pypi_0 pypi. packaging 24.1 pypi_0 pypi. pip 24.0 py310h06a4308_0 . protobuf 3.13.0 pypi_0 pypi. pygments 2.18.0 pypi_0 pypi. python 3.10.14 h955ad1f_1 . pyyaml 6.0.1 pypi_0 pypi. readline 8.2 h5eee18b_0 . rich 13.7.1 pypi_0 pypi. scipy 1.14.0 pypi_0 pypi. setuptools 69.5.1 py310h06a4308_0 . six 1.16.0 pypi_0 pypi. sortedcontainers 2.1.0 pypi_0 pypi. sqlite 3.45.3 h5eee18b_0 . tbb 2021.8.0 hdb19cb5_0 . tensorstore 0.1.64 pypi_0 pypi. tf-slim 1.1.0 pypi_0 pypi. tk 8.6.14 h39e8969_0 . toolz 0.12.1 pypi_0 pypi. typing-extensions 4.12.2 pypi_0 pypi. tzdata 2,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:13624,integrability,wrap,wrapt,13624,rsion Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. jaxlib 0.4.31 pypi_0 pypi. ld_impl_linux-64 2.38 h1181459_1 . libffi 3.4.4 h6a678d5_1 . libgcc-ng 11.2.0 h1234567_1 . libgomp 11.2.0 h1234567_1 . libstdcxx-ng 11.2.0 h1234567_1 . libuuid 1.41.5 h5eee18b_0 . markdown-it-py 3.0.0 pypi_0 pypi. mdurl 0.1.2 pypi_0 pypi. mkl 2023.1.0 h213fc3f_46344 . mkl-service 2.4.0 py310h5eee18b_1 . mkl_fft 1.3.8 py310h5eee18b_0 . mkl_random 1.2.4 py310hdb19cb5_0 . ml-collections 0.1.1 pypi_0 pypi. ml-dtypes 0.4.0 pypi_0 pypi. mock 5.1.0 pypi_0 pypi. msgpack 1.0.8 pypi_0 pypi. ncurses 6.4 h6a678d5_0 . nest-asyncio 1.6.0 pypi_0 pypi. numpy 1.24.3 py310h5f9d8c6_1 . numpy-base 1.24.3 py310hb5e798b_1 . openssl 3.0.14 h5eee18b_0 . opt-einsum 3.3.0 pypi_0 pypi. optax 0.2.3 pypi_0 pypi. orbax-checkpoint 0.5.23 pypi_0 pypi. packaging 24.1 pypi_0 pypi. pip 24.0 py310h06a4308_0 . protobuf 3.13.0 pypi_0 pypi. pygments 2.18.0 pypi_0 pypi. python 3.10.14 h955ad1f_1 . pyyaml 6.0.1 pypi_0 pypi. readline 8.2 h5eee18b_0 . rich 13.7.1 pypi_0 pypi. scipy 1.14.0 pypi_0 pypi. setuptools 69.5.1 py310h06a4308_0 . six 1.16.0 pypi_0 pypi. sortedcontainers 2.1.0 pypi_0 pypi. sqlite 3.45.3 h5eee18b_0 . tbb 2021.8.0 hdb19cb5_0 . tensorstore 0.1.64 pypi_0 pypi. tf-slim 1.1.0 pypi_0 pypi. tk 8.6.14 h39e8969_0 . toolz 0.12.1 pypi_0 pypi. typing-extensions 4.12.2 pypi_0 pypi. tzdata 2024a h04d1e81_0 . wheel 0.43.0 py310h06a4308_0 . wrapt 1.16.0 pypi_0 pypi. xz 5.4.6 h5eee18b_1 . zipp 3.19.2 pypi_0 pypi. zlib 1.2.13 h5eee18b_1 .,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:175,interoperability,incompatib,incompatibility,175,"Source code compilation of DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:1627,interoperability,conflict,conflicting,1627,"Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:8558,interoperability,incompatib,incompatible,8558,"ou don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. ------------------------------------------------------------. . _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned. Processing numpy/random/_bounded_integers.pxd.in. Processing numpy/random/_common.pyx. Processing numpy/random/_philox.pyx. Traceback (most recent call last):. File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 235, in <module>. main(). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 231, in main. find_process_files(root_dir). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 222, in find_process_files. process(root_dir, fromfile, tofile, function, hash_db). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 188, in process. processor_function(fromfile, tofile). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 77, in process_pyx. subprocess.check_call(. File ""/public/home/zhanghl3",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:12991,interoperability,orb,orbax-checkpoint,12991,rsion Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. jaxlib 0.4.31 pypi_0 pypi. ld_impl_linux-64 2.38 h1181459_1 . libffi 3.4.4 h6a678d5_1 . libgcc-ng 11.2.0 h1234567_1 . libgomp 11.2.0 h1234567_1 . libstdcxx-ng 11.2.0 h1234567_1 . libuuid 1.41.5 h5eee18b_0 . markdown-it-py 3.0.0 pypi_0 pypi. mdurl 0.1.2 pypi_0 pypi. mkl 2023.1.0 h213fc3f_46344 . mkl-service 2.4.0 py310h5eee18b_1 . mkl_fft 1.3.8 py310h5eee18b_0 . mkl_random 1.2.4 py310hdb19cb5_0 . ml-collections 0.1.1 pypi_0 pypi. ml-dtypes 0.4.0 pypi_0 pypi. mock 5.1.0 pypi_0 pypi. msgpack 1.0.8 pypi_0 pypi. ncurses 6.4 h6a678d5_0 . nest-asyncio 1.6.0 pypi_0 pypi. numpy 1.24.3 py310h5f9d8c6_1 . numpy-base 1.24.3 py310hb5e798b_1 . openssl 3.0.14 h5eee18b_0 . opt-einsum 3.3.0 pypi_0 pypi. optax 0.2.3 pypi_0 pypi. orbax-checkpoint 0.5.23 pypi_0 pypi. packaging 24.1 pypi_0 pypi. pip 24.0 py310h06a4308_0 . protobuf 3.13.0 pypi_0 pypi. pygments 2.18.0 pypi_0 pypi. python 3.10.14 h955ad1f_1 . pyyaml 6.0.1 pypi_0 pypi. readline 8.2 h5eee18b_0 . rich 13.7.1 pypi_0 pypi. scipy 1.14.0 pypi_0 pypi. setuptools 69.5.1 py310h06a4308_0 . six 1.16.0 pypi_0 pypi. sortedcontainers 2.1.0 pypi_0 pypi. sqlite 3.45.3 h5eee18b_0 . tbb 2021.8.0 hdb19cb5_0 . tensorstore 0.1.64 pypi_0 pypi. tf-slim 1.1.0 pypi_0 pypi. tk 8.6.14 h39e8969_0 . toolz 0.12.1 pypi_0 pypi. typing-extensions 4.12.2 pypi_0 pypi. tzdata 2024a h04d1e81_0 . wheel 0.43.0 py310h06a4308_0 . wrapt 1.16.0 pypi_0 pypi. xz 5.4.6 h5eee18b_1 . zipp 3.19.2 pypi_0 pypi. zlib 1.2.13 h5eee18b_1 .,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:59,modifiability,version,version,59,"Source code compilation of DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:228,modifiability,version,versions,228,"Source code compilation of DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:334,modifiability,maintain,maintained,334,"Source code compilation of DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:468,modifiability,pac,packages,468,"Source code compilation of DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:519,modifiability,maintain,maintained,519,"Source code compilation of DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:714,modifiability,pac,package,714,"Source code compilation of DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:825,modifiability,pac,packages,825,"Source code compilation of DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:941,modifiability,pac,packaging,941,"Source code compilation of DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:1287,modifiability,pac,packages,1287,"-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run su",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:1665,modifiability,pac,package,1665,"i 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquir",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:2010,modifiability,upgrad,upgrade,2010,"eed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure yo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:2084,modifiability,pac,packages,2084," 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:2180,modifiability,pac,packages,2180,"-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquire",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:8905,modifiability,modul,module,8905,"r calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. ------------------------------------------------------------. . _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned. Processing numpy/random/_bounded_integers.pxd.in. Processing numpy/random/_common.pyx. Processing numpy/random/_philox.pyx. Traceback (most recent call last):. File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 235, in <module>. main(). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 231, in main. find_process_files(root_dir). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 222, in find_process_files. process(root_dir, fromfile, tofile, function, hash_db). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 188, in process. processor_function(fromfile, tofile). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 77, in process_pyx. subprocess.check_call(. File ""/public/home/zhanghl3/miniconda3/envs/deepvariant/lib/python3.10/subprocess.py"", line 369, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '['/public/home/zhanghl3/miniconda3/envs/deepvariant/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_philox.c', '_philox.pyx']' returned non-zero exit status 1. Cythoniz",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:9994,modifiability,pac,packages,9994,"/cythonize.py"", line 231, in main. find_process_files(root_dir). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 222, in find_process_files. process(root_dir, fromfile, tofile, function, hash_db). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 188, in process. processor_function(fromfile, tofile). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 77, in process_pyx. subprocess.check_call(. File ""/public/home/zhanghl3/miniconda3/envs/deepvariant/lib/python3.10/subprocess.py"", line 369, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '['/public/home/zhanghl3/miniconda3/envs/deepvariant/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_philox.c', '_philox.pyx']' returned non-zero exit status 1. Cythonizing sources. Traceback (most recent call last):. File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 353, in <module>. main(). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 335, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. se",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:10074,modifiability,modul,module,10074,"-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 222, in find_process_files. process(root_dir, fromfile, tofile, function, hash_db). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 188, in process. processor_function(fromfile, tofile). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 77, in process_pyx. subprocess.check_call(. File ""/public/home/zhanghl3/miniconda3/envs/deepvariant/lib/python3.10/subprocess.py"", line 369, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '['/public/home/zhanghl3/miniconda3/envs/deepvariant/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_philox.c', '_philox.pyx']' returned non-zero exit status 1. Cythonizing sources. Traceback (most recent call last):. File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 353, in <module>. main(). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 335, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:10128,modifiability,pac,packages,10128,"2/tools/cythonize.py"", line 222, in find_process_files. process(root_dir, fromfile, tofile, function, hash_db). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 188, in process. processor_function(fromfile, tofile). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 77, in process_pyx. subprocess.check_call(. File ""/public/home/zhanghl3/miniconda3/envs/deepvariant/lib/python3.10/subprocess.py"", line 369, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '['/public/home/zhanghl3/miniconda3/envs/deepvariant/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_philox.c', '_philox.pyx']' returned non-zero exit status 1. Cythonizing sources. Traceback (most recent call last):. File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 353, in <module>. main(). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 335, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise Ru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:10305,modifiability,pac,packages,10305,"ef0c2/tools/cythonize.py"", line 188, in process. processor_function(fromfile, tofile). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 77, in process_pyx. subprocess.check_call(. File ""/public/home/zhanghl3/miniconda3/envs/deepvariant/lib/python3.10/subprocess.py"", line 369, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '['/public/home/zhanghl3/miniconda3/envs/deepvariant/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_philox.c', '_philox.pyx']' returned non-zero exit status 1. Cythonizing sources. Traceback (most recent call last):. File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 353, in <module>. main(). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 335, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem wi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:10530,modifiability,pac,packages,10530,"(. File ""/public/home/zhanghl3/miniconda3/envs/deepvariant/lib/python3.10/subprocess.py"", line 369, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '['/public/home/zhanghl3/miniconda3/envs/deepvariant/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_philox.c', '_philox.pyx']' returned non-zero exit status 1. Cythonizing sources. Traceback (most recent call last):. File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 353, in <module>. main(). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 335, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*****",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:10693,modifiability,pac,packages,10693,"ss.CalledProcessError: Command '['/public/home/zhanghl3/miniconda3/envs/deepvariant/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_philox.c', '_philox.pyx']' returned non-zero exit status 1. Cythonizing sources. Traceback (most recent call last):. File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 353, in <module>. main(). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 335, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/de",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:10847,modifiability,pac,packages,10847,"'_philox.pyx']' returned non-zero exit status 1. Cythonizing sources. Traceback (most recent call last):. File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 353, in <module>. main(). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 335, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. bla",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:10987,modifiability,modul,module,10987,"ite-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 353, in <module>. main(). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 335, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:11389,modifiability,pac,package,11389,"etadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. jaxlib 0.4.31 pypi_0 pypi. ld_impl_linux-64 2.38 h1181459_1 . libffi 3.4.4 h6a678d5_1 . libgcc-ng 11.2.0 h1234567_1 . libg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:11465,modifiability,pac,package,11465,"ile ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. jaxlib 0.4.31 pypi_0 pypi. ld_impl_linux-64 2.38 h1181459_1 . libffi 3.4.4 h6a678d5_1 . libgcc-ng 11.2.0 h1234567_1 . libgomp 11.2.0 h1234567_1 . libstdcxx-ng 11.2.0 h1234567_1 . libuuid 1.41.5 h5ee",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:11647,modifiability,pac,packages,11647,"-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. jaxlib 0.4.31 pypi_0 pypi. ld_impl_linux-64 2.38 h1181459_1 . libffi 3.4.4 h6a678d5_1 . libgcc-ng 11.2.0 h1234567_1 . libgomp 11.2.0 h1234567_1 . libstdcxx-ng 11.2.0 h1234567_1 . libuuid 1.41.5 h5eee18b_0 . markdown-it-py 3.0.0 pypi_0 pypi. mdurl 0.1.2 pypi_0 pypi. mkl 2023.1.0 h213fc3f_46344 . mkl-service 2.4.0 py310h5eee18b_1 . mkl_fft 1.3.8 py310h5eee18b_0 . mkl_random 1.2.4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:11719,modifiability,Version,Version,11719,".py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. jaxlib 0.4.31 pypi_0 pypi. ld_impl_linux-64 2.38 h1181459_1 . libffi 3.4.4 h6a678d5_1 . libgcc-ng 11.2.0 h1234567_1 . libgomp 11.2.0 h1234567_1 . libstdcxx-ng 11.2.0 h1234567_1 . libuuid 1.41.5 h5eee18b_0 . markdown-it-py 3.0.0 pypi_0 pypi. mdurl 0.1.2 pypi_0 pypi. mkl 2023.1.0 h213fc3f_46344 . mkl-service 2.4.0 py310h5eee18b_1 . mkl_fft 1.3.8 py310h5eee18b_0 . mkl_random 1.2.4 py310hdb19cb5_0 . ml-collections 0.1.1 pypi_0 pypi. ml-dtypes 0.4.0 pyp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:12571,modifiability,servic,service,12571,. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. jaxlib 0.4.31 pypi_0 pypi. ld_impl_linux-64 2.38 h1181459_1 . libffi 3.4.4 h6a678d5_1 . libgcc-ng 11.2.0 h1234567_1 . libgomp 11.2.0 h1234567_1 . libstdcxx-ng 11.2.0 h1234567_1 . libuuid 1.41.5 h5eee18b_0 . markdown-it-py 3.0.0 pypi_0 pypi. mdurl 0.1.2 pypi_0 pypi. mkl 2023.1.0 h213fc3f_46344 . mkl-service 2.4.0 py310h5eee18b_1 . mkl_fft 1.3.8 py310h5eee18b_0 . mkl_random 1.2.4 py310hdb19cb5_0 . ml-collections 0.1.1 pypi_0 pypi. ml-dtypes 0.4.0 pypi_0 pypi. mock 5.1.0 pypi_0 pypi. msgpack 1.0.8 pypi_0 pypi. ncurses 6.4 h6a678d5_0 . nest-asyncio 1.6.0 pypi_0 pypi. numpy 1.24.3 py310h5f9d8c6_1 . numpy-base 1.24.3 py310hb5e798b_1 . openssl 3.0.14 h5eee18b_0 . opt-einsum 3.3.0 pypi_0 pypi. optax 0.2.3 pypi_0 pypi. orbax-checkpoint 0.5.23 pypi_0 pypi. packaging 24.1 pypi_0 pypi. pip 24.0 py310h06a4308_0 . protobuf 3.13.0 pypi_0 pypi. pygments 2.18.0 pypi_0 pypi. python 3.10.14 h955ad1f_1 . pyyaml 6.0.1 pypi_0 pypi. readline 8.2 h5eee18b_0 . rich 13.7.1 pypi_0 pypi. scipy 1.14.0 pypi_0 pypi. setuptools 69.5.1 py310h06a4308_0 . six 1.16.0 pypi_0 pypi. sortedcontainers 2.1.0 pypi_0 pypi. sqlite 3.45.3 h5eee18b_0 . tbb 2021.8.0 hdb19cb5_0 . tensorstore 0.1.64 pypi_0 pypi. tf-slim 1.1.0 pypi_0 pypi. tk 8.6.14 h39e8969_0 . toolz 0.12.1 pypi_0 pypi. typing-extensions 4.12.2 pypi_0 pypi. tzdata 2,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:13028,modifiability,pac,packaging,13028,rsion Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. jaxlib 0.4.31 pypi_0 pypi. ld_impl_linux-64 2.38 h1181459_1 . libffi 3.4.4 h6a678d5_1 . libgcc-ng 11.2.0 h1234567_1 . libgomp 11.2.0 h1234567_1 . libstdcxx-ng 11.2.0 h1234567_1 . libuuid 1.41.5 h5eee18b_0 . markdown-it-py 3.0.0 pypi_0 pypi. mdurl 0.1.2 pypi_0 pypi. mkl 2023.1.0 h213fc3f_46344 . mkl-service 2.4.0 py310h5eee18b_1 . mkl_fft 1.3.8 py310h5eee18b_0 . mkl_random 1.2.4 py310hdb19cb5_0 . ml-collections 0.1.1 pypi_0 pypi. ml-dtypes 0.4.0 pypi_0 pypi. mock 5.1.0 pypi_0 pypi. msgpack 1.0.8 pypi_0 pypi. ncurses 6.4 h6a678d5_0 . nest-asyncio 1.6.0 pypi_0 pypi. numpy 1.24.3 py310h5f9d8c6_1 . numpy-base 1.24.3 py310hb5e798b_1 . openssl 3.0.14 h5eee18b_0 . opt-einsum 3.3.0 pypi_0 pypi. optax 0.2.3 pypi_0 pypi. orbax-checkpoint 0.5.23 pypi_0 pypi. packaging 24.1 pypi_0 pypi. pip 24.0 py310h06a4308_0 . protobuf 3.13.0 pypi_0 pypi. pygments 2.18.0 pypi_0 pypi. python 3.10.14 h955ad1f_1 . pyyaml 6.0.1 pypi_0 pypi. readline 8.2 h5eee18b_0 . rich 13.7.1 pypi_0 pypi. scipy 1.14.0 pypi_0 pypi. setuptools 69.5.1 py310h06a4308_0 . six 1.16.0 pypi_0 pypi. sortedcontainers 2.1.0 pypi_0 pypi. sqlite 3.45.3 h5eee18b_0 . tbb 2021.8.0 hdb19cb5_0 . tensorstore 0.1.64 pypi_0 pypi. tf-slim 1.1.0 pypi_0 pypi. tk 8.6.14 h39e8969_0 . toolz 0.12.1 pypi_0 pypi. typing-extensions 4.12.2 pypi_0 pypi. tzdata 2024a h04d1e81_0 . wheel 0.43.0 py310h06a4308_0 . wrapt 1.16.0 pypi_0 pypi. xz 5.4.6 h5eee18b_1 . zipp 3.19.2 pypi_0 pypi. zlib 1.2.13 h5eee18b_1 .,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:13536,modifiability,extens,extensions,13536,rsion Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. jaxlib 0.4.31 pypi_0 pypi. ld_impl_linux-64 2.38 h1181459_1 . libffi 3.4.4 h6a678d5_1 . libgcc-ng 11.2.0 h1234567_1 . libgomp 11.2.0 h1234567_1 . libstdcxx-ng 11.2.0 h1234567_1 . libuuid 1.41.5 h5eee18b_0 . markdown-it-py 3.0.0 pypi_0 pypi. mdurl 0.1.2 pypi_0 pypi. mkl 2023.1.0 h213fc3f_46344 . mkl-service 2.4.0 py310h5eee18b_1 . mkl_fft 1.3.8 py310h5eee18b_0 . mkl_random 1.2.4 py310hdb19cb5_0 . ml-collections 0.1.1 pypi_0 pypi. ml-dtypes 0.4.0 pypi_0 pypi. mock 5.1.0 pypi_0 pypi. msgpack 1.0.8 pypi_0 pypi. ncurses 6.4 h6a678d5_0 . nest-asyncio 1.6.0 pypi_0 pypi. numpy 1.24.3 py310h5f9d8c6_1 . numpy-base 1.24.3 py310hb5e798b_1 . openssl 3.0.14 h5eee18b_0 . opt-einsum 3.3.0 pypi_0 pypi. optax 0.2.3 pypi_0 pypi. orbax-checkpoint 0.5.23 pypi_0 pypi. packaging 24.1 pypi_0 pypi. pip 24.0 py310h06a4308_0 . protobuf 3.13.0 pypi_0 pypi. pygments 2.18.0 pypi_0 pypi. python 3.10.14 h955ad1f_1 . pyyaml 6.0.1 pypi_0 pypi. readline 8.2 h5eee18b_0 . rich 13.7.1 pypi_0 pypi. scipy 1.14.0 pypi_0 pypi. setuptools 69.5.1 py310h06a4308_0 . six 1.16.0 pypi_0 pypi. sortedcontainers 2.1.0 pypi_0 pypi. sqlite 3.45.3 h5eee18b_0 . tbb 2021.8.0 hdb19cb5_0 . tensorstore 0.1.64 pypi_0 pypi. tf-slim 1.1.0 pypi_0 pypi. tk 8.6.14 h39e8969_0 . toolz 0.12.1 pypi_0 pypi. typing-extensions 4.12.2 pypi_0 pypi. tzdata 2024a h04d1e81_0 . wheel 0.43.0 py310h06a4308_0 . wrapt 1.16.0 pypi_0 pypi. xz 5.4.6 h5eee18b_1 . zipp 3.19.2 pypi_0 pypi. zlib 1.2.13 h5eee18b_1 .,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:105,performance,error,error,105,"Source code compilation of DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:374,performance,Load,Load,374,"Source code compilation of DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:559,performance,Load,Load,559,"Source code compilation of DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:1018,performance,Time,Time,1018,"ion of DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:1023,performance,Time,Time,1023,"f DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Py",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:1028,performance,Time,Time,1028,"pVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:1165,performance,cach,cached,1165,"due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Inst",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:1223,performance,cach,cached,1223,"r versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:2200,performance,error,error,2200,"ata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:2230,performance,error,error,2230,"-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you con",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:2547,performance,perform,performance,2547,"NING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:2804,performance,perform,performance,2804,"v. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:3061,performance,perform,performance,3061,"/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:3318,performance,perform,performance,3318,"78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check af",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:3555,performance,perform,performance,3555,nt: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check ,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:3792,performance,perform,performance,3792,ions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception chec,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4029,performance,perform,performance,4029,tion to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception ch,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4268,performance,perform,performance,4268,on't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception chec,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4507,performance,perform,performance,4507,'t want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check ,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4746,performance,perform,performance,4746, want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check af,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4985,performance,perform,performance,4985,ant the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check afte,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:5222,performance,perform,performance,5222, want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check afte,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:5459,performance,perform,performance,5459,'t want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check af,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:5696,performance,perform,performance,5696,on't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check ,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:5933,performance,perform,performance,5933, don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception ch,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6170,performance,perform,performance,6170, don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception ,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6409,performance,perform,performance,6409,on't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exceptio,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6648,performance,perform,performance,6648,'t want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exce,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6889,performance,perform,performance,6889,ant the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Excepti,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:7128,performance,perform,performance,7128,t the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. -------------,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:7369,performance,perform,performance,7369,the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. -----------------------,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:7612,performance,perform,performance,7612,function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. ------------------------------------------------------------. . _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of the v,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:7849,performance,perform,performance,7849,"the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. ------------------------------------------------------------. . _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned. Processing numpy/random/_bounded_integers.pxd.in. Processing numpy/random/_common.pyx. Processing numpy/random/_philox.pyx. Traceback (most recent call last):. File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:8091,performance,Error,Error,8091,"the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. ------------------------------------------------------------. . _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned. Processing numpy/random/_bounded_integers.pxd.in. Processing numpy/random/_common.pyx. Processing numpy/random/_philox.pyx. Traceback (most recent call last):. File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 235, in <module>. main(). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 231, in main. find_process_files(root_dir). File ""/tmp/pip-install-u4pd848o",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:11243,performance,error,error,11243,"ook_input['kwargs']). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:11317,performance,error,error,11317,"endor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. jaxlib 0.4.31 pypi_0 pypi. ld_impl_linux-64 2.38 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:11366,performance,error,error,11366,", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. jaxlib 0.4.31 pypi_0 pypi. ld_impl_linux-64 2.38 h1181459_1 . libffi 3.4.4 h6a678d5_1 . libgcc-ng ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:12147,performance,resourc,resources,12147,"cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. jaxlib 0.4.31 pypi_0 pypi. ld_impl_linux-64 2.38 h1181459_1 . libffi 3.4.4 h6a678d5_1 . libgcc-ng 11.2.0 h1234567_1 . libgomp 11.2.0 h1234567_1 . libstdcxx-ng 11.2.0 h1234567_1 . libuuid 1.41.5 h5eee18b_0 . markdown-it-py 3.0.0 pypi_0 pypi. mdurl 0.1.2 pypi_0 pypi. mkl 2023.1.0 h213fc3f_46344 . mkl-service 2.4.0 py310h5eee18b_1 . mkl_fft 1.3.8 py310h5eee18b_0 . mkl_random 1.2.4 py310hdb19cb5_0 . ml-collections 0.1.1 pypi_0 pypi. ml-dtypes 0.4.0 pypi_0 pypi. mock 5.1.0 pypi_0 pypi. msgpack 1.0.8 pypi_0 pypi. ncurses 6.4 h6a678d5_0 . nest-asyncio 1.6.0 pypi_0 pypi. numpy 1.24.3 py310h5f9d8c6_1 . numpy-base 1.24.3 py310hb5e798b_1 . openssl 3.0.14 h5eee18b_0 . opt-einsum 3.3.0 pypi_0 pypi. optax 0.2.3 pypi_0 pypi. orbax-checkpoint 0.5.23 pypi_0 pypi. packaging 24.1 pypi_0 pypi. pip 24.0 py310h06a4308_0 . protobuf 3.13.0 pypi_0 pypi. pygments 2.18.0 pypi_0 pypi. python 3.10",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:39,reliability,fail,failed,39,"Source code compilation of DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:1946,reliability,availab,available,1946,"infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:9825,reliability,fail,fail,9825,"48o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 235, in <module>. main(). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 231, in main. find_process_files(root_dir). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 222, in find_process_files. process(root_dir, fromfile, tofile, function, hash_db). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 188, in process. processor_function(fromfile, tofile). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 77, in process_pyx. subprocess.check_call(. File ""/public/home/zhanghl3/miniconda3/envs/deepvariant/lib/python3.10/subprocess.py"", line 369, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '['/public/home/zhanghl3/miniconda3/envs/deepvariant/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_philox.c', '_philox.pyx']' returned non-zero exit status 1. Cythonizing sources. Traceback (most recent call last):. File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 353, in <module>. main(). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 335, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:11162,reliability,fail,failed,11162,"_in_process/_in_process.py"", line 335, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 py",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:11205,reliability,fail,failed,11205,"ain. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:11344,reliability,fail,failed,11344,"rocess/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. jaxlib 0.4.31 pypi_0 pypi. ld_impl_linux-64 2.38 h1181459_1 . libffi 3.4.4 h",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:12997,reliability,checkpoint,checkpoint,12997,rsion Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. jaxlib 0.4.31 pypi_0 pypi. ld_impl_linux-64 2.38 h1181459_1 . libffi 3.4.4 h6a678d5_1 . libgcc-ng 11.2.0 h1234567_1 . libgomp 11.2.0 h1234567_1 . libstdcxx-ng 11.2.0 h1234567_1 . libuuid 1.41.5 h5eee18b_0 . markdown-it-py 3.0.0 pypi_0 pypi. mdurl 0.1.2 pypi_0 pypi. mkl 2023.1.0 h213fc3f_46344 . mkl-service 2.4.0 py310h5eee18b_1 . mkl_fft 1.3.8 py310h5eee18b_0 . mkl_random 1.2.4 py310hdb19cb5_0 . ml-collections 0.1.1 pypi_0 pypi. ml-dtypes 0.4.0 pypi_0 pypi. mock 5.1.0 pypi_0 pypi. msgpack 1.0.8 pypi_0 pypi. ncurses 6.4 h6a678d5_0 . nest-asyncio 1.6.0 pypi_0 pypi. numpy 1.24.3 py310h5f9d8c6_1 . numpy-base 1.24.3 py310hb5e798b_1 . openssl 3.0.14 h5eee18b_0 . opt-einsum 3.3.0 pypi_0 pypi. optax 0.2.3 pypi_0 pypi. orbax-checkpoint 0.5.23 pypi_0 pypi. packaging 24.1 pypi_0 pypi. pip 24.0 py310h06a4308_0 . protobuf 3.13.0 pypi_0 pypi. pygments 2.18.0 pypi_0 pypi. python 3.10.14 h955ad1f_1 . pyyaml 6.0.1 pypi_0 pypi. readline 8.2 h5eee18b_0 . rich 13.7.1 pypi_0 pypi. scipy 1.14.0 pypi_0 pypi. setuptools 69.5.1 py310h06a4308_0 . six 1.16.0 pypi_0 pypi. sortedcontainers 2.1.0 pypi_0 pypi. sqlite 3.45.3 h5eee18b_0 . tbb 2021.8.0 hdb19cb5_0 . tensorstore 0.1.64 pypi_0 pypi. tf-slim 1.1.0 pypi_0 pypi. tk 8.6.14 h39e8969_0 . toolz 0.12.1 pypi_0 pypi. typing-extensions 4.12.2 pypi_0 pypi. tzdata 2024a h04d1e81_0 . wheel 0.43.0 py310h06a4308_0 . wrapt 1.16.0 pypi_0 pypi. xz 5.4.6 h5eee18b_1 . zipp 3.19.2 pypi_0 pypi. zlib 1.2.13 h5eee18b_1 .,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:13456,reliability,sli,slim,13456,rsion Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. jaxlib 0.4.31 pypi_0 pypi. ld_impl_linux-64 2.38 h1181459_1 . libffi 3.4.4 h6a678d5_1 . libgcc-ng 11.2.0 h1234567_1 . libgomp 11.2.0 h1234567_1 . libstdcxx-ng 11.2.0 h1234567_1 . libuuid 1.41.5 h5eee18b_0 . markdown-it-py 3.0.0 pypi_0 pypi. mdurl 0.1.2 pypi_0 pypi. mkl 2023.1.0 h213fc3f_46344 . mkl-service 2.4.0 py310h5eee18b_1 . mkl_fft 1.3.8 py310h5eee18b_0 . mkl_random 1.2.4 py310hdb19cb5_0 . ml-collections 0.1.1 pypi_0 pypi. ml-dtypes 0.4.0 pypi_0 pypi. mock 5.1.0 pypi_0 pypi. msgpack 1.0.8 pypi_0 pypi. ncurses 6.4 h6a678d5_0 . nest-asyncio 1.6.0 pypi_0 pypi. numpy 1.24.3 py310h5f9d8c6_1 . numpy-base 1.24.3 py310hb5e798b_1 . openssl 3.0.14 h5eee18b_0 . opt-einsum 3.3.0 pypi_0 pypi. optax 0.2.3 pypi_0 pypi. orbax-checkpoint 0.5.23 pypi_0 pypi. packaging 24.1 pypi_0 pypi. pip 24.0 py310h06a4308_0 . protobuf 3.13.0 pypi_0 pypi. pygments 2.18.0 pypi_0 pypi. python 3.10.14 h955ad1f_1 . pyyaml 6.0.1 pypi_0 pypi. readline 8.2 h5eee18b_0 . rich 13.7.1 pypi_0 pypi. scipy 1.14.0 pypi_0 pypi. setuptools 69.5.1 py310h06a4308_0 . six 1.16.0 pypi_0 pypi. sortedcontainers 2.1.0 pypi_0 pypi. sqlite 3.45.3 h5eee18b_0 . tbb 2021.8.0 hdb19cb5_0 . tensorstore 0.1.64 pypi_0 pypi. tf-slim 1.1.0 pypi_0 pypi. tk 8.6.14 h39e8969_0 . toolz 0.12.1 pypi_0 pypi. typing-extensions 4.12.2 pypi_0 pypi. tzdata 2024a h04d1e81_0 . wheel 0.43.0 py310h06a4308_0 . wrapt 1.16.0 pypi_0 pypi. xz 5.4.6 h5eee18b_1 . zipp 3.19.2 pypi_0 pypi. zlib 1.2.13 h5eee18b_1 .,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:105,safety,error,error,105,"Source code compilation of DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:334,safety,maintain,maintained,334,"Source code compilation of DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:519,safety,maintain,maintained,519,"Source code compilation of DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:707,safety,Updat,Update,707,"Source code compilation of DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:1611,safety,permiss,permissions,1611," PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:1673,safety,manag,manager,1673," 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Decl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:1946,safety,avail,available,1946,"infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:1983,safety,updat,update,1983," Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:2200,safety,error,error,2200,"ata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:2230,safety,error,error,2230,"-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you con",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:2585,safety,Except,Exception,2585,"can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:3",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:2792,safety,except,exceptions,2792,"/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. perfo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:2842,safety,Except,Exception,2842,"if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:3049,safety,except,exceptions,3049,"usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:3099,safety,Except,Exception,3099," 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' wi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:3306,safety,except,exceptions,3306,"ode: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Excep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:3356,safety,Except,Exception,3356,"py source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:3543,safety,except,exceptions,3543,erformance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exc,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:3593,safety,Except,Exception,3593,ck after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always requir,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:3780,safety,except,exceptions,3780, raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: E,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:3830,safety,Except,Exception,3830,99:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always requ,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4017,safety,except,exceptions,4017,want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31:,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4067,safety,Except,Exception,4067, hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always req,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4256,safety,except,exceptions,4256,re sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: E,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4306,safety,Except,Exception,4306,tions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always requi,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4495,safety,except,exceptions,4495, sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exc,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4545,safety,Except,Exception,4545,ons. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4734,safety,except,exceptions,4734,ure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Excep,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4784,safety,Except,Exception,4784,s. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require t,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4973,safety,except,exceptions,4973,e you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Excepti,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:5023,safety,Except,Exception,5023, performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:5210,safety,except,exceptions,5210,ure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Excepti,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:5260,safety,Except,Exception,5260,s. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require th,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:5447,safety,except,exceptions,5447, sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Excep,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:5497,safety,Except,Exception,5497,ons. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require ,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:5684,safety,except,exceptions,5684,re sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exc,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:5734,safety,Except,Exception,5734,tions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always requi,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:5921,safety,except,exceptions,5921,u're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40:,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:5971,safety,Except,Exception,5971,eptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always re,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6158,safety,except,exceptions,6158,u're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:4,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6208,safety,Except,Exception,6208,eptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6397,safety,except,exceptions,6397,re sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6447,safety,Except,Exception,6447,tions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will alw,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6636,safety,except,exceptions,6636, sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6686,safety,Except,Exception,6686,ons. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will al,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6877,safety,except,exceptions,6877,e you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:100,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6927,safety,Except,Exception,6927, performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will alwa,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:7116,safety,except,exceptions,7116,you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:7166,safety,Except,Exception,7166,erformance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. --------------------------------------------------,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:7357,safety,except,exceptions,7357,u don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. ----------,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:7407,safety,Except,Exception,7407,formance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. ------------------------------------------------------------,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:7600,safety,except,exceptions,7600,n't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. ------------------------------------------------------------. . _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the ,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:7650,safety,Except,Exception,7650,ance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. ------------------------------------------------------------. . _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned. Processing numpy,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:7837,safety,except,exceptions,7837,"u don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. ------------------------------------------------------------. . _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned. Processing numpy/random/_bounded_integers.pxd.in. Processing numpy/random/_common.pyx. Processing numpy/random/_philox.pyx. Traceback (most recent call last):. File ""/tmp/pip-install-u4pd848o/numpy_1b14e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:7888,safety,Except,Exception,7888,"ormance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. ------------------------------------------------------------. . _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned. Processing numpy/random/_bounded_integers.pxd.in. Processing numpy/random/_common.pyx. Processing numpy/random/_philox.pyx. Traceback (most recent call last):. File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", li",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:8077,safety,except,exceptions,8077," don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. ------------------------------------------------------------. . _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned. Processing numpy/random/_bounded_integers.pxd.in. Processing numpy/random/_common.pyx. Processing numpy/random/_philox.pyx. Traceback (most recent call last):. File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 235, in <module>. main(). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 231, in main. find_process_files(root_dir). File ""/tmp/pip-inst",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:8091,safety,Error,Error,8091,"the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. ------------------------------------------------------------. . _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned. Processing numpy/random/_bounded_integers.pxd.in. Processing numpy/random/_common.pyx. Processing numpy/random/_philox.pyx. Traceback (most recent call last):. File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 235, in <module>. main(). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 231, in main. find_process_files(root_dir). File ""/tmp/pip-install-u4pd848o",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:8477,safety,except,except,8477,"quired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. ------------------------------------------------------------. . _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned. Processing numpy/random/_bounded_integers.pxd.in. Processing numpy/random/_common.pyx. Processing numpy/random/_philox.pyx. Traceback (most recent call last):. File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 235, in <module>. main(). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 231, in main. find_process_files(root_dir). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 222, in find_process_files. process(root_dir, fromfile, tofile, function, hash_db). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 188, in process. processor_function(fromfile, tofile). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythoni",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:8537,safety,Except,Exception,8537,"tion and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. ------------------------------------------------------------. . _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned. Processing numpy/random/_bounded_integers.pxd.in. Processing numpy/random/_common.pyx. Processing numpy/random/_philox.pyx. Traceback (most recent call last):. File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 235, in <module>. main(). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 231, in main. find_process_files(root_dir). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 222, in find_process_files. process(root_dir, fromfile, tofile, function, hash_db). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 188, in process. processor_function(fromfile, tofile). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 77, in process_pyx. subprocess.check_call(. File ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:8905,safety,modul,module,8905,"r calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. ------------------------------------------------------------. . _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned. Processing numpy/random/_bounded_integers.pxd.in. Processing numpy/random/_common.pyx. Processing numpy/random/_philox.pyx. Traceback (most recent call last):. File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 235, in <module>. main(). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 231, in main. find_process_files(root_dir). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 222, in find_process_files. process(root_dir, fromfile, tofile, function, hash_db). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 188, in process. processor_function(fromfile, tofile). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 77, in process_pyx. subprocess.check_call(. File ""/public/home/zhanghl3/miniconda3/envs/deepvariant/lib/python3.10/subprocess.py"", line 369, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '['/public/home/zhanghl3/miniconda3/envs/deepvariant/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_philox.c', '_philox.pyx']' returned non-zero exit status 1. Cythoniz",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:10074,safety,modul,module,10074,"-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 222, in find_process_files. process(root_dir, fromfile, tofile, function, hash_db). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 188, in process. processor_function(fromfile, tofile). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 77, in process_pyx. subprocess.check_call(. File ""/public/home/zhanghl3/miniconda3/envs/deepvariant/lib/python3.10/subprocess.py"", line 369, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '['/public/home/zhanghl3/miniconda3/envs/deepvariant/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_philox.c', '_philox.pyx']' returned non-zero exit status 1. Cythonizing sources. Traceback (most recent call last):. File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 353, in <module>. main(). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 335, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:10987,safety,modul,module,10987,"ite-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 353, in <module>. main(). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 335, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:11243,safety,error,error,11243,"ook_input['kwargs']). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:11317,safety,error,error,11317,"endor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. jaxlib 0.4.31 pypi_0 pypi. ld_impl_linux-64 2.38 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:11366,safety,error,error,11366,", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. jaxlib 0.4.31 pypi_0 pypi. ld_impl_linux-64 2.38 h1181459_1 . libffi 3.4.4 h6a678d5_1 . libgcc-ng ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:12147,safety,resourc,resources,12147,"cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. jaxlib 0.4.31 pypi_0 pypi. ld_impl_linux-64 2.38 h1181459_1 . libffi 3.4.4 h6a678d5_1 . libgcc-ng 11.2.0 h1234567_1 . libgomp 11.2.0 h1234567_1 . libstdcxx-ng 11.2.0 h1234567_1 . libuuid 1.41.5 h5eee18b_0 . markdown-it-py 3.0.0 pypi_0 pypi. mdurl 0.1.2 pypi_0 pypi. mkl 2023.1.0 h213fc3f_46344 . mkl-service 2.4.0 py310h5eee18b_1 . mkl_fft 1.3.8 py310h5eee18b_0 . mkl_random 1.2.4 py310hdb19cb5_0 . ml-collections 0.1.1 pypi_0 pypi. ml-dtypes 0.4.0 pypi_0 pypi. mock 5.1.0 pypi_0 pypi. msgpack 1.0.8 pypi_0 pypi. ncurses 6.4 h6a678d5_0 . nest-asyncio 1.6.0 pypi_0 pypi. numpy 1.24.3 py310h5f9d8c6_1 . numpy-base 1.24.3 py310hb5e798b_1 . openssl 3.0.14 h5eee18b_0 . opt-einsum 3.3.0 pypi_0 pypi. optax 0.2.3 pypi_0 pypi. orbax-checkpoint 0.5.23 pypi_0 pypi. packaging 24.1 pypi_0 pypi. pip 24.0 py310h06a4308_0 . protobuf 3.13.0 pypi_0 pypi. pygments 2.18.0 pypi_0 pypi. python 3.10",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:707,security,Updat,Update,707,"Source code compilation of DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:1946,security,availab,available,1946,"infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:1983,security,updat,update,1983," Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:2716,security,control,control,2716,"e.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the defi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:2973,security,control,control,2973,"e] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're su",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:3230,security,control,control,3230,"r. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:3467,security,control,control,3467,thon sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't wan,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:3704,security,control,control,3704, if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't w,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:3941,security,control,control,3941,_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4180,security,control,control,4180,d. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't w,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4419,security,control,control,4419, acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't wan,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4658,security,control,control,4658,cquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want ,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4897,security,control,control,4897,uired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want th,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:5134,security,control,control,5134,quired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want th,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:5371,security,control,control,5371,acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want ,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:5608,security,control,control,5608,e acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't wan,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:5845,security,control,control,5845, be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6082,security,control,control,6082,o be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6321,security,control,control,6321,be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you d,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6560,security,control,control,6560, acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure y,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6801,security,control,control,6801,uired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you d,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:7040,security,control,control,7040,red. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you ,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:7281,security,control,control,7281,. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <voi,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:7524,security,control,control,7524,clare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. ------------------------------------------------------------. . _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:7761,security,control,control,7761, Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. ------------------------------------------------------------. . _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned. Processing numpy/random/_bounded_integers.pxd.in. Processing numpy/random/_common.pyx. Processing numpy/random/_philox.pyx. Tr,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:8001,security,control,control,8001," Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. ------------------------------------------------------------. . _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned. Processing numpy/random/_bounded_integers.pxd.in. Processing numpy/random/_common.pyx. Processing numpy/random/_philox.pyx. Traceback (most recent call last):. File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 235, in <module>. main(). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cython",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:11891,security,certif,certificates,11891,"un_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. jaxlib 0.4.31 pypi_0 pypi. ld_impl_linux-64 2.38 h1181459_1 . libffi 3.4.4 h6a678d5_1 . libgcc-ng 11.2.0 h1234567_1 . libgomp 11.2.0 h1234567_1 . libstdcxx-ng 11.2.0 h1234567_1 . libuuid 1.41.5 h5eee18b_0 . markdown-it-py 3.0.0 pypi_0 pypi. mdurl 0.1.2 pypi_0 pypi. mkl 2023.1.0 h213fc3f_46344 . mkl-service 2.4.0 py310h5eee18b_1 . mkl_fft 1.3.8 py310h5eee18b_0 . mkl_random 1.2.4 py310hdb19cb5_0 . ml-collections 0.1.1 pypi_0 pypi. ml-dtypes 0.4.0 pypi_0 pypi. mock 5.1.0 pypi_0 pypi. msgpack 1.0.8 pypi_0 pypi. ncurses 6.4 h6a678d5_0 . nest-asyncio 1.6.0 pypi_0 pypi. numpy 1.24.3 py310h5f9d8c6_1 . numpy-base 1.24.3 py310hb",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:2716,testability,control,control,2716,"e.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the defi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:2973,testability,control,control,2973,"e] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're su",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:3230,testability,control,control,3230,"r. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:3467,testability,control,control,3467,thon sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't wan,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:3704,testability,control,control,3704, if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't w,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:3941,testability,control,control,3941,_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4180,testability,control,control,4180,d. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't w,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4419,testability,control,control,4419, acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't wan,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4658,testability,control,control,4658,cquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want ,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4897,testability,control,control,4897,uired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want th,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:5134,testability,control,control,5134,quired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want th,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:5371,testability,control,control,5371,acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want ,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:5608,testability,control,control,5608,e acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't wan,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:5845,testability,control,control,5845, be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6082,testability,control,control,6082,o be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6321,testability,control,control,6321,be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you d,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6560,testability,control,control,6560, acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure y,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6801,testability,control,control,6801,uired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you d,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:7040,testability,control,control,7040,red. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you ,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:7281,testability,control,control,7281,. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <voi,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:7524,testability,control,control,7524,clare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. ------------------------------------------------------------. . _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:7761,testability,control,control,7761, Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. ------------------------------------------------------------. . _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned. Processing numpy/random/_bounded_integers.pxd.in. Processing numpy/random/_common.pyx. Processing numpy/random/_philox.pyx. Tr,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:8001,testability,control,control,8001," Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. ------------------------------------------------------------. . _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned. Processing numpy/random/_bounded_integers.pxd.in. Processing numpy/random/_common.pyx. Processing numpy/random/_philox.pyx. Traceback (most recent call last):. File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 235, in <module>. main(). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cython",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:8763,testability,Trace,Traceback,8763," the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. ------------------------------------------------------------. . _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned. Processing numpy/random/_bounded_integers.pxd.in. Processing numpy/random/_common.pyx. Processing numpy/random/_philox.pyx. Traceback (most recent call last):. File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 235, in <module>. main(). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 231, in main. find_process_files(root_dir). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 222, in find_process_files. process(root_dir, fromfile, tofile, function, hash_db). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 188, in process. processor_function(fromfile, tofile). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 77, in process_pyx. subprocess.check_call(. File ""/public/home/zhanghl3/miniconda3/envs/deepvariant/lib/python3.10/subprocess.py"", line 369, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '['/public/home/zhanghl3/miniconda3/envs",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:9921,testability,Trace,Traceback,9921," ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 231, in main. find_process_files(root_dir). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 222, in find_process_files. process(root_dir, fromfile, tofile, function, hash_db). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 188, in process. processor_function(fromfile, tofile). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 77, in process_pyx. subprocess.check_call(. File ""/public/home/zhanghl3/miniconda3/envs/deepvariant/lib/python3.10/subprocess.py"", line 369, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '['/public/home/zhanghl3/miniconda3/envs/deepvariant/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_philox.c', '_philox.pyx']' returned non-zero exit status 1. Cythonizing sources. Traceback (most recent call last):. File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 353, in <module>. main(). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 335, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:10238,testability,hook,hook,10238,"b). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 188, in process. processor_function(fromfile, tofile). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 77, in process_pyx. subprocess.check_call(. File ""/public/home/zhanghl3/miniconda3/envs/deepvariant/lib/python3.10/subprocess.py"", line 369, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '['/public/home/zhanghl3/miniconda3/envs/deepvariant/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_philox.c', '_philox.pyx']' returned non-zero exit status 1. Cythonizing sources. Traceback (most recent call last):. File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 353, in <module>. main(). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 335, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: Th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:10425,testability,hook,hook,10425,"/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 77, in process_pyx. subprocess.check_call(. File ""/public/home/zhanghl3/miniconda3/envs/deepvariant/lib/python3.10/subprocess.py"", line 369, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '['/public/home/zhanghl3/miniconda3/envs/deepvariant/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_philox.c', '_philox.pyx']' returned non-zero exit status 1. Cythonizing sources. Traceback (most recent call last):. File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 353, in <module>. main(). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 335, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for ou",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:12147,testability,resourc,resources,12147,"cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. jaxlib 0.4.31 pypi_0 pypi. ld_impl_linux-64 2.38 h1181459_1 . libffi 3.4.4 h6a678d5_1 . libgcc-ng 11.2.0 h1234567_1 . libgomp 11.2.0 h1234567_1 . libstdcxx-ng 11.2.0 h1234567_1 . libuuid 1.41.5 h5eee18b_0 . markdown-it-py 3.0.0 pypi_0 pypi. mdurl 0.1.2 pypi_0 pypi. mkl 2023.1.0 h213fc3f_46344 . mkl-service 2.4.0 py310h5eee18b_1 . mkl_fft 1.3.8 py310h5eee18b_0 . mkl_random 1.2.4 py310hdb19cb5_0 . ml-collections 0.1.1 pypi_0 pypi. ml-dtypes 0.4.0 pypi_0 pypi. mock 5.1.0 pypi_0 pypi. msgpack 1.0.8 pypi_0 pypi. ncurses 6.4 h6a678d5_0 . nest-asyncio 1.6.0 pypi_0 pypi. numpy 1.24.3 py310h5f9d8c6_1 . numpy-base 1.24.3 py310hb5e798b_1 . openssl 3.0.14 h5eee18b_0 . opt-einsum 3.3.0 pypi_0 pypi. optax 0.2.3 pypi_0 pypi. orbax-checkpoint 0.5.23 pypi_0 pypi. packaging 24.1 pypi_0 pypi. pip 24.0 py310h06a4308_0 . protobuf 3.13.0 pypi_0 pypi. pygments 2.18.0 pypi_0 pypi. python 3.10",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:12733,testability,mock,mock,12733,rsion Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. jaxlib 0.4.31 pypi_0 pypi. ld_impl_linux-64 2.38 h1181459_1 . libffi 3.4.4 h6a678d5_1 . libgcc-ng 11.2.0 h1234567_1 . libgomp 11.2.0 h1234567_1 . libstdcxx-ng 11.2.0 h1234567_1 . libuuid 1.41.5 h5eee18b_0 . markdown-it-py 3.0.0 pypi_0 pypi. mdurl 0.1.2 pypi_0 pypi. mkl 2023.1.0 h213fc3f_46344 . mkl-service 2.4.0 py310h5eee18b_1 . mkl_fft 1.3.8 py310h5eee18b_0 . mkl_random 1.2.4 py310hdb19cb5_0 . ml-collections 0.1.1 pypi_0 pypi. ml-dtypes 0.4.0 pypi_0 pypi. mock 5.1.0 pypi_0 pypi. msgpack 1.0.8 pypi_0 pypi. ncurses 6.4 h6a678d5_0 . nest-asyncio 1.6.0 pypi_0 pypi. numpy 1.24.3 py310h5f9d8c6_1 . numpy-base 1.24.3 py310hb5e798b_1 . openssl 3.0.14 h5eee18b_0 . opt-einsum 3.3.0 pypi_0 pypi. optax 0.2.3 pypi_0 pypi. orbax-checkpoint 0.5.23 pypi_0 pypi. packaging 24.1 pypi_0 pypi. pip 24.0 py310h06a4308_0 . protobuf 3.13.0 pypi_0 pypi. pygments 2.18.0 pypi_0 pypi. python 3.10.14 h955ad1f_1 . pyyaml 6.0.1 pypi_0 pypi. readline 8.2 h5eee18b_0 . rich 13.7.1 pypi_0 pypi. scipy 1.14.0 pypi_0 pypi. setuptools 69.5.1 py310h06a4308_0 . six 1.16.0 pypi_0 pypi. sortedcontainers 2.1.0 pypi_0 pypi. sqlite 3.45.3 h5eee18b_0 . tbb 2021.8.0 hdb19cb5_0 . tensorstore 0.1.64 pypi_0 pypi. tf-slim 1.1.0 pypi_0 pypi. tk 8.6.14 h39e8969_0 . toolz 0.12.1 pypi_0 pypi. typing-extensions 4.12.2 pypi_0 pypi. tzdata 2024a h04d1e81_0 . wheel 0.43.0 py310h06a4308_0 . wrapt 1.16.0 pypi_0 pypi. xz 5.4.6 h5eee18b_1 . zipp 3.19.2 pypi_0 pypi. zlib 1.2.13 h5eee18b_1 .,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:105,usability,error,error,105,"Source code compilation of DeepVariant failed; When I used version 1.6.1 for source code compilation, an error related to the numpy library occurred. I suspect this is due to incompatibility with TensorFlow. I tried using other versions of the numpy library, but the issue persisted. ./build-prereq.sh. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Install the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:1453,usability,prefer,prefer,1453,"the runtime packages' starting. ========== This script is only maintained for Ubuntu 20.04. ========== Load config settings. ========== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding wit",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:1585,usability,user,user,1585,"==== [Fri 02 Aug 2024 02:19:28 PM CST] Stage 'Misc setup' starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Ex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:1639,usability,behavi,behaviour,1639," starting. ========== [Fri 02 Aug 2024 02:20:04 PM CST] Stage 'Update package list' starting. ========== [Fri 02 Aug 2024 02:20:06 PM CST] Stage 'run-prereq.sh: Install development packages' starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always req",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:1828,usability,user,user-action,1828," starting. Calling wait_for_dpkg_lock. ========== [Fri 02 Aug 2024 02:20:10 PM CST] Stage 'Install python3 packaging infrastructure' starting. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 100 2213k 100 2213k 0 0 1634k 0 0:00:01 0:00:01 --:--:-- 1634k. Collecting pip. Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:2200,usability,error,error,2200,"ata (3.6 kB). Using cached pip-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:2230,usability,error,error,2230,"-24.2-py3-none-any.whl (1.8 MB). Installing collected packages: pip. WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you con",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:2396,usability,User,UserWarning,2396," Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:2433,usability,command,command,2433,"PATH or, if you prefer to suppress this warning, use --no-warn-script-location. Successfully installed pip-24.2. WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Dec",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:2547,usability,perform,performance,2547,"NING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:2559,usability,hint,hint,2559,"nning pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. perfor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:2804,usability,perform,performance,2804,"v. Use the --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:2816,usability,hint,hint,2816,"he --root-user-action option if you know what you are doing and want to suppress this warning. [notice] A new release of pip is available: 24.0 -> 24.2. [notice] To update, run: pip install --upgrade pip. Python 3.10.14. pip 24.0 from /usr/local/lib/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:3061,usability,perform,performance,3061,"/python3.10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:3073,usability,hint,hint,3073,".10/site-packages/pip (python 3.10). ========== [Fri 02 Aug 2024 02:20:22 PM CST] Stage 'Install python3 packages' starting. error: subprocess-exited-with-error. .  Preparing metadata (pyproject.toml) did not run successfully.  exit code: 1. > [78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exceptio",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:3318,usability,perform,performance,3318,"78 lines of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check af",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:3330,usability,hint,hint,3330," of output]. Running from numpy source directory. setup.py:470: UserWarning: Unrecognized setuptools command, proceeding with generating Cython sources and expanding templates. run_build = parse_setuppy_commands(). performance hint: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after call",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:3555,usability,perform,performance,3555,nt: _common.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check ,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:3567,usability,hint,hint,3567,mon.pyx:275:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after ca,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:3792,usability,perform,performance,3792,ions. performance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception chec,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:3804,usability,hint,hint,3804,rformance hint: _common.pyx:299:19: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after ,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4029,usability,perform,performance,4029,tion to raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception ch,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4041,usability,hint,hint,4041,raise exceptions. performance hint: _common.pyx:322:50: Exception check after calling 'random_func' will always require the GIL to be acquired. Declare 'random_func' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check afte,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4268,usability,perform,performance,4268,on't want the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception chec,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4280,usability,hint,hint,4280,t the function to raise exceptions. performance hint: _common.pyx:426:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after ,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4507,usability,perform,performance,4507,'t want the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check ,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4519,usability,hint,hint,4519,the function to raise exceptions. performance hint: _common.pyx:465:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after ca,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4746,usability,perform,performance,4746, want the function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check af,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4758,usability,hint,hint,4758,e function to raise exceptions. performance hint: _common.pyx:509:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after call,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4985,usability,perform,performance,4985,ant the function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check afte,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4997,usability,hint,hint,4997,function to raise exceptions. performance hint: _common.pyx:592:36: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after callin,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:5222,usability,perform,performance,5222, want the function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check afte,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:5234,usability,hint,hint,5234,e function to raise exceptions. performance hint: _common.pyx:596:36: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after callin,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:5459,usability,perform,performance,5459,'t want the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check af,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:5471,usability,hint,hint,5471,the function to raise exceptions. performance hint: _common.pyx:600:36: Exception check after calling 'f2' will always require the GIL to be acquired. Declare 'f2' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after call,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:5696,usability,perform,performance,5696,on't want the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check ,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:5708,usability,hint,hint,5708,t the function to raise exceptions. performance hint: _common.pyx:604:36: Exception check after calling 'f3' will always require the GIL to be acquired. Declare 'f3' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after ca,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:5933,usability,perform,performance,5933, don't want the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception ch,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:5945,usability,hint,hint,5945,ant the function to raise exceptions. performance hint: _common.pyx:638:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check afte,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6170,usability,perform,performance,6170, don't want the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception ,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6182,usability,hint,hint,6182,ant the function to raise exceptions. performance hint: _common.pyx:675:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check af,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6409,usability,perform,performance,6409,on't want the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exceptio,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6421,usability,hint,hint,6421,t the function to raise exceptions. performance hint: _common.pyx:712:63: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check ,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6648,usability,perform,performance,6648,'t want the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exce,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6660,usability,hint,hint,6660,the function to raise exceptions. performance hint: _common.pyx:754:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception ch,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6889,usability,perform,performance,6889,ant the function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Excepti,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6901,usability,hint,hint,6901,function to raise exceptions. performance hint: _common.pyx:785:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:7128,usability,perform,performance,7128,t the function to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. -------------,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:7140,usability,hint,hint,7140,nction to raise exceptions. performance hint: _common.pyx:903:40: Exception check after calling 'f0' will always require the GIL to be acquired. Declare 'f0' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ---------------------,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:7369,usability,perform,performance,7369,the function to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. -----------------------,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:7381,usability,hint,hint,7381,tion to raise exceptions. performance hint: _common.pyx:907:40: Exception check after calling 'fd' will always require the GIL to be acquired. Declare 'fd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. -------------------------------,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:7612,usability,perform,performance,7612,function to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. ------------------------------------------------------------. . _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of the v,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:7624,usability,hint,hint,7624, to raise exceptions. performance hint: _common.pyx:911:41: Exception check after calling 'fdd' will always require the GIL to be acquired. Declare 'fdd' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. ------------------------------------------------------------. . _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of the value bei,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:7849,usability,perform,performance,7849,"the function to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. ------------------------------------------------------------. . _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned. Processing numpy/random/_bounded_integers.pxd.in. Processing numpy/random/_common.pyx. Processing numpy/random/_philox.pyx. Traceback (most recent call last):. File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:7861,usability,hint,hint,7861,"tion to raise exceptions. performance hint: _common.pyx:916:40: Exception check after calling 'fi' will always require the GIL to be acquired. Declare 'fi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. ------------------------------------------------------------. . _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned. Processing numpy/random/_bounded_integers.pxd.in. Processing numpy/random/_common.pyx. Processing numpy/random/_philox.pyx. Traceback (most recent call last):. File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:8091,usability,Error,Error,8091,"the function to raise exceptions. performance hint: _common.pyx:920:41: Exception check after calling 'fdi' will always require the GIL to be acquired. Declare 'fdi' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:924:38: Exception check after calling 'fiii' will always require the GIL to be acquired. Declare 'fiii' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:960:31: Exception check after calling 'f' will always require the GIL to be acquired. Declare 'f' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. performance hint: _common.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. ------------------------------------------------------------. . _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned. Processing numpy/random/_bounded_integers.pxd.in. Processing numpy/random/_common.pyx. Processing numpy/random/_philox.pyx. Traceback (most recent call last):. File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 235, in <module>. main(). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 231, in main. find_process_files(root_dir). File ""/tmp/pip-install-u4pd848o",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:8870,usability,tool,tools,8870,"n.pyx:1002:32: Exception check after calling 'f1' will always require the GIL to be acquired. Declare 'f1' as 'noexcept' if you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. ------------------------------------------------------------. . _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned. Processing numpy/random/_bounded_integers.pxd.in. Processing numpy/random/_common.pyx. Processing numpy/random/_philox.pyx. Traceback (most recent call last):. File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 235, in <module>. main(). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 231, in main. find_process_files(root_dir). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 222, in find_process_files. process(root_dir, fromfile, tofile, function, hash_db). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 188, in process. processor_function(fromfile, tofile). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 77, in process_pyx. subprocess.check_call(. File ""/public/home/zhanghl3/miniconda3/envs/deepvariant/lib/python3.10/subprocess.py"", line 369, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '['/public/home/zhanghl3/miniconda3/envs/deepvariant/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_philox.c', '_philox.pyx']' return",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:8993,usability,tool,tools,8993," you control the definition and you're sure you don't want the function to raise exceptions. . Error compiling Cython file:. ------------------------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. ------------------------------------------------------------. . _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned. Processing numpy/random/_bounded_integers.pxd.in. Processing numpy/random/_common.pyx. Processing numpy/random/_philox.pyx. Traceback (most recent call last):. File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 235, in <module>. main(). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 231, in main. find_process_files(root_dir). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 222, in find_process_files. process(root_dir, fromfile, tofile, function, hash_db). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 188, in process. processor_function(fromfile, tofile). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 77, in process_pyx. subprocess.check_call(. File ""/public/home/zhanghl3/miniconda3/envs/deepvariant/lib/python3.10/subprocess.py"", line 369, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '['/public/home/zhanghl3/miniconda3/envs/deepvariant/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_philox.c', '_philox.pyx']' returned non-zero exit status 1. Cythonizing sources. Traceback (most recent call last):. File ""/usr/local/lib/python3.10/site-pa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:9134,usability,tool,tools,9134,"--------------------------------------------. ... self.rng_state.ctr.v[i] = counter[i]. . self._reset_state_variables(). . self._bitgen.state = <void *>&self.rng_state. self._bitgen.next_uint64 = &philox_uint64. ^. ------------------------------------------------------------. . _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned. Processing numpy/random/_bounded_integers.pxd.in. Processing numpy/random/_common.pyx. Processing numpy/random/_philox.pyx. Traceback (most recent call last):. File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 235, in <module>. main(). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 231, in main. find_process_files(root_dir). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 222, in find_process_files. process(root_dir, fromfile, tofile, function, hash_db). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 188, in process. processor_function(fromfile, tofile). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 77, in process_pyx. subprocess.check_call(. File ""/public/home/zhanghl3/miniconda3/envs/deepvariant/lib/python3.10/subprocess.py"", line 369, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '['/public/home/zhanghl3/miniconda3/envs/deepvariant/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_philox.c', '_philox.pyx']' returned non-zero exit status 1. Cythonizing sources. Traceback (most recent call last):. File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 353, in <module>. main(). File ""/usr/local/lib/python3.10/site-packages/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:9315,usability,tool,tools,9315,".next_uint64 = &philox_uint64. ^. ------------------------------------------------------------. . _philox.pyx:195:35: Cannot assign type 'uint64_t (*)(void *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned. Processing numpy/random/_bounded_integers.pxd.in. Processing numpy/random/_common.pyx. Processing numpy/random/_philox.pyx. Traceback (most recent call last):. File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 235, in <module>. main(). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 231, in main. find_process_files(root_dir). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 222, in find_process_files. process(root_dir, fromfile, tofile, function, hash_db). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 188, in process. processor_function(fromfile, tofile). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 77, in process_pyx. subprocess.check_call(. File ""/public/home/zhanghl3/miniconda3/envs/deepvariant/lib/python3.10/subprocess.py"", line 369, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '['/public/home/zhanghl3/miniconda3/envs/deepvariant/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_philox.c', '_philox.pyx']' returned non-zero exit status 1. Cythonizing sources. Traceback (most recent call last):. File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 353, in <module>. main(). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 335, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/usr/local/lib/python3.10/site-packages/pip/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:9467,usability,tool,tools,9467,"oid *) except? -1 nogil' to 'uint64_t (*)(void *) noexcept nogil'. Exception values are incompatible. Suggest adding 'noexcept' to the type of the value being assigned. Processing numpy/random/_bounded_integers.pxd.in. Processing numpy/random/_common.pyx. Processing numpy/random/_philox.pyx. Traceback (most recent call last):. File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 235, in <module>. main(). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 231, in main. find_process_files(root_dir). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 222, in find_process_files. process(root_dir, fromfile, tofile, function, hash_db). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 188, in process. processor_function(fromfile, tofile). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 77, in process_pyx. subprocess.check_call(. File ""/public/home/zhanghl3/miniconda3/envs/deepvariant/lib/python3.10/subprocess.py"", line 369, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '['/public/home/zhanghl3/miniconda3/envs/deepvariant/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_philox.c', '_philox.pyx']' returned non-zero exit status 1. Cythonizing sources. Traceback (most recent call last):. File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 353, in <module>. main(). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 335, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). Fi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:9720,usability,Command,Command,9720,". Processing numpy/random/_philox.pyx. Traceback (most recent call last):. File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 235, in <module>. main(). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 231, in main. find_process_files(root_dir). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 222, in find_process_files. process(root_dir, fromfile, tofile, function, hash_db). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 188, in process. processor_function(fromfile, tofile). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 77, in process_pyx. subprocess.check_call(. File ""/public/home/zhanghl3/miniconda3/envs/deepvariant/lib/python3.10/subprocess.py"", line 369, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '['/public/home/zhanghl3/miniconda3/envs/deepvariant/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_philox.c', '_philox.pyx']' returned non-zero exit status 1. Cythonizing sources. Traceback (most recent call last):. File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 353, in <module>. main(). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 335, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:9890,usability,statu,status,9890,"ne 235, in <module>. main(). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 231, in main. find_process_files(root_dir). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 222, in find_process_files. process(root_dir, fromfile, tofile, function, hash_db). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 188, in process. processor_function(fromfile, tofile). File ""/tmp/pip-install-u4pd848o/numpy_1b14eb8cc70c49928ac1e9fd7d7ef0c2/tools/cythonize.py"", line 77, in process_pyx. subprocess.check_call(. File ""/public/home/zhanghl3/miniconda3/envs/deepvariant/lib/python3.10/subprocess.py"", line 369, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '['/public/home/zhanghl3/miniconda3/envs/deepvariant/bin/python3', '-m', 'cython', '-3', '--fast-fail', '-o', '_philox.c', '_philox.pyx']' returned non-zero exit status 1. Cythonizing sources. Traceback (most recent call last):. File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 353, in <module>. main(). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 335, in main. json_out['return_val'] = hook(**hook_input['kwargs']). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:11243,usability,error,error,11243,"ook_input['kwargs']). File ""/usr/local/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:11317,usability,error,error,11317,"endor/pyproject_hooks/_in_process/_in_process.py"", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. jaxlib 0.4.31 pypi_0 pypi. ld_impl_linux-64 2.38 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:11366,usability,error,error,11366,", line 149, in prepare_metadata_for_build_wheel. return hook(metadata_directory, config_settings). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. jaxlib 0.4.31 pypi_0 pypi. ld_impl_linux-64 2.38 h1181459_1 . libffi 3.4.4 h6a678d5_1 . libgcc-ng ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:11499,usability,hint,hint,11499,"/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 157, in prepare_metadata_for_build_wheel. self.run_setup(). File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 248, in run_setup. super(_BuildMetaLegacyBackend,. File ""/tmp/pip-build-env-u8h8jp6y/overlay/lib/python3.10/site-packages/setuptools/build_meta.py"", line 142, in run_setup. exec(compile(code, __file__, 'exec'), locals()). File ""setup.py"", line 499, in <module>. setup_package(). File ""setup.py"", line 479, in setup_package. generate_cython(). File ""setup.py"", line 274, in generate_cython. raise RuntimeError(""Running cythonize failed!""). RuntimeError: Running cythonize failed! [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. error: metadata-generation-failed.  Encountered error while generating package metadata. > See above for output. note: This is an issue with the package mentioned above, not pip. hint: See above for details. /*********************************************/. My conda environment contains the following libraries:. conda list. # packages in environment at /opt/miniconda3/envs/deepvariant:. #. # Name Version Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. jaxlib 0.4.31 pypi_0 pypi. ld_impl_linux-64 2.38 h1181459_1 . libffi 3.4.4 h6a678d5_1 . libgcc-ng 11.2.0 h1234567_1 . libgomp 11.2.0 h1234567_1 . libstdcxx-ng 11.2.0 h1234567_1 . libuuid 1.41.5 h5eee18b_0 . markdown-it-py 3.0.0 py",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:13503,usability,tool,toolz,13503,rsion Build Channel. _libgcc_mutex 0.1 main . _openmp_mutex 5.1 1_gnu . absl-py 2.1.0 pypi_0 pypi. argparse 1.4.0 pypi_0 pypi. blas 1.0 mkl . bzip2 1.0.8 h5eee18b_6 . ca-certificates 2024.7.2 h06a4308_0 . chex 0.1.86 pypi_0 pypi. clu 0.0.9 pypi_0 pypi. contextlib2 21.6.0 pypi_0 pypi. cython 3.0.10 pypi_0 pypi. enum34 1.1.8 pypi_0 pypi. etils 1.7.0 pypi_0 pypi. flax 0.8.5 pypi_0 pypi. fsspec 2024.6.1 pypi_0 pypi. importlib-resources 6.4.0 pypi_0 pypi. intel-openmp 2023.1.0 hdb19cb5_46306 . intervaltree 3.0.2 pypi_0 pypi. jax 0.4.31 pypi_0 pypi. jaxlib 0.4.31 pypi_0 pypi. ld_impl_linux-64 2.38 h1181459_1 . libffi 3.4.4 h6a678d5_1 . libgcc-ng 11.2.0 h1234567_1 . libgomp 11.2.0 h1234567_1 . libstdcxx-ng 11.2.0 h1234567_1 . libuuid 1.41.5 h5eee18b_0 . markdown-it-py 3.0.0 pypi_0 pypi. mdurl 0.1.2 pypi_0 pypi. mkl 2023.1.0 h213fc3f_46344 . mkl-service 2.4.0 py310h5eee18b_1 . mkl_fft 1.3.8 py310h5eee18b_0 . mkl_random 1.2.4 py310hdb19cb5_0 . ml-collections 0.1.1 pypi_0 pypi. ml-dtypes 0.4.0 pypi_0 pypi. mock 5.1.0 pypi_0 pypi. msgpack 1.0.8 pypi_0 pypi. ncurses 6.4 h6a678d5_0 . nest-asyncio 1.6.0 pypi_0 pypi. numpy 1.24.3 py310h5f9d8c6_1 . numpy-base 1.24.3 py310hb5e798b_1 . openssl 3.0.14 h5eee18b_0 . opt-einsum 3.3.0 pypi_0 pypi. optax 0.2.3 pypi_0 pypi. orbax-checkpoint 0.5.23 pypi_0 pypi. packaging 24.1 pypi_0 pypi. pip 24.0 py310h06a4308_0 . protobuf 3.13.0 pypi_0 pypi. pygments 2.18.0 pypi_0 pypi. python 3.10.14 h955ad1f_1 . pyyaml 6.0.1 pypi_0 pypi. readline 8.2 h5eee18b_0 . rich 13.7.1 pypi_0 pypi. scipy 1.14.0 pypi_0 pypi. setuptools 69.5.1 py310h06a4308_0 . six 1.16.0 pypi_0 pypi. sortedcontainers 2.1.0 pypi_0 pypi. sqlite 3.45.3 h5eee18b_0 . tbb 2021.8.0 hdb19cb5_0 . tensorstore 0.1.64 pypi_0 pypi. tf-slim 1.1.0 pypi_0 pypi. tk 8.6.14 h39e8969_0 . toolz 0.12.1 pypi_0 pypi. typing-extensions 4.12.2 pypi_0 pypi. tzdata 2024a h04d1e81_0 . wheel 0.43.0 py310h06a4308_0 . wrapt 1.16.0 pypi_0 pypi. xz 5.4.6 h5eee18b_1 . zipp 3.19.2 pypi_0 pypi. zlib 1.2.13 h5eee18b_1 .,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/860:440,energy efficiency,current,current,440,"What is deepvariant trained on?; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. Sorry, this might be a very naive question but I believe this isn't addressed in the 2018 publication. What dataset(s) is/are the deepvariant method trained on? I understand for the 2016 truth challenge, deepvariant was trained on the HG001 GIAB reference. Is this also true for the current standard deepvariant method?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/860
https://github.com/google/deepvariant/issues/860:247,integrability,pub,publication,247,"What is deepvariant trained on?; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. Sorry, this might be a very naive question but I believe this isn't addressed in the 2018 publication. What dataset(s) is/are the deepvariant method trained on? I understand for the 2016 truth challenge, deepvariant was trained on the HG001 GIAB reference. Is this also true for the current standard deepvariant method?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/860
https://github.com/google/deepvariant/issues/860:448,interoperability,standard,standard,448,"What is deepvariant trained on?; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. Sorry, this might be a very naive question but I believe this isn't addressed in the 2018 publication. What dataset(s) is/are the deepvariant method trained on? I understand for the 2016 truth challenge, deepvariant was trained on the HG001 GIAB reference. Is this also true for the current standard deepvariant method?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/860
https://github.com/google/deepvariant/issues/860:320,testability,understand,understand,320,"What is deepvariant trained on?; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. Sorry, this might be a very naive question but I believe this isn't addressed in the 2018 publication. What dataset(s) is/are the deepvariant method trained on? I understand for the 2016 truth challenge, deepvariant was trained on the HG001 GIAB reference. Is this also true for the current standard deepvariant method?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/860
https://github.com/google/deepvariant/issues/861:324,interoperability,mismatch,mismatches,324,DeepVariant Channel clarification; Thank you for the wonderful tool + great user support! i'm wondering if someone might be able to clarify channel 5 (read supports variant) vs channel 6 (base differs from ref). . Is the purpose of channel 6 to capture the context of the putative (centered) variant with reference to other mismatches on the same read? While channel 5 counts pileups with the putative (centered) variant?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/861
https://github.com/google/deepvariant/issues/861:257,testability,context,context,257,DeepVariant Channel clarification; Thank you for the wonderful tool + great user support! i'm wondering if someone might be able to clarify channel 5 (read supports variant) vs channel 6 (base differs from ref). . Is the purpose of channel 6 to capture the context of the putative (centered) variant with reference to other mismatches on the same read? While channel 5 counts pileups with the putative (centered) variant?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/861
https://github.com/google/deepvariant/issues/861:63,usability,tool,tool,63,DeepVariant Channel clarification; Thank you for the wonderful tool + great user support! i'm wondering if someone might be able to clarify channel 5 (read supports variant) vs channel 6 (base differs from ref). . Is the purpose of channel 6 to capture the context of the putative (centered) variant with reference to other mismatches on the same read? While channel 5 counts pileups with the putative (centered) variant?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/861
https://github.com/google/deepvariant/issues/861:76,usability,user,user,76,DeepVariant Channel clarification; Thank you for the wonderful tool + great user support! i'm wondering if someone might be able to clarify channel 5 (read supports variant) vs channel 6 (base differs from ref). . Is the purpose of channel 6 to capture the context of the putative (centered) variant with reference to other mismatches on the same read? While channel 5 counts pileups with the putative (centered) variant?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/861
https://github.com/google/deepvariant/issues/861:81,usability,support,support,81,DeepVariant Channel clarification; Thank you for the wonderful tool + great user support! i'm wondering if someone might be able to clarify channel 5 (read supports variant) vs channel 6 (base differs from ref). . Is the purpose of channel 6 to capture the context of the putative (centered) variant with reference to other mismatches on the same read? While channel 5 counts pileups with the putative (centered) variant?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/861
https://github.com/google/deepvariant/issues/861:156,usability,support,supports,156,DeepVariant Channel clarification; Thank you for the wonderful tool + great user support! i'm wondering if someone might be able to clarify channel 5 (read supports variant) vs channel 6 (base differs from ref). . Is the purpose of channel 6 to capture the context of the putative (centered) variant with reference to other mismatches on the same read? While channel 5 counts pileups with the putative (centered) variant?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/861
https://github.com/google/deepvariant/issues/862:67,deployability,version,version,67,"Info Singularity; I would like to try to make a custom singularity version of deepvariant in which is integrated with some custom scripts, do you know where I could find the singularity recepie of deepvariant? It would be a good starting point for me. Thank you in advance for any suggestion,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/862
https://github.com/google/deepvariant/issues/862:102,deployability,integr,integrated,102,"Info Singularity; I would like to try to make a custom singularity version of deepvariant in which is integrated with some custom scripts, do you know where I could find the singularity recepie of deepvariant? It would be a good starting point for me. Thank you in advance for any suggestion,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/862
https://github.com/google/deepvariant/issues/862:67,integrability,version,version,67,"Info Singularity; I would like to try to make a custom singularity version of deepvariant in which is integrated with some custom scripts, do you know where I could find the singularity recepie of deepvariant? It would be a good starting point for me. Thank you in advance for any suggestion,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/862
https://github.com/google/deepvariant/issues/862:102,integrability,integr,integrated,102,"Info Singularity; I would like to try to make a custom singularity version of deepvariant in which is integrated with some custom scripts, do you know where I could find the singularity recepie of deepvariant? It would be a good starting point for me. Thank you in advance for any suggestion,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/862
https://github.com/google/deepvariant/issues/862:102,interoperability,integr,integrated,102,"Info Singularity; I would like to try to make a custom singularity version of deepvariant in which is integrated with some custom scripts, do you know where I could find the singularity recepie of deepvariant? It would be a good starting point for me. Thank you in advance for any suggestion,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/862
https://github.com/google/deepvariant/issues/862:67,modifiability,version,version,67,"Info Singularity; I would like to try to make a custom singularity version of deepvariant in which is integrated with some custom scripts, do you know where I could find the singularity recepie of deepvariant? It would be a good starting point for me. Thank you in advance for any suggestion,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/862
https://github.com/google/deepvariant/issues/862:102,modifiability,integr,integrated,102,"Info Singularity; I would like to try to make a custom singularity version of deepvariant in which is integrated with some custom scripts, do you know where I could find the singularity recepie of deepvariant? It would be a good starting point for me. Thank you in advance for any suggestion,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/862
https://github.com/google/deepvariant/issues/862:102,reliability,integr,integrated,102,"Info Singularity; I would like to try to make a custom singularity version of deepvariant in which is integrated with some custom scripts, do you know where I could find the singularity recepie of deepvariant? It would be a good starting point for me. Thank you in advance for any suggestion,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/862
https://github.com/google/deepvariant/issues/862:102,security,integr,integrated,102,"Info Singularity; I would like to try to make a custom singularity version of deepvariant in which is integrated with some custom scripts, do you know where I could find the singularity recepie of deepvariant? It would be a good starting point for me. Thank you in advance for any suggestion,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/862
https://github.com/google/deepvariant/issues/862:102,testability,integr,integrated,102,"Info Singularity; I would like to try to make a custom singularity version of deepvariant in which is integrated with some custom scripts, do you know where I could find the singularity recepie of deepvariant? It would be a good starting point for me. Thank you in advance for any suggestion,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/862
https://github.com/google/deepvariant/issues/862:48,usability,custom,custom,48,"Info Singularity; I would like to try to make a custom singularity version of deepvariant in which is integrated with some custom scripts, do you know where I could find the singularity recepie of deepvariant? It would be a good starting point for me. Thank you in advance for any suggestion,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/862
https://github.com/google/deepvariant/issues/862:123,usability,custom,custom,123,"Info Singularity; I would like to try to make a custom singularity version of deepvariant in which is integrated with some custom scripts, do you know where I could find the singularity recepie of deepvariant? It would be a good starting point for me. Thank you in advance for any suggestion,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/862
https://github.com/google/deepvariant/issues/863:202,integrability,filter,filtered,202,"dealing with chimeric alignments; hello, . sorry if this question is dumb or the answer is obvious. . is there a plausible explanation on how deepvariant treats chimeric reads? . I tried deepvariant on filtered .bam files (after `samtools view -h -F 2048`) and before that step w/o filtering, and the number of found variants is exactly the same before/after. just to check if I am not doing something weird, I also used bcftools, and the results for the numbers of called variants were affected. is deepvariant not considering chimeric reads? . thank you for creating and supporting deepvariant,. alisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/863
https://github.com/google/deepvariant/issues/863:282,integrability,filter,filtering,282,"dealing with chimeric alignments; hello, . sorry if this question is dumb or the answer is obvious. . is there a plausible explanation on how deepvariant treats chimeric reads? . I tried deepvariant on filtered .bam files (after `samtools view -h -F 2048`) and before that step w/o filtering, and the number of found variants is exactly the same before/after. just to check if I am not doing something weird, I also used bcftools, and the results for the numbers of called variants were affected. is deepvariant not considering chimeric reads? . thank you for creating and supporting deepvariant,. alisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/863
https://github.com/google/deepvariant/issues/863:573,usability,support,supporting,573,"dealing with chimeric alignments; hello, . sorry if this question is dumb or the answer is obvious. . is there a plausible explanation on how deepvariant treats chimeric reads? . I tried deepvariant on filtered .bam files (after `samtools view -h -F 2048`) and before that step w/o filtering, and the number of found variants is exactly the same before/after. just to check if I am not doing something weird, I also used bcftools, and the results for the numbers of called variants were affected. is deepvariant not considering chimeric reads? . thank you for creating and supporting deepvariant,. alisa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/863
https://github.com/google/deepvariant/issues/864:913,availability,degrad,degradation,913,"Question about RNA-seq; This is from DeepVariant's documentation. ""For somatic data or any other samples where the genotypes go beyond two copies of DNA, DeepVariant will not work out of the box because the only genotypes supported are hom-alt, het, and hom-ref."". Does the same apply to the RNA-seq model of DeepVariant? If a mutation has a low VAF is it predicted as hom-ref? Because in RNA-seq, low VAF doesn't necessarily mean the variant is hom-ref in the genome. . ### In RNA-seq:. - **Expression Levels**: RNA-seq measures gene expression, so the VAF of a mutation depends on the expression of the mutant and wild-type alleles. If a gene is highly expressed in some cells and not others, or if only one allele is expressed (allele-specific expression), the VAF may be skewed. - **Variable Expression**: The VAF in RNA-seq data can be influenced by tissue-specific expression, transcriptional noise, or RNA degradation, making it less consistent compared to DNA-seq. - **Allelic Imbalance**: In RNA-seq, you might observe allelic imbalance due to factors like imprinting or preferential expression of one allele, further complicating the interpretation of VAF.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:941,availability,consist,consistent,941,"Question about RNA-seq; This is from DeepVariant's documentation. ""For somatic data or any other samples where the genotypes go beyond two copies of DNA, DeepVariant will not work out of the box because the only genotypes supported are hom-alt, het, and hom-ref."". Does the same apply to the RNA-seq model of DeepVariant? If a mutation has a low VAF is it predicted as hom-ref? Because in RNA-seq, low VAF doesn't necessarily mean the variant is hom-ref in the genome. . ### In RNA-seq:. - **Expression Levels**: RNA-seq measures gene expression, so the VAF of a mutation depends on the expression of the mutant and wild-type alleles. If a gene is highly expressed in some cells and not others, or if only one allele is expressed (allele-specific expression), the VAF may be skewed. - **Variable Expression**: The VAF in RNA-seq data can be influenced by tissue-specific expression, transcriptional noise, or RNA degradation, making it less consistent compared to DNA-seq. - **Allelic Imbalance**: In RNA-seq, you might observe allelic imbalance due to factors like imprinting or preferential expression of one allele, further complicating the interpretation of VAF.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:572,deployability,depend,depends,572,"Question about RNA-seq; This is from DeepVariant's documentation. ""For somatic data or any other samples where the genotypes go beyond two copies of DNA, DeepVariant will not work out of the box because the only genotypes supported are hom-alt, het, and hom-ref."". Does the same apply to the RNA-seq model of DeepVariant? If a mutation has a low VAF is it predicted as hom-ref? Because in RNA-seq, low VAF doesn't necessarily mean the variant is hom-ref in the genome. . ### In RNA-seq:. - **Expression Levels**: RNA-seq measures gene expression, so the VAF of a mutation depends on the expression of the mutant and wild-type alleles. If a gene is highly expressed in some cells and not others, or if only one allele is expressed (allele-specific expression), the VAF may be skewed. - **Variable Expression**: The VAF in RNA-seq data can be influenced by tissue-specific expression, transcriptional noise, or RNA degradation, making it less consistent compared to DNA-seq. - **Allelic Imbalance**: In RNA-seq, you might observe allelic imbalance due to factors like imprinting or preferential expression of one allele, further complicating the interpretation of VAF.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:1020,deployability,observ,observe,1020,"Question about RNA-seq; This is from DeepVariant's documentation. ""For somatic data or any other samples where the genotypes go beyond two copies of DNA, DeepVariant will not work out of the box because the only genotypes supported are hom-alt, het, and hom-ref."". Does the same apply to the RNA-seq model of DeepVariant? If a mutation has a low VAF is it predicted as hom-ref? Because in RNA-seq, low VAF doesn't necessarily mean the variant is hom-ref in the genome. . ### In RNA-seq:. - **Expression Levels**: RNA-seq measures gene expression, so the VAF of a mutation depends on the expression of the mutant and wild-type alleles. If a gene is highly expressed in some cells and not others, or if only one allele is expressed (allele-specific expression), the VAF may be skewed. - **Variable Expression**: The VAF in RNA-seq data can be influenced by tissue-specific expression, transcriptional noise, or RNA degradation, making it less consistent compared to DNA-seq. - **Allelic Imbalance**: In RNA-seq, you might observe allelic imbalance due to factors like imprinting or preferential expression of one allele, further complicating the interpretation of VAF.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:300,energy efficiency,model,model,300,"Question about RNA-seq; This is from DeepVariant's documentation. ""For somatic data or any other samples where the genotypes go beyond two copies of DNA, DeepVariant will not work out of the box because the only genotypes supported are hom-alt, het, and hom-ref."". Does the same apply to the RNA-seq model of DeepVariant? If a mutation has a low VAF is it predicted as hom-ref? Because in RNA-seq, low VAF doesn't necessarily mean the variant is hom-ref in the genome. . ### In RNA-seq:. - **Expression Levels**: RNA-seq measures gene expression, so the VAF of a mutation depends on the expression of the mutant and wild-type alleles. If a gene is highly expressed in some cells and not others, or if only one allele is expressed (allele-specific expression), the VAF may be skewed. - **Variable Expression**: The VAF in RNA-seq data can be influenced by tissue-specific expression, transcriptional noise, or RNA degradation, making it less consistent compared to DNA-seq. - **Allelic Imbalance**: In RNA-seq, you might observe allelic imbalance due to factors like imprinting or preferential expression of one allele, further complicating the interpretation of VAF.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:356,energy efficiency,predict,predicted,356,"Question about RNA-seq; This is from DeepVariant's documentation. ""For somatic data or any other samples where the genotypes go beyond two copies of DNA, DeepVariant will not work out of the box because the only genotypes supported are hom-alt, het, and hom-ref."". Does the same apply to the RNA-seq model of DeepVariant? If a mutation has a low VAF is it predicted as hom-ref? Because in RNA-seq, low VAF doesn't necessarily mean the variant is hom-ref in the genome. . ### In RNA-seq:. - **Expression Levels**: RNA-seq measures gene expression, so the VAF of a mutation depends on the expression of the mutant and wild-type alleles. If a gene is highly expressed in some cells and not others, or if only one allele is expressed (allele-specific expression), the VAF may be skewed. - **Variable Expression**: The VAF in RNA-seq data can be influenced by tissue-specific expression, transcriptional noise, or RNA degradation, making it less consistent compared to DNA-seq. - **Allelic Imbalance**: In RNA-seq, you might observe allelic imbalance due to factors like imprinting or preferential expression of one allele, further complicating the interpretation of VAF.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:521,energy efficiency,measur,measures,521,"Question about RNA-seq; This is from DeepVariant's documentation. ""For somatic data or any other samples where the genotypes go beyond two copies of DNA, DeepVariant will not work out of the box because the only genotypes supported are hom-alt, het, and hom-ref."". Does the same apply to the RNA-seq model of DeepVariant? If a mutation has a low VAF is it predicted as hom-ref? Because in RNA-seq, low VAF doesn't necessarily mean the variant is hom-ref in the genome. . ### In RNA-seq:. - **Expression Levels**: RNA-seq measures gene expression, so the VAF of a mutation depends on the expression of the mutant and wild-type alleles. If a gene is highly expressed in some cells and not others, or if only one allele is expressed (allele-specific expression), the VAF may be skewed. - **Variable Expression**: The VAF in RNA-seq data can be influenced by tissue-specific expression, transcriptional noise, or RNA degradation, making it less consistent compared to DNA-seq. - **Allelic Imbalance**: In RNA-seq, you might observe allelic imbalance due to factors like imprinting or preferential expression of one allele, further complicating the interpretation of VAF.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:572,integrability,depend,depends,572,"Question about RNA-seq; This is from DeepVariant's documentation. ""For somatic data or any other samples where the genotypes go beyond two copies of DNA, DeepVariant will not work out of the box because the only genotypes supported are hom-alt, het, and hom-ref."". Does the same apply to the RNA-seq model of DeepVariant? If a mutation has a low VAF is it predicted as hom-ref? Because in RNA-seq, low VAF doesn't necessarily mean the variant is hom-ref in the genome. . ### In RNA-seq:. - **Expression Levels**: RNA-seq measures gene expression, so the VAF of a mutation depends on the expression of the mutant and wild-type alleles. If a gene is highly expressed in some cells and not others, or if only one allele is expressed (allele-specific expression), the VAF may be skewed. - **Variable Expression**: The VAF in RNA-seq data can be influenced by tissue-specific expression, transcriptional noise, or RNA degradation, making it less consistent compared to DNA-seq. - **Allelic Imbalance**: In RNA-seq, you might observe allelic imbalance due to factors like imprinting or preferential expression of one allele, further complicating the interpretation of VAF.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:738,interoperability,specif,specific,738,"Question about RNA-seq; This is from DeepVariant's documentation. ""For somatic data or any other samples where the genotypes go beyond two copies of DNA, DeepVariant will not work out of the box because the only genotypes supported are hom-alt, het, and hom-ref."". Does the same apply to the RNA-seq model of DeepVariant? If a mutation has a low VAF is it predicted as hom-ref? Because in RNA-seq, low VAF doesn't necessarily mean the variant is hom-ref in the genome. . ### In RNA-seq:. - **Expression Levels**: RNA-seq measures gene expression, so the VAF of a mutation depends on the expression of the mutant and wild-type alleles. If a gene is highly expressed in some cells and not others, or if only one allele is expressed (allele-specific expression), the VAF may be skewed. - **Variable Expression**: The VAF in RNA-seq data can be influenced by tissue-specific expression, transcriptional noise, or RNA degradation, making it less consistent compared to DNA-seq. - **Allelic Imbalance**: In RNA-seq, you might observe allelic imbalance due to factors like imprinting or preferential expression of one allele, further complicating the interpretation of VAF.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:862,interoperability,specif,specific,862,"Question about RNA-seq; This is from DeepVariant's documentation. ""For somatic data or any other samples where the genotypes go beyond two copies of DNA, DeepVariant will not work out of the box because the only genotypes supported are hom-alt, het, and hom-ref."". Does the same apply to the RNA-seq model of DeepVariant? If a mutation has a low VAF is it predicted as hom-ref? Because in RNA-seq, low VAF doesn't necessarily mean the variant is hom-ref in the genome. . ### In RNA-seq:. - **Expression Levels**: RNA-seq measures gene expression, so the VAF of a mutation depends on the expression of the mutant and wild-type alleles. If a gene is highly expressed in some cells and not others, or if only one allele is expressed (allele-specific expression), the VAF may be skewed. - **Variable Expression**: The VAF in RNA-seq data can be influenced by tissue-specific expression, transcriptional noise, or RNA degradation, making it less consistent compared to DNA-seq. - **Allelic Imbalance**: In RNA-seq, you might observe allelic imbalance due to factors like imprinting or preferential expression of one allele, further complicating the interpretation of VAF.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:572,modifiability,depend,depends,572,"Question about RNA-seq; This is from DeepVariant's documentation. ""For somatic data or any other samples where the genotypes go beyond two copies of DNA, DeepVariant will not work out of the box because the only genotypes supported are hom-alt, het, and hom-ref."". Does the same apply to the RNA-seq model of DeepVariant? If a mutation has a low VAF is it predicted as hom-ref? Because in RNA-seq, low VAF doesn't necessarily mean the variant is hom-ref in the genome. . ### In RNA-seq:. - **Expression Levels**: RNA-seq measures gene expression, so the VAF of a mutation depends on the expression of the mutant and wild-type alleles. If a gene is highly expressed in some cells and not others, or if only one allele is expressed (allele-specific expression), the VAF may be skewed. - **Variable Expression**: The VAF in RNA-seq data can be influenced by tissue-specific expression, transcriptional noise, or RNA degradation, making it less consistent compared to DNA-seq. - **Allelic Imbalance**: In RNA-seq, you might observe allelic imbalance due to factors like imprinting or preferential expression of one allele, further complicating the interpretation of VAF.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:787,modifiability,Variab,Variable,787,"Question about RNA-seq; This is from DeepVariant's documentation. ""For somatic data or any other samples where the genotypes go beyond two copies of DNA, DeepVariant will not work out of the box because the only genotypes supported are hom-alt, het, and hom-ref."". Does the same apply to the RNA-seq model of DeepVariant? If a mutation has a low VAF is it predicted as hom-ref? Because in RNA-seq, low VAF doesn't necessarily mean the variant is hom-ref in the genome. . ### In RNA-seq:. - **Expression Levels**: RNA-seq measures gene expression, so the VAF of a mutation depends on the expression of the mutant and wild-type alleles. If a gene is highly expressed in some cells and not others, or if only one allele is expressed (allele-specific expression), the VAF may be skewed. - **Variable Expression**: The VAF in RNA-seq data can be influenced by tissue-specific expression, transcriptional noise, or RNA degradation, making it less consistent compared to DNA-seq. - **Allelic Imbalance**: In RNA-seq, you might observe allelic imbalance due to factors like imprinting or preferential expression of one allele, further complicating the interpretation of VAF.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:265,reliability,Doe,Does,265,"Question about RNA-seq; This is from DeepVariant's documentation. ""For somatic data or any other samples where the genotypes go beyond two copies of DNA, DeepVariant will not work out of the box because the only genotypes supported are hom-alt, het, and hom-ref."". Does the same apply to the RNA-seq model of DeepVariant? If a mutation has a low VAF is it predicted as hom-ref? Because in RNA-seq, low VAF doesn't necessarily mean the variant is hom-ref in the genome. . ### In RNA-seq:. - **Expression Levels**: RNA-seq measures gene expression, so the VAF of a mutation depends on the expression of the mutant and wild-type alleles. If a gene is highly expressed in some cells and not others, or if only one allele is expressed (allele-specific expression), the VAF may be skewed. - **Variable Expression**: The VAF in RNA-seq data can be influenced by tissue-specific expression, transcriptional noise, or RNA degradation, making it less consistent compared to DNA-seq. - **Allelic Imbalance**: In RNA-seq, you might observe allelic imbalance due to factors like imprinting or preferential expression of one allele, further complicating the interpretation of VAF.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:406,reliability,doe,doesn,406,"Question about RNA-seq; This is from DeepVariant's documentation. ""For somatic data or any other samples where the genotypes go beyond two copies of DNA, DeepVariant will not work out of the box because the only genotypes supported are hom-alt, het, and hom-ref."". Does the same apply to the RNA-seq model of DeepVariant? If a mutation has a low VAF is it predicted as hom-ref? Because in RNA-seq, low VAF doesn't necessarily mean the variant is hom-ref in the genome. . ### In RNA-seq:. - **Expression Levels**: RNA-seq measures gene expression, so the VAF of a mutation depends on the expression of the mutant and wild-type alleles. If a gene is highly expressed in some cells and not others, or if only one allele is expressed (allele-specific expression), the VAF may be skewed. - **Variable Expression**: The VAF in RNA-seq data can be influenced by tissue-specific expression, transcriptional noise, or RNA degradation, making it less consistent compared to DNA-seq. - **Allelic Imbalance**: In RNA-seq, you might observe allelic imbalance due to factors like imprinting or preferential expression of one allele, further complicating the interpretation of VAF.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:913,reliability,degrad,degradation,913,"Question about RNA-seq; This is from DeepVariant's documentation. ""For somatic data or any other samples where the genotypes go beyond two copies of DNA, DeepVariant will not work out of the box because the only genotypes supported are hom-alt, het, and hom-ref."". Does the same apply to the RNA-seq model of DeepVariant? If a mutation has a low VAF is it predicted as hom-ref? Because in RNA-seq, low VAF doesn't necessarily mean the variant is hom-ref in the genome. . ### In RNA-seq:. - **Expression Levels**: RNA-seq measures gene expression, so the VAF of a mutation depends on the expression of the mutant and wild-type alleles. If a gene is highly expressed in some cells and not others, or if only one allele is expressed (allele-specific expression), the VAF may be skewed. - **Variable Expression**: The VAF in RNA-seq data can be influenced by tissue-specific expression, transcriptional noise, or RNA degradation, making it less consistent compared to DNA-seq. - **Allelic Imbalance**: In RNA-seq, you might observe allelic imbalance due to factors like imprinting or preferential expression of one allele, further complicating the interpretation of VAF.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:356,safety,predict,predicted,356,"Question about RNA-seq; This is from DeepVariant's documentation. ""For somatic data or any other samples where the genotypes go beyond two copies of DNA, DeepVariant will not work out of the box because the only genotypes supported are hom-alt, het, and hom-ref."". Does the same apply to the RNA-seq model of DeepVariant? If a mutation has a low VAF is it predicted as hom-ref? Because in RNA-seq, low VAF doesn't necessarily mean the variant is hom-ref in the genome. . ### In RNA-seq:. - **Expression Levels**: RNA-seq measures gene expression, so the VAF of a mutation depends on the expression of the mutant and wild-type alleles. If a gene is highly expressed in some cells and not others, or if only one allele is expressed (allele-specific expression), the VAF may be skewed. - **Variable Expression**: The VAF in RNA-seq data can be influenced by tissue-specific expression, transcriptional noise, or RNA degradation, making it less consistent compared to DNA-seq. - **Allelic Imbalance**: In RNA-seq, you might observe allelic imbalance due to factors like imprinting or preferential expression of one allele, further complicating the interpretation of VAF.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:572,safety,depend,depends,572,"Question about RNA-seq; This is from DeepVariant's documentation. ""For somatic data or any other samples where the genotypes go beyond two copies of DNA, DeepVariant will not work out of the box because the only genotypes supported are hom-alt, het, and hom-ref."". Does the same apply to the RNA-seq model of DeepVariant? If a mutation has a low VAF is it predicted as hom-ref? Because in RNA-seq, low VAF doesn't necessarily mean the variant is hom-ref in the genome. . ### In RNA-seq:. - **Expression Levels**: RNA-seq measures gene expression, so the VAF of a mutation depends on the expression of the mutant and wild-type alleles. If a gene is highly expressed in some cells and not others, or if only one allele is expressed (allele-specific expression), the VAF may be skewed. - **Variable Expression**: The VAF in RNA-seq data can be influenced by tissue-specific expression, transcriptional noise, or RNA degradation, making it less consistent compared to DNA-seq. - **Allelic Imbalance**: In RNA-seq, you might observe allelic imbalance due to factors like imprinting or preferential expression of one allele, further complicating the interpretation of VAF.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:1127,safety,compl,complicating,1127,"Question about RNA-seq; This is from DeepVariant's documentation. ""For somatic data or any other samples where the genotypes go beyond two copies of DNA, DeepVariant will not work out of the box because the only genotypes supported are hom-alt, het, and hom-ref."". Does the same apply to the RNA-seq model of DeepVariant? If a mutation has a low VAF is it predicted as hom-ref? Because in RNA-seq, low VAF doesn't necessarily mean the variant is hom-ref in the genome. . ### In RNA-seq:. - **Expression Levels**: RNA-seq measures gene expression, so the VAF of a mutation depends on the expression of the mutant and wild-type alleles. If a gene is highly expressed in some cells and not others, or if only one allele is expressed (allele-specific expression), the VAF may be skewed. - **Variable Expression**: The VAF in RNA-seq data can be influenced by tissue-specific expression, transcriptional noise, or RNA degradation, making it less consistent compared to DNA-seq. - **Allelic Imbalance**: In RNA-seq, you might observe allelic imbalance due to factors like imprinting or preferential expression of one allele, further complicating the interpretation of VAF.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:300,security,model,model,300,"Question about RNA-seq; This is from DeepVariant's documentation. ""For somatic data or any other samples where the genotypes go beyond two copies of DNA, DeepVariant will not work out of the box because the only genotypes supported are hom-alt, het, and hom-ref."". Does the same apply to the RNA-seq model of DeepVariant? If a mutation has a low VAF is it predicted as hom-ref? Because in RNA-seq, low VAF doesn't necessarily mean the variant is hom-ref in the genome. . ### In RNA-seq:. - **Expression Levels**: RNA-seq measures gene expression, so the VAF of a mutation depends on the expression of the mutant and wild-type alleles. If a gene is highly expressed in some cells and not others, or if only one allele is expressed (allele-specific expression), the VAF may be skewed. - **Variable Expression**: The VAF in RNA-seq data can be influenced by tissue-specific expression, transcriptional noise, or RNA degradation, making it less consistent compared to DNA-seq. - **Allelic Imbalance**: In RNA-seq, you might observe allelic imbalance due to factors like imprinting or preferential expression of one allele, further complicating the interpretation of VAF.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:1127,security,compl,complicating,1127,"Question about RNA-seq; This is from DeepVariant's documentation. ""For somatic data or any other samples where the genotypes go beyond two copies of DNA, DeepVariant will not work out of the box because the only genotypes supported are hom-alt, het, and hom-ref."". Does the same apply to the RNA-seq model of DeepVariant? If a mutation has a low VAF is it predicted as hom-ref? Because in RNA-seq, low VAF doesn't necessarily mean the variant is hom-ref in the genome. . ### In RNA-seq:. - **Expression Levels**: RNA-seq measures gene expression, so the VAF of a mutation depends on the expression of the mutant and wild-type alleles. If a gene is highly expressed in some cells and not others, or if only one allele is expressed (allele-specific expression), the VAF may be skewed. - **Variable Expression**: The VAF in RNA-seq data can be influenced by tissue-specific expression, transcriptional noise, or RNA degradation, making it less consistent compared to DNA-seq. - **Allelic Imbalance**: In RNA-seq, you might observe allelic imbalance due to factors like imprinting or preferential expression of one allele, further complicating the interpretation of VAF.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:572,testability,depend,depends,572,"Question about RNA-seq; This is from DeepVariant's documentation. ""For somatic data or any other samples where the genotypes go beyond two copies of DNA, DeepVariant will not work out of the box because the only genotypes supported are hom-alt, het, and hom-ref."". Does the same apply to the RNA-seq model of DeepVariant? If a mutation has a low VAF is it predicted as hom-ref? Because in RNA-seq, low VAF doesn't necessarily mean the variant is hom-ref in the genome. . ### In RNA-seq:. - **Expression Levels**: RNA-seq measures gene expression, so the VAF of a mutation depends on the expression of the mutant and wild-type alleles. If a gene is highly expressed in some cells and not others, or if only one allele is expressed (allele-specific expression), the VAF may be skewed. - **Variable Expression**: The VAF in RNA-seq data can be influenced by tissue-specific expression, transcriptional noise, or RNA degradation, making it less consistent compared to DNA-seq. - **Allelic Imbalance**: In RNA-seq, you might observe allelic imbalance due to factors like imprinting or preferential expression of one allele, further complicating the interpretation of VAF.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:1020,testability,observ,observe,1020,"Question about RNA-seq; This is from DeepVariant's documentation. ""For somatic data or any other samples where the genotypes go beyond two copies of DNA, DeepVariant will not work out of the box because the only genotypes supported are hom-alt, het, and hom-ref."". Does the same apply to the RNA-seq model of DeepVariant? If a mutation has a low VAF is it predicted as hom-ref? Because in RNA-seq, low VAF doesn't necessarily mean the variant is hom-ref in the genome. . ### In RNA-seq:. - **Expression Levels**: RNA-seq measures gene expression, so the VAF of a mutation depends on the expression of the mutant and wild-type alleles. If a gene is highly expressed in some cells and not others, or if only one allele is expressed (allele-specific expression), the VAF may be skewed. - **Variable Expression**: The VAF in RNA-seq data can be influenced by tissue-specific expression, transcriptional noise, or RNA degradation, making it less consistent compared to DNA-seq. - **Allelic Imbalance**: In RNA-seq, you might observe allelic imbalance due to factors like imprinting or preferential expression of one allele, further complicating the interpretation of VAF.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:51,usability,document,documentation,51,"Question about RNA-seq; This is from DeepVariant's documentation. ""For somatic data or any other samples where the genotypes go beyond two copies of DNA, DeepVariant will not work out of the box because the only genotypes supported are hom-alt, het, and hom-ref."". Does the same apply to the RNA-seq model of DeepVariant? If a mutation has a low VAF is it predicted as hom-ref? Because in RNA-seq, low VAF doesn't necessarily mean the variant is hom-ref in the genome. . ### In RNA-seq:. - **Expression Levels**: RNA-seq measures gene expression, so the VAF of a mutation depends on the expression of the mutant and wild-type alleles. If a gene is highly expressed in some cells and not others, or if only one allele is expressed (allele-specific expression), the VAF may be skewed. - **Variable Expression**: The VAF in RNA-seq data can be influenced by tissue-specific expression, transcriptional noise, or RNA degradation, making it less consistent compared to DNA-seq. - **Allelic Imbalance**: In RNA-seq, you might observe allelic imbalance due to factors like imprinting or preferential expression of one allele, further complicating the interpretation of VAF.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:222,usability,support,supported,222,"Question about RNA-seq; This is from DeepVariant's documentation. ""For somatic data or any other samples where the genotypes go beyond two copies of DNA, DeepVariant will not work out of the box because the only genotypes supported are hom-alt, het, and hom-ref."". Does the same apply to the RNA-seq model of DeepVariant? If a mutation has a low VAF is it predicted as hom-ref? Because in RNA-seq, low VAF doesn't necessarily mean the variant is hom-ref in the genome. . ### In RNA-seq:. - **Expression Levels**: RNA-seq measures gene expression, so the VAF of a mutation depends on the expression of the mutant and wild-type alleles. If a gene is highly expressed in some cells and not others, or if only one allele is expressed (allele-specific expression), the VAF may be skewed. - **Variable Expression**: The VAF in RNA-seq data can be influenced by tissue-specific expression, transcriptional noise, or RNA degradation, making it less consistent compared to DNA-seq. - **Allelic Imbalance**: In RNA-seq, you might observe allelic imbalance due to factors like imprinting or preferential expression of one allele, further complicating the interpretation of VAF.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:941,usability,consist,consistent,941,"Question about RNA-seq; This is from DeepVariant's documentation. ""For somatic data or any other samples where the genotypes go beyond two copies of DNA, DeepVariant will not work out of the box because the only genotypes supported are hom-alt, het, and hom-ref."". Does the same apply to the RNA-seq model of DeepVariant? If a mutation has a low VAF is it predicted as hom-ref? Because in RNA-seq, low VAF doesn't necessarily mean the variant is hom-ref in the genome. . ### In RNA-seq:. - **Expression Levels**: RNA-seq measures gene expression, so the VAF of a mutation depends on the expression of the mutant and wild-type alleles. If a gene is highly expressed in some cells and not others, or if only one allele is expressed (allele-specific expression), the VAF may be skewed. - **Variable Expression**: The VAF in RNA-seq data can be influenced by tissue-specific expression, transcriptional noise, or RNA degradation, making it less consistent compared to DNA-seq. - **Allelic Imbalance**: In RNA-seq, you might observe allelic imbalance due to factors like imprinting or preferential expression of one allele, further complicating the interpretation of VAF.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:1080,usability,prefer,preferential,1080,"Question about RNA-seq; This is from DeepVariant's documentation. ""For somatic data or any other samples where the genotypes go beyond two copies of DNA, DeepVariant will not work out of the box because the only genotypes supported are hom-alt, het, and hom-ref."". Does the same apply to the RNA-seq model of DeepVariant? If a mutation has a low VAF is it predicted as hom-ref? Because in RNA-seq, low VAF doesn't necessarily mean the variant is hom-ref in the genome. . ### In RNA-seq:. - **Expression Levels**: RNA-seq measures gene expression, so the VAF of a mutation depends on the expression of the mutant and wild-type alleles. If a gene is highly expressed in some cells and not others, or if only one allele is expressed (allele-specific expression), the VAF may be skewed. - **Variable Expression**: The VAF in RNA-seq data can be influenced by tissue-specific expression, transcriptional noise, or RNA degradation, making it less consistent compared to DNA-seq. - **Allelic Imbalance**: In RNA-seq, you might observe allelic imbalance due to factors like imprinting or preferential expression of one allele, further complicating the interpretation of VAF.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/865:789,availability,Operat,Operating,789,"Running with Conda; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. This isn't a code problem, but rather a documentation issue. I've run DeepVariant via your docker with success. To integrate it with our project I would like to install it via conda. I was able to do that but it isn't clear how to run deep variant. Do you have documentation/examples of what commands to send? . When using docker, we invoke the google/deepvariant:1.6.1 image and send it the command ""/opt/deepvariant/bin/run_deepvariant"" with appropriate arguments. What do we run when using conda? . Note the docs/deepvariant-quick-start.md has examples for docker (very useful and they work with our data) but nothing for conda. **Setup**. - Operating system: linux. - DeepVariant version: 1.5.0 (latest from conda). - Installation method (Docker, built from source, etc.): conda. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Do you have plans to update conda with the latest deepvariant version? It is still at 1.5.0. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:1077,availability,Error,Error,1077,"Running with Conda; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. This isn't a code problem, but rather a documentation issue. I've run DeepVariant via your docker with success. To integrate it with our project I would like to install it via conda. I was able to do that but it isn't clear how to run deep variant. Do you have documentation/examples of what commands to send? . When using docker, we invoke the google/deepvariant:1.6.1 image and send it the command ""/opt/deepvariant/bin/run_deepvariant"" with appropriate arguments. What do we run when using conda? . Note the docs/deepvariant-quick-start.md has examples for docker (very useful and they work with our data) but nothing for conda. **Setup**. - Operating system: linux. - DeepVariant version: 1.5.0 (latest from conda). - Installation method (Docker, built from source, etc.): conda. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Do you have plans to update conda with the latest deepvariant version? It is still at 1.5.0. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:259,deployability,integr,integrate,259,"Running with Conda; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. This isn't a code problem, but rather a documentation issue. I've run DeepVariant via your docker with success. To integrate it with our project I would like to install it via conda. I was able to do that but it isn't clear how to run deep variant. Do you have documentation/examples of what commands to send? . When using docker, we invoke the google/deepvariant:1.6.1 image and send it the command ""/opt/deepvariant/bin/run_deepvariant"" with appropriate arguments. What do we run when using conda? . Note the docs/deepvariant-quick-start.md has examples for docker (very useful and they work with our data) but nothing for conda. **Setup**. - Operating system: linux. - DeepVariant version: 1.5.0 (latest from conda). - Installation method (Docker, built from source, etc.): conda. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Do you have plans to update conda with the latest deepvariant version? It is still at 1.5.0. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:305,deployability,instal,install,305,"Running with Conda; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. This isn't a code problem, but rather a documentation issue. I've run DeepVariant via your docker with success. To integrate it with our project I would like to install it via conda. I was able to do that but it isn't clear how to run deep variant. Do you have documentation/examples of what commands to send? . When using docker, we invoke the google/deepvariant:1.6.1 image and send it the command ""/opt/deepvariant/bin/run_deepvariant"" with appropriate arguments. What do we run when using conda? . Note the docs/deepvariant-quick-start.md has examples for docker (very useful and they work with our data) but nothing for conda. **Setup**. - Operating system: linux. - DeepVariant version: 1.5.0 (latest from conda). - Installation method (Docker, built from source, etc.): conda. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Do you have plans to update conda with the latest deepvariant version? It is still at 1.5.0. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:828,deployability,version,version,828,"Running with Conda; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. This isn't a code problem, but rather a documentation issue. I've run DeepVariant via your docker with success. To integrate it with our project I would like to install it via conda. I was able to do that but it isn't clear how to run deep variant. Do you have documentation/examples of what commands to send? . When using docker, we invoke the google/deepvariant:1.6.1 image and send it the command ""/opt/deepvariant/bin/run_deepvariant"" with appropriate arguments. What do we run when using conda? . Note the docs/deepvariant-quick-start.md has examples for docker (very useful and they work with our data) but nothing for conda. **Setup**. - Operating system: linux. - DeepVariant version: 1.5.0 (latest from conda). - Installation method (Docker, built from source, etc.): conda. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Do you have plans to update conda with the latest deepvariant version? It is still at 1.5.0. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:866,deployability,Instal,Installation,866,"Running with Conda; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. This isn't a code problem, but rather a documentation issue. I've run DeepVariant via your docker with success. To integrate it with our project I would like to install it via conda. I was able to do that but it isn't clear how to run deep variant. Do you have documentation/examples of what commands to send? . When using docker, we invoke the google/deepvariant:1.6.1 image and send it the command ""/opt/deepvariant/bin/run_deepvariant"" with appropriate arguments. What do we run when using conda? . Note the docs/deepvariant-quick-start.md has examples for docker (very useful and they work with our data) but nothing for conda. **Setup**. - Operating system: linux. - DeepVariant version: 1.5.0 (latest from conda). - Installation method (Docker, built from source, etc.): conda. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Do you have plans to update conda with the latest deepvariant version? It is still at 1.5.0. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:1373,deployability,updat,update,1373,"Running with Conda; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. This isn't a code problem, but rather a documentation issue. I've run DeepVariant via your docker with success. To integrate it with our project I would like to install it via conda. I was able to do that but it isn't clear how to run deep variant. Do you have documentation/examples of what commands to send? . When using docker, we invoke the google/deepvariant:1.6.1 image and send it the command ""/opt/deepvariant/bin/run_deepvariant"" with appropriate arguments. What do we run when using conda? . Note the docs/deepvariant-quick-start.md has examples for docker (very useful and they work with our data) but nothing for conda. **Setup**. - Operating system: linux. - DeepVariant version: 1.5.0 (latest from conda). - Installation method (Docker, built from source, etc.): conda. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Do you have plans to update conda with the latest deepvariant version? It is still at 1.5.0. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:1414,deployability,version,version,1414,"Running with Conda; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. This isn't a code problem, but rather a documentation issue. I've run DeepVariant via your docker with success. To integrate it with our project I would like to install it via conda. I was able to do that but it isn't clear how to run deep variant. Do you have documentation/examples of what commands to send? . When using docker, we invoke the google/deepvariant:1.6.1 image and send it the command ""/opt/deepvariant/bin/run_deepvariant"" with appropriate arguments. What do we run when using conda? . Note the docs/deepvariant-quick-start.md has examples for docker (very useful and they work with our data) but nothing for conda. **Setup**. - Operating system: linux. - DeepVariant version: 1.5.0 (latest from conda). - Installation method (Docker, built from source, etc.): conda. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Do you have plans to update conda with the latest deepvariant version? It is still at 1.5.0. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:259,integrability,integr,integrate,259,"Running with Conda; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. This isn't a code problem, but rather a documentation issue. I've run DeepVariant via your docker with success. To integrate it with our project I would like to install it via conda. I was able to do that but it isn't clear how to run deep variant. Do you have documentation/examples of what commands to send? . When using docker, we invoke the google/deepvariant:1.6.1 image and send it the command ""/opt/deepvariant/bin/run_deepvariant"" with appropriate arguments. What do we run when using conda? . Note the docs/deepvariant-quick-start.md has examples for docker (very useful and they work with our data) but nothing for conda. **Setup**. - Operating system: linux. - DeepVariant version: 1.5.0 (latest from conda). - Installation method (Docker, built from source, etc.): conda. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Do you have plans to update conda with the latest deepvariant version? It is still at 1.5.0. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:828,integrability,version,version,828,"Running with Conda; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. This isn't a code problem, but rather a documentation issue. I've run DeepVariant via your docker with success. To integrate it with our project I would like to install it via conda. I was able to do that but it isn't clear how to run deep variant. Do you have documentation/examples of what commands to send? . When using docker, we invoke the google/deepvariant:1.6.1 image and send it the command ""/opt/deepvariant/bin/run_deepvariant"" with appropriate arguments. What do we run when using conda? . Note the docs/deepvariant-quick-start.md has examples for docker (very useful and they work with our data) but nothing for conda. **Setup**. - Operating system: linux. - DeepVariant version: 1.5.0 (latest from conda). - Installation method (Docker, built from source, etc.): conda. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Do you have plans to update conda with the latest deepvariant version? It is still at 1.5.0. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:1414,integrability,version,version,1414,"Running with Conda; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. This isn't a code problem, but rather a documentation issue. I've run DeepVariant via your docker with success. To integrate it with our project I would like to install it via conda. I was able to do that but it isn't clear how to run deep variant. Do you have documentation/examples of what commands to send? . When using docker, we invoke the google/deepvariant:1.6.1 image and send it the command ""/opt/deepvariant/bin/run_deepvariant"" with appropriate arguments. What do we run when using conda? . Note the docs/deepvariant-quick-start.md has examples for docker (very useful and they work with our data) but nothing for conda. **Setup**. - Operating system: linux. - DeepVariant version: 1.5.0 (latest from conda). - Installation method (Docker, built from source, etc.): conda. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Do you have plans to update conda with the latest deepvariant version? It is still at 1.5.0. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:259,interoperability,integr,integrate,259,"Running with Conda; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. This isn't a code problem, but rather a documentation issue. I've run DeepVariant via your docker with success. To integrate it with our project I would like to install it via conda. I was able to do that but it isn't clear how to run deep variant. Do you have documentation/examples of what commands to send? . When using docker, we invoke the google/deepvariant:1.6.1 image and send it the command ""/opt/deepvariant/bin/run_deepvariant"" with appropriate arguments. What do we run when using conda? . Note the docs/deepvariant-quick-start.md has examples for docker (very useful and they work with our data) but nothing for conda. **Setup**. - Operating system: linux. - DeepVariant version: 1.5.0 (latest from conda). - Installation method (Docker, built from source, etc.): conda. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Do you have plans to update conda with the latest deepvariant version? It is still at 1.5.0. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:259,modifiability,integr,integrate,259,"Running with Conda; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. This isn't a code problem, but rather a documentation issue. I've run DeepVariant via your docker with success. To integrate it with our project I would like to install it via conda. I was able to do that but it isn't clear how to run deep variant. Do you have documentation/examples of what commands to send? . When using docker, we invoke the google/deepvariant:1.6.1 image and send it the command ""/opt/deepvariant/bin/run_deepvariant"" with appropriate arguments. What do we run when using conda? . Note the docs/deepvariant-quick-start.md has examples for docker (very useful and they work with our data) but nothing for conda. **Setup**. - Operating system: linux. - DeepVariant version: 1.5.0 (latest from conda). - Installation method (Docker, built from source, etc.): conda. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Do you have plans to update conda with the latest deepvariant version? It is still at 1.5.0. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:828,modifiability,version,version,828,"Running with Conda; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. This isn't a code problem, but rather a documentation issue. I've run DeepVariant via your docker with success. To integrate it with our project I would like to install it via conda. I was able to do that but it isn't clear how to run deep variant. Do you have documentation/examples of what commands to send? . When using docker, we invoke the google/deepvariant:1.6.1 image and send it the command ""/opt/deepvariant/bin/run_deepvariant"" with appropriate arguments. What do we run when using conda? . Note the docs/deepvariant-quick-start.md has examples for docker (very useful and they work with our data) but nothing for conda. **Setup**. - Operating system: linux. - DeepVariant version: 1.5.0 (latest from conda). - Installation method (Docker, built from source, etc.): conda. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Do you have plans to update conda with the latest deepvariant version? It is still at 1.5.0. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:1414,modifiability,version,version,1414,"Running with Conda; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. This isn't a code problem, but rather a documentation issue. I've run DeepVariant via your docker with success. To integrate it with our project I would like to install it via conda. I was able to do that but it isn't clear how to run deep variant. Do you have documentation/examples of what commands to send? . When using docker, we invoke the google/deepvariant:1.6.1 image and send it the command ""/opt/deepvariant/bin/run_deepvariant"" with appropriate arguments. What do we run when using conda? . Note the docs/deepvariant-quick-start.md has examples for docker (very useful and they work with our data) but nothing for conda. **Setup**. - Operating system: linux. - DeepVariant version: 1.5.0 (latest from conda). - Installation method (Docker, built from source, etc.): conda. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Do you have plans to update conda with the latest deepvariant version? It is still at 1.5.0. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:1077,performance,Error,Error,1077,"Running with Conda; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. This isn't a code problem, but rather a documentation issue. I've run DeepVariant via your docker with success. To integrate it with our project I would like to install it via conda. I was able to do that but it isn't clear how to run deep variant. Do you have documentation/examples of what commands to send? . When using docker, we invoke the google/deepvariant:1.6.1 image and send it the command ""/opt/deepvariant/bin/run_deepvariant"" with appropriate arguments. What do we run when using conda? . Note the docs/deepvariant-quick-start.md has examples for docker (very useful and they work with our data) but nothing for conda. **Setup**. - Operating system: linux. - DeepVariant version: 1.5.0 (latest from conda). - Installation method (Docker, built from source, etc.): conda. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Do you have plans to update conda with the latest deepvariant version? It is still at 1.5.0. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:259,reliability,integr,integrate,259,"Running with Conda; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. This isn't a code problem, but rather a documentation issue. I've run DeepVariant via your docker with success. To integrate it with our project I would like to install it via conda. I was able to do that but it isn't clear how to run deep variant. Do you have documentation/examples of what commands to send? . When using docker, we invoke the google/deepvariant:1.6.1 image and send it the command ""/opt/deepvariant/bin/run_deepvariant"" with appropriate arguments. What do we run when using conda? . Note the docs/deepvariant-quick-start.md has examples for docker (very useful and they work with our data) but nothing for conda. **Setup**. - Operating system: linux. - DeepVariant version: 1.5.0 (latest from conda). - Installation method (Docker, built from source, etc.): conda. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Do you have plans to update conda with the latest deepvariant version? It is still at 1.5.0. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:1109,reliability,Doe,Does,1109,"Running with Conda; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. This isn't a code problem, but rather a documentation issue. I've run DeepVariant via your docker with success. To integrate it with our project I would like to install it via conda. I was able to do that but it isn't clear how to run deep variant. Do you have documentation/examples of what commands to send? . When using docker, we invoke the google/deepvariant:1.6.1 image and send it the command ""/opt/deepvariant/bin/run_deepvariant"" with appropriate arguments. What do we run when using conda? . Note the docs/deepvariant-quick-start.md has examples for docker (very useful and they work with our data) but nothing for conda. **Setup**. - Operating system: linux. - DeepVariant version: 1.5.0 (latest from conda). - Installation method (Docker, built from source, etc.): conda. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Do you have plans to update conda with the latest deepvariant version? It is still at 1.5.0. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:1077,safety,Error,Error,1077,"Running with Conda; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. This isn't a code problem, but rather a documentation issue. I've run DeepVariant via your docker with success. To integrate it with our project I would like to install it via conda. I was able to do that but it isn't clear how to run deep variant. Do you have documentation/examples of what commands to send? . When using docker, we invoke the google/deepvariant:1.6.1 image and send it the command ""/opt/deepvariant/bin/run_deepvariant"" with appropriate arguments. What do we run when using conda? . Note the docs/deepvariant-quick-start.md has examples for docker (very useful and they work with our data) but nothing for conda. **Setup**. - Operating system: linux. - DeepVariant version: 1.5.0 (latest from conda). - Installation method (Docker, built from source, etc.): conda. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Do you have plans to update conda with the latest deepvariant version? It is still at 1.5.0. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:1130,safety,test,test,1130,"Running with Conda; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. This isn't a code problem, but rather a documentation issue. I've run DeepVariant via your docker with success. To integrate it with our project I would like to install it via conda. I was able to do that but it isn't clear how to run deep variant. Do you have documentation/examples of what commands to send? . When using docker, we invoke the google/deepvariant:1.6.1 image and send it the command ""/opt/deepvariant/bin/run_deepvariant"" with appropriate arguments. What do we run when using conda? . Note the docs/deepvariant-quick-start.md has examples for docker (very useful and they work with our data) but nothing for conda. **Setup**. - Operating system: linux. - DeepVariant version: 1.5.0 (latest from conda). - Installation method (Docker, built from source, etc.): conda. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Do you have plans to update conda with the latest deepvariant version? It is still at 1.5.0. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:1166,safety,test,test,1166,"Running with Conda; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. This isn't a code problem, but rather a documentation issue. I've run DeepVariant via your docker with success. To integrate it with our project I would like to install it via conda. I was able to do that but it isn't clear how to run deep variant. Do you have documentation/examples of what commands to send? . When using docker, we invoke the google/deepvariant:1.6.1 image and send it the command ""/opt/deepvariant/bin/run_deepvariant"" with appropriate arguments. What do we run when using conda? . Note the docs/deepvariant-quick-start.md has examples for docker (very useful and they work with our data) but nothing for conda. **Setup**. - Operating system: linux. - DeepVariant version: 1.5.0 (latest from conda). - Installation method (Docker, built from source, etc.): conda. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Do you have plans to update conda with the latest deepvariant version? It is still at 1.5.0. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:1373,safety,updat,update,1373,"Running with Conda; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. This isn't a code problem, but rather a documentation issue. I've run DeepVariant via your docker with success. To integrate it with our project I would like to install it via conda. I was able to do that but it isn't clear how to run deep variant. Do you have documentation/examples of what commands to send? . When using docker, we invoke the google/deepvariant:1.6.1 image and send it the command ""/opt/deepvariant/bin/run_deepvariant"" with appropriate arguments. What do we run when using conda? . Note the docs/deepvariant-quick-start.md has examples for docker (very useful and they work with our data) but nothing for conda. **Setup**. - Operating system: linux. - DeepVariant version: 1.5.0 (latest from conda). - Installation method (Docker, built from source, etc.): conda. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Do you have plans to update conda with the latest deepvariant version? It is still at 1.5.0. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:259,security,integr,integrate,259,"Running with Conda; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. This isn't a code problem, but rather a documentation issue. I've run DeepVariant via your docker with success. To integrate it with our project I would like to install it via conda. I was able to do that but it isn't clear how to run deep variant. Do you have documentation/examples of what commands to send? . When using docker, we invoke the google/deepvariant:1.6.1 image and send it the command ""/opt/deepvariant/bin/run_deepvariant"" with appropriate arguments. What do we run when using conda? . Note the docs/deepvariant-quick-start.md has examples for docker (very useful and they work with our data) but nothing for conda. **Setup**. - Operating system: linux. - DeepVariant version: 1.5.0 (latest from conda). - Installation method (Docker, built from source, etc.): conda. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Do you have plans to update conda with the latest deepvariant version? It is still at 1.5.0. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:1373,security,updat,update,1373,"Running with Conda; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. This isn't a code problem, but rather a documentation issue. I've run DeepVariant via your docker with success. To integrate it with our project I would like to install it via conda. I was able to do that but it isn't clear how to run deep variant. Do you have documentation/examples of what commands to send? . When using docker, we invoke the google/deepvariant:1.6.1 image and send it the command ""/opt/deepvariant/bin/run_deepvariant"" with appropriate arguments. What do we run when using conda? . Note the docs/deepvariant-quick-start.md has examples for docker (very useful and they work with our data) but nothing for conda. **Setup**. - Operating system: linux. - DeepVariant version: 1.5.0 (latest from conda). - Installation method (Docker, built from source, etc.): conda. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Do you have plans to update conda with the latest deepvariant version? It is still at 1.5.0. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:259,testability,integr,integrate,259,"Running with Conda; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. This isn't a code problem, but rather a documentation issue. I've run DeepVariant via your docker with success. To integrate it with our project I would like to install it via conda. I was able to do that but it isn't clear how to run deep variant. Do you have documentation/examples of what commands to send? . When using docker, we invoke the google/deepvariant:1.6.1 image and send it the command ""/opt/deepvariant/bin/run_deepvariant"" with appropriate arguments. What do we run when using conda? . Note the docs/deepvariant-quick-start.md has examples for docker (very useful and they work with our data) but nothing for conda. **Setup**. - Operating system: linux. - DeepVariant version: 1.5.0 (latest from conda). - Installation method (Docker, built from source, etc.): conda. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Do you have plans to update conda with the latest deepvariant version? It is still at 1.5.0. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:956,testability,instrument,instrument,956,"Running with Conda; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. This isn't a code problem, but rather a documentation issue. I've run DeepVariant via your docker with success. To integrate it with our project I would like to install it via conda. I was able to do that but it isn't clear how to run deep variant. Do you have documentation/examples of what commands to send? . When using docker, we invoke the google/deepvariant:1.6.1 image and send it the command ""/opt/deepvariant/bin/run_deepvariant"" with appropriate arguments. What do we run when using conda? . Note the docs/deepvariant-quick-start.md has examples for docker (very useful and they work with our data) but nothing for conda. **Setup**. - Operating system: linux. - DeepVariant version: 1.5.0 (latest from conda). - Installation method (Docker, built from source, etc.): conda. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Do you have plans to update conda with the latest deepvariant version? It is still at 1.5.0. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:1083,testability,trace,trace,1083,"Running with Conda; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. This isn't a code problem, but rather a documentation issue. I've run DeepVariant via your docker with success. To integrate it with our project I would like to install it via conda. I was able to do that but it isn't clear how to run deep variant. Do you have documentation/examples of what commands to send? . When using docker, we invoke the google/deepvariant:1.6.1 image and send it the command ""/opt/deepvariant/bin/run_deepvariant"" with appropriate arguments. What do we run when using conda? . Note the docs/deepvariant-quick-start.md has examples for docker (very useful and they work with our data) but nothing for conda. **Setup**. - Operating system: linux. - DeepVariant version: 1.5.0 (latest from conda). - Installation method (Docker, built from source, etc.): conda. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Do you have plans to update conda with the latest deepvariant version? It is still at 1.5.0. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:1130,testability,test,test,1130,"Running with Conda; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. This isn't a code problem, but rather a documentation issue. I've run DeepVariant via your docker with success. To integrate it with our project I would like to install it via conda. I was able to do that but it isn't clear how to run deep variant. Do you have documentation/examples of what commands to send? . When using docker, we invoke the google/deepvariant:1.6.1 image and send it the command ""/opt/deepvariant/bin/run_deepvariant"" with appropriate arguments. What do we run when using conda? . Note the docs/deepvariant-quick-start.md has examples for docker (very useful and they work with our data) but nothing for conda. **Setup**. - Operating system: linux. - DeepVariant version: 1.5.0 (latest from conda). - Installation method (Docker, built from source, etc.): conda. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Do you have plans to update conda with the latest deepvariant version? It is still at 1.5.0. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:1166,testability,test,test,1166,"Running with Conda; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. This isn't a code problem, but rather a documentation issue. I've run DeepVariant via your docker with success. To integrate it with our project I would like to install it via conda. I was able to do that but it isn't clear how to run deep variant. Do you have documentation/examples of what commands to send? . When using docker, we invoke the google/deepvariant:1.6.1 image and send it the command ""/opt/deepvariant/bin/run_deepvariant"" with appropriate arguments. What do we run when using conda? . Note the docs/deepvariant-quick-start.md has examples for docker (very useful and they work with our data) but nothing for conda. **Setup**. - Operating system: linux. - DeepVariant version: 1.5.0 (latest from conda). - Installation method (Docker, built from source, etc.): conda. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Do you have plans to update conda with the latest deepvariant version? It is still at 1.5.0. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:1340,testability,context,context,1340,"Running with Conda; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. This isn't a code problem, but rather a documentation issue. I've run DeepVariant via your docker with success. To integrate it with our project I would like to install it via conda. I was able to do that but it isn't clear how to run deep variant. Do you have documentation/examples of what commands to send? . When using docker, we invoke the google/deepvariant:1.6.1 image and send it the command ""/opt/deepvariant/bin/run_deepvariant"" with appropriate arguments. What do we run when using conda? . Note the docs/deepvariant-quick-start.md has examples for docker (very useful and they work with our data) but nothing for conda. **Setup**. - Operating system: linux. - DeepVariant version: 1.5.0 (latest from conda). - Installation method (Docker, built from source, etc.): conda. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Do you have plans to update conda with the latest deepvariant version? It is still at 1.5.0. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:1364,testability,plan,plans,1364,"Running with Conda; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. This isn't a code problem, but rather a documentation issue. I've run DeepVariant via your docker with success. To integrate it with our project I would like to install it via conda. I was able to do that but it isn't clear how to run deep variant. Do you have documentation/examples of what commands to send? . When using docker, we invoke the google/deepvariant:1.6.1 image and send it the command ""/opt/deepvariant/bin/run_deepvariant"" with appropriate arguments. What do we run when using conda? . Note the docs/deepvariant-quick-start.md has examples for docker (very useful and they work with our data) but nothing for conda. **Setup**. - Operating system: linux. - DeepVariant version: 1.5.0 (latest from conda). - Installation method (Docker, built from source, etc.): conda. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Do you have plans to update conda with the latest deepvariant version? It is still at 1.5.0. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:184,usability,document,documentation,184,"Running with Conda; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. This isn't a code problem, but rather a documentation issue. I've run DeepVariant via your docker with success. To integrate it with our project I would like to install it via conda. I was able to do that but it isn't clear how to run deep variant. Do you have documentation/examples of what commands to send? . When using docker, we invoke the google/deepvariant:1.6.1 image and send it the command ""/opt/deepvariant/bin/run_deepvariant"" with appropriate arguments. What do we run when using conda? . Note the docs/deepvariant-quick-start.md has examples for docker (very useful and they work with our data) but nothing for conda. **Setup**. - Operating system: linux. - DeepVariant version: 1.5.0 (latest from conda). - Installation method (Docker, built from source, etc.): conda. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Do you have plans to update conda with the latest deepvariant version? It is still at 1.5.0. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:362,usability,clear,clear,362,"Running with Conda; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. This isn't a code problem, but rather a documentation issue. I've run DeepVariant via your docker with success. To integrate it with our project I would like to install it via conda. I was able to do that but it isn't clear how to run deep variant. Do you have documentation/examples of what commands to send? . When using docker, we invoke the google/deepvariant:1.6.1 image and send it the command ""/opt/deepvariant/bin/run_deepvariant"" with appropriate arguments. What do we run when using conda? . Note the docs/deepvariant-quick-start.md has examples for docker (very useful and they work with our data) but nothing for conda. **Setup**. - Operating system: linux. - DeepVariant version: 1.5.0 (latest from conda). - Installation method (Docker, built from source, etc.): conda. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Do you have plans to update conda with the latest deepvariant version? It is still at 1.5.0. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:405,usability,document,documentation,405,"Running with Conda; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. This isn't a code problem, but rather a documentation issue. I've run DeepVariant via your docker with success. To integrate it with our project I would like to install it via conda. I was able to do that but it isn't clear how to run deep variant. Do you have documentation/examples of what commands to send? . When using docker, we invoke the google/deepvariant:1.6.1 image and send it the command ""/opt/deepvariant/bin/run_deepvariant"" with appropriate arguments. What do we run when using conda? . Note the docs/deepvariant-quick-start.md has examples for docker (very useful and they work with our data) but nothing for conda. **Setup**. - Operating system: linux. - DeepVariant version: 1.5.0 (latest from conda). - Installation method (Docker, built from source, etc.): conda. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Do you have plans to update conda with the latest deepvariant version? It is still at 1.5.0. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:436,usability,command,commands,436,"Running with Conda; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. This isn't a code problem, but rather a documentation issue. I've run DeepVariant via your docker with success. To integrate it with our project I would like to install it via conda. I was able to do that but it isn't clear how to run deep variant. Do you have documentation/examples of what commands to send? . When using docker, we invoke the google/deepvariant:1.6.1 image and send it the command ""/opt/deepvariant/bin/run_deepvariant"" with appropriate arguments. What do we run when using conda? . Note the docs/deepvariant-quick-start.md has examples for docker (very useful and they work with our data) but nothing for conda. **Setup**. - Operating system: linux. - DeepVariant version: 1.5.0 (latest from conda). - Installation method (Docker, built from source, etc.): conda. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Do you have plans to update conda with the latest deepvariant version? It is still at 1.5.0. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:536,usability,command,command,536,"Running with Conda; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. This isn't a code problem, but rather a documentation issue. I've run DeepVariant via your docker with success. To integrate it with our project I would like to install it via conda. I was able to do that but it isn't clear how to run deep variant. Do you have documentation/examples of what commands to send? . When using docker, we invoke the google/deepvariant:1.6.1 image and send it the command ""/opt/deepvariant/bin/run_deepvariant"" with appropriate arguments. What do we run when using conda? . Note the docs/deepvariant-quick-start.md has examples for docker (very useful and they work with our data) but nothing for conda. **Setup**. - Operating system: linux. - DeepVariant version: 1.5.0 (latest from conda). - Installation method (Docker, built from source, etc.): conda. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Do you have plans to update conda with the latest deepvariant version? It is still at 1.5.0. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:1065,usability,Command,Command,1065,"Running with Conda; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. This isn't a code problem, but rather a documentation issue. I've run DeepVariant via your docker with success. To integrate it with our project I would like to install it via conda. I was able to do that but it isn't clear how to run deep variant. Do you have documentation/examples of what commands to send? . When using docker, we invoke the google/deepvariant:1.6.1 image and send it the command ""/opt/deepvariant/bin/run_deepvariant"" with appropriate arguments. What do we run when using conda? . Note the docs/deepvariant-quick-start.md has examples for docker (very useful and they work with our data) but nothing for conda. **Setup**. - Operating system: linux. - DeepVariant version: 1.5.0 (latest from conda). - Installation method (Docker, built from source, etc.): conda. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Do you have plans to update conda with the latest deepvariant version? It is still at 1.5.0. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:1077,usability,Error,Error,1077,"Running with Conda; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. This isn't a code problem, but rather a documentation issue. I've run DeepVariant via your docker with success. To integrate it with our project I would like to install it via conda. I was able to do that but it isn't clear how to run deep variant. Do you have documentation/examples of what commands to send? . When using docker, we invoke the google/deepvariant:1.6.1 image and send it the command ""/opt/deepvariant/bin/run_deepvariant"" with appropriate arguments. What do we run when using conda? . Note the docs/deepvariant-quick-start.md has examples for docker (very useful and they work with our data) but nothing for conda. **Setup**. - Operating system: linux. - DeepVariant version: 1.5.0 (latest from conda). - Installation method (Docker, built from source, etc.): conda. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. Do you have plans to update conda with the latest deepvariant version? It is still at 1.5.0. Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/866:0,availability,Checkpoint,Checkpoint,0,"Checkpoint ""Model files do not exist"" when testing custom model; Hello, I trained a customized model, and am now trying to test it. However, when I try to run it, it says that the model files in the checkpoint do not exist. . Here is the command I tried to run: . > module load apptainer. > . > apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant \. > --model_type WGS \. > --customized_model ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902"" \. > --ref ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/Bactrocera_dorsalis_rearing_male_mt_chr_unpl.fasta"" \. > --reads ""${filesdir}_mapped/${sample}.bam"" \. > --output_vcf ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/modeltestout/2fullindividualmodeltest/${sample}.vcf.gz"". Here are the contents of the checkpoints folder for this training: . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jun 29 01:06 .. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:199,availability,checkpoint,checkpoint,199,"Checkpoint ""Model files do not exist"" when testing custom model; Hello, I trained a customized model, and am now trying to test it. However, when I try to run it, it says that the model files in the checkpoint do not exist. . Here is the command I tried to run: . > module load apptainer. > . > apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant \. > --model_type WGS \. > --customized_model ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902"" \. > --ref ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/Bactrocera_dorsalis_rearing_male_mt_chr_unpl.fasta"" \. > --reads ""${filesdir}_mapped/${sample}.bam"" \. > --output_vcf ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/modeltestout/2fullindividualmodeltest/${sample}.vcf.gz"". Here are the contents of the checkpoints folder for this training: . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jun 29 01:06 .. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:535,availability,checkpoint,checkpoints,535,"Checkpoint ""Model files do not exist"" when testing custom model; Hello, I trained a customized model, and am now trying to test it. However, when I try to run it, it says that the model files in the checkpoint do not exist. . Here is the command I tried to run: . > module load apptainer. > . > apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant \. > --model_type WGS \. > --customized_model ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902"" \. > --ref ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/Bactrocera_dorsalis_rearing_male_mt_chr_unpl.fasta"" \. > --reads ""${filesdir}_mapped/${sample}.bam"" \. > --output_vcf ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/modeltestout/2fullindividualmodeltest/${sample}.vcf.gz"". Here are the contents of the checkpoints folder for this training: . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jun 29 01:06 .. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:930,availability,checkpoint,checkpoints,930,"Checkpoint ""Model files do not exist"" when testing custom model; Hello, I trained a customized model, and am now trying to test it. However, when I try to run it, it says that the model files in the checkpoint do not exist. . Here is the command I tried to run: . > module load apptainer. > . > apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant \. > --model_type WGS \. > --customized_model ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902"" \. > --ref ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/Bactrocera_dorsalis_rearing_male_mt_chr_unpl.fasta"" \. > --reads ""${filesdir}_mapped/${sample}.bam"" \. > --output_vcf ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/modeltestout/2fullindividualmodeltest/${sample}.vcf.gz"". Here are the contents of the checkpoints folder for this training: . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jun 29 01:06 .. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:1532,availability,checkpoint,checkpoint,1532,"eckpoints/ckpt-14902"" \. > --ref ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/Bactrocera_dorsalis_rearing_male_mt_chr_unpl.fasta"" \. > --reads ""${filesdir}_mapped/${sample}.bam"" \. > --output_vcf ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/modeltestout/2fullindividualmodeltest/${sample}.vcf.gz"". Here are the contents of the checkpoints folder for this training: . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jun 29 01:06 .. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fingerprint.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:2097,availability,error,error,2097," 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fingerprint.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:2345,availability,operat,operations,2345,"barc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fingerprint.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 572, in create_all_commands_and_logfiles. check_flags(). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 544, in check_flags. raise RuntimeError(. > RuntimeError: The model files /90daydata/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:2413,availability,operat,operations,2413,"roj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fingerprint.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 572, in create_all_commands_and_logfiles. check_flags(). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 544, in check_flags. raise RuntimeError(. > RuntimeError: The model files /90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/ou",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:3458,availability,checkpoint,checkpoints,3458,"nt.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 572, in create_all_commands_and_logfiles. check_flags(). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 544, in check_flags. raise RuntimeError(. > RuntimeError: The model files /90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. Can someone please help me figure out what's going on? The link provided showed a different set of files than the ones I have. Am I missing files? Is something upstream not functioning properly? I have trained models before, with the same kinds out output, and have been able to test them before. What am I missing? . Thank you for your help! Best,. Haley Arnold",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:266,deployability,modul,module,266,"Checkpoint ""Model files do not exist"" when testing custom model; Hello, I trained a customized model, and am now trying to test it. However, when I try to run it, it says that the model files in the checkpoint do not exist. . Here is the command I tried to run: . > module load apptainer. > . > apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant \. > --model_type WGS \. > --customized_model ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902"" \. > --ref ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/Bactrocera_dorsalis_rearing_male_mt_chr_unpl.fasta"" \. > --reads ""${filesdir}_mapped/${sample}.bam"" \. > --output_vcf ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/modeltestout/2fullindividualmodeltest/${sample}.vcf.gz"". Here are the contents of the checkpoints folder for this training: . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jun 29 01:06 .. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:2103,deployability,log,log,2103,"ley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fingerprint.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > File ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:2716,deployability,modul,module,2716,"22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fingerprint.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 572, in create_all_commands_and_logfiles. check_flags(). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 544, in check_flags. raise RuntimeError(. > RuntimeError: The model files /90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. Can someone please help me figure out what's going on? The link provided sho",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:12,energy efficiency,Model,Model,12,"Checkpoint ""Model files do not exist"" when testing custom model; Hello, I trained a customized model, and am now trying to test it. However, when I try to run it, it says that the model files in the checkpoint do not exist. . Here is the command I tried to run: . > module load apptainer. > . > apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant \. > --model_type WGS \. > --customized_model ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902"" \. > --ref ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/Bactrocera_dorsalis_rearing_male_mt_chr_unpl.fasta"" \. > --reads ""${filesdir}_mapped/${sample}.bam"" \. > --output_vcf ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/modeltestout/2fullindividualmodeltest/${sample}.vcf.gz"". Here are the contents of the checkpoints folder for this training: . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jun 29 01:06 .. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:58,energy efficiency,model,model,58,"Checkpoint ""Model files do not exist"" when testing custom model; Hello, I trained a customized model, and am now trying to test it. However, when I try to run it, it says that the model files in the checkpoint do not exist. . Here is the command I tried to run: . > module load apptainer. > . > apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant \. > --model_type WGS \. > --customized_model ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902"" \. > --ref ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/Bactrocera_dorsalis_rearing_male_mt_chr_unpl.fasta"" \. > --reads ""${filesdir}_mapped/${sample}.bam"" \. > --output_vcf ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/modeltestout/2fullindividualmodeltest/${sample}.vcf.gz"". Here are the contents of the checkpoints folder for this training: . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jun 29 01:06 .. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:95,energy efficiency,model,model,95,"Checkpoint ""Model files do not exist"" when testing custom model; Hello, I trained a customized model, and am now trying to test it. However, when I try to run it, it says that the model files in the checkpoint do not exist. . Here is the command I tried to run: . > module load apptainer. > . > apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant \. > --model_type WGS \. > --customized_model ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902"" \. > --ref ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/Bactrocera_dorsalis_rearing_male_mt_chr_unpl.fasta"" \. > --reads ""${filesdir}_mapped/${sample}.bam"" \. > --output_vcf ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/modeltestout/2fullindividualmodeltest/${sample}.vcf.gz"". Here are the contents of the checkpoints folder for this training: . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jun 29 01:06 .. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:180,energy efficiency,model,model,180,"Checkpoint ""Model files do not exist"" when testing custom model; Hello, I trained a customized model, and am now trying to test it. However, when I try to run it, it says that the model files in the checkpoint do not exist. . Here is the command I tried to run: . > module load apptainer. > . > apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant \. > --model_type WGS \. > --customized_model ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902"" \. > --ref ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/Bactrocera_dorsalis_rearing_male_mt_chr_unpl.fasta"" \. > --reads ""${filesdir}_mapped/${sample}.bam"" \. > --output_vcf ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/modeltestout/2fullindividualmodeltest/${sample}.vcf.gz"". Here are the contents of the checkpoints folder for this training: . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jun 29 01:06 .. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:273,energy efficiency,load,load,273,"Checkpoint ""Model files do not exist"" when testing custom model; Hello, I trained a customized model, and am now trying to test it. However, when I try to run it, it says that the model files in the checkpoint do not exist. . Here is the command I tried to run: . > module load apptainer. > . > apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant \. > --model_type WGS \. > --customized_model ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902"" \. > --ref ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/Bactrocera_dorsalis_rearing_male_mt_chr_unpl.fasta"" \. > --reads ""${filesdir}_mapped/${sample}.bam"" \. > --output_vcf ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/modeltestout/2fullindividualmodeltest/${sample}.vcf.gz"". Here are the contents of the checkpoints folder for this training: . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jun 29 01:06 .. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:500,energy efficiency,model,modeltrainout,500,"Checkpoint ""Model files do not exist"" when testing custom model; Hello, I trained a customized model, and am now trying to test it. However, when I try to run it, it says that the model files in the checkpoint do not exist. . Here is the command I tried to run: . > module load apptainer. > . > apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant \. > --model_type WGS \. > --customized_model ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902"" \. > --ref ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/Bactrocera_dorsalis_rearing_male_mt_chr_unpl.fasta"" \. > --reads ""${filesdir}_mapped/${sample}.bam"" \. > --output_vcf ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/modeltestout/2fullindividualmodeltest/${sample}.vcf.gz"". Here are the contents of the checkpoints folder for this training: . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jun 29 01:06 .. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:830,energy efficiency,model,modeltrainout,830,"Checkpoint ""Model files do not exist"" when testing custom model; Hello, I trained a customized model, and am now trying to test it. However, when I try to run it, it says that the model files in the checkpoint do not exist. . Here is the command I tried to run: . > module load apptainer. > . > apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant \. > --model_type WGS \. > --customized_model ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902"" \. > --ref ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/Bactrocera_dorsalis_rearing_male_mt_chr_unpl.fasta"" \. > --reads ""${filesdir}_mapped/${sample}.bam"" \. > --output_vcf ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/modeltestout/2fullindividualmodeltest/${sample}.vcf.gz"". Here are the contents of the checkpoints folder for this training: . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jun 29 01:06 .. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:844,energy efficiency,model,modeltestout,844,"Checkpoint ""Model files do not exist"" when testing custom model; Hello, I trained a customized model, and am now trying to test it. However, when I try to run it, it says that the model files in the checkpoint do not exist. . Here is the command I tried to run: . > module load apptainer. > . > apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant \. > --model_type WGS \. > --customized_model ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902"" \. > --ref ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/Bactrocera_dorsalis_rearing_male_mt_chr_unpl.fasta"" \. > --reads ""${filesdir}_mapped/${sample}.bam"" \. > --output_vcf ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/modeltestout/2fullindividualmodeltest/${sample}.vcf.gz"". Here are the contents of the checkpoints folder for this training: . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jun 29 01:06 .. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:2158,energy efficiency,core,core,2158,"rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fingerprint.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 572, in",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:2224,energy efficiency,optim,optimized,2224,"> -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fingerprint.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 572, in create_all_commands_and_logfiles. check_flags(). > File ""/opt/deepva",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:2304,energy efficiency,CPU,CPU,2304,"of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fingerprint.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 572, in create_all_commands_and_logfiles. check_flags(). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 544, in check_flags. raise RuntimeError(.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:3327,energy efficiency,model,model,3327,"nt.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 572, in create_all_commands_and_logfiles. check_flags(). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 544, in check_flags. raise RuntimeError(. > RuntimeError: The model files /90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. Can someone please help me figure out what's going on? The link provided showed a different set of files than the ones I have. Am I missing files? Is something upstream not functioning properly? I have trained models before, with the same kinds out output, and have been able to test them before. What am I missing? . Thank you for your help! Best,. Haley Arnold",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:3423,energy efficiency,model,modeltrainout,3423,"nt.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 572, in create_all_commands_and_logfiles. check_flags(). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 544, in check_flags. raise RuntimeError(. > RuntimeError: The model files /90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. Can someone please help me figure out what's going on? The link provided showed a different set of files than the ones I have. Am I missing files? Is something upstream not functioning properly? I have trained models before, with the same kinds out output, and have been able to test them before. What am I missing? . Thank you for your help! Best,. Haley Arnold",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:3853,energy efficiency,model,models,3853,"nt.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 572, in create_all_commands_and_logfiles. check_flags(). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 544, in check_flags. raise RuntimeError(. > RuntimeError: The model files /90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. Can someone please help me figure out what's going on? The link provided showed a different set of files than the ones I have. Am I missing files? Is something upstream not functioning properly? I have trained models before, with the same kinds out output, and have been able to test them before. What am I missing? . Thank you for your help! Best,. Haley Arnold",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:2163,interoperability,platform,platform,2163,"-- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fingerprint.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 572, in create",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:266,modifiability,modul,module,266,"Checkpoint ""Model files do not exist"" when testing custom model; Hello, I trained a customized model, and am now trying to test it. However, when I try to run it, it says that the model files in the checkpoint do not exist. . Here is the command I tried to run: . > module load apptainer. > . > apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant \. > --model_type WGS \. > --customized_model ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902"" \. > --ref ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/Bactrocera_dorsalis_rearing_male_mt_chr_unpl.fasta"" \. > --reads ""${filesdir}_mapped/${sample}.bam"" \. > --output_vcf ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/modeltestout/2fullindividualmodeltest/${sample}.vcf.gz"". Here are the contents of the checkpoints folder for this training: . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jun 29 01:06 .. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:1725,modifiability,variab,variables,1725,"> --output_vcf ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/modeltestout/2fullindividualmodeltest/${sample}.vcf.gz"". Here are the contents of the checkpoints folder for this training: . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jun 29 01:06 .. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fingerprint.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:2572,modifiability,interm,intermediate,2572," of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fingerprint.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 572, in create_all_commands_and_logfiles. check_flags(). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 544, in check_flags. raise RuntimeError(. > RuntimeError: The model files /90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.6/docs/F",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:2716,modifiability,modul,module,2716,"22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fingerprint.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 572, in create_all_commands_and_logfiles. check_flags(). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 544, in check_flags. raise RuntimeError(. > RuntimeError: The model files /90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. Can someone please help me figure out what's going on? The link provided sho",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:2778,modifiability,pac,packages,2778,"l 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fingerprint.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 572, in create_all_commands_and_logfiles. check_flags(). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 544, in check_flags. raise RuntimeError(. > RuntimeError: The model files /90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. Can someone please help me figure out what's going on? The link provided showed a different set of files than the ones I have. Am I missing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:2880,modifiability,pac,packages,2880,"ley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fingerprint.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 572, in create_all_commands_and_logfiles. check_flags(). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 544, in check_flags. raise RuntimeError(. > RuntimeError: The model files /90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. Can someone please help me figure out what's going on? The link provided showed a different set of files than the ones I have. Am I missing files? Is something upstream not functioning properly? I have trained models before, with the same ki",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:273,performance,load,load,273,"Checkpoint ""Model files do not exist"" when testing custom model; Hello, I trained a customized model, and am now trying to test it. However, when I try to run it, it says that the model files in the checkpoint do not exist. . Here is the command I tried to run: . > module load apptainer. > . > apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant \. > --model_type WGS \. > --customized_model ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902"" \. > --ref ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/Bactrocera_dorsalis_rearing_male_mt_chr_unpl.fasta"" \. > --reads ""${filesdir}_mapped/${sample}.bam"" \. > --output_vcf ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/modeltestout/2fullindividualmodeltest/${sample}.vcf.gz"". Here are the contents of the checkpoints folder for this training: . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jun 29 01:06 .. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:914,performance,content,contents,914,"Checkpoint ""Model files do not exist"" when testing custom model; Hello, I trained a customized model, and am now trying to test it. However, when I try to run it, it says that the model files in the checkpoint do not exist. . Here is the command I tried to run: . > module load apptainer. > . > apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant \. > --model_type WGS \. > --customized_model ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902"" \. > --ref ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/Bactrocera_dorsalis_rearing_male_mt_chr_unpl.fasta"" \. > --reads ""${filesdir}_mapped/${sample}.bam"" \. > --output_vcf ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/modeltestout/2fullindividualmodeltest/${sample}.vcf.gz"". Here are the contents of the checkpoints folder for this training: . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jun 29 01:06 .. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:1570,performance,content,contents,1570,"daydata/pbarc/haley.arnold/AI_Model_Training/Samples/Bactrocera_dorsalis_rearing_male_mt_chr_unpl.fasta"" \. > --reads ""${filesdir}_mapped/${sample}.bam"" \. > --output_vcf ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/modeltestout/2fullindividualmodeltest/${sample}.vcf.gz"". Here are the contents of the checkpoints folder for this training: . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jun 29 01:06 .. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fingerprint.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for in",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:2097,performance,error,error,2097," 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fingerprint.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:2224,performance,optimiz,optimized,2224,"> -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fingerprint.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 572, in create_all_commands_and_logfiles. check_flags(). > File ""/opt/deepva",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:2258,performance,Network,Network,2258,"pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fingerprint.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 572, in create_all_commands_and_logfiles. check_flags(). > File ""/opt/deepvariant/bin/run_deepvariant.py"", li",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:2304,performance,CPU,CPU,2304,"of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fingerprint.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 572, in create_all_commands_and_logfiles. check_flags(). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 544, in check_flags. raise RuntimeError(.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:2324,performance,perform,performance-critical,2324,"ey.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fingerprint.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 572, in create_all_commands_and_logfiles. check_flags(). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 544, in check_flags. raise RuntimeError(. > RuntimeError: The model f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:0,reliability,Checkpoint,Checkpoint,0,"Checkpoint ""Model files do not exist"" when testing custom model; Hello, I trained a customized model, and am now trying to test it. However, when I try to run it, it says that the model files in the checkpoint do not exist. . Here is the command I tried to run: . > module load apptainer. > . > apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant \. > --model_type WGS \. > --customized_model ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902"" \. > --ref ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/Bactrocera_dorsalis_rearing_male_mt_chr_unpl.fasta"" \. > --reads ""${filesdir}_mapped/${sample}.bam"" \. > --output_vcf ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/modeltestout/2fullindividualmodeltest/${sample}.vcf.gz"". Here are the contents of the checkpoints folder for this training: . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jun 29 01:06 .. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:199,reliability,checkpoint,checkpoint,199,"Checkpoint ""Model files do not exist"" when testing custom model; Hello, I trained a customized model, and am now trying to test it. However, when I try to run it, it says that the model files in the checkpoint do not exist. . Here is the command I tried to run: . > module load apptainer. > . > apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant \. > --model_type WGS \. > --customized_model ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902"" \. > --ref ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/Bactrocera_dorsalis_rearing_male_mt_chr_unpl.fasta"" \. > --reads ""${filesdir}_mapped/${sample}.bam"" \. > --output_vcf ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/modeltestout/2fullindividualmodeltest/${sample}.vcf.gz"". Here are the contents of the checkpoints folder for this training: . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jun 29 01:06 .. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:535,reliability,checkpoint,checkpoints,535,"Checkpoint ""Model files do not exist"" when testing custom model; Hello, I trained a customized model, and am now trying to test it. However, when I try to run it, it says that the model files in the checkpoint do not exist. . Here is the command I tried to run: . > module load apptainer. > . > apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant \. > --model_type WGS \. > --customized_model ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902"" \. > --ref ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/Bactrocera_dorsalis_rearing_male_mt_chr_unpl.fasta"" \. > --reads ""${filesdir}_mapped/${sample}.bam"" \. > --output_vcf ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/modeltestout/2fullindividualmodeltest/${sample}.vcf.gz"". Here are the contents of the checkpoints folder for this training: . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jun 29 01:06 .. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:930,reliability,checkpoint,checkpoints,930,"Checkpoint ""Model files do not exist"" when testing custom model; Hello, I trained a customized model, and am now trying to test it. However, when I try to run it, it says that the model files in the checkpoint do not exist. . Here is the command I tried to run: . > module load apptainer. > . > apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant \. > --model_type WGS \. > --customized_model ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902"" \. > --ref ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/Bactrocera_dorsalis_rearing_male_mt_chr_unpl.fasta"" \. > --reads ""${filesdir}_mapped/${sample}.bam"" \. > --output_vcf ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/modeltestout/2fullindividualmodeltest/${sample}.vcf.gz"". Here are the contents of the checkpoints folder for this training: . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jun 29 01:06 .. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:1532,reliability,checkpoint,checkpoint,1532,"eckpoints/ckpt-14902"" \. > --ref ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/Bactrocera_dorsalis_rearing_male_mt_chr_unpl.fasta"" \. > --reads ""${filesdir}_mapped/${sample}.bam"" \. > --output_vcf ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/modeltestout/2fullindividualmodeltest/${sample}.vcf.gz"". Here are the contents of the checkpoints folder for this training: . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jun 29 01:06 .. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fingerprint.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:3458,reliability,checkpoint,checkpoints,3458,"nt.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 572, in create_all_commands_and_logfiles. check_flags(). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 544, in check_flags. raise RuntimeError(. > RuntimeError: The model files /90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. Can someone please help me figure out what's going on? The link provided showed a different set of files than the ones I have. Am I missing files? Is something upstream not functioning properly? I have trained models before, with the same kinds out output, and have been able to test them before. What am I missing? . Thank you for your help! Best,. Haley Arnold",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:43,safety,test,testing,43,"Checkpoint ""Model files do not exist"" when testing custom model; Hello, I trained a customized model, and am now trying to test it. However, when I try to run it, it says that the model files in the checkpoint do not exist. . Here is the command I tried to run: . > module load apptainer. > . > apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant \. > --model_type WGS \. > --customized_model ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902"" \. > --ref ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/Bactrocera_dorsalis_rearing_male_mt_chr_unpl.fasta"" \. > --reads ""${filesdir}_mapped/${sample}.bam"" \. > --output_vcf ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/modeltestout/2fullindividualmodeltest/${sample}.vcf.gz"". Here are the contents of the checkpoints folder for this training: . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jun 29 01:06 .. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:123,safety,test,test,123,"Checkpoint ""Model files do not exist"" when testing custom model; Hello, I trained a customized model, and am now trying to test it. However, when I try to run it, it says that the model files in the checkpoint do not exist. . Here is the command I tried to run: . > module load apptainer. > . > apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant \. > --model_type WGS \. > --customized_model ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902"" \. > --ref ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/Bactrocera_dorsalis_rearing_male_mt_chr_unpl.fasta"" \. > --reads ""${filesdir}_mapped/${sample}.bam"" \. > --output_vcf ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/modeltestout/2fullindividualmodeltest/${sample}.vcf.gz"". Here are the contents of the checkpoints folder for this training: . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jun 29 01:06 .. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:266,safety,modul,module,266,"Checkpoint ""Model files do not exist"" when testing custom model; Hello, I trained a customized model, and am now trying to test it. However, when I try to run it, it says that the model files in the checkpoint do not exist. . Here is the command I tried to run: . > module load apptainer. > . > apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant \. > --model_type WGS \. > --customized_model ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902"" \. > --ref ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/Bactrocera_dorsalis_rearing_male_mt_chr_unpl.fasta"" \. > --reads ""${filesdir}_mapped/${sample}.bam"" \. > --output_vcf ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/modeltestout/2fullindividualmodeltest/${sample}.vcf.gz"". Here are the contents of the checkpoints folder for this training: . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jun 29 01:06 .. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:2097,safety,error,error,2097," 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fingerprint.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:2103,safety,log,log,2103,"ley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fingerprint.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > File ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:2716,safety,modul,module,2716,"22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fingerprint.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 572, in create_all_commands_and_logfiles. check_flags(). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 544, in check_flags. raise RuntimeError(. > RuntimeError: The model files /90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. Can someone please help me figure out what's going on? The link provided sho",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:3612,safety,input,input-files-eg-could-not-open,3612,"nt.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 572, in create_all_commands_and_logfiles. check_flags(). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 544, in check_flags. raise RuntimeError(. > RuntimeError: The model files /90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. Can someone please help me figure out what's going on? The link provided showed a different set of files than the ones I have. Am I missing files? Is something upstream not functioning properly? I have trained models before, with the same kinds out output, and have been able to test them before. What am I missing? . Thank you for your help! Best,. Haley Arnold",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:3922,safety,test,test,3922,"nt.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 572, in create_all_commands_and_logfiles. check_flags(). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 544, in check_flags. raise RuntimeError(. > RuntimeError: The model files /90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. Can someone please help me figure out what's going on? The link provided showed a different set of files than the ones I have. Am I missing files? Is something upstream not functioning properly? I have trained models before, with the same kinds out output, and have been able to test them before. What am I missing? . Thank you for your help! Best,. Haley Arnold",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:12,security,Model,Model,12,"Checkpoint ""Model files do not exist"" when testing custom model; Hello, I trained a customized model, and am now trying to test it. However, when I try to run it, it says that the model files in the checkpoint do not exist. . Here is the command I tried to run: . > module load apptainer. > . > apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant \. > --model_type WGS \. > --customized_model ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902"" \. > --ref ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/Bactrocera_dorsalis_rearing_male_mt_chr_unpl.fasta"" \. > --reads ""${filesdir}_mapped/${sample}.bam"" \. > --output_vcf ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/modeltestout/2fullindividualmodeltest/${sample}.vcf.gz"". Here are the contents of the checkpoints folder for this training: . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jun 29 01:06 .. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:58,security,model,model,58,"Checkpoint ""Model files do not exist"" when testing custom model; Hello, I trained a customized model, and am now trying to test it. However, when I try to run it, it says that the model files in the checkpoint do not exist. . Here is the command I tried to run: . > module load apptainer. > . > apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant \. > --model_type WGS \. > --customized_model ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902"" \. > --ref ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/Bactrocera_dorsalis_rearing_male_mt_chr_unpl.fasta"" \. > --reads ""${filesdir}_mapped/${sample}.bam"" \. > --output_vcf ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/modeltestout/2fullindividualmodeltest/${sample}.vcf.gz"". Here are the contents of the checkpoints folder for this training: . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jun 29 01:06 .. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:95,security,model,model,95,"Checkpoint ""Model files do not exist"" when testing custom model; Hello, I trained a customized model, and am now trying to test it. However, when I try to run it, it says that the model files in the checkpoint do not exist. . Here is the command I tried to run: . > module load apptainer. > . > apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant \. > --model_type WGS \. > --customized_model ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902"" \. > --ref ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/Bactrocera_dorsalis_rearing_male_mt_chr_unpl.fasta"" \. > --reads ""${filesdir}_mapped/${sample}.bam"" \. > --output_vcf ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/modeltestout/2fullindividualmodeltest/${sample}.vcf.gz"". Here are the contents of the checkpoints folder for this training: . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jun 29 01:06 .. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:180,security,model,model,180,"Checkpoint ""Model files do not exist"" when testing custom model; Hello, I trained a customized model, and am now trying to test it. However, when I try to run it, it says that the model files in the checkpoint do not exist. . Here is the command I tried to run: . > module load apptainer. > . > apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant \. > --model_type WGS \. > --customized_model ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902"" \. > --ref ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/Bactrocera_dorsalis_rearing_male_mt_chr_unpl.fasta"" \. > --reads ""${filesdir}_mapped/${sample}.bam"" \. > --output_vcf ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/modeltestout/2fullindividualmodeltest/${sample}.vcf.gz"". Here are the contents of the checkpoints folder for this training: . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jun 29 01:06 .. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:500,security,model,modeltrainout,500,"Checkpoint ""Model files do not exist"" when testing custom model; Hello, I trained a customized model, and am now trying to test it. However, when I try to run it, it says that the model files in the checkpoint do not exist. . Here is the command I tried to run: . > module load apptainer. > . > apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant \. > --model_type WGS \. > --customized_model ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902"" \. > --ref ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/Bactrocera_dorsalis_rearing_male_mt_chr_unpl.fasta"" \. > --reads ""${filesdir}_mapped/${sample}.bam"" \. > --output_vcf ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/modeltestout/2fullindividualmodeltest/${sample}.vcf.gz"". Here are the contents of the checkpoints folder for this training: . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jun 29 01:06 .. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:830,security,model,modeltrainout,830,"Checkpoint ""Model files do not exist"" when testing custom model; Hello, I trained a customized model, and am now trying to test it. However, when I try to run it, it says that the model files in the checkpoint do not exist. . Here is the command I tried to run: . > module load apptainer. > . > apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant \. > --model_type WGS \. > --customized_model ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902"" \. > --ref ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/Bactrocera_dorsalis_rearing_male_mt_chr_unpl.fasta"" \. > --reads ""${filesdir}_mapped/${sample}.bam"" \. > --output_vcf ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/modeltestout/2fullindividualmodeltest/${sample}.vcf.gz"". Here are the contents of the checkpoints folder for this training: . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jun 29 01:06 .. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:844,security,model,modeltestout,844,"Checkpoint ""Model files do not exist"" when testing custom model; Hello, I trained a customized model, and am now trying to test it. However, when I try to run it, it says that the model files in the checkpoint do not exist. . Here is the command I tried to run: . > module load apptainer. > . > apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant \. > --model_type WGS \. > --customized_model ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902"" \. > --ref ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/Bactrocera_dorsalis_rearing_male_mt_chr_unpl.fasta"" \. > --reads ""${filesdir}_mapped/${sample}.bam"" \. > --output_vcf ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/modeltestout/2fullindividualmodeltest/${sample}.vcf.gz"". Here are the contents of the checkpoints folder for this training: . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jun 29 01:06 .. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:2103,security,log,log,2103,"ley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fingerprint.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > File ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:2258,security,Network,Network,2258,"pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fingerprint.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 572, in create_all_commands_and_logfiles. check_flags(). > File ""/opt/deepvariant/bin/run_deepvariant.py"", li",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:3327,security,model,model,3327,"nt.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 572, in create_all_commands_and_logfiles. check_flags(). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 544, in check_flags. raise RuntimeError(. > RuntimeError: The model files /90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. Can someone please help me figure out what's going on? The link provided showed a different set of files than the ones I have. Am I missing files? Is something upstream not functioning properly? I have trained models before, with the same kinds out output, and have been able to test them before. What am I missing? . Thank you for your help! Best,. Haley Arnold",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:3423,security,model,modeltrainout,3423,"nt.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 572, in create_all_commands_and_logfiles. check_flags(). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 544, in check_flags. raise RuntimeError(. > RuntimeError: The model files /90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. Can someone please help me figure out what's going on? The link provided showed a different set of files than the ones I have. Am I missing files? Is something upstream not functioning properly? I have trained models before, with the same kinds out output, and have been able to test them before. What am I missing? . Thank you for your help! Best,. Haley Arnold",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:3853,security,model,models,3853,"nt.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 572, in create_all_commands_and_logfiles. check_flags(). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 544, in check_flags. raise RuntimeError(. > RuntimeError: The model files /90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. Can someone please help me figure out what's going on? The link provided showed a different set of files than the ones I have. Am I missing files? Is something upstream not functioning properly? I have trained models before, with the same kinds out output, and have been able to test them before. What am I missing? . Thank you for your help! Best,. Haley Arnold",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:43,testability,test,testing,43,"Checkpoint ""Model files do not exist"" when testing custom model; Hello, I trained a customized model, and am now trying to test it. However, when I try to run it, it says that the model files in the checkpoint do not exist. . Here is the command I tried to run: . > module load apptainer. > . > apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant \. > --model_type WGS \. > --customized_model ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902"" \. > --ref ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/Bactrocera_dorsalis_rearing_male_mt_chr_unpl.fasta"" \. > --reads ""${filesdir}_mapped/${sample}.bam"" \. > --output_vcf ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/modeltestout/2fullindividualmodeltest/${sample}.vcf.gz"". Here are the contents of the checkpoints folder for this training: . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jun 29 01:06 .. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:123,testability,test,test,123,"Checkpoint ""Model files do not exist"" when testing custom model; Hello, I trained a customized model, and am now trying to test it. However, when I try to run it, it says that the model files in the checkpoint do not exist. . Here is the command I tried to run: . > module load apptainer. > . > apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant \. > --model_type WGS \. > --customized_model ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902"" \. > --ref ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/Bactrocera_dorsalis_rearing_male_mt_chr_unpl.fasta"" \. > --reads ""${filesdir}_mapped/${sample}.bam"" \. > --output_vcf ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/modeltestout/2fullindividualmodeltest/${sample}.vcf.gz"". Here are the contents of the checkpoints folder for this training: . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jun 29 01:06 .. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:2103,testability,log,log,2103,"ley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fingerprint.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > File ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:2616,testability,Trace,Traceback,2616,"- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fingerprint.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 572, in create_all_commands_and_logfiles. check_flags(). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 544, in check_flags. raise RuntimeError(. > RuntimeError: The model files /90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#why-cant-it-find-one-of-the-input-fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:3922,testability,test,test,3922,"nt.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 572, in create_all_commands_and_logfiles. check_flags(). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 544, in check_flags. raise RuntimeError(. > RuntimeError: The model files /90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. Can someone please help me figure out what's going on? The link provided showed a different set of files than the ones I have. Am I missing files? Is something upstream not functioning properly? I have trained models before, with the same kinds out output, and have been able to test them before. What am I missing? . Thank you for your help! Best,. Haley Arnold",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:51,usability,custom,custom,51,"Checkpoint ""Model files do not exist"" when testing custom model; Hello, I trained a customized model, and am now trying to test it. However, when I try to run it, it says that the model files in the checkpoint do not exist. . Here is the command I tried to run: . > module load apptainer. > . > apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant \. > --model_type WGS \. > --customized_model ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902"" \. > --ref ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/Bactrocera_dorsalis_rearing_male_mt_chr_unpl.fasta"" \. > --reads ""${filesdir}_mapped/${sample}.bam"" \. > --output_vcf ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/modeltestout/2fullindividualmodeltest/${sample}.vcf.gz"". Here are the contents of the checkpoints folder for this training: . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jun 29 01:06 .. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:84,usability,custom,customized,84,"Checkpoint ""Model files do not exist"" when testing custom model; Hello, I trained a customized model, and am now trying to test it. However, when I try to run it, it says that the model files in the checkpoint do not exist. . Here is the command I tried to run: . > module load apptainer. > . > apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant \. > --model_type WGS \. > --customized_model ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902"" \. > --ref ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/Bactrocera_dorsalis_rearing_male_mt_chr_unpl.fasta"" \. > --reads ""${filesdir}_mapped/${sample}.bam"" \. > --output_vcf ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/modeltestout/2fullindividualmodeltest/${sample}.vcf.gz"". Here are the contents of the checkpoints folder for this training: . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jun 29 01:06 .. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:238,usability,command,command,238,"Checkpoint ""Model files do not exist"" when testing custom model; Hello, I trained a customized model, and am now trying to test it. However, when I try to run it, it says that the model files in the checkpoint do not exist. . Here is the command I tried to run: . > module load apptainer. > . > apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/run_deepvariant \. > --model_type WGS \. > --customized_model ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902"" \. > --ref ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/Bactrocera_dorsalis_rearing_male_mt_chr_unpl.fasta"" \. > --reads ""${filesdir}_mapped/${sample}.bam"" \. > --output_vcf ""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/modeltestout/2fullindividualmodeltest/${sample}.vcf.gz"". Here are the contents of the checkpoints folder for this training: . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jun 29 01:06 .. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 . > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:2097,usability,error,error,2097," 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 ckpt-14902. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-7451.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-7451.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fingerprint.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:2324,usability,perform,performance-critical,2324,"ey.arnold proj-pbarc 54K Aug 6 22:51 ckpt-14902.index. > -rw-r----- 1 haley.arnold proj-pbarc 250M Aug 6 22:51 ckpt-14902.data-00000-of-00001. > -rw-r----- 1 haley.arnold proj-pbarc 266 Aug 6 22:51 checkpoint. and finally, here are the contents of ckpt-14902: . > total 7.6M. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 1 22:49 .. > drwxr-s--- 2 haley.arnold proj-pbarc 4.0K Jul 1 22:49 variables. > drwxr-s--- 3 haley.arnold proj-pbarc 4.0K Jul 21 23:11 . > -rw-r----- 1 haley.arnold proj-pbarc 6.9M Aug 6 22:51 saved_model.pb. > -rw-r----- 1 haley.arnold proj-pbarc 677K Aug 6 22:51 keras_metadata.pb. > -rw-r----- 1 haley.arnold proj-pbarc 55 Aug 6 22:51 fingerprint.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 572, in create_all_commands_and_logfiles. check_flags(). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 544, in check_flags. raise RuntimeError(. > RuntimeError: The model f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:3612,usability,input,input-files-eg-could-not-open,3612,"nt.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 572, in create_all_commands_and_logfiles. check_flags(). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 544, in check_flags. raise RuntimeError(. > RuntimeError: The model files /90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. Can someone please help me figure out what's going on? The link provided showed a different set of files than the ones I have. Am I missing files? Is something upstream not functioning properly? I have trained models before, with the same kinds out output, and have been able to test them before. What am I missing? . Thank you for your help! Best,. Haley Arnold",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:3662,usability,help,help,3662,"nt.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 572, in create_all_commands_and_logfiles. check_flags(). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 544, in check_flags. raise RuntimeError(. > RuntimeError: The model files /90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. Can someone please help me figure out what's going on? The link provided showed a different set of files than the ones I have. Am I missing files? Is something upstream not functioning properly? I have trained models before, with the same kinds out output, and have been able to test them before. What am I missing? . Thank you for your help! Best,. Haley Arnold",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:3980,usability,help,help,3980,"nt.pb. > -rw-r----- 1 haley.arnold proj-pbarc 80 Aug 6 22:51 example_info.json. Here is the error log file: . > 2024-08-09 20:05:25.101938: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. > To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. > I0809 20:05:40.093672 139993880950592 run_deepvariant.py:519] Re-using the directory for intermediate results in /tmp/tmp4wzl_5p3. > Traceback (most recent call last):. > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 722, in <module>. app.run(main). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). > File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 693, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 572, in create_all_commands_and_logfiles. check_flags(). > File ""/opt/deepvariant/bin/run_deepvariant.py"", line 544, in check_flags. raise RuntimeError(. > RuntimeError: The model files /90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.6/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. Can someone please help me figure out what's going on? The link provided showed a different set of files than the ones I have. Am I missing files? Is something upstream not functioning properly? I have trained models before, with the same kinds out output, and have been able to test them before. What am I missing? . Thank you for your help! Best,. Haley Arnold",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/867:758,availability,cluster,clusterbasics,758,"make_examples_core.py gets stuck on STAR aligned rnaseq BAM (deepvariant 1.6.1); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am running deepvariant 1.6.1 through singularity (apptainer) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 secon",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:942,availability,echo,echo,942,"make_examples_core.py gets stuck on STAR aligned rnaseq BAM (deepvariant 1.6.1); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am running deepvariant 1.6.1 through singularity (apptainer) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 secon",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:5777,availability,Operat,Operating,5777,"ith --ref. I0812 17:25:09.205637 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.119529 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.163989 140700470552384 make_examples_core.py:301] Task 15/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00015-of-00032.gz. I0812 17:25:10.169354 140700470552384 make_examples_core.py:301] Task 15/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecord-00015-of-00032.gz. I0812 17:25:10.170929 140700470552384 make_examples_core.py:301] Task 15/32: Overhead for preparing inputs: 281 seconds. I0812 17:25:10.353756 140700470552384 make_examples_core.py:301] Task 15/32: 0 candidates (0 examples) [0.18s elapsed]. '. While RNAseq data is expected to be sparsely mapped onto the genome, wouldn't deepvariant focus on the regions specified by the bed file? I'm a bit surprised that 0 examples were made. Is it possible that the reads do not map with high enough MAPQ in these regions? But I'm still not sure why make_samples get stuck though. **Setup**. - Operating system: Ubuntu server 22.04. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity (docker image). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). RNAseq data NCBI SRA SRR18493715, ref genome (produced by ourself, but can probably be replaced by another version https://www.ncbi.nlm.nih.gov/datasets/genome/GCA_025200525.1/ ). **Steps to reproduce:**. - Map reads with STAR, use samtools index to index the BAM. - run the above deepvariant command.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:527,deployability,contain,containing,527,"make_examples_core.py gets stuck on STAR aligned rnaseq BAM (deepvariant 1.6.1); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am running deepvariant 1.6.1 through singularity (apptainer) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 secon",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:717,deployability,modul,module,717,"make_examples_core.py gets stuck on STAR aligned rnaseq BAM (deepvariant 1.6.1); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am running deepvariant 1.6.1 through singularity (apptainer) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 secon",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:746,deployability,modul,module,746,"make_examples_core.py gets stuck on STAR aligned rnaseq BAM (deepvariant 1.6.1); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am running deepvariant 1.6.1 through singularity (apptainer) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 secon",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:758,deployability,cluster,clusterbasics,758,"make_examples_core.py gets stuck on STAR aligned rnaseq BAM (deepvariant 1.6.1); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am running deepvariant 1.6.1 through singularity (apptainer) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 secon",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:773,deployability,modul,module,773,"make_examples_core.py gets stuck on STAR aligned rnaseq BAM (deepvariant 1.6.1); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am running deepvariant 1.6.1 through singularity (apptainer) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 secon",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:795,deployability,modul,module,795,"make_examples_core.py gets stuck on STAR aligned rnaseq BAM (deepvariant 1.6.1); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am running deepvariant 1.6.1 through singularity (apptainer) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 secon",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:1032,deployability,log,log,1032,"n STAR aligned rnaseq BAM (deepvariant 1.6.1); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am running deepvariant 1.6.1 through singularity (apptainer) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 seconds. I0812 17:25:00.763086 13968250",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:1722,deployability,log,log,1722,"load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 seconds. I0812 17:25:00.763086 139682501986112 make_examples_core.py:301] Task 14/32: 0 candidates (0 examples) [0.06s elapsed]. I0812 17:25:01.273164 139627217889088 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:01.308415 139627217889088 make_examples_core.py:301] Task 18/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00018-of-00032.gz. I0812 17:25:01.325705 139627217889088 make_examples_core.py:301] Task 18/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvaria",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:1762,deployability,log,log,1762,"rbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 seconds. I0812 17:25:00.763086 139682501986112 make_examples_core.py:301] Task 14/32: 0 candidates (0 examples) [0.06s elapsed]. I0812 17:25:01.273164 139627217889088 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:01.308415 139627217889088 make_examples_core.py:301] Task 18/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00018-of-00032.gz. I0812 17:25:01.325705 139627217889088 make_examples_core.py:301] Task 18/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:5830,deployability,version,version,5830,"ith --ref. I0812 17:25:09.205637 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.119529 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.163989 140700470552384 make_examples_core.py:301] Task 15/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00015-of-00032.gz. I0812 17:25:10.169354 140700470552384 make_examples_core.py:301] Task 15/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecord-00015-of-00032.gz. I0812 17:25:10.170929 140700470552384 make_examples_core.py:301] Task 15/32: Overhead for preparing inputs: 281 seconds. I0812 17:25:10.353756 140700470552384 make_examples_core.py:301] Task 15/32: 0 candidates (0 examples) [0.18s elapsed]. '. While RNAseq data is expected to be sparsely mapped onto the genome, wouldn't deepvariant focus on the regions specified by the bed file? I'm a bit surprised that 0 examples were made. Is it possible that the reads do not map with high enough MAPQ in these regions? But I'm still not sure why make_samples get stuck though. **Setup**. - Operating system: Ubuntu server 22.04. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity (docker image). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). RNAseq data NCBI SRA SRR18493715, ref genome (produced by ourself, but can probably be replaced by another version https://www.ncbi.nlm.nih.gov/datasets/genome/GCA_025200525.1/ ). **Steps to reproduce:**. - Map reads with STAR, use samtools index to index the BAM. - run the above deepvariant command.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:5848,deployability,Instal,Installation,5848,"ith --ref. I0812 17:25:09.205637 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.119529 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.163989 140700470552384 make_examples_core.py:301] Task 15/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00015-of-00032.gz. I0812 17:25:10.169354 140700470552384 make_examples_core.py:301] Task 15/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecord-00015-of-00032.gz. I0812 17:25:10.170929 140700470552384 make_examples_core.py:301] Task 15/32: Overhead for preparing inputs: 281 seconds. I0812 17:25:10.353756 140700470552384 make_examples_core.py:301] Task 15/32: 0 candidates (0 examples) [0.18s elapsed]. '. While RNAseq data is expected to be sparsely mapped onto the genome, wouldn't deepvariant focus on the regions specified by the bed file? I'm a bit surprised that 0 examples were made. Is it possible that the reads do not map with high enough MAPQ in these regions? But I'm still not sure why make_samples get stuck though. **Setup**. - Operating system: Ubuntu server 22.04. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity (docker image). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). RNAseq data NCBI SRA SRR18493715, ref genome (produced by ourself, but can probably be replaced by another version https://www.ncbi.nlm.nih.gov/datasets/genome/GCA_025200525.1/ ). **Steps to reproduce:**. - Map reads with STAR, use samtools index to index the BAM. - run the above deepvariant command.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:6148,deployability,version,version,6148,"ith --ref. I0812 17:25:09.205637 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.119529 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.163989 140700470552384 make_examples_core.py:301] Task 15/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00015-of-00032.gz. I0812 17:25:10.169354 140700470552384 make_examples_core.py:301] Task 15/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecord-00015-of-00032.gz. I0812 17:25:10.170929 140700470552384 make_examples_core.py:301] Task 15/32: Overhead for preparing inputs: 281 seconds. I0812 17:25:10.353756 140700470552384 make_examples_core.py:301] Task 15/32: 0 candidates (0 examples) [0.18s elapsed]. '. While RNAseq data is expected to be sparsely mapped onto the genome, wouldn't deepvariant focus on the regions specified by the bed file? I'm a bit surprised that 0 examples were made. Is it possible that the reads do not map with high enough MAPQ in these regions? But I'm still not sure why make_samples get stuck though. **Setup**. - Operating system: Ubuntu server 22.04. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity (docker image). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). RNAseq data NCBI SRA SRR18493715, ref genome (produced by ourself, but can probably be replaced by another version https://www.ncbi.nlm.nih.gov/datasets/genome/GCA_025200525.1/ ). **Steps to reproduce:**. - Map reads with STAR, use samtools index to index the BAM. - run the above deepvariant command.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:464,energy efficiency,model,model,464,"make_examples_core.py gets stuck on STAR aligned rnaseq BAM (deepvariant 1.6.1); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am running deepvariant 1.6.1 through singularity (apptainer) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 secon",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:493,energy efficiency,model,model,493,"make_examples_core.py gets stuck on STAR aligned rnaseq BAM (deepvariant 1.6.1); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am running deepvariant 1.6.1 through singularity (apptainer) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 secon",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:686,energy efficiency,CPU,CPU,686,"make_examples_core.py gets stuck on STAR aligned rnaseq BAM (deepvariant 1.6.1); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am running deepvariant 1.6.1 through singularity (apptainer) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 secon",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:704,energy efficiency,CPU,CPUs,704,"make_examples_core.py gets stuck on STAR aligned rnaseq BAM (deepvariant 1.6.1); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am running deepvariant 1.6.1 through singularity (apptainer) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 secon",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:724,energy efficiency,load,load,724,"make_examples_core.py gets stuck on STAR aligned rnaseq BAM (deepvariant 1.6.1); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am running deepvariant 1.6.1 through singularity (apptainer) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 secon",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:753,energy efficiency,load,load,753,"make_examples_core.py gets stuck on STAR aligned rnaseq BAM (deepvariant 1.6.1); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am running deepvariant 1.6.1 through singularity (apptainer) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 secon",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:780,energy efficiency,load,load,780,"make_examples_core.py gets stuck on STAR aligned rnaseq BAM (deepvariant 1.6.1); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am running deepvariant 1.6.1 through singularity (apptainer) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 secon",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:802,energy efficiency,load,load,802,"make_examples_core.py gets stuck on STAR aligned rnaseq BAM (deepvariant 1.6.1); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am running deepvariant 1.6.1 through singularity (apptainer) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 secon",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:1377,energy efficiency,cpu,cpuver,1377,"NAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 seconds. I0812 17:25:00.763086 139682501986112 make_examples_core.py:301] Task 14/32: 0 candidates (0 examples) [0.06s elapsed]. I0812 17:25:01.273164 139627217889088 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:01.308415 139627217889088 make_examples_core.py:301] Task 18/3",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:1699,energy efficiency,CPU,CPU,1699,"of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 seconds. I0812 17:25:00.763086 139682501986112 make_examples_core.py:301] Task 14/32: 0 candidates (0 examples) [0.06s elapsed]. I0812 17:25:01.273164 139627217889088 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:01.308415 139627217889088 make_examples_core.py:301] Task 18/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00018-of-00032.gz. I0812 17:25:01.325705 139627217889088 make_examples_core.py:301] Task 18/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:1255,integrability,pub,public,1255,"ner) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 seconds. I0812 17:25:00.763086 139682501986112 make_examples_core.py:301] Task 14/32: 0 candidates (0 examples) [0.06s elapsed]. I0812 17:25:01.273164 139627217889088 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Alig",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:1263,integrability,pub,public,1263,"both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 seconds. I0812 17:25:00.763086 139682501986112 make_examples_core.py:301] Task 14/32: 0 candidates (0 examples) [0.06s elapsed]. I0812 17:25:01.273164 139627217889088 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sort",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:5830,integrability,version,version,5830,"ith --ref. I0812 17:25:09.205637 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.119529 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.163989 140700470552384 make_examples_core.py:301] Task 15/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00015-of-00032.gz. I0812 17:25:10.169354 140700470552384 make_examples_core.py:301] Task 15/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecord-00015-of-00032.gz. I0812 17:25:10.170929 140700470552384 make_examples_core.py:301] Task 15/32: Overhead for preparing inputs: 281 seconds. I0812 17:25:10.353756 140700470552384 make_examples_core.py:301] Task 15/32: 0 candidates (0 examples) [0.18s elapsed]. '. While RNAseq data is expected to be sparsely mapped onto the genome, wouldn't deepvariant focus on the regions specified by the bed file? I'm a bit surprised that 0 examples were made. Is it possible that the reads do not map with high enough MAPQ in these regions? But I'm still not sure why make_samples get stuck though. **Setup**. - Operating system: Ubuntu server 22.04. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity (docker image). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). RNAseq data NCBI SRA SRR18493715, ref genome (produced by ourself, but can probably be replaced by another version https://www.ncbi.nlm.nih.gov/datasets/genome/GCA_025200525.1/ ). **Steps to reproduce:**. - Map reads with STAR, use samtools index to index the BAM. - run the above deepvariant command.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:6148,integrability,version,version,6148,"ith --ref. I0812 17:25:09.205637 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.119529 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.163989 140700470552384 make_examples_core.py:301] Task 15/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00015-of-00032.gz. I0812 17:25:10.169354 140700470552384 make_examples_core.py:301] Task 15/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecord-00015-of-00032.gz. I0812 17:25:10.170929 140700470552384 make_examples_core.py:301] Task 15/32: Overhead for preparing inputs: 281 seconds. I0812 17:25:10.353756 140700470552384 make_examples_core.py:301] Task 15/32: 0 candidates (0 examples) [0.18s elapsed]. '. While RNAseq data is expected to be sparsely mapped onto the genome, wouldn't deepvariant focus on the regions specified by the bed file? I'm a bit surprised that 0 examples were made. Is it possible that the reads do not map with high enough MAPQ in these regions? But I'm still not sure why make_samples get stuck though. **Setup**. - Operating system: Ubuntu server 22.04. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity (docker image). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). RNAseq data NCBI SRA SRR18493715, ref genome (produced by ourself, but can probably be replaced by another version https://www.ncbi.nlm.nih.gov/datasets/genome/GCA_025200525.1/ ). **Steps to reproduce:**. - Map reads with STAR, use samtools index to index the BAM. - run the above deepvariant command.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:2431,interoperability,share,shareddata,2431,"epvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 seconds. I0812 17:25:00.763086 139682501986112 make_examples_core.py:301] Task 14/32: 0 candidates (0 examples) [0.06s elapsed]. I0812 17:25:01.273164 139627217889088 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:01.308415 139627217889088 make_examples_core.py:301] Task 18/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00018-of-00032.gz. I0812 17:25:01.325705 139627217889088 make_examples_core.py:301] Task 18/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecord-00018-of-00032.gz. I0812 17:25:01.326699 139627217889088 make_examples_core.py:301] Task 18/32: Overhead for preparing inputs: 274 seconds. I0812 17:25:01.388018 139627217889088 make_examples_core.py:301] Task 18/32: 0 candidates (0 examples) [0.06s elapsed]. I0812 17:25:00.904305 140574087989056 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:02.391861 140574087989056 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:02.424664 140574087989056 make_exa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:2664,interoperability,share,shareddata,2664,"}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 seconds. I0812 17:25:00.763086 139682501986112 make_examples_core.py:301] Task 14/32: 0 candidates (0 examples) [0.06s elapsed]. I0812 17:25:01.273164 139627217889088 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:01.308415 139627217889088 make_examples_core.py:301] Task 18/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00018-of-00032.gz. I0812 17:25:01.325705 139627217889088 make_examples_core.py:301] Task 18/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecord-00018-of-00032.gz. I0812 17:25:01.326699 139627217889088 make_examples_core.py:301] Task 18/32: Overhead for preparing inputs: 274 seconds. I0812 17:25:01.388018 139627217889088 make_examples_core.py:301] Task 18/32: 0 candidates (0 examples) [0.06s elapsed]. I0812 17:25:00.904305 140574087989056 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:02.391861 140574087989056 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:02.424664 140574087989056 make_examples_core.py:301] Task 17/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00017-of-00032.gz. I0812 17:25:02.457828 140574087989056 make",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:3515,interoperability,share,shareddata,3515,"ord-00018-of-00032.gz. I0812 17:25:01.325705 139627217889088 make_examples_core.py:301] Task 18/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecord-00018-of-00032.gz. I0812 17:25:01.326699 139627217889088 make_examples_core.py:301] Task 18/32: Overhead for preparing inputs: 274 seconds. I0812 17:25:01.388018 139627217889088 make_examples_core.py:301] Task 18/32: 0 candidates (0 examples) [0.06s elapsed]. I0812 17:25:00.904305 140574087989056 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:02.391861 140574087989056 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:02.424664 140574087989056 make_examples_core.py:301] Task 17/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00017-of-00032.gz. I0812 17:25:02.457828 140574087989056 make_examples_core.py:301] Task 17/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecord-00017-of-00032.gz. I0812 17:25:02.458879 140574087989056 make_examples_core.py:301] Task 17/32: Overhead for preparing inputs: 271 seconds. I0812 17:25:02.603747 140574087989056 make_examples_core.py:301] Task 17/32: 0 candidates (0 examples) [0.14s elapsed]. I0812 17:25:08.541687 140700470552384 make_examples_core.py:301] Task 15/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0812 17:25:09.205637 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with Na",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:3748,interoperability,share,shareddata,3748,"les.tfrecord-00018-of-00032.gz. I0812 17:25:01.326699 139627217889088 make_examples_core.py:301] Task 18/32: Overhead for preparing inputs: 274 seconds. I0812 17:25:01.388018 139627217889088 make_examples_core.py:301] Task 18/32: 0 candidates (0 examples) [0.06s elapsed]. I0812 17:25:00.904305 140574087989056 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:02.391861 140574087989056 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:02.424664 140574087989056 make_examples_core.py:301] Task 17/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00017-of-00032.gz. I0812 17:25:02.457828 140574087989056 make_examples_core.py:301] Task 17/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecord-00017-of-00032.gz. I0812 17:25:02.458879 140574087989056 make_examples_core.py:301] Task 17/32: Overhead for preparing inputs: 271 seconds. I0812 17:25:02.603747 140574087989056 make_examples_core.py:301] Task 17/32: 0 candidates (0 examples) [0.14s elapsed]. I0812 17:25:08.541687 140700470552384 make_examples_core.py:301] Task 15/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0812 17:25:09.205637 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.119529 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.163989 14070047055238",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:4842,interoperability,share,shareddata,4842,"rd-00017-of-00032.gz. I0812 17:25:02.458879 140574087989056 make_examples_core.py:301] Task 17/32: Overhead for preparing inputs: 271 seconds. I0812 17:25:02.603747 140574087989056 make_examples_core.py:301] Task 17/32: 0 candidates (0 examples) [0.14s elapsed]. I0812 17:25:08.541687 140700470552384 make_examples_core.py:301] Task 15/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0812 17:25:09.205637 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.119529 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.163989 140700470552384 make_examples_core.py:301] Task 15/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00015-of-00032.gz. I0812 17:25:10.169354 140700470552384 make_examples_core.py:301] Task 15/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecord-00015-of-00032.gz. I0812 17:25:10.170929 140700470552384 make_examples_core.py:301] Task 15/32: Overhead for preparing inputs: 281 seconds. I0812 17:25:10.353756 140700470552384 make_examples_core.py:301] Task 15/32: 0 candidates (0 examples) [0.18s elapsed]. '. While RNAseq data is expected to be sparsely mapped onto the genome, wouldn't deepvariant focus on the regions specified by the bed file? I'm a bit surprised that 0 examples were made. Is it possible that the reads do not map with high enough MAPQ in these regions? But I'm still not sure why make_samples get stuck though. **Setup**. - Operating system: Ubuntu server 22.04. - DeepVariant version: 1.6.1. -",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:5075,interoperability,share,shareddata,5075,"(0 examples) [0.14s elapsed]. I0812 17:25:08.541687 140700470552384 make_examples_core.py:301] Task 15/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0812 17:25:09.205637 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.119529 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.163989 140700470552384 make_examples_core.py:301] Task 15/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00015-of-00032.gz. I0812 17:25:10.169354 140700470552384 make_examples_core.py:301] Task 15/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecord-00015-of-00032.gz. I0812 17:25:10.170929 140700470552384 make_examples_core.py:301] Task 15/32: Overhead for preparing inputs: 281 seconds. I0812 17:25:10.353756 140700470552384 make_examples_core.py:301] Task 15/32: 0 candidates (0 examples) [0.18s elapsed]. '. While RNAseq data is expected to be sparsely mapped onto the genome, wouldn't deepvariant focus on the regions specified by the bed file? I'm a bit surprised that 0 examples were made. Is it possible that the reads do not map with high enough MAPQ in these regions? But I'm still not sure why make_samples get stuck though. **Setup**. - Operating system: Ubuntu server 22.04. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity (docker image). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). RNAseq data NCBI SRA SRR18493715, ref g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:5551,interoperability,specif,specified,5551,"ith --ref. I0812 17:25:09.205637 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.119529 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.163989 140700470552384 make_examples_core.py:301] Task 15/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00015-of-00032.gz. I0812 17:25:10.169354 140700470552384 make_examples_core.py:301] Task 15/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecord-00015-of-00032.gz. I0812 17:25:10.170929 140700470552384 make_examples_core.py:301] Task 15/32: Overhead for preparing inputs: 281 seconds. I0812 17:25:10.353756 140700470552384 make_examples_core.py:301] Task 15/32: 0 candidates (0 examples) [0.18s elapsed]. '. While RNAseq data is expected to be sparsely mapped onto the genome, wouldn't deepvariant focus on the regions specified by the bed file? I'm a bit surprised that 0 examples were made. Is it possible that the reads do not map with high enough MAPQ in these regions? But I'm still not sure why make_samples get stuck though. **Setup**. - Operating system: Ubuntu server 22.04. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity (docker image). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). RNAseq data NCBI SRA SRR18493715, ref genome (produced by ourself, but can probably be replaced by another version https://www.ncbi.nlm.nih.gov/datasets/genome/GCA_025200525.1/ ). **Steps to reproduce:**. - Map reads with STAR, use samtools index to index the BAM. - run the above deepvariant command.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:717,modifiability,modul,module,717,"make_examples_core.py gets stuck on STAR aligned rnaseq BAM (deepvariant 1.6.1); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am running deepvariant 1.6.1 through singularity (apptainer) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 secon",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:746,modifiability,modul,module,746,"make_examples_core.py gets stuck on STAR aligned rnaseq BAM (deepvariant 1.6.1); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am running deepvariant 1.6.1 through singularity (apptainer) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 secon",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:773,modifiability,modul,module,773,"make_examples_core.py gets stuck on STAR aligned rnaseq BAM (deepvariant 1.6.1); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am running deepvariant 1.6.1 through singularity (apptainer) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 secon",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:795,modifiability,modul,module,795,"make_examples_core.py gets stuck on STAR aligned rnaseq BAM (deepvariant 1.6.1); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am running deepvariant 1.6.1 through singularity (apptainer) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 secon",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:4295,modifiability,deco,decode,4295,"5.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:02.424664 140574087989056 make_examples_core.py:301] Task 17/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00017-of-00032.gz. I0812 17:25:02.457828 140574087989056 make_examples_core.py:301] Task 17/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecord-00017-of-00032.gz. I0812 17:25:02.458879 140574087989056 make_examples_core.py:301] Task 17/32: Overhead for preparing inputs: 271 seconds. I0812 17:25:02.603747 140574087989056 make_examples_core.py:301] Task 17/32: 0 candidates (0 examples) [0.14s elapsed]. I0812 17:25:08.541687 140700470552384 make_examples_core.py:301] Task 15/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0812 17:25:09.205637 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.119529 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.163989 140700470552384 make_examples_core.py:301] Task 15/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00015-of-00032.gz. I0812 17:25:10.169354 140700470552384 make_examples_core.py:301] Task 15/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecord-00015-of-00032.gz. I0812 17:25:10.170929 140700470552384 make_examples_core.py:301] Task 15/32: Overhead for preparing in",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:5830,modifiability,version,version,5830,"ith --ref. I0812 17:25:09.205637 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.119529 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.163989 140700470552384 make_examples_core.py:301] Task 15/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00015-of-00032.gz. I0812 17:25:10.169354 140700470552384 make_examples_core.py:301] Task 15/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecord-00015-of-00032.gz. I0812 17:25:10.170929 140700470552384 make_examples_core.py:301] Task 15/32: Overhead for preparing inputs: 281 seconds. I0812 17:25:10.353756 140700470552384 make_examples_core.py:301] Task 15/32: 0 candidates (0 examples) [0.18s elapsed]. '. While RNAseq data is expected to be sparsely mapped onto the genome, wouldn't deepvariant focus on the regions specified by the bed file? I'm a bit surprised that 0 examples were made. Is it possible that the reads do not map with high enough MAPQ in these regions? But I'm still not sure why make_samples get stuck though. **Setup**. - Operating system: Ubuntu server 22.04. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity (docker image). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). RNAseq data NCBI SRA SRR18493715, ref genome (produced by ourself, but can probably be replaced by another version https://www.ncbi.nlm.nih.gov/datasets/genome/GCA_025200525.1/ ). **Steps to reproduce:**. - Map reads with STAR, use samtools index to index the BAM. - run the above deepvariant command.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:6148,modifiability,version,version,6148,"ith --ref. I0812 17:25:09.205637 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.119529 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.163989 140700470552384 make_examples_core.py:301] Task 15/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00015-of-00032.gz. I0812 17:25:10.169354 140700470552384 make_examples_core.py:301] Task 15/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecord-00015-of-00032.gz. I0812 17:25:10.170929 140700470552384 make_examples_core.py:301] Task 15/32: Overhead for preparing inputs: 281 seconds. I0812 17:25:10.353756 140700470552384 make_examples_core.py:301] Task 15/32: 0 candidates (0 examples) [0.18s elapsed]. '. While RNAseq data is expected to be sparsely mapped onto the genome, wouldn't deepvariant focus on the regions specified by the bed file? I'm a bit surprised that 0 examples were made. Is it possible that the reads do not map with high enough MAPQ in these regions? But I'm still not sure why make_samples get stuck though. **Setup**. - Operating system: Ubuntu server 22.04. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity (docker image). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). RNAseq data NCBI SRA SRR18493715, ref genome (produced by ourself, but can probably be replaced by another version https://www.ncbi.nlm.nih.gov/datasets/genome/GCA_025200525.1/ ). **Steps to reproduce:**. - Map reads with STAR, use samtools index to index the BAM. - run the above deepvariant command.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:686,performance,CPU,CPU,686,"make_examples_core.py gets stuck on STAR aligned rnaseq BAM (deepvariant 1.6.1); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am running deepvariant 1.6.1 through singularity (apptainer) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 secon",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:704,performance,CPU,CPUs,704,"make_examples_core.py gets stuck on STAR aligned rnaseq BAM (deepvariant 1.6.1); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am running deepvariant 1.6.1 through singularity (apptainer) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 secon",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:724,performance,load,load,724,"make_examples_core.py gets stuck on STAR aligned rnaseq BAM (deepvariant 1.6.1); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am running deepvariant 1.6.1 through singularity (apptainer) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 secon",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:753,performance,load,load,753,"make_examples_core.py gets stuck on STAR aligned rnaseq BAM (deepvariant 1.6.1); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am running deepvariant 1.6.1 through singularity (apptainer) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 secon",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:780,performance,load,load,780,"make_examples_core.py gets stuck on STAR aligned rnaseq BAM (deepvariant 1.6.1); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am running deepvariant 1.6.1 through singularity (apptainer) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 secon",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:802,performance,load,load,802,"make_examples_core.py gets stuck on STAR aligned rnaseq BAM (deepvariant 1.6.1); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am running deepvariant 1.6.1 through singularity (apptainer) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 secon",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:1377,performance,cpu,cpuver,1377,"NAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 seconds. I0812 17:25:00.763086 139682501986112 make_examples_core.py:301] Task 14/32: 0 candidates (0 examples) [0.06s elapsed]. I0812 17:25:01.273164 139627217889088 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:01.308415 139627217889088 make_examples_core.py:301] Task 18/3",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:1699,performance,CPU,CPU,1699,"of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 seconds. I0812 17:25:00.763086 139682501986112 make_examples_core.py:301] Task 14/32: 0 candidates (0 examples) [0.06s elapsed]. I0812 17:25:01.273164 139627217889088 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:01.308415 139627217889088 make_examples_core.py:301] Task 18/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00018-of-00032.gz. I0812 17:25:01.325705 139627217889088 make_examples_core.py:301] Task 18/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:1960,performance,Overhead,Overhead,1960,"ex for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 seconds. I0812 17:25:00.763086 139682501986112 make_examples_core.py:301] Task 14/32: 0 candidates (0 examples) [0.06s elapsed]. I0812 17:25:01.273164 139627217889088 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:01.308415 139627217889088 make_examples_core.py:301] Task 18/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00018-of-00032.gz. I0812 17:25:01.325705 139627217889088 make_examples_core.py:301] Task 18/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecord-00018-of-00032.gz. I0812 17:25:01.326699 139627217889088 make_examples_core.py:301] Task 18/32: Overhead for preparing inputs: 274 seconds. I0812 17:25:01.388018 139627217889088 make_examples_core.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:2862,performance,Overhead,Overhead,2862,ng 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 seconds. I0812 17:25:00.763086 139682501986112 make_examples_core.py:301] Task 14/32: 0 candidates (0 examples) [0.06s elapsed]. I0812 17:25:01.273164 139627217889088 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:01.308415 139627217889088 make_examples_core.py:301] Task 18/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00018-of-00032.gz. I0812 17:25:01.325705 139627217889088 make_examples_core.py:301] Task 18/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecord-00018-of-00032.gz. I0812 17:25:01.326699 139627217889088 make_examples_core.py:301] Task 18/32: Overhead for preparing inputs: 274 seconds. I0812 17:25:01.388018 139627217889088 make_examples_core.py:301] Task 18/32: 0 candidates (0 examples) [0.06s elapsed]. I0812 17:25:00.904305 140574087989056 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:02.391861 140574087989056 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:02.424664 140574087989056 make_examples_core.py:301] Task 17/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00017-of-00032.gz. I0812 17:25:02.457828 140574087989056 make_examples_core.py:301] Task 17/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecord-00017-of-00032.g,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:3946,performance,Overhead,Overhead,3946,"xamples_core.py:301] Task 18/32: 0 candidates (0 examples) [0.06s elapsed]. I0812 17:25:00.904305 140574087989056 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:02.391861 140574087989056 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:02.424664 140574087989056 make_examples_core.py:301] Task 17/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00017-of-00032.gz. I0812 17:25:02.457828 140574087989056 make_examples_core.py:301] Task 17/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecord-00017-of-00032.gz. I0812 17:25:02.458879 140574087989056 make_examples_core.py:301] Task 17/32: Overhead for preparing inputs: 271 seconds. I0812 17:25:02.603747 140574087989056 make_examples_core.py:301] Task 17/32: 0 candidates (0 examples) [0.14s elapsed]. I0812 17:25:08.541687 140700470552384 make_examples_core.py:301] Task 15/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0812 17:25:09.205637 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.119529 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.163989 140700470552384 make_examples_core.py:301] Task 15/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00015-of-00032.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:5273,performance,Overhead,Overhead,5273,"note that we will decode CRAM using the reference you passed in with --ref. I0812 17:25:09.205637 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.119529 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.163989 140700470552384 make_examples_core.py:301] Task 15/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00015-of-00032.gz. I0812 17:25:10.169354 140700470552384 make_examples_core.py:301] Task 15/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecord-00015-of-00032.gz. I0812 17:25:10.170929 140700470552384 make_examples_core.py:301] Task 15/32: Overhead for preparing inputs: 281 seconds. I0812 17:25:10.353756 140700470552384 make_examples_core.py:301] Task 15/32: 0 candidates (0 examples) [0.18s elapsed]. '. While RNAseq data is expected to be sparsely mapped onto the genome, wouldn't deepvariant focus on the regions specified by the bed file? I'm a bit surprised that 0 examples were made. Is it possible that the reads do not map with high enough MAPQ in these regions? But I'm still not sure why make_samples get stuck though. **Setup**. - Operating system: Ubuntu server 22.04. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity (docker image). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). RNAseq data NCBI SRA SRR18493715, ref genome (produced by ourself, but can probably be replaced by another version https://www.ncbi.nlm.nih.gov/datasets/genome/GCA_025200525.1/ ). **Steps to reproduce:**. - Map reads with STAR, use samt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:437,reliability,doe,does,437,"make_examples_core.py gets stuck on STAR aligned rnaseq BAM (deepvariant 1.6.1); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am running deepvariant 1.6.1 through singularity (apptainer) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 secon",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:717,safety,modul,module,717,"make_examples_core.py gets stuck on STAR aligned rnaseq BAM (deepvariant 1.6.1); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am running deepvariant 1.6.1 through singularity (apptainer) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 secon",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:746,safety,modul,module,746,"make_examples_core.py gets stuck on STAR aligned rnaseq BAM (deepvariant 1.6.1); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am running deepvariant 1.6.1 through singularity (apptainer) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 secon",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:773,safety,modul,module,773,"make_examples_core.py gets stuck on STAR aligned rnaseq BAM (deepvariant 1.6.1); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am running deepvariant 1.6.1 through singularity (apptainer) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 secon",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:795,safety,modul,module,795,"make_examples_core.py gets stuck on STAR aligned rnaseq BAM (deepvariant 1.6.1); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am running deepvariant 1.6.1 through singularity (apptainer) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 secon",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:1032,safety,log,log,1032,"n STAR aligned rnaseq BAM (deepvariant 1.6.1); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am running deepvariant 1.6.1 through singularity (apptainer) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 seconds. I0812 17:25:00.763086 13968250",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:1722,safety,log,log,1722,"load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 seconds. I0812 17:25:00.763086 139682501986112 make_examples_core.py:301] Task 14/32: 0 candidates (0 examples) [0.06s elapsed]. I0812 17:25:01.273164 139627217889088 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:01.308415 139627217889088 make_examples_core.py:301] Task 18/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00018-of-00032.gz. I0812 17:25:01.325705 139627217889088 make_examples_core.py:301] Task 18/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvaria",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:1762,safety,log,log,1762,"rbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 seconds. I0812 17:25:00.763086 139682501986112 make_examples_core.py:301] Task 14/32: 0 candidates (0 examples) [0.06s elapsed]. I0812 17:25:01.273164 139627217889088 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:01.308415 139627217889088 make_examples_core.py:301] Task 18/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00018-of-00032.gz. I0812 17:25:01.325705 139627217889088 make_examples_core.py:301] Task 18/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:1983,safety,input,inputs,1983," index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 seconds. I0812 17:25:00.763086 139682501986112 make_examples_core.py:301] Task 14/32: 0 candidates (0 examples) [0.06s elapsed]. I0812 17:25:01.273164 139627217889088 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:01.308415 139627217889088 make_examples_core.py:301] Task 18/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00018-of-00032.gz. I0812 17:25:01.325705 139627217889088 make_examples_core.py:301] Task 18/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecord-00018-of-00032.gz. I0812 17:25:01.326699 139627217889088 make_examples_core.py:301] Task 18/32: Overhead for preparing inputs: 274 seconds. I0812 17:25:01.388018 139627217889088 make_examples_core.py:301] Task 18/32: 0 c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:2885,safety,input,inputs,2885, 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 seconds. I0812 17:25:00.763086 139682501986112 make_examples_core.py:301] Task 14/32: 0 candidates (0 examples) [0.06s elapsed]. I0812 17:25:01.273164 139627217889088 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:01.308415 139627217889088 make_examples_core.py:301] Task 18/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00018-of-00032.gz. I0812 17:25:01.325705 139627217889088 make_examples_core.py:301] Task 18/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecord-00018-of-00032.gz. I0812 17:25:01.326699 139627217889088 make_examples_core.py:301] Task 18/32: Overhead for preparing inputs: 274 seconds. I0812 17:25:01.388018 139627217889088 make_examples_core.py:301] Task 18/32: 0 candidates (0 examples) [0.06s elapsed]. I0812 17:25:00.904305 140574087989056 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:02.391861 140574087989056 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:02.424664 140574087989056 make_examples_core.py:301] Task 17/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00017-of-00032.gz. I0812 17:25:02.457828 140574087989056 make_examples_core.py:301] Task 17/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecord-00017-of-00032.gz. I0812 17:25:02.4588,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:3969,safety,input,inputs,3969,"ask 18/32: 0 candidates (0 examples) [0.06s elapsed]. I0812 17:25:00.904305 140574087989056 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:02.391861 140574087989056 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:02.424664 140574087989056 make_examples_core.py:301] Task 17/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00017-of-00032.gz. I0812 17:25:02.457828 140574087989056 make_examples_core.py:301] Task 17/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecord-00017-of-00032.gz. I0812 17:25:02.458879 140574087989056 make_examples_core.py:301] Task 17/32: Overhead for preparing inputs: 271 seconds. I0812 17:25:02.603747 140574087989056 make_examples_core.py:301] Task 17/32: 0 candidates (0 examples) [0.14s elapsed]. I0812 17:25:08.541687 140700470552384 make_examples_core.py:301] Task 15/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0812 17:25:09.205637 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.119529 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.163989 140700470552384 make_examples_core.py:301] Task 15/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00015-of-00032.gz. I0812 17:25:10.169",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:4270,safety,input,input,4270,"ding ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:02.424664 140574087989056 make_examples_core.py:301] Task 17/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00017-of-00032.gz. I0812 17:25:02.457828 140574087989056 make_examples_core.py:301] Task 17/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecord-00017-of-00032.gz. I0812 17:25:02.458879 140574087989056 make_examples_core.py:301] Task 17/32: Overhead for preparing inputs: 271 seconds. I0812 17:25:02.603747 140574087989056 make_examples_core.py:301] Task 17/32: 0 candidates (0 examples) [0.14s elapsed]. I0812 17:25:08.541687 140700470552384 make_examples_core.py:301] Task 15/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0812 17:25:09.205637 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.119529 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.163989 140700470552384 make_examples_core.py:301] Task 15/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00015-of-00032.gz. I0812 17:25:10.169354 140700470552384 make_examples_core.py:301] Task 15/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecord-00015-of-00032.gz. I0812 17:25:10.170929 140700470552384 make_examples_core.py:301] Task 15/32: ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:5296,safety,input,inputs,5296,"de CRAM using the reference you passed in with --ref. I0812 17:25:09.205637 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.119529 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.163989 140700470552384 make_examples_core.py:301] Task 15/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00015-of-00032.gz. I0812 17:25:10.169354 140700470552384 make_examples_core.py:301] Task 15/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecord-00015-of-00032.gz. I0812 17:25:10.170929 140700470552384 make_examples_core.py:301] Task 15/32: Overhead for preparing inputs: 281 seconds. I0812 17:25:10.353756 140700470552384 make_examples_core.py:301] Task 15/32: 0 candidates (0 examples) [0.18s elapsed]. '. While RNAseq data is expected to be sparsely mapped onto the genome, wouldn't deepvariant focus on the regions specified by the bed file? I'm a bit surprised that 0 examples were made. Is it possible that the reads do not map with high enough MAPQ in these regions? But I'm still not sure why make_samples get stuck though. **Setup**. - Operating system: Ubuntu server 22.04. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity (docker image). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). RNAseq data NCBI SRA SRR18493715, ref genome (produced by ourself, but can probably be replaced by another version https://www.ncbi.nlm.nih.gov/datasets/genome/GCA_025200525.1/ ). **Steps to reproduce:**. - Map reads with STAR, use samtools index to index th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:464,security,model,model,464,"make_examples_core.py gets stuck on STAR aligned rnaseq BAM (deepvariant 1.6.1); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am running deepvariant 1.6.1 through singularity (apptainer) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 secon",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:493,security,model,model,493,"make_examples_core.py gets stuck on STAR aligned rnaseq BAM (deepvariant 1.6.1); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am running deepvariant 1.6.1 through singularity (apptainer) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 secon",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:1032,security,log,log,1032,"n STAR aligned rnaseq BAM (deepvariant 1.6.1); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am running deepvariant 1.6.1 through singularity (apptainer) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 seconds. I0812 17:25:00.763086 13968250",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:1722,security,log,log,1722,"load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 seconds. I0812 17:25:00.763086 139682501986112 make_examples_core.py:301] Task 14/32: 0 candidates (0 examples) [0.06s elapsed]. I0812 17:25:01.273164 139627217889088 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:01.308415 139627217889088 make_examples_core.py:301] Task 18/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00018-of-00032.gz. I0812 17:25:01.325705 139627217889088 make_examples_core.py:301] Task 18/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvaria",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:1762,security,log,log,1762,"rbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 seconds. I0812 17:25:00.763086 139682501986112 make_examples_core.py:301] Task 14/32: 0 candidates (0 examples) [0.06s elapsed]. I0812 17:25:01.273164 139627217889088 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:01.308415 139627217889088 make_examples_core.py:301] Task 18/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00018-of-00032.gz. I0812 17:25:01.325705 139627217889088 make_examples_core.py:301] Task 18/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:1032,testability,log,log,1032,"n STAR aligned rnaseq BAM (deepvariant 1.6.1); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am running deepvariant 1.6.1 through singularity (apptainer) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 seconds. I0812 17:25:00.763086 13968250",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:1054,testability,coverag,coverage,1054,"M (deepvariant 1.6.1); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am running deepvariant 1.6.1 through singularity (apptainer) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 seconds. I0812 17:25:00.763086 139682501986112 make_examples_co",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:1722,testability,log,log,1722,"load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 seconds. I0812 17:25:00.763086 139682501986112 make_examples_core.py:301] Task 14/32: 0 candidates (0 examples) [0.06s elapsed]. I0812 17:25:01.273164 139627217889088 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:01.308415 139627217889088 make_examples_core.py:301] Task 18/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00018-of-00032.gz. I0812 17:25:01.325705 139627217889088 make_examples_core.py:301] Task 18/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvaria",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:1762,testability,log,log,1762,"rbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 seconds. I0812 17:25:00.763086 139682501986112 make_examples_core.py:301] Task 14/32: 0 candidates (0 examples) [0.06s elapsed]. I0812 17:25:01.273164 139627217889088 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:01.308415 139627217889088 make_examples_core.py:301] Task 18/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00018-of-00032.gz. I0812 17:25:01.325705 139627217889088 make_examples_core.py:301] Task 18/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:5959,testability,instrument,instrument,5959,"ith --ref. I0812 17:25:09.205637 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.119529 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.163989 140700470552384 make_examples_core.py:301] Task 15/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00015-of-00032.gz. I0812 17:25:10.169354 140700470552384 make_examples_core.py:301] Task 15/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecord-00015-of-00032.gz. I0812 17:25:10.170929 140700470552384 make_examples_core.py:301] Task 15/32: Overhead for preparing inputs: 281 seconds. I0812 17:25:10.353756 140700470552384 make_examples_core.py:301] Task 15/32: 0 candidates (0 examples) [0.18s elapsed]. '. While RNAseq data is expected to be sparsely mapped onto the genome, wouldn't deepvariant focus on the regions specified by the bed file? I'm a bit surprised that 0 examples were made. Is it possible that the reads do not map with high enough MAPQ in these regions? But I'm still not sure why make_samples get stuck though. **Setup**. - Operating system: Ubuntu server 22.04. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity (docker image). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). RNAseq data NCBI SRA SRR18493715, ref genome (produced by ourself, but can probably be replaced by another version https://www.ncbi.nlm.nih.gov/datasets/genome/GCA_025200525.1/ ). **Steps to reproduce:**. - Map reads with STAR, use samtools index to index the BAM. - run the above deepvariant command.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:446,usability,support,support,446,"make_examples_core.py gets stuck on STAR aligned rnaseq BAM (deepvariant 1.6.1); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. I am running deepvariant 1.6.1 through singularity (apptainer) on both WGS and RNAseq bams. The WGS bam was much larger in file size, but was processed much more quickly than the RNAseq bams produced by STAR. . Because deepvariant 1.6.1 does not support an rnaseq model, so I just ran the WES model on it, providing a BED file containing all regions with at least 3X read depth. Here is the script I used:. `sID=$1 #sample ID. sBAM=$2 #full path to BAM. REF=$3 #full path to fasta ref. CPU=$4 #number of CPUs to use. module load apptainer/1.2.5. module load clusterbasics. module load samtools. module load bedtools. OUTPUT_DIR=./output/$sID. mkdir -p $OUTPUT_DIR. mkdir -p ./tmp. export TMPDIR=`realpath ./tmp`. if [ ! -f $sBAM.bai ]; then. echo producing bai index for $sBAM. samtools index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 secon",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:1983,usability,input,inputs,1983," index $sBAM. fi. if [ ! -f ""${OUTPUT_DIR}/dv.log"" ];then. bedtools coverage -g genome.file -sorted -d -a genome.bed -b ""$sBAM"" | awk '{if ($5>=3) print $1""\t""($4-1)""\t""$4""\t""$5}' | bedtools merge -d 1 -c 4 -o mean -i - > ${OUTPUT_DIR}/cov3x.bed. fi. apptainer run -B /public:/public,/public3:/public3,/public2:/public2,/fast3:/fast3,/public4:/public4 \. /public4/software/deepvariant/1.6.1/cpuver/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --make_examples_extra_args=""normalize_reads=true"" \. --model_type=WES \. --ref=$REF \. --reads=""$sBAM"" \. --output_vcf=${OUTPUT_DIR}/output.vcf.gz \. --output_gvcf=${OUTPUT_DIR}/output.g.vcf.gz \. --regions=""${OUTPUT_DIR}/cov3x.bed"" \. --num_shards=$CPU > ${OUTPUT_DIR}/dv.log 2>&1. `. Inspecting the tail of the log, it appears that the program gets stuck at the make_examples step, with many threads reporting finding 0 examples:. 'I0812 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 seconds. I0812 17:25:00.763086 139682501986112 make_examples_core.py:301] Task 14/32: 0 candidates (0 examples) [0.06s elapsed]. I0812 17:25:01.273164 139627217889088 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:01.308415 139627217889088 make_examples_core.py:301] Task 18/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00018-of-00032.gz. I0812 17:25:01.325705 139627217889088 make_examples_core.py:301] Task 18/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecord-00018-of-00032.gz. I0812 17:25:01.326699 139627217889088 make_examples_core.py:301] Task 18/32: Overhead for preparing inputs: 274 seconds. I0812 17:25:01.388018 139627217889088 make_examples_core.py:301] Task 18/32: 0 c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:2885,usability,input,inputs,2885, 17:25:00.705988 139682501986112 make_examples_core.py:301] Task 14/32: Overhead for preparing inputs: 270 seconds. I0812 17:25:00.763086 139682501986112 make_examples_core.py:301] Task 14/32: 0 candidates (0 examples) [0.06s elapsed]. I0812 17:25:01.273164 139627217889088 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:01.308415 139627217889088 make_examples_core.py:301] Task 18/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00018-of-00032.gz. I0812 17:25:01.325705 139627217889088 make_examples_core.py:301] Task 18/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecord-00018-of-00032.gz. I0812 17:25:01.326699 139627217889088 make_examples_core.py:301] Task 18/32: Overhead for preparing inputs: 274 seconds. I0812 17:25:01.388018 139627217889088 make_examples_core.py:301] Task 18/32: 0 candidates (0 examples) [0.06s elapsed]. I0812 17:25:00.904305 140574087989056 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:02.391861 140574087989056 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:02.424664 140574087989056 make_examples_core.py:301] Task 17/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00017-of-00032.gz. I0812 17:25:02.457828 140574087989056 make_examples_core.py:301] Task 17/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecord-00017-of-00032.gz. I0812 17:25:02.4588,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:3969,usability,input,inputs,3969,"ask 18/32: 0 candidates (0 examples) [0.06s elapsed]. I0812 17:25:00.904305 140574087989056 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:02.391861 140574087989056 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:02.424664 140574087989056 make_examples_core.py:301] Task 17/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00017-of-00032.gz. I0812 17:25:02.457828 140574087989056 make_examples_core.py:301] Task 17/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecord-00017-of-00032.gz. I0812 17:25:02.458879 140574087989056 make_examples_core.py:301] Task 17/32: Overhead for preparing inputs: 271 seconds. I0812 17:25:02.603747 140574087989056 make_examples_core.py:301] Task 17/32: 0 candidates (0 examples) [0.14s elapsed]. I0812 17:25:08.541687 140700470552384 make_examples_core.py:301] Task 15/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0812 17:25:09.205637 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.119529 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.163989 140700470552384 make_examples_core.py:301] Task 15/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00015-of-00032.gz. I0812 17:25:10.169",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:4270,usability,input,input,4270,"ding ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:02.424664 140574087989056 make_examples_core.py:301] Task 17/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00017-of-00032.gz. I0812 17:25:02.457828 140574087989056 make_examples_core.py:301] Task 17/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecord-00017-of-00032.gz. I0812 17:25:02.458879 140574087989056 make_examples_core.py:301] Task 17/32: Overhead for preparing inputs: 271 seconds. I0812 17:25:02.603747 140574087989056 make_examples_core.py:301] Task 17/32: 0 candidates (0 examples) [0.14s elapsed]. I0812 17:25:08.541687 140700470552384 make_examples_core.py:301] Task 15/32: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. I0812 17:25:09.205637 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.119529 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.163989 140700470552384 make_examples_core.py:301] Task 15/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00015-of-00032.gz. I0812 17:25:10.169354 140700470552384 make_examples_core.py:301] Task 15/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecord-00015-of-00032.gz. I0812 17:25:10.170929 140700470552384 make_examples_core.py:301] Task 15/32: ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:5296,usability,input,inputs,5296,"de CRAM using the reference you passed in with --ref. I0812 17:25:09.205637 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.119529 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.163989 140700470552384 make_examples_core.py:301] Task 15/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00015-of-00032.gz. I0812 17:25:10.169354 140700470552384 make_examples_core.py:301] Task 15/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecord-00015-of-00032.gz. I0812 17:25:10.170929 140700470552384 make_examples_core.py:301] Task 15/32: Overhead for preparing inputs: 281 seconds. I0812 17:25:10.353756 140700470552384 make_examples_core.py:301] Task 15/32: 0 candidates (0 examples) [0.18s elapsed]. '. While RNAseq data is expected to be sparsely mapped onto the genome, wouldn't deepvariant focus on the regions specified by the bed file? I'm a bit surprised that 0 examples were made. Is it possible that the reads do not map with high enough MAPQ in these regions? But I'm still not sure why make_samples get stuck though. **Setup**. - Operating system: Ubuntu server 22.04. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity (docker image). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). RNAseq data NCBI SRA SRR18493715, ref genome (produced by ourself, but can probably be replaced by another version https://www.ncbi.nlm.nih.gov/datasets/genome/GCA_025200525.1/ ). **Steps to reproduce:**. - Map reads with STAR, use samtools index to index th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:6334,usability,command,command,6334,"ith --ref. I0812 17:25:09.205637 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.119529 140700470552384 genomics_reader.py:222] Reading ../mapped/SRR18493715.RNA-Seq.Camellia_sp._multipetala.leaf/Aligned.sortedByCoord.out.bam with NativeSamReader. I0812 17:25:10.163989 140700470552384 make_examples_core.py:301] Task 15/32: Writing gvcf records to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/gvcf.tfrecord-00015-of-00032.gz. I0812 17:25:10.169354 140700470552384 make_examples_core.py:301] Task 15/32: Writing examples to /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/star_hapbetter/deepvariant/tmp/tmp0n4wz07d/make_examples.tfrecord-00015-of-00032.gz. I0812 17:25:10.170929 140700470552384 make_examples_core.py:301] Task 15/32: Overhead for preparing inputs: 281 seconds. I0812 17:25:10.353756 140700470552384 make_examples_core.py:301] Task 15/32: 0 candidates (0 examples) [0.18s elapsed]. '. While RNAseq data is expected to be sparsely mapped onto the genome, wouldn't deepvariant focus on the regions specified by the bed file? I'm a bit surprised that 0 examples were made. Is it possible that the reads do not map with high enough MAPQ in these regions? But I'm still not sure why make_samples get stuck though. **Setup**. - Operating system: Ubuntu server 22.04. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity (docker image). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). RNAseq data NCBI SRA SRR18493715, ref genome (produced by ourself, but can probably be replaced by another version https://www.ncbi.nlm.nih.gov/datasets/genome/GCA_025200525.1/ ). **Steps to reproduce:**. - Map reads with STAR, use samtools index to index the BAM. - run the above deepvariant command.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/868:407,availability,Operat,Operating,407,"No output files (VCFs) for all genome; **Describe the issue:**. I am not obtaining any output files even though there are no major issues in the log file, (see attached). I ran it with the same data first, only for the chr20, and everything went fine. For all the genome now, I don't have the vcfs. [deepvariant_run.log](https://github.com/user-attachments/files/16596005/deepvariant_run.log). **Setup**. - Operating system: Windows, WSL2 (5.15.146.1-microsoft-standard-WSL2). - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: NA12878, bam file. **Steps to reproduce:**. sudo docker run \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing:/input"" \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output:/output"" \. google/deepvariant:1.4.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/genome.fa \. --reads=/input/sorted.bam \. --output_vcf=/output/outputdeepvar.vcf \. --output_gvcf=/output/outputdeepvar.g.vcf \. --num_shards=4 \. > ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output/deepvariant_run.log"" 2>&1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:145,deployability,log,log,145,"No output files (VCFs) for all genome; **Describe the issue:**. I am not obtaining any output files even though there are no major issues in the log file, (see attached). I ran it with the same data first, only for the chr20, and everything went fine. For all the genome now, I don't have the vcfs. [deepvariant_run.log](https://github.com/user-attachments/files/16596005/deepvariant_run.log). **Setup**. - Operating system: Windows, WSL2 (5.15.146.1-microsoft-standard-WSL2). - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: NA12878, bam file. **Steps to reproduce:**. sudo docker run \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing:/input"" \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output:/output"" \. google/deepvariant:1.4.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/genome.fa \. --reads=/input/sorted.bam \. --output_vcf=/output/outputdeepvar.vcf \. --output_gvcf=/output/outputdeepvar.g.vcf \. --num_shards=4 \. > ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output/deepvariant_run.log"" 2>&1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:316,deployability,log,log,316,"No output files (VCFs) for all genome; **Describe the issue:**. I am not obtaining any output files even though there are no major issues in the log file, (see attached). I ran it with the same data first, only for the chr20, and everything went fine. For all the genome now, I don't have the vcfs. [deepvariant_run.log](https://github.com/user-attachments/files/16596005/deepvariant_run.log). **Setup**. - Operating system: Windows, WSL2 (5.15.146.1-microsoft-standard-WSL2). - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: NA12878, bam file. **Steps to reproduce:**. sudo docker run \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing:/input"" \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output:/output"" \. google/deepvariant:1.4.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/genome.fa \. --reads=/input/sorted.bam \. --output_vcf=/output/outputdeepvar.vcf \. --output_gvcf=/output/outputdeepvar.g.vcf \. --num_shards=4 \. > ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output/deepvariant_run.log"" 2>&1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:388,deployability,log,log,388,"No output files (VCFs) for all genome; **Describe the issue:**. I am not obtaining any output files even though there are no major issues in the log file, (see attached). I ran it with the same data first, only for the chr20, and everything went fine. For all the genome now, I don't have the vcfs. [deepvariant_run.log](https://github.com/user-attachments/files/16596005/deepvariant_run.log). **Setup**. - Operating system: Windows, WSL2 (5.15.146.1-microsoft-standard-WSL2). - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: NA12878, bam file. **Steps to reproduce:**. sudo docker run \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing:/input"" \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output:/output"" \. google/deepvariant:1.4.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/genome.fa \. --reads=/input/sorted.bam \. --output_vcf=/output/outputdeepvar.vcf \. --output_gvcf=/output/outputdeepvar.g.vcf \. --num_shards=4 \. > ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output/deepvariant_run.log"" 2>&1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:491,deployability,version,version,491,"No output files (VCFs) for all genome; **Describe the issue:**. I am not obtaining any output files even though there are no major issues in the log file, (see attached). I ran it with the same data first, only for the chr20, and everything went fine. For all the genome now, I don't have the vcfs. [deepvariant_run.log](https://github.com/user-attachments/files/16596005/deepvariant_run.log). **Setup**. - Operating system: Windows, WSL2 (5.15.146.1-microsoft-standard-WSL2). - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: NA12878, bam file. **Steps to reproduce:**. sudo docker run \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing:/input"" \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output:/output"" \. google/deepvariant:1.4.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/genome.fa \. --reads=/input/sorted.bam \. --output_vcf=/output/outputdeepvar.vcf \. --output_gvcf=/output/outputdeepvar.g.vcf \. --num_shards=4 \. > ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output/deepvariant_run.log"" 2>&1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:509,deployability,Instal,Installation,509,"No output files (VCFs) for all genome; **Describe the issue:**. I am not obtaining any output files even though there are no major issues in the log file, (see attached). I ran it with the same data first, only for the chr20, and everything went fine. For all the genome now, I don't have the vcfs. [deepvariant_run.log](https://github.com/user-attachments/files/16596005/deepvariant_run.log). **Setup**. - Operating system: Windows, WSL2 (5.15.146.1-microsoft-standard-WSL2). - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: NA12878, bam file. **Steps to reproduce:**. sudo docker run \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing:/input"" \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output:/output"" \. google/deepvariant:1.4.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/genome.fa \. --reads=/input/sorted.bam \. --output_vcf=/output/outputdeepvar.vcf \. --output_gvcf=/output/outputdeepvar.g.vcf \. --num_shards=4 \. > ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output/deepvariant_run.log"" 2>&1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:1235,deployability,log,log,1235,"No output files (VCFs) for all genome; **Describe the issue:**. I am not obtaining any output files even though there are no major issues in the log file, (see attached). I ran it with the same data first, only for the chr20, and everything went fine. For all the genome now, I don't have the vcfs. [deepvariant_run.log](https://github.com/user-attachments/files/16596005/deepvariant_run.log). **Setup**. - Operating system: Windows, WSL2 (5.15.146.1-microsoft-standard-WSL2). - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: NA12878, bam file. **Steps to reproduce:**. sudo docker run \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing:/input"" \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output:/output"" \. google/deepvariant:1.4.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/genome.fa \. --reads=/input/sorted.bam \. --output_vcf=/output/outputdeepvar.vcf \. --output_gvcf=/output/outputdeepvar.g.vcf \. --num_shards=4 \. > ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output/deepvariant_run.log"" 2>&1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:491,integrability,version,version,491,"No output files (VCFs) for all genome; **Describe the issue:**. I am not obtaining any output files even though there are no major issues in the log file, (see attached). I ran it with the same data first, only for the chr20, and everything went fine. For all the genome now, I don't have the vcfs. [deepvariant_run.log](https://github.com/user-attachments/files/16596005/deepvariant_run.log). **Setup**. - Operating system: Windows, WSL2 (5.15.146.1-microsoft-standard-WSL2). - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: NA12878, bam file. **Steps to reproduce:**. sudo docker run \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing:/input"" \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output:/output"" \. google/deepvariant:1.4.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/genome.fa \. --reads=/input/sorted.bam \. --output_vcf=/output/outputdeepvar.vcf \. --output_gvcf=/output/outputdeepvar.g.vcf \. --num_shards=4 \. > ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output/deepvariant_run.log"" 2>&1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:461,interoperability,standard,standard-,461,"No output files (VCFs) for all genome; **Describe the issue:**. I am not obtaining any output files even though there are no major issues in the log file, (see attached). I ran it with the same data first, only for the chr20, and everything went fine. For all the genome now, I don't have the vcfs. [deepvariant_run.log](https://github.com/user-attachments/files/16596005/deepvariant_run.log). **Setup**. - Operating system: Windows, WSL2 (5.15.146.1-microsoft-standard-WSL2). - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: NA12878, bam file. **Steps to reproduce:**. sudo docker run \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing:/input"" \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output:/output"" \. google/deepvariant:1.4.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/genome.fa \. --reads=/input/sorted.bam \. --output_vcf=/output/outputdeepvar.vcf \. --output_gvcf=/output/outputdeepvar.g.vcf \. --num_shards=4 \. > ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output/deepvariant_run.log"" 2>&1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:491,modifiability,version,version,491,"No output files (VCFs) for all genome; **Describe the issue:**. I am not obtaining any output files even though there are no major issues in the log file, (see attached). I ran it with the same data first, only for the chr20, and everything went fine. For all the genome now, I don't have the vcfs. [deepvariant_run.log](https://github.com/user-attachments/files/16596005/deepvariant_run.log). **Setup**. - Operating system: Windows, WSL2 (5.15.146.1-microsoft-standard-WSL2). - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: NA12878, bam file. **Steps to reproduce:**. sudo docker run \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing:/input"" \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output:/output"" \. google/deepvariant:1.4.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/genome.fa \. --reads=/input/sorted.bam \. --output_vcf=/output/outputdeepvar.vcf \. --output_gvcf=/output/outputdeepvar.g.vcf \. --num_shards=4 \. > ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output/deepvariant_run.log"" 2>&1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:145,safety,log,log,145,"No output files (VCFs) for all genome; **Describe the issue:**. I am not obtaining any output files even though there are no major issues in the log file, (see attached). I ran it with the same data first, only for the chr20, and everything went fine. For all the genome now, I don't have the vcfs. [deepvariant_run.log](https://github.com/user-attachments/files/16596005/deepvariant_run.log). **Setup**. - Operating system: Windows, WSL2 (5.15.146.1-microsoft-standard-WSL2). - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: NA12878, bam file. **Steps to reproduce:**. sudo docker run \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing:/input"" \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output:/output"" \. google/deepvariant:1.4.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/genome.fa \. --reads=/input/sorted.bam \. --output_vcf=/output/outputdeepvar.vcf \. --output_gvcf=/output/outputdeepvar.g.vcf \. --num_shards=4 \. > ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output/deepvariant_run.log"" 2>&1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:316,safety,log,log,316,"No output files (VCFs) for all genome; **Describe the issue:**. I am not obtaining any output files even though there are no major issues in the log file, (see attached). I ran it with the same data first, only for the chr20, and everything went fine. For all the genome now, I don't have the vcfs. [deepvariant_run.log](https://github.com/user-attachments/files/16596005/deepvariant_run.log). **Setup**. - Operating system: Windows, WSL2 (5.15.146.1-microsoft-standard-WSL2). - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: NA12878, bam file. **Steps to reproduce:**. sudo docker run \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing:/input"" \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output:/output"" \. google/deepvariant:1.4.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/genome.fa \. --reads=/input/sorted.bam \. --output_vcf=/output/outputdeepvar.vcf \. --output_gvcf=/output/outputdeepvar.g.vcf \. --num_shards=4 \. > ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output/deepvariant_run.log"" 2>&1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:388,safety,log,log,388,"No output files (VCFs) for all genome; **Describe the issue:**. I am not obtaining any output files even though there are no major issues in the log file, (see attached). I ran it with the same data first, only for the chr20, and everything went fine. For all the genome now, I don't have the vcfs. [deepvariant_run.log](https://github.com/user-attachments/files/16596005/deepvariant_run.log). **Setup**. - Operating system: Windows, WSL2 (5.15.146.1-microsoft-standard-WSL2). - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: NA12878, bam file. **Steps to reproduce:**. sudo docker run \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing:/input"" \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output:/output"" \. google/deepvariant:1.4.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/genome.fa \. --reads=/input/sorted.bam \. --output_vcf=/output/outputdeepvar.vcf \. --output_gvcf=/output/outputdeepvar.g.vcf \. --num_shards=4 \. > ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output/deepvariant_run.log"" 2>&1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:704,safety,Review,Review,704,"No output files (VCFs) for all genome; **Describe the issue:**. I am not obtaining any output files even though there are no major issues in the log file, (see attached). I ran it with the same data first, only for the chr20, and everything went fine. For all the genome now, I don't have the vcfs. [deepvariant_run.log](https://github.com/user-attachments/files/16596005/deepvariant_run.log). **Setup**. - Operating system: Windows, WSL2 (5.15.146.1-microsoft-standard-WSL2). - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: NA12878, bam file. **Steps to reproduce:**. sudo docker run \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing:/input"" \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output:/output"" \. google/deepvariant:1.4.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/genome.fa \. --reads=/input/sorted.bam \. --output_vcf=/output/outputdeepvar.vcf \. --output_gvcf=/output/outputdeepvar.g.vcf \. --num_shards=4 \. > ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output/deepvariant_run.log"" 2>&1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:724,safety,input,input,724,"No output files (VCFs) for all genome; **Describe the issue:**. I am not obtaining any output files even though there are no major issues in the log file, (see attached). I ran it with the same data first, only for the chr20, and everything went fine. For all the genome now, I don't have the vcfs. [deepvariant_run.log](https://github.com/user-attachments/files/16596005/deepvariant_run.log). **Setup**. - Operating system: Windows, WSL2 (5.15.146.1-microsoft-standard-WSL2). - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: NA12878, bam file. **Steps to reproduce:**. sudo docker run \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing:/input"" \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output:/output"" \. google/deepvariant:1.4.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/genome.fa \. --reads=/input/sorted.bam \. --output_vcf=/output/outputdeepvar.vcf \. --output_gvcf=/output/outputdeepvar.g.vcf \. --num_shards=4 \. > ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output/deepvariant_run.log"" 2>&1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:821,safety,Review,Review,821,"No output files (VCFs) for all genome; **Describe the issue:**. I am not obtaining any output files even though there are no major issues in the log file, (see attached). I ran it with the same data first, only for the chr20, and everything went fine. For all the genome now, I don't have the vcfs. [deepvariant_run.log](https://github.com/user-attachments/files/16596005/deepvariant_run.log). **Setup**. - Operating system: Windows, WSL2 (5.15.146.1-microsoft-standard-WSL2). - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: NA12878, bam file. **Steps to reproduce:**. sudo docker run \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing:/input"" \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output:/output"" \. google/deepvariant:1.4.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/genome.fa \. --reads=/input/sorted.bam \. --output_vcf=/output/outputdeepvar.vcf \. --output_gvcf=/output/outputdeepvar.g.vcf \. --num_shards=4 \. > ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output/deepvariant_run.log"" 2>&1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:954,safety,input,input,954,"No output files (VCFs) for all genome; **Describe the issue:**. I am not obtaining any output files even though there are no major issues in the log file, (see attached). I ran it with the same data first, only for the chr20, and everything went fine. For all the genome now, I don't have the vcfs. [deepvariant_run.log](https://github.com/user-attachments/files/16596005/deepvariant_run.log). **Setup**. - Operating system: Windows, WSL2 (5.15.146.1-microsoft-standard-WSL2). - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: NA12878, bam file. **Steps to reproduce:**. sudo docker run \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing:/input"" \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output:/output"" \. google/deepvariant:1.4.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/genome.fa \. --reads=/input/sorted.bam \. --output_vcf=/output/outputdeepvar.vcf \. --output_gvcf=/output/outputdeepvar.g.vcf \. --num_shards=4 \. > ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output/deepvariant_run.log"" 2>&1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:982,safety,input,input,982,"No output files (VCFs) for all genome; **Describe the issue:**. I am not obtaining any output files even though there are no major issues in the log file, (see attached). I ran it with the same data first, only for the chr20, and everything went fine. For all the genome now, I don't have the vcfs. [deepvariant_run.log](https://github.com/user-attachments/files/16596005/deepvariant_run.log). **Setup**. - Operating system: Windows, WSL2 (5.15.146.1-microsoft-standard-WSL2). - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: NA12878, bam file. **Steps to reproduce:**. sudo docker run \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing:/input"" \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output:/output"" \. google/deepvariant:1.4.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/genome.fa \. --reads=/input/sorted.bam \. --output_vcf=/output/outputdeepvar.vcf \. --output_gvcf=/output/outputdeepvar.g.vcf \. --num_shards=4 \. > ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output/deepvariant_run.log"" 2>&1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:1193,safety,Review,Review,1193,"No output files (VCFs) for all genome; **Describe the issue:**. I am not obtaining any output files even though there are no major issues in the log file, (see attached). I ran it with the same data first, only for the chr20, and everything went fine. For all the genome now, I don't have the vcfs. [deepvariant_run.log](https://github.com/user-attachments/files/16596005/deepvariant_run.log). **Setup**. - Operating system: Windows, WSL2 (5.15.146.1-microsoft-standard-WSL2). - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: NA12878, bam file. **Steps to reproduce:**. sudo docker run \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing:/input"" \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output:/output"" \. google/deepvariant:1.4.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/genome.fa \. --reads=/input/sorted.bam \. --output_vcf=/output/outputdeepvar.vcf \. --output_gvcf=/output/outputdeepvar.g.vcf \. --num_shards=4 \. > ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output/deepvariant_run.log"" 2>&1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:1235,safety,log,log,1235,"No output files (VCFs) for all genome; **Describe the issue:**. I am not obtaining any output files even though there are no major issues in the log file, (see attached). I ran it with the same data first, only for the chr20, and everything went fine. For all the genome now, I don't have the vcfs. [deepvariant_run.log](https://github.com/user-attachments/files/16596005/deepvariant_run.log). **Setup**. - Operating system: Windows, WSL2 (5.15.146.1-microsoft-standard-WSL2). - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: NA12878, bam file. **Steps to reproduce:**. sudo docker run \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing:/input"" \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output:/output"" \. google/deepvariant:1.4.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/genome.fa \. --reads=/input/sorted.bam \. --output_vcf=/output/outputdeepvar.vcf \. --output_gvcf=/output/outputdeepvar.g.vcf \. --num_shards=4 \. > ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output/deepvariant_run.log"" 2>&1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:145,security,log,log,145,"No output files (VCFs) for all genome; **Describe the issue:**. I am not obtaining any output files even though there are no major issues in the log file, (see attached). I ran it with the same data first, only for the chr20, and everything went fine. For all the genome now, I don't have the vcfs. [deepvariant_run.log](https://github.com/user-attachments/files/16596005/deepvariant_run.log). **Setup**. - Operating system: Windows, WSL2 (5.15.146.1-microsoft-standard-WSL2). - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: NA12878, bam file. **Steps to reproduce:**. sudo docker run \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing:/input"" \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output:/output"" \. google/deepvariant:1.4.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/genome.fa \. --reads=/input/sorted.bam \. --output_vcf=/output/outputdeepvar.vcf \. --output_gvcf=/output/outputdeepvar.g.vcf \. --num_shards=4 \. > ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output/deepvariant_run.log"" 2>&1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:316,security,log,log,316,"No output files (VCFs) for all genome; **Describe the issue:**. I am not obtaining any output files even though there are no major issues in the log file, (see attached). I ran it with the same data first, only for the chr20, and everything went fine. For all the genome now, I don't have the vcfs. [deepvariant_run.log](https://github.com/user-attachments/files/16596005/deepvariant_run.log). **Setup**. - Operating system: Windows, WSL2 (5.15.146.1-microsoft-standard-WSL2). - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: NA12878, bam file. **Steps to reproduce:**. sudo docker run \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing:/input"" \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output:/output"" \. google/deepvariant:1.4.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/genome.fa \. --reads=/input/sorted.bam \. --output_vcf=/output/outputdeepvar.vcf \. --output_gvcf=/output/outputdeepvar.g.vcf \. --num_shards=4 \. > ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output/deepvariant_run.log"" 2>&1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:388,security,log,log,388,"No output files (VCFs) for all genome; **Describe the issue:**. I am not obtaining any output files even though there are no major issues in the log file, (see attached). I ran it with the same data first, only for the chr20, and everything went fine. For all the genome now, I don't have the vcfs. [deepvariant_run.log](https://github.com/user-attachments/files/16596005/deepvariant_run.log). **Setup**. - Operating system: Windows, WSL2 (5.15.146.1-microsoft-standard-WSL2). - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: NA12878, bam file. **Steps to reproduce:**. sudo docker run \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing:/input"" \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output:/output"" \. google/deepvariant:1.4.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/genome.fa \. --reads=/input/sorted.bam \. --output_vcf=/output/outputdeepvar.vcf \. --output_gvcf=/output/outputdeepvar.g.vcf \. --num_shards=4 \. > ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output/deepvariant_run.log"" 2>&1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:1235,security,log,log,1235,"No output files (VCFs) for all genome; **Describe the issue:**. I am not obtaining any output files even though there are no major issues in the log file, (see attached). I ran it with the same data first, only for the chr20, and everything went fine. For all the genome now, I don't have the vcfs. [deepvariant_run.log](https://github.com/user-attachments/files/16596005/deepvariant_run.log). **Setup**. - Operating system: Windows, WSL2 (5.15.146.1-microsoft-standard-WSL2). - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: NA12878, bam file. **Steps to reproduce:**. sudo docker run \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing:/input"" \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output:/output"" \. google/deepvariant:1.4.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/genome.fa \. --reads=/input/sorted.bam \. --output_vcf=/output/outputdeepvar.vcf \. --output_gvcf=/output/outputdeepvar.g.vcf \. --num_shards=4 \. > ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output/deepvariant_run.log"" 2>&1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:145,testability,log,log,145,"No output files (VCFs) for all genome; **Describe the issue:**. I am not obtaining any output files even though there are no major issues in the log file, (see attached). I ran it with the same data first, only for the chr20, and everything went fine. For all the genome now, I don't have the vcfs. [deepvariant_run.log](https://github.com/user-attachments/files/16596005/deepvariant_run.log). **Setup**. - Operating system: Windows, WSL2 (5.15.146.1-microsoft-standard-WSL2). - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: NA12878, bam file. **Steps to reproduce:**. sudo docker run \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing:/input"" \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output:/output"" \. google/deepvariant:1.4.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/genome.fa \. --reads=/input/sorted.bam \. --output_vcf=/output/outputdeepvar.vcf \. --output_gvcf=/output/outputdeepvar.g.vcf \. --num_shards=4 \. > ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output/deepvariant_run.log"" 2>&1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:316,testability,log,log,316,"No output files (VCFs) for all genome; **Describe the issue:**. I am not obtaining any output files even though there are no major issues in the log file, (see attached). I ran it with the same data first, only for the chr20, and everything went fine. For all the genome now, I don't have the vcfs. [deepvariant_run.log](https://github.com/user-attachments/files/16596005/deepvariant_run.log). **Setup**. - Operating system: Windows, WSL2 (5.15.146.1-microsoft-standard-WSL2). - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: NA12878, bam file. **Steps to reproduce:**. sudo docker run \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing:/input"" \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output:/output"" \. google/deepvariant:1.4.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/genome.fa \. --reads=/input/sorted.bam \. --output_vcf=/output/outputdeepvar.vcf \. --output_gvcf=/output/outputdeepvar.g.vcf \. --num_shards=4 \. > ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output/deepvariant_run.log"" 2>&1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:388,testability,log,log,388,"No output files (VCFs) for all genome; **Describe the issue:**. I am not obtaining any output files even though there are no major issues in the log file, (see attached). I ran it with the same data first, only for the chr20, and everything went fine. For all the genome now, I don't have the vcfs. [deepvariant_run.log](https://github.com/user-attachments/files/16596005/deepvariant_run.log). **Setup**. - Operating system: Windows, WSL2 (5.15.146.1-microsoft-standard-WSL2). - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: NA12878, bam file. **Steps to reproduce:**. sudo docker run \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing:/input"" \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output:/output"" \. google/deepvariant:1.4.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/genome.fa \. --reads=/input/sorted.bam \. --output_vcf=/output/outputdeepvar.vcf \. --output_gvcf=/output/outputdeepvar.g.vcf \. --num_shards=4 \. > ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output/deepvariant_run.log"" 2>&1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:704,testability,Review,Review,704,"No output files (VCFs) for all genome; **Describe the issue:**. I am not obtaining any output files even though there are no major issues in the log file, (see attached). I ran it with the same data first, only for the chr20, and everything went fine. For all the genome now, I don't have the vcfs. [deepvariant_run.log](https://github.com/user-attachments/files/16596005/deepvariant_run.log). **Setup**. - Operating system: Windows, WSL2 (5.15.146.1-microsoft-standard-WSL2). - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: NA12878, bam file. **Steps to reproduce:**. sudo docker run \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing:/input"" \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output:/output"" \. google/deepvariant:1.4.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/genome.fa \. --reads=/input/sorted.bam \. --output_vcf=/output/outputdeepvar.vcf \. --output_gvcf=/output/outputdeepvar.g.vcf \. --num_shards=4 \. > ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output/deepvariant_run.log"" 2>&1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:821,testability,Review,Review,821,"No output files (VCFs) for all genome; **Describe the issue:**. I am not obtaining any output files even though there are no major issues in the log file, (see attached). I ran it with the same data first, only for the chr20, and everything went fine. For all the genome now, I don't have the vcfs. [deepvariant_run.log](https://github.com/user-attachments/files/16596005/deepvariant_run.log). **Setup**. - Operating system: Windows, WSL2 (5.15.146.1-microsoft-standard-WSL2). - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: NA12878, bam file. **Steps to reproduce:**. sudo docker run \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing:/input"" \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output:/output"" \. google/deepvariant:1.4.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/genome.fa \. --reads=/input/sorted.bam \. --output_vcf=/output/outputdeepvar.vcf \. --output_gvcf=/output/outputdeepvar.g.vcf \. --num_shards=4 \. > ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output/deepvariant_run.log"" 2>&1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:1193,testability,Review,Review,1193,"No output files (VCFs) for all genome; **Describe the issue:**. I am not obtaining any output files even though there are no major issues in the log file, (see attached). I ran it with the same data first, only for the chr20, and everything went fine. For all the genome now, I don't have the vcfs. [deepvariant_run.log](https://github.com/user-attachments/files/16596005/deepvariant_run.log). **Setup**. - Operating system: Windows, WSL2 (5.15.146.1-microsoft-standard-WSL2). - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: NA12878, bam file. **Steps to reproduce:**. sudo docker run \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing:/input"" \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output:/output"" \. google/deepvariant:1.4.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/genome.fa \. --reads=/input/sorted.bam \. --output_vcf=/output/outputdeepvar.vcf \. --output_gvcf=/output/outputdeepvar.g.vcf \. --num_shards=4 \. > ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output/deepvariant_run.log"" 2>&1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:1235,testability,log,log,1235,"No output files (VCFs) for all genome; **Describe the issue:**. I am not obtaining any output files even though there are no major issues in the log file, (see attached). I ran it with the same data first, only for the chr20, and everything went fine. For all the genome now, I don't have the vcfs. [deepvariant_run.log](https://github.com/user-attachments/files/16596005/deepvariant_run.log). **Setup**. - Operating system: Windows, WSL2 (5.15.146.1-microsoft-standard-WSL2). - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: NA12878, bam file. **Steps to reproduce:**. sudo docker run \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing:/input"" \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output:/output"" \. google/deepvariant:1.4.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/genome.fa \. --reads=/input/sorted.bam \. --output_vcf=/output/outputdeepvar.vcf \. --output_gvcf=/output/outputdeepvar.g.vcf \. --num_shards=4 \. > ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output/deepvariant_run.log"" 2>&1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:340,usability,user,user-attachments,340,"No output files (VCFs) for all genome; **Describe the issue:**. I am not obtaining any output files even though there are no major issues in the log file, (see attached). I ran it with the same data first, only for the chr20, and everything went fine. For all the genome now, I don't have the vcfs. [deepvariant_run.log](https://github.com/user-attachments/files/16596005/deepvariant_run.log). **Setup**. - Operating system: Windows, WSL2 (5.15.146.1-microsoft-standard-WSL2). - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: NA12878, bam file. **Steps to reproduce:**. sudo docker run \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing:/input"" \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output:/output"" \. google/deepvariant:1.4.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/genome.fa \. --reads=/input/sorted.bam \. --output_vcf=/output/outputdeepvar.vcf \. --output_gvcf=/output/outputdeepvar.g.vcf \. --num_shards=4 \. > ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output/deepvariant_run.log"" 2>&1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:628,usability,User,Users,628,"No output files (VCFs) for all genome; **Describe the issue:**. I am not obtaining any output files even though there are no major issues in the log file, (see attached). I ran it with the same data first, only for the chr20, and everything went fine. For all the genome now, I don't have the vcfs. [deepvariant_run.log](https://github.com/user-attachments/files/16596005/deepvariant_run.log). **Setup**. - Operating system: Windows, WSL2 (5.15.146.1-microsoft-standard-WSL2). - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: NA12878, bam file. **Steps to reproduce:**. sudo docker run \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing:/input"" \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output:/output"" \. google/deepvariant:1.4.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/genome.fa \. --reads=/input/sorted.bam \. --output_vcf=/output/outputdeepvar.vcf \. --output_gvcf=/output/outputdeepvar.g.vcf \. --num_shards=4 \. > ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output/deepvariant_run.log"" 2>&1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:724,usability,input,input,724,"No output files (VCFs) for all genome; **Describe the issue:**. I am not obtaining any output files even though there are no major issues in the log file, (see attached). I ran it with the same data first, only for the chr20, and everything went fine. For all the genome now, I don't have the vcfs. [deepvariant_run.log](https://github.com/user-attachments/files/16596005/deepvariant_run.log). **Setup**. - Operating system: Windows, WSL2 (5.15.146.1-microsoft-standard-WSL2). - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: NA12878, bam file. **Steps to reproduce:**. sudo docker run \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing:/input"" \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output:/output"" \. google/deepvariant:1.4.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/genome.fa \. --reads=/input/sorted.bam \. --output_vcf=/output/outputdeepvar.vcf \. --output_gvcf=/output/outputdeepvar.g.vcf \. --num_shards=4 \. > ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output/deepvariant_run.log"" 2>&1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:745,usability,User,Users,745,"No output files (VCFs) for all genome; **Describe the issue:**. I am not obtaining any output files even though there are no major issues in the log file, (see attached). I ran it with the same data first, only for the chr20, and everything went fine. For all the genome now, I don't have the vcfs. [deepvariant_run.log](https://github.com/user-attachments/files/16596005/deepvariant_run.log). **Setup**. - Operating system: Windows, WSL2 (5.15.146.1-microsoft-standard-WSL2). - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: NA12878, bam file. **Steps to reproduce:**. sudo docker run \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing:/input"" \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output:/output"" \. google/deepvariant:1.4.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/genome.fa \. --reads=/input/sorted.bam \. --output_vcf=/output/outputdeepvar.vcf \. --output_gvcf=/output/outputdeepvar.g.vcf \. --num_shards=4 \. > ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output/deepvariant_run.log"" 2>&1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:954,usability,input,input,954,"No output files (VCFs) for all genome; **Describe the issue:**. I am not obtaining any output files even though there are no major issues in the log file, (see attached). I ran it with the same data first, only for the chr20, and everything went fine. For all the genome now, I don't have the vcfs. [deepvariant_run.log](https://github.com/user-attachments/files/16596005/deepvariant_run.log). **Setup**. - Operating system: Windows, WSL2 (5.15.146.1-microsoft-standard-WSL2). - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: NA12878, bam file. **Steps to reproduce:**. sudo docker run \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing:/input"" \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output:/output"" \. google/deepvariant:1.4.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/genome.fa \. --reads=/input/sorted.bam \. --output_vcf=/output/outputdeepvar.vcf \. --output_gvcf=/output/outputdeepvar.g.vcf \. --num_shards=4 \. > ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output/deepvariant_run.log"" 2>&1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:982,usability,input,input,982,"No output files (VCFs) for all genome; **Describe the issue:**. I am not obtaining any output files even though there are no major issues in the log file, (see attached). I ran it with the same data first, only for the chr20, and everything went fine. For all the genome now, I don't have the vcfs. [deepvariant_run.log](https://github.com/user-attachments/files/16596005/deepvariant_run.log). **Setup**. - Operating system: Windows, WSL2 (5.15.146.1-microsoft-standard-WSL2). - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: NA12878, bam file. **Steps to reproduce:**. sudo docker run \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing:/input"" \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output:/output"" \. google/deepvariant:1.4.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/genome.fa \. --reads=/input/sorted.bam \. --output_vcf=/output/outputdeepvar.vcf \. --output_gvcf=/output/outputdeepvar.g.vcf \. --num_shards=4 \. > ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output/deepvariant_run.log"" 2>&1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:1117,usability,User,Users,1117,"No output files (VCFs) for all genome; **Describe the issue:**. I am not obtaining any output files even though there are no major issues in the log file, (see attached). I ran it with the same data first, only for the chr20, and everything went fine. For all the genome now, I don't have the vcfs. [deepvariant_run.log](https://github.com/user-attachments/files/16596005/deepvariant_run.log). **Setup**. - Operating system: Windows, WSL2 (5.15.146.1-microsoft-standard-WSL2). - DeepVariant version: 1.4.0. - Installation method: Docker. - Type of data: NA12878, bam file. **Steps to reproduce:**. sudo docker run \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing:/input"" \. -v ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output:/output"" \. google/deepvariant:1.4.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/genome.fa \. --reads=/input/sorted.bam \. --output_vcf=/output/outputdeepvar.vcf \. --output_gvcf=/output/outputdeepvar.g.vcf \. --num_shards=4 \. > ""/mnt/c/Users/pinto/OneDrive - Universidade de Lisboa/Revisao bibliografica/Scoping Review/alg_testing/output/deepvariant_run.log"" 2>&1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/869:481,availability,error,errors,481,"No output vcf obtained from custom model; **ISSUE**. First of all, I found DeepVariant to be a very good and innovative tool. I'm considering including it in my exome analysis pipeline. I followed the tutorial (DeepVariant worked correctly with the Complete Genomics model), and I created my own model using Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:614,availability,Operat,Operating,614,"No output vcf obtained from custom model; **ISSUE**. First of all, I found DeepVariant to be a very good and innovative tool. I'm considering including it in my exome analysis pipeline. I followed the tutorial (DeepVariant worked correctly with the Complete Genomics model), and I created my own model using Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:2908,availability,checkpoint,checkpoints,2908,"ng.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/validation_set.gz --output_pattern_prefix=""output/validation_shuffled"" --output_dataset_name=""27"" --output_dataset_config_pbtxt=""output/validation.pbtxt"" --job_name=shuffle-tfrecords `. _Model trainning_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" train --config=/input/dv_config.py:base --config.train_dataset_pbtxt=""/output/training.pbtxt"" --config.tune_dataset_pbtxt=""/output/validation.pbtxt"" --config.num_epochs=10 --config.learning_rate=0.0001 --config.num_validation_examples=0 --strategy=mirrored --experiment_dir=""/output/"" --config.batch_size=512`. _Model test_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type WES --customized_model ""/output/checkpoints/ckpt-679"" --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/33_r_groups.bam"" --output_vcf ""/output/33.vcf.gz"" --output_gvcf ""/output/33.g.vcf.gz"" -intermediate_results_dir ""/output/intermediate_results_dir"" --num_shards 10`. - Error trace: . ` - I0822 07:51:54.272576 127450974123840 make_examples_core.py:301] Task 17/20: Writing example info to /output/intermediate_results_dir/make_examples.tfrecord-00017-of-00020.gz.example_info.json. I0822 07:51:54.272647 127450974123840 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0822 07:51:54.272740 127450974123840 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0822 07:51:54.272911 127450974123840 make_examples_core.py:301] Task 17/20: Found 17451 candidate variants. I0822 07:51:54.272932 127450974123840 make_examples_core.py:301] Task 17/20: Created 18817 examples. I0822 07:52:09.283522 133276175411008 make_examples_core.py:301] Task 8/20: Writing example info to /output/intermediate_results_dir/make_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:3147,availability,Error,Error,3147,"output_dataset_config_pbtxt=""output/validation.pbtxt"" --job_name=shuffle-tfrecords `. _Model trainning_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" train --config=/input/dv_config.py:base --config.train_dataset_pbtxt=""/output/training.pbtxt"" --config.tune_dataset_pbtxt=""/output/validation.pbtxt"" --config.num_epochs=10 --config.learning_rate=0.0001 --config.num_validation_examples=0 --strategy=mirrored --experiment_dir=""/output/"" --config.batch_size=512`. _Model test_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" /opt/deepvariant/bin/run_deepvariant --model_type WES --customized_model ""/output/checkpoints/ckpt-679"" --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/33_r_groups.bam"" --output_vcf ""/output/33.vcf.gz"" --output_gvcf ""/output/33.g.vcf.gz"" -intermediate_results_dir ""/output/intermediate_results_dir"" --num_shards 10`. - Error trace: . ` - I0822 07:51:54.272576 127450974123840 make_examples_core.py:301] Task 17/20: Writing example info to /output/intermediate_results_dir/make_examples.tfrecord-00017-of-00020.gz.example_info.json. I0822 07:51:54.272647 127450974123840 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0822 07:51:54.272740 127450974123840 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0822 07:51:54.272911 127450974123840 make_examples_core.py:301] Task 17/20: Found 17451 candidate variants. I0822 07:51:54.272932 127450974123840 make_examples_core.py:301] Task 17/20: Created 18817 examples. I0822 07:52:09.283522 133276175411008 make_examples_core.py:301] Task 8/20: Writing example info to /output/intermediate_results_dir/make_examples.tfrecord-00008-of-00020.gz.example_info.json. I0822 07:52:09.283617 133276175411008 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0822 07:52:09.283712 133276175411008 make_examples_core.py:2959] example_channels =",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:4661,availability,checkpoint,checkpoint,4661,"ariants. I0822 07:51:54.272932 127450974123840 make_examples_core.py:301] Task 17/20: Created 18817 examples. I0822 07:52:09.283522 133276175411008 make_examples_core.py:301] Task 8/20: Writing example info to /output/intermediate_results_dir/make_examples.tfrecord-00008-of-00020.gz.example_info.json. I0822 07:52:09.283617 133276175411008 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0822 07:52:09.283712 133276175411008 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:09.283882 133276175411008 make_examples_core.py:301] Task 8/20: Found 17371 candidate variants. I0822 07:52:09.283904 133276175411008 make_examples_core.py:301] Task 8/20: Created 18820 examples. real 34m15.728s. user 624m43.553s. sys 2m24.932s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@20.gz"" --checkpoint ""/output/checkpoints/ckpt-679"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0822 07:52:10.812179 127086447671104 call_variants.py:563] Total 1 writing processes started. I0822 07:52:10.813103 127086447671104 dv_utils.py:370] From /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:10.813141 127086447671104 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0822 0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:4681,availability,checkpoint,checkpoints,4681,"54.272932 127450974123840 make_examples_core.py:301] Task 17/20: Created 18817 examples. I0822 07:52:09.283522 133276175411008 make_examples_core.py:301] Task 8/20: Writing example info to /output/intermediate_results_dir/make_examples.tfrecord-00008-of-00020.gz.example_info.json. I0822 07:52:09.283617 133276175411008 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0822 07:52:09.283712 133276175411008 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:09.283882 133276175411008 make_examples_core.py:301] Task 8/20: Found 17371 candidate variants. I0822 07:52:09.283904 133276175411008 make_examples_core.py:301] Task 8/20: Created 18820 examples. real 34m15.728s. user 624m43.553s. sys 2m24.932s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@20.gz"" --checkpoint ""/output/checkpoints/ckpt-679"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0822 07:52:10.812179 127086447671104 call_variants.py:563] Total 1 writing processes started. I0822 07:52:10.813103 127086447671104 dv_utils.py:370] From /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:10.813141 127086447671104 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0822 07:52:10.813338 127086",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:4907,availability,mainten,maintenance,4907,"_examples.tfrecord-00008-of-00020.gz.example_info.json. I0822 07:52:09.283617 133276175411008 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0822 07:52:09.283712 133276175411008 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:09.283882 133276175411008 make_examples_core.py:301] Task 8/20: Found 17371 candidate variants. I0822 07:52:09.283904 133276175411008 make_examples_core.py:301] Task 8/20: Created 18820 examples. real 34m15.728s. user 624m43.553s. sys 2m24.932s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@20.gz"" --checkpoint ""/output/checkpoints/ckpt-679"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0822 07:52:10.812179 127086447671104 call_variants.py:563] Total 1 writing processes started. I0822 07:52:10.813103 127086447671104 dv_utils.py:370] From /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:10.813141 127086447671104 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0822 07:52:10.813338 127086447671104 call_variants.py:592] Use saved model: True. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:4991,availability,down,downstream,4991,"6175411008 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0822 07:52:09.283712 133276175411008 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:09.283882 133276175411008 make_examples_core.py:301] Task 8/20: Found 17371 candidate variants. I0822 07:52:09.283904 133276175411008 make_examples_core.py:301] Task 8/20: Created 18820 examples. real 34m15.728s. user 624m43.553s. sys 2m24.932s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@20.gz"" --checkpoint ""/output/checkpoints/ckpt-679"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0822 07:52:10.812179 127086447671104 call_variants.py:563] Total 1 writing processes started. I0822 07:52:10.813103 127086447671104 dv_utils.py:370] From /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:10.813141 127086447671104 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0822 07:52:10.813338 127086447671104 call_variants.py:592] Use saved model: True. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:176,deployability,pipelin,pipeline,176,"No output vcf obtained from custom model; **ISSUE**. First of all, I found DeepVariant to be a very good and innovative tool. I'm considering including it in my exome analysis pipeline. I followed the tutorial (DeepVariant worked correctly with the Complete Genomics model), and I created my own model using Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:666,deployability,version,version,666,"No output vcf obtained from custom model; **ISSUE**. First of all, I found DeepVariant to be a very good and innovative tool. I'm considering including it in my exome analysis pipeline. I followed the tutorial (DeepVariant worked correctly with the Complete Genomics model), and I created my own model using Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:683,deployability,Instal,Installation,683,"No output vcf obtained from custom model; **ISSUE**. First of all, I found DeepVariant to be a very good and innovative tool. I'm considering including it in my exome analysis pipeline. I followed the tutorial (DeepVariant worked correctly with the Complete Genomics model), and I created my own model using Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:4923,deployability,releas,release,4923,"cord-00008-of-00020.gz.example_info.json. I0822 07:52:09.283617 133276175411008 make_examples_core.py:2958] example_shape = [100, 221, 7]. I0822 07:52:09.283712 133276175411008 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:09.283882 133276175411008 make_examples_core.py:301] Task 8/20: Found 17371 candidate variants. I0822 07:52:09.283904 133276175411008 make_examples_core.py:301] Task 8/20: Created 18820 examples. real 34m15.728s. user 624m43.553s. sys 2m24.932s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@20.gz"" --checkpoint ""/output/checkpoints/ckpt-679"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0822 07:52:10.812179 127086447671104 call_variants.py:563] Total 1 writing processes started. I0822 07:52:10.813103 127086447671104 dv_utils.py:370] From /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:10.813141 127086447671104 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0822 07:52:10.813338 127086447671104 call_variants.py:592] Use saved model: True. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Ba",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:5020,deployability,depend,dependencies,5020,"py:2958] example_shape = [100, 221, 7]. I0822 07:52:09.283712 133276175411008 make_examples_core.py:2959] example_channels = [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:09.283882 133276175411008 make_examples_core.py:301] Task 8/20: Found 17371 candidate variants. I0822 07:52:09.283904 133276175411008 make_examples_core.py:301] Task 8/20: Created 18820 examples. real 34m15.728s. user 624m43.553s. sys 2m24.932s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@20.gz"" --checkpoint ""/output/checkpoints/ckpt-679"". /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0822 07:52:10.812179 127086447671104 call_variants.py:563] Total 1 writing processes started. I0822 07:52:10.813103 127086447671104 dv_utils.py:370] From /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:10.813141 127086447671104 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0822 07:52:10.813338 127086447671104 call_variants.py:592] Use saved model: True. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:5890,deployability,modul,module,5890,"red a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0822 07:52:10.812179 127086447671104 call_variants.py:563] Total 1 writing processes started. I0822 07:52:10.813103 127086447671104 dv_utils.py:370] From /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00020.gz.example_info.json: Shape of input examples: [100, 221, 7], Channels of input examples: [1, 2, 3, 4, 5, 6, 19]. I0822 07:52:10.813141 127086447671104 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0822 07:52:10.813338 127086447671104 call_variants.py:592] Use saved model: True. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768, in main. call_variants(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 598, in call_variants. model_example_shape = dv_utils.get_shape_and_channels_from_json(. File ""/tmp/Bazel.runfiles_5v5s5_vp/runfiles/com_google_deepvariant/deepvariant/dv_utils.py"", line 367, in get_shape_and_channels_from_json. example_info = json.load(f). File ""/usr/lib/python3.8/json/__init__.py"", line 293, in load. return loads(fp.read(),. File ""/usr/lib/python3.8/json/__init__.py"", line 357, in loads. return _default_decoder.decode(s). File ""/usr/lib/python3.8/json/decoder.py"", line 337, in decode. obj, end = self",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:35,energy efficiency,model,model,35,"No output vcf obtained from custom model; **ISSUE**. First of all, I found DeepVariant to be a very good and innovative tool. I'm considering including it in my exome analysis pipeline. I followed the tutorial (DeepVariant worked correctly with the Complete Genomics model), and I created my own model using Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:267,energy efficiency,model,model,267,"No output vcf obtained from custom model; **ISSUE**. First of all, I found DeepVariant to be a very good and innovative tool. I'm considering including it in my exome analysis pipeline. I followed the tutorial (DeepVariant worked correctly with the Complete Genomics model), and I created my own model using Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:296,energy efficiency,model,model,296,"No output vcf obtained from custom model; **ISSUE**. First of all, I found DeepVariant to be a very good and innovative tool. I'm considering including it in my exome analysis pipeline. I followed the tutorial (DeepVariant worked correctly with the Complete Genomics model), and I created my own model using Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:499,energy efficiency,model,model,499,"No output vcf obtained from custom model; **ISSUE**. First of all, I found DeepVariant to be a very good and innovative tool. I'm considering including it in my exome analysis pipeline. I followed the tutorial (DeepVariant worked correctly with the Complete Genomics model), and I created my own model using Genome in a Bottle samples. To do this, I sequenced the same reference sample three times to use each BAM file for training, validation, and testing. I didn't encounter any errors during the model creation process, but when I tried to test it, the process got stuck at the call_variants step. **Setup**. - Operating system: Ubuntu 22.04.4 LTS. - DeepVariant version:1.6.1. - Installation method:docker. - Type of data: MGI DNBSEQ 400, exome sequencing. **Steps to reproduce:**. - Command:. _Create examples for trainning set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/26_r_groups.bam"" --examples ""/output/training_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed""`. _Create examples for validation set_. `sudo docker run -v ""${PWD}/input"":""/input"" -v ""${PWD}/REF"":""/ref"" -v ""${PWD}""/output:""/output"" google/deepvariant:""1.6.1"" make_examples --mode training --ref ""/ref/GRCh38.p14.genome.fa"" --reads ""/input/27_r_groups.bam"" --examples ""/output/validation_set.gz"" --truth_variants ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.vcf.gz"" --confident_regions ""/ref/HG001_GRCh38_1_22_v4.2.1_benchmark_ROCHE.bed"" `. _Trainning Shuffling_. `python3 scripts/shuffle_tfrecords_beam.py --input_pattern_list=output/training_set.gz --output_pattern_prefix=""output/training_shuffled"" --output_dataset_name=""26"" --output_dataset_config_pbtxt=""output/training.pbtxt"" --job_name=shuffle-tfrecords`. _Validation Shuffling_. `python3 scripts/shuf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
