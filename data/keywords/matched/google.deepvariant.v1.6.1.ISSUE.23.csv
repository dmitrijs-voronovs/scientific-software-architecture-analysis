id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/google/deepvariant/issues/812:6231,safety,modul,module,6231,"vcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. 	--intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. 	--num_shards=12. ```. Error:. ```. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 15, in <module>. from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/attr_value_pb2.py"", line 15, in <module>. from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/tensor_pb2.py"", line 15, in <module>. from tensorflow.core.framework import resource_handle_pb2 as tensorflow_dot_core_dot_framework_dot_resource__handle__pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/resource_handle_pb2.py"", line 16, in <module>. from tensorflow.core.framework import types_pb2 as tensorflow_dot_core_dot_framework_dot_types__pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/types_pb2.py"", line 71, in <module>. _SERIALIZEDDTYPE = DESCRIPTOR.message_types_by_name['SerializedDType']. KeyError: 'SerializedDType'. ```. **Any additional context:** Some other issues suggested that the cause may be related to using singularity. I don't really have a choice in that, unfortunately. .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/812
https://github.com/google/deepvariant/issues/812:6471,safety,modul,module,6471,"vcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. 	--intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. 	--num_shards=12. ```. Error:. ```. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 15, in <module>. from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/attr_value_pb2.py"", line 15, in <module>. from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/tensor_pb2.py"", line 15, in <module>. from tensorflow.core.framework import resource_handle_pb2 as tensorflow_dot_core_dot_framework_dot_resource__handle__pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/resource_handle_pb2.py"", line 16, in <module>. from tensorflow.core.framework import types_pb2 as tensorflow_dot_core_dot_framework_dot_types__pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/types_pb2.py"", line 71, in <module>. _SERIALIZEDDTYPE = DESCRIPTOR.message_types_by_name['SerializedDType']. KeyError: 'SerializedDType'. ```. **Any additional context:** Some other issues suggested that the cause may be related to using singularity. I don't really have a choice in that, unfortunately. .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/812
https://github.com/google/deepvariant/issues/812:6680,safety,modul,module,6680,"vcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. 	--intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. 	--num_shards=12. ```. Error:. ```. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 15, in <module>. from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/attr_value_pb2.py"", line 15, in <module>. from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/tensor_pb2.py"", line 15, in <module>. from tensorflow.core.framework import resource_handle_pb2 as tensorflow_dot_core_dot_framework_dot_resource__handle__pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/resource_handle_pb2.py"", line 16, in <module>. from tensorflow.core.framework import types_pb2 as tensorflow_dot_core_dot_framework_dot_types__pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/types_pb2.py"", line 71, in <module>. _SERIALIZEDDTYPE = DESCRIPTOR.message_types_by_name['SerializedDType']. KeyError: 'SerializedDType'. ```. **Any additional context:** Some other issues suggested that the cause may be related to using singularity. I don't really have a choice in that, unfortunately. .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/812
https://github.com/google/deepvariant/issues/812:449,security,LOG,LOGO,449,"Dynamic cast failed; DeepVariant fails to run with test data, giving error:. ""RuntimeError: PythonNext() argument read is not valid: Dynamic cast failed"" . **Setup**. running from HPC. OS info:. `cat /etc/os-release`. output:. ```. NAME=""AlmaLinux"". VERSION=""9.3 (Shamrock Pampas Cat)"". ID=""almalinux"". ID_LIKE=""rhel centos fedora"". VERSION_ID=""9.3"". PLATFORM_ID=""platform:el9"". PRETTY_NAME=""AlmaLinux 9.3 (Shamrock Pampas Cat)"". ANSI_COLOR=""0;34"". LOGO=""fedora-logo-icon"". CPE_NAME=""cpe:/o:almalinux:almalinux:9::baseos"". HOME_URL=""https://almalinux.org/"". DOCUMENTATION_URL=""https://wiki.almalinux.org/"". BUG_REPORT_URL=""https://bugs.almalinux.org/"". ALMALINUX_MANTISBT_PROJECT=""AlmaLinux-9"". ALMALINUX_MANTISBT_PROJECT_VERSION=""9.3"". REDHAT_SUPPORT_PRODUCT=""AlmaLinux"". REDHAT_SUPPORT_PRODUCT_VERSION=""9.3"". ```. - DeepVariant version: **1.6.1**. - Installation method (Docker, built from source, etc.): **Docker**. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) **Test data provided in documentation.** . **Steps to reproduce:**. - Command: . ``` . run_deepvariant --model_type=WGS \. 	--ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. 	--reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. 	--regions ""chr20:10,000,000-10,010,000"" \. 	--output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. 	--intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. 	--num_shards=12. ```. - Error trace: (if applicable). ```. I0423 14:28:39.396079 139638090712896 make_examples_core.py:301] Task 0/12: Overhead for preparing inputs: 0 seconds. 2024-04-23 14:28:39.402994: W ./third_party/nucleus/util/proto_clif_converter.h:75] Failed to cast type N6google8protobuf14DynamicMessageE. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rrr7jr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/812
https://github.com/google/deepvariant/issues/812:462,security,log,logo-icon,462,"Dynamic cast failed; DeepVariant fails to run with test data, giving error:. ""RuntimeError: PythonNext() argument read is not valid: Dynamic cast failed"" . **Setup**. running from HPC. OS info:. `cat /etc/os-release`. output:. ```. NAME=""AlmaLinux"". VERSION=""9.3 (Shamrock Pampas Cat)"". ID=""almalinux"". ID_LIKE=""rhel centos fedora"". VERSION_ID=""9.3"". PLATFORM_ID=""platform:el9"". PRETTY_NAME=""AlmaLinux 9.3 (Shamrock Pampas Cat)"". ANSI_COLOR=""0;34"". LOGO=""fedora-logo-icon"". CPE_NAME=""cpe:/o:almalinux:almalinux:9::baseos"". HOME_URL=""https://almalinux.org/"". DOCUMENTATION_URL=""https://wiki.almalinux.org/"". BUG_REPORT_URL=""https://bugs.almalinux.org/"". ALMALINUX_MANTISBT_PROJECT=""AlmaLinux-9"". ALMALINUX_MANTISBT_PROJECT_VERSION=""9.3"". REDHAT_SUPPORT_PRODUCT=""AlmaLinux"". REDHAT_SUPPORT_PRODUCT_VERSION=""9.3"". ```. - DeepVariant version: **1.6.1**. - Installation method (Docker, built from source, etc.): **Docker**. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) **Test data provided in documentation.** . **Steps to reproduce:**. - Command: . ``` . run_deepvariant --model_type=WGS \. 	--ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. 	--reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. 	--regions ""chr20:10,000,000-10,010,000"" \. 	--output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. 	--intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. 	--num_shards=12. ```. - Error trace: (if applicable). ```. I0423 14:28:39.396079 139638090712896 make_examples_core.py:301] Task 0/12: Overhead for preparing inputs: 0 seconds. 2024-04-23 14:28:39.402994: W ./third_party/nucleus/util/proto_clif_converter.h:75] Failed to cast type N6google8protobuf14DynamicMessageE. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rrr7jr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/812
https://github.com/google/deepvariant/issues/812:51,testability,test,test,51,"Dynamic cast failed; DeepVariant fails to run with test data, giving error:. ""RuntimeError: PythonNext() argument read is not valid: Dynamic cast failed"" . **Setup**. running from HPC. OS info:. `cat /etc/os-release`. output:. ```. NAME=""AlmaLinux"". VERSION=""9.3 (Shamrock Pampas Cat)"". ID=""almalinux"". ID_LIKE=""rhel centos fedora"". VERSION_ID=""9.3"". PLATFORM_ID=""platform:el9"". PRETTY_NAME=""AlmaLinux 9.3 (Shamrock Pampas Cat)"". ANSI_COLOR=""0;34"". LOGO=""fedora-logo-icon"". CPE_NAME=""cpe:/o:almalinux:almalinux:9::baseos"". HOME_URL=""https://almalinux.org/"". DOCUMENTATION_URL=""https://wiki.almalinux.org/"". BUG_REPORT_URL=""https://bugs.almalinux.org/"". ALMALINUX_MANTISBT_PROJECT=""AlmaLinux-9"". ALMALINUX_MANTISBT_PROJECT_VERSION=""9.3"". REDHAT_SUPPORT_PRODUCT=""AlmaLinux"". REDHAT_SUPPORT_PRODUCT_VERSION=""9.3"". ```. - DeepVariant version: **1.6.1**. - Installation method (Docker, built from source, etc.): **Docker**. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) **Test data provided in documentation.** . **Steps to reproduce:**. - Command: . ``` . run_deepvariant --model_type=WGS \. 	--ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. 	--reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. 	--regions ""chr20:10,000,000-10,010,000"" \. 	--output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. 	--intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. 	--num_shards=12. ```. - Error trace: (if applicable). ```. I0423 14:28:39.396079 139638090712896 make_examples_core.py:301] Task 0/12: Overhead for preparing inputs: 0 seconds. 2024-04-23 14:28:39.402994: W ./third_party/nucleus/util/proto_clif_converter.h:75] Failed to cast type N6google8protobuf14DynamicMessageE. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rrr7jr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/812
https://github.com/google/deepvariant/issues/812:449,testability,LOG,LOGO,449,"Dynamic cast failed; DeepVariant fails to run with test data, giving error:. ""RuntimeError: PythonNext() argument read is not valid: Dynamic cast failed"" . **Setup**. running from HPC. OS info:. `cat /etc/os-release`. output:. ```. NAME=""AlmaLinux"". VERSION=""9.3 (Shamrock Pampas Cat)"". ID=""almalinux"". ID_LIKE=""rhel centos fedora"". VERSION_ID=""9.3"". PLATFORM_ID=""platform:el9"". PRETTY_NAME=""AlmaLinux 9.3 (Shamrock Pampas Cat)"". ANSI_COLOR=""0;34"". LOGO=""fedora-logo-icon"". CPE_NAME=""cpe:/o:almalinux:almalinux:9::baseos"". HOME_URL=""https://almalinux.org/"". DOCUMENTATION_URL=""https://wiki.almalinux.org/"". BUG_REPORT_URL=""https://bugs.almalinux.org/"". ALMALINUX_MANTISBT_PROJECT=""AlmaLinux-9"". ALMALINUX_MANTISBT_PROJECT_VERSION=""9.3"". REDHAT_SUPPORT_PRODUCT=""AlmaLinux"". REDHAT_SUPPORT_PRODUCT_VERSION=""9.3"". ```. - DeepVariant version: **1.6.1**. - Installation method (Docker, built from source, etc.): **Docker**. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) **Test data provided in documentation.** . **Steps to reproduce:**. - Command: . ``` . run_deepvariant --model_type=WGS \. 	--ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. 	--reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. 	--regions ""chr20:10,000,000-10,010,000"" \. 	--output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. 	--intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. 	--num_shards=12. ```. - Error trace: (if applicable). ```. I0423 14:28:39.396079 139638090712896 make_examples_core.py:301] Task 0/12: Overhead for preparing inputs: 0 seconds. 2024-04-23 14:28:39.402994: W ./third_party/nucleus/util/proto_clif_converter.h:75] Failed to cast type N6google8protobuf14DynamicMessageE. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rrr7jr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/812
https://github.com/google/deepvariant/issues/812:462,testability,log,logo-icon,462,"Dynamic cast failed; DeepVariant fails to run with test data, giving error:. ""RuntimeError: PythonNext() argument read is not valid: Dynamic cast failed"" . **Setup**. running from HPC. OS info:. `cat /etc/os-release`. output:. ```. NAME=""AlmaLinux"". VERSION=""9.3 (Shamrock Pampas Cat)"". ID=""almalinux"". ID_LIKE=""rhel centos fedora"". VERSION_ID=""9.3"". PLATFORM_ID=""platform:el9"". PRETTY_NAME=""AlmaLinux 9.3 (Shamrock Pampas Cat)"". ANSI_COLOR=""0;34"". LOGO=""fedora-logo-icon"". CPE_NAME=""cpe:/o:almalinux:almalinux:9::baseos"". HOME_URL=""https://almalinux.org/"". DOCUMENTATION_URL=""https://wiki.almalinux.org/"". BUG_REPORT_URL=""https://bugs.almalinux.org/"". ALMALINUX_MANTISBT_PROJECT=""AlmaLinux-9"". ALMALINUX_MANTISBT_PROJECT_VERSION=""9.3"". REDHAT_SUPPORT_PRODUCT=""AlmaLinux"". REDHAT_SUPPORT_PRODUCT_VERSION=""9.3"". ```. - DeepVariant version: **1.6.1**. - Installation method (Docker, built from source, etc.): **Docker**. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) **Test data provided in documentation.** . **Steps to reproduce:**. - Command: . ``` . run_deepvariant --model_type=WGS \. 	--ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. 	--reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. 	--regions ""chr20:10,000,000-10,010,000"" \. 	--output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. 	--intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. 	--num_shards=12. ```. - Error trace: (if applicable). ```. I0423 14:28:39.396079 139638090712896 make_examples_core.py:301] Task 0/12: Overhead for preparing inputs: 0 seconds. 2024-04-23 14:28:39.402994: W ./third_party/nucleus/util/proto_clif_converter.h:75] Failed to cast type N6google8protobuf14DynamicMessageE. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rrr7jr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/812
https://github.com/google/deepvariant/issues/812:947,testability,instrument,instrument,947,"Dynamic cast failed; DeepVariant fails to run with test data, giving error:. ""RuntimeError: PythonNext() argument read is not valid: Dynamic cast failed"" . **Setup**. running from HPC. OS info:. `cat /etc/os-release`. output:. ```. NAME=""AlmaLinux"". VERSION=""9.3 (Shamrock Pampas Cat)"". ID=""almalinux"". ID_LIKE=""rhel centos fedora"". VERSION_ID=""9.3"". PLATFORM_ID=""platform:el9"". PRETTY_NAME=""AlmaLinux 9.3 (Shamrock Pampas Cat)"". ANSI_COLOR=""0;34"". LOGO=""fedora-logo-icon"". CPE_NAME=""cpe:/o:almalinux:almalinux:9::baseos"". HOME_URL=""https://almalinux.org/"". DOCUMENTATION_URL=""https://wiki.almalinux.org/"". BUG_REPORT_URL=""https://bugs.almalinux.org/"". ALMALINUX_MANTISBT_PROJECT=""AlmaLinux-9"". ALMALINUX_MANTISBT_PROJECT_VERSION=""9.3"". REDHAT_SUPPORT_PRODUCT=""AlmaLinux"". REDHAT_SUPPORT_PRODUCT_VERSION=""9.3"". ```. - DeepVariant version: **1.6.1**. - Installation method (Docker, built from source, etc.): **Docker**. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) **Test data provided in documentation.** . **Steps to reproduce:**. - Command: . ``` . run_deepvariant --model_type=WGS \. 	--ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. 	--reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. 	--regions ""chr20:10,000,000-10,010,000"" \. 	--output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. 	--intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. 	--num_shards=12. ```. - Error trace: (if applicable). ```. I0423 14:28:39.396079 139638090712896 make_examples_core.py:301] Task 0/12: Overhead for preparing inputs: 0 seconds. 2024-04-23 14:28:39.402994: W ./third_party/nucleus/util/proto_clif_converter.h:75] Failed to cast type N6google8protobuf14DynamicMessageE. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rrr7jr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/812
https://github.com/google/deepvariant/issues/812:1030,testability,Test,Test,1030," fails to run with test data, giving error:. ""RuntimeError: PythonNext() argument read is not valid: Dynamic cast failed"" . **Setup**. running from HPC. OS info:. `cat /etc/os-release`. output:. ```. NAME=""AlmaLinux"". VERSION=""9.3 (Shamrock Pampas Cat)"". ID=""almalinux"". ID_LIKE=""rhel centos fedora"". VERSION_ID=""9.3"". PLATFORM_ID=""platform:el9"". PRETTY_NAME=""AlmaLinux 9.3 (Shamrock Pampas Cat)"". ANSI_COLOR=""0;34"". LOGO=""fedora-logo-icon"". CPE_NAME=""cpe:/o:almalinux:almalinux:9::baseos"". HOME_URL=""https://almalinux.org/"". DOCUMENTATION_URL=""https://wiki.almalinux.org/"". BUG_REPORT_URL=""https://bugs.almalinux.org/"". ALMALINUX_MANTISBT_PROJECT=""AlmaLinux-9"". ALMALINUX_MANTISBT_PROJECT_VERSION=""9.3"". REDHAT_SUPPORT_PRODUCT=""AlmaLinux"". REDHAT_SUPPORT_PRODUCT_VERSION=""9.3"". ```. - DeepVariant version: **1.6.1**. - Installation method (Docker, built from source, etc.): **Docker**. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) **Test data provided in documentation.** . **Steps to reproduce:**. - Command: . ``` . run_deepvariant --model_type=WGS \. 	--ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. 	--reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. 	--regions ""chr20:10,000,000-10,010,000"" \. 	--output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. 	--intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. 	--num_shards=12. ```. - Error trace: (if applicable). ```. I0423 14:28:39.396079 139638090712896 make_examples_core.py:301] Task 0/12: Overhead for preparing inputs: 0 seconds. 2024-04-23 14:28:39.402994: W ./third_party/nucleus/util/proto_clif_converter.h:75] Failed to cast type N6google8protobuf14DynamicMessageE. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/absl_py/absl/app.py""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/812
https://github.com/google/deepvariant/issues/812:1189,testability,unit,unittest,1189,". `cat /etc/os-release`. output:. ```. NAME=""AlmaLinux"". VERSION=""9.3 (Shamrock Pampas Cat)"". ID=""almalinux"". ID_LIKE=""rhel centos fedora"". VERSION_ID=""9.3"". PLATFORM_ID=""platform:el9"". PRETTY_NAME=""AlmaLinux 9.3 (Shamrock Pampas Cat)"". ANSI_COLOR=""0;34"". LOGO=""fedora-logo-icon"". CPE_NAME=""cpe:/o:almalinux:almalinux:9::baseos"". HOME_URL=""https://almalinux.org/"". DOCUMENTATION_URL=""https://wiki.almalinux.org/"". BUG_REPORT_URL=""https://bugs.almalinux.org/"". ALMALINUX_MANTISBT_PROJECT=""AlmaLinux-9"". ALMALINUX_MANTISBT_PROJECT_VERSION=""9.3"". REDHAT_SUPPORT_PRODUCT=""AlmaLinux"". REDHAT_SUPPORT_PRODUCT_VERSION=""9.3"". ```. - DeepVariant version: **1.6.1**. - Installation method (Docker, built from source, etc.): **Docker**. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) **Test data provided in documentation.** . **Steps to reproduce:**. - Command: . ``` . run_deepvariant --model_type=WGS \. 	--ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. 	--reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. 	--regions ""chr20:10,000,000-10,010,000"" \. 	--output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. 	--intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. 	--num_shards=12. ```. - Error trace: (if applicable). ```. I0423 14:28:39.396079 139638090712896 make_examples_core.py:301] Task 0/12: Overhead for preparing inputs: 0 seconds. 2024-04-23 14:28:39.402994: W ./third_party/nucleus/util/proto_clif_converter.h:75] Failed to cast type N6google8protobuf14DynamicMessageE. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File """,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/812
https://github.com/google/deepvariant/issues/812:1509,testability,trace,trace,1509,"::baseos"". HOME_URL=""https://almalinux.org/"". DOCUMENTATION_URL=""https://wiki.almalinux.org/"". BUG_REPORT_URL=""https://bugs.almalinux.org/"". ALMALINUX_MANTISBT_PROJECT=""AlmaLinux-9"". ALMALINUX_MANTISBT_PROJECT_VERSION=""9.3"". REDHAT_SUPPORT_PRODUCT=""AlmaLinux"". REDHAT_SUPPORT_PRODUCT_VERSION=""9.3"". ```. - DeepVariant version: **1.6.1**. - Installation method (Docker, built from source, etc.): **Docker**. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) **Test data provided in documentation.** . **Steps to reproduce:**. - Command: . ``` . run_deepvariant --model_type=WGS \. 	--ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. 	--reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. 	--regions ""chr20:10,000,000-10,010,000"" \. 	--output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. 	--intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. 	--num_shards=12. ```. - Error trace: (if applicable). ```. I0423 14:28:39.396079 139638090712896 make_examples_core.py:301] Task 0/12: Overhead for preparing inputs: 0 seconds. 2024-04-23 14:28:39.402994: W ./third_party/nucleus/util/proto_clif_converter.h:75] Failed to cast type N6google8protobuf14DynamicMessageE. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838, in make_examples_runner. region_processor.pr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/812
https://github.com/google/deepvariant/issues/812:1796,testability,Trace,Traceback,1796,"ON=""9.3"". ```. - DeepVariant version: **1.6.1**. - Installation method (Docker, built from source, etc.): **Docker**. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) **Test data provided in documentation.** . **Steps to reproduce:**. - Command: . ``` . run_deepvariant --model_type=WGS \. 	--ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. 	--reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. 	--regions ""chr20:10,000,000-10,010,000"" \. 	--output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. 	--intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. 	--num_shards=12. ```. - Error trace: (if applicable). ```. I0423 14:28:39.396079 139638090712896 make_examples_core.py:301] Task 0/12: Overhead for preparing inputs: 0 seconds. 2024-04-23 14:28:39.402994: W ./third_party/nucleus/util/proto_clif_converter.h:75] Failed to cast type N6google8protobuf14DynamicMessageE. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838, in make_examples_runner. region_processor.process(region, region_n). File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 1695, in process. sample_reads = self.region_reads_norealign(. File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/deepvariant/make_examples_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/812
https://github.com/google/deepvariant/issues/812:3806,testability,test,testdata,3806," line 1817, in region_reads_norealign. reads = reservoir_sample_reads(. File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 976, in reservoir_sample_reads. return utils.reservoir_sample(iterable_of_reads, k, random). File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/third_party/nucleus/util/utils.py"", line 117, in reservoir_sample. for i, item in enumerate(iterable):. File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 95, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 154, in _raw_next. not_done = self._cc_iterable.PythonNext(record). RuntimeError: PythonNext() argument read is not valid: Dynamic cast failed. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/cjm124/SWFst/DeepVariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads /work/cjm124/SWFst/DeepVariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --examples /work/cjm124/SWFst/DeepVariant/quickstart-output/intermediate_results_dir/make_examples.tfrecord@12.gz --channels insert_size --gvcf /work/cjm124/SWFst/DeepVariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@12.gz --regions chr20:10,000,000-10,010,000 --task 0. ```. **Does the quick start test work on your system?** No. Is there any way to reproduce the issue by using the quick start? . I first observed this issue when trying to use my own data, but have the same issue with quickstart and above command. I found a prior issue (#559) and tried the suggested solution of explicitly installing nucleus. The commands and error from that is below:. commands:. ```. singularity exec DeepVariant_1.6.1.sif bash. pip install --user google-nucleus. run_deepvariant --model_type=WGS \. 	--ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. 	--reads=""${I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/812
https://github.com/google/deepvariant/issues/812:3831,testability,unit,unittest,3831,"ds_norealign. reads = reservoir_sample_reads(. File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 976, in reservoir_sample_reads. return utils.reservoir_sample(iterable_of_reads, k, random). File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/third_party/nucleus/util/utils.py"", line 117, in reservoir_sample. for i, item in enumerate(iterable):. File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 95, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 154, in _raw_next. not_done = self._cc_iterable.PythonNext(record). RuntimeError: PythonNext() argument read is not valid: Dynamic cast failed. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/cjm124/SWFst/DeepVariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads /work/cjm124/SWFst/DeepVariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --examples /work/cjm124/SWFst/DeepVariant/quickstart-output/intermediate_results_dir/make_examples.tfrecord@12.gz --channels insert_size --gvcf /work/cjm124/SWFst/DeepVariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@12.gz --regions chr20:10,000,000-10,010,000 --task 0. ```. **Does the quick start test work on your system?** No. Is there any way to reproduce the issue by using the quick start? . I first observed this issue when trying to use my own data, but have the same issue with quickstart and above command. I found a prior issue (#559) and tried the suggested solution of explicitly installing nucleus. The commands and error from that is below:. commands:. ```. singularity exec DeepVariant_1.6.1.sif bash. pip install --user google-nucleus. run_deepvariant --model_type=WGS \. 	--ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. 	--reads=""${INPUT_DIR}""/NA12878_S1.chr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/812
https://github.com/google/deepvariant/issues/812:3896,testability,test,testdata,3896,"unfiles_rrr7jrkj/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 976, in reservoir_sample_reads. return utils.reservoir_sample(iterable_of_reads, k, random). File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/third_party/nucleus/util/utils.py"", line 117, in reservoir_sample. for i, item in enumerate(iterable):. File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 95, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 154, in _raw_next. not_done = self._cc_iterable.PythonNext(record). RuntimeError: PythonNext() argument read is not valid: Dynamic cast failed. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/cjm124/SWFst/DeepVariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads /work/cjm124/SWFst/DeepVariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --examples /work/cjm124/SWFst/DeepVariant/quickstart-output/intermediate_results_dir/make_examples.tfrecord@12.gz --channels insert_size --gvcf /work/cjm124/SWFst/DeepVariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@12.gz --regions chr20:10,000,000-10,010,000 --task 0. ```. **Does the quick start test work on your system?** No. Is there any way to reproduce the issue by using the quick start? . I first observed this issue when trying to use my own data, but have the same issue with quickstart and above command. I found a prior issue (#559) and tried the suggested solution of explicitly installing nucleus. The commands and error from that is below:. commands:. ```. singularity exec DeepVariant_1.6.1.sif bash. pip install --user google-nucleus. run_deepvariant --model_type=WGS \. 	--ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. 	--reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. 	--regions ""chr20:10,000,000-10,010,000"" \. 	",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/812
https://github.com/google/deepvariant/issues/812:4250,testability,test,test,4250,". File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 95, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 154, in _raw_next. not_done = self._cc_iterable.PythonNext(record). RuntimeError: PythonNext() argument read is not valid: Dynamic cast failed. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/cjm124/SWFst/DeepVariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads /work/cjm124/SWFst/DeepVariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --examples /work/cjm124/SWFst/DeepVariant/quickstart-output/intermediate_results_dir/make_examples.tfrecord@12.gz --channels insert_size --gvcf /work/cjm124/SWFst/DeepVariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@12.gz --regions chr20:10,000,000-10,010,000 --task 0. ```. **Does the quick start test work on your system?** No. Is there any way to reproduce the issue by using the quick start? . I first observed this issue when trying to use my own data, but have the same issue with quickstart and above command. I found a prior issue (#559) and tried the suggested solution of explicitly installing nucleus. The commands and error from that is below:. commands:. ```. singularity exec DeepVariant_1.6.1.sif bash. pip install --user google-nucleus. run_deepvariant --model_type=WGS \. 	--ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. 	--reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. 	--regions ""chr20:10,000,000-10,010,000"" \. 	--output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. 	--intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. 	--num_shards=12. ```. Error:. ```. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/812
https://github.com/google/deepvariant/issues/812:4358,testability,observ,observed,4358," line 95, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 154, in _raw_next. not_done = self._cc_iterable.PythonNext(record). RuntimeError: PythonNext() argument read is not valid: Dynamic cast failed. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/cjm124/SWFst/DeepVariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads /work/cjm124/SWFst/DeepVariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --examples /work/cjm124/SWFst/DeepVariant/quickstart-output/intermediate_results_dir/make_examples.tfrecord@12.gz --channels insert_size --gvcf /work/cjm124/SWFst/DeepVariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@12.gz --regions chr20:10,000,000-10,010,000 --task 0. ```. **Does the quick start test work on your system?** No. Is there any way to reproduce the issue by using the quick start? . I first observed this issue when trying to use my own data, but have the same issue with quickstart and above command. I found a prior issue (#559) and tried the suggested solution of explicitly installing nucleus. The commands and error from that is below:. commands:. ```. singularity exec DeepVariant_1.6.1.sif bash. pip install --user google-nucleus. run_deepvariant --model_type=WGS \. 	--ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. 	--reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. 	--regions ""chr20:10,000,000-10,010,000"" \. 	--output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. 	--intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. 	--num_shards=12. ```. Error:. ```. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/812
https://github.com/google/deepvariant/issues/812:4779,testability,unit,unittest,4779,"DeepVariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads /work/cjm124/SWFst/DeepVariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --examples /work/cjm124/SWFst/DeepVariant/quickstart-output/intermediate_results_dir/make_examples.tfrecord@12.gz --channels insert_size --gvcf /work/cjm124/SWFst/DeepVariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@12.gz --regions chr20:10,000,000-10,010,000 --task 0. ```. **Does the quick start test work on your system?** No. Is there any way to reproduce the issue by using the quick start? . I first observed this issue when trying to use my own data, but have the same issue with quickstart and above command. I found a prior issue (#559) and tried the suggested solution of explicitly installing nucleus. The commands and error from that is below:. commands:. ```. singularity exec DeepVariant_1.6.1.sif bash. pip install --user google-nucleus. run_deepvariant --model_type=WGS \. 	--ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. 	--reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. 	--regions ""chr20:10,000,000-10,010,000"" \. 	--output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. 	--intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. 	--num_shards=12. ```. Error:. ```. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", li",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/812
https://github.com/google/deepvariant/issues/812:5104,testability,Trace,Traceback,5104,"t/quickstart-output/intermediate_results_dir/gvcf.tfrecord@12.gz --regions chr20:10,000,000-10,010,000 --task 0. ```. **Does the quick start test work on your system?** No. Is there any way to reproduce the issue by using the quick start? . I first observed this issue when trying to use my own data, but have the same issue with quickstart and above command. I found a prior issue (#559) and tried the suggested solution of explicitly installing nucleus. The commands and error from that is below:. commands:. ```. singularity exec DeepVariant_1.6.1.sif bash. pip install --user google-nucleus. run_deepvariant --model_type=WGS \. 	--ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. 	--reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. 	--regions ""chr20:10,000,000-10,010,000"" \. 	--output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. 	--intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. 	--num_shards=12. ```. Error:. ```. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 15, in <module>. from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/attr_value_pb2.py"", line 15, in <module>. from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_frame",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/812
https://github.com/google/deepvariant/issues/812:5527,testability,context,context,5527,"of explicitly installing nucleus. The commands and error from that is below:. commands:. ```. singularity exec DeepVariant_1.6.1.sif bash. pip install --user google-nucleus. run_deepvariant --model_type=WGS \. 	--ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. 	--reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. 	--regions ""chr20:10,000,000-10,010,000"" \. 	--output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. 	--intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. 	--num_shards=12. ```. Error:. ```. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 15, in <module>. from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/attr_value_pb2.py"", line 15, in <module>. from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/tensor_pb2.py"", line 15, in <module>. from tensorflow.core.framework import resource_handle_pb2 as tensorflow_dot_core_dot_framework_dot_resource__handle__pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/resource_handle_pb2.py"", line 16, in <module>. from tensorflow.core.framework import types_pb2 as ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/812
https://github.com/google/deepvariant/issues/812:5605,testability,context,context,5605,"commands:. ```. singularity exec DeepVariant_1.6.1.sif bash. pip install --user google-nucleus. run_deepvariant --model_type=WGS \. 	--ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. 	--reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. 	--regions ""chr20:10,000,000-10,010,000"" \. 	--output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. 	--intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. 	--num_shards=12. ```. Error:. ```. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 15, in <module>. from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/attr_value_pb2.py"", line 15, in <module>. from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/tensor_pb2.py"", line 15, in <module>. from tensorflow.core.framework import resource_handle_pb2 as tensorflow_dot_core_dot_framework_dot_resource__handle__pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/resource_handle_pb2.py"", line 16, in <module>. from tensorflow.core.framework import types_pb2 as tensorflow_dot_core_dot_framework_dot_types__pb2. File ""/usr/local/lib/python3",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/812
https://github.com/google/deepvariant/issues/812:6812,testability,context,context,6812,"vcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. 	--intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. 	--num_shards=12. ```. Error:. ```. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 15, in <module>. from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/attr_value_pb2.py"", line 15, in <module>. from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/tensor_pb2.py"", line 15, in <module>. from tensorflow.core.framework import resource_handle_pb2 as tensorflow_dot_core_dot_framework_dot_resource__handle__pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/resource_handle_pb2.py"", line 16, in <module>. from tensorflow.core.framework import types_pb2 as tensorflow_dot_core_dot_framework_dot_types__pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/types_pb2.py"", line 71, in <module>. _SERIALIZEDDTYPE = DESCRIPTOR.message_types_by_name['SerializedDType']. KeyError: 'SerializedDType'. ```. **Any additional context:** Some other issues suggested that the cause may be related to using singularity. I don't really have a choice in that, unfortunately. .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/812
https://github.com/google/deepvariant/issues/812:69,usability,error,error,69,"Dynamic cast failed; DeepVariant fails to run with test data, giving error:. ""RuntimeError: PythonNext() argument read is not valid: Dynamic cast failed"" . **Setup**. running from HPC. OS info:. `cat /etc/os-release`. output:. ```. NAME=""AlmaLinux"". VERSION=""9.3 (Shamrock Pampas Cat)"". ID=""almalinux"". ID_LIKE=""rhel centos fedora"". VERSION_ID=""9.3"". PLATFORM_ID=""platform:el9"". PRETTY_NAME=""AlmaLinux 9.3 (Shamrock Pampas Cat)"". ANSI_COLOR=""0;34"". LOGO=""fedora-logo-icon"". CPE_NAME=""cpe:/o:almalinux:almalinux:9::baseos"". HOME_URL=""https://almalinux.org/"". DOCUMENTATION_URL=""https://wiki.almalinux.org/"". BUG_REPORT_URL=""https://bugs.almalinux.org/"". ALMALINUX_MANTISBT_PROJECT=""AlmaLinux-9"". ALMALINUX_MANTISBT_PROJECT_VERSION=""9.3"". REDHAT_SUPPORT_PRODUCT=""AlmaLinux"". REDHAT_SUPPORT_PRODUCT_VERSION=""9.3"". ```. - DeepVariant version: **1.6.1**. - Installation method (Docker, built from source, etc.): **Docker**. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) **Test data provided in documentation.** . **Steps to reproduce:**. - Command: . ``` . run_deepvariant --model_type=WGS \. 	--ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. 	--reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. 	--regions ""chr20:10,000,000-10,010,000"" \. 	--output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. 	--intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. 	--num_shards=12. ```. - Error trace: (if applicable). ```. I0423 14:28:39.396079 139638090712896 make_examples_core.py:301] Task 0/12: Overhead for preparing inputs: 0 seconds. 2024-04-23 14:28:39.402994: W ./third_party/nucleus/util/proto_clif_converter.h:75] Failed to cast type N6google8protobuf14DynamicMessageE. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rrr7jr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/812
https://github.com/google/deepvariant/issues/812:1052,usability,document,documentation,1052,"a, giving error:. ""RuntimeError: PythonNext() argument read is not valid: Dynamic cast failed"" . **Setup**. running from HPC. OS info:. `cat /etc/os-release`. output:. ```. NAME=""AlmaLinux"". VERSION=""9.3 (Shamrock Pampas Cat)"". ID=""almalinux"". ID_LIKE=""rhel centos fedora"". VERSION_ID=""9.3"". PLATFORM_ID=""platform:el9"". PRETTY_NAME=""AlmaLinux 9.3 (Shamrock Pampas Cat)"". ANSI_COLOR=""0;34"". LOGO=""fedora-logo-icon"". CPE_NAME=""cpe:/o:almalinux:almalinux:9::baseos"". HOME_URL=""https://almalinux.org/"". DOCUMENTATION_URL=""https://wiki.almalinux.org/"". BUG_REPORT_URL=""https://bugs.almalinux.org/"". ALMALINUX_MANTISBT_PROJECT=""AlmaLinux-9"". ALMALINUX_MANTISBT_PROJECT_VERSION=""9.3"". REDHAT_SUPPORT_PRODUCT=""AlmaLinux"". REDHAT_SUPPORT_PRODUCT_VERSION=""9.3"". ```. - DeepVariant version: **1.6.1**. - Installation method (Docker, built from source, etc.): **Docker**. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) **Test data provided in documentation.** . **Steps to reproduce:**. - Command: . ``` . run_deepvariant --model_type=WGS \. 	--ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. 	--reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. 	--regions ""chr20:10,000,000-10,010,000"" \. 	--output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. 	--intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. 	--num_shards=12. ```. - Error trace: (if applicable). ```. I0423 14:28:39.396079 139638090712896 make_examples_core.py:301] Task 0/12: Overhead for preparing inputs: 0 seconds. 2024-04-23 14:28:39.402994: W ./third_party/nucleus/util/proto_clif_converter.h:75] Failed to cast type N6google8protobuf14DynamicMessageE. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/absl_py/absl/app.py"", line 312, in run. _run_ma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/812
https://github.com/google/deepvariant/issues/812:1098,usability,Command,Command,1098,"() argument read is not valid: Dynamic cast failed"" . **Setup**. running from HPC. OS info:. `cat /etc/os-release`. output:. ```. NAME=""AlmaLinux"". VERSION=""9.3 (Shamrock Pampas Cat)"". ID=""almalinux"". ID_LIKE=""rhel centos fedora"". VERSION_ID=""9.3"". PLATFORM_ID=""platform:el9"". PRETTY_NAME=""AlmaLinux 9.3 (Shamrock Pampas Cat)"". ANSI_COLOR=""0;34"". LOGO=""fedora-logo-icon"". CPE_NAME=""cpe:/o:almalinux:almalinux:9::baseos"". HOME_URL=""https://almalinux.org/"". DOCUMENTATION_URL=""https://wiki.almalinux.org/"". BUG_REPORT_URL=""https://bugs.almalinux.org/"". ALMALINUX_MANTISBT_PROJECT=""AlmaLinux-9"". ALMALINUX_MANTISBT_PROJECT_VERSION=""9.3"". REDHAT_SUPPORT_PRODUCT=""AlmaLinux"". REDHAT_SUPPORT_PRODUCT_VERSION=""9.3"". ```. - DeepVariant version: **1.6.1**. - Installation method (Docker, built from source, etc.): **Docker**. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) **Test data provided in documentation.** . **Steps to reproduce:**. - Command: . ``` . run_deepvariant --model_type=WGS \. 	--ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. 	--reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. 	--regions ""chr20:10,000,000-10,010,000"" \. 	--output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. 	--intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. 	--num_shards=12. ```. - Error trace: (if applicable). ```. I0423 14:28:39.396079 139638090712896 make_examples_core.py:301] Task 0/12: Overhead for preparing inputs: 0 seconds. 2024-04-23 14:28:39.402994: W ./third_party/nucleus/util/proto_clif_converter.h:75] Failed to cast type N6google8protobuf14DynamicMessageE. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/812
https://github.com/google/deepvariant/issues/812:1503,usability,Error,Error,1503,"inux:9::baseos"". HOME_URL=""https://almalinux.org/"". DOCUMENTATION_URL=""https://wiki.almalinux.org/"". BUG_REPORT_URL=""https://bugs.almalinux.org/"". ALMALINUX_MANTISBT_PROJECT=""AlmaLinux-9"". ALMALINUX_MANTISBT_PROJECT_VERSION=""9.3"". REDHAT_SUPPORT_PRODUCT=""AlmaLinux"". REDHAT_SUPPORT_PRODUCT_VERSION=""9.3"". ```. - DeepVariant version: **1.6.1**. - Installation method (Docker, built from source, etc.): **Docker**. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) **Test data provided in documentation.** . **Steps to reproduce:**. - Command: . ``` . run_deepvariant --model_type=WGS \. 	--ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. 	--reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. 	--regions ""chr20:10,000,000-10,010,000"" \. 	--output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. 	--intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. 	--num_shards=12. ```. - Error trace: (if applicable). ```. I0423 14:28:39.396079 139638090712896 make_examples_core.py:301] Task 0/12: Overhead for preparing inputs: 0 seconds. 2024-04-23 14:28:39.402994: W ./third_party/nucleus/util/proto_clif_converter.h:75] Failed to cast type N6google8protobuf14DynamicMessageE. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838, in make_examples_runner. region_proces",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/812
https://github.com/google/deepvariant/issues/812:1637,usability,input,inputs,1637,"linux.org/"". ALMALINUX_MANTISBT_PROJECT=""AlmaLinux-9"". ALMALINUX_MANTISBT_PROJECT_VERSION=""9.3"". REDHAT_SUPPORT_PRODUCT=""AlmaLinux"". REDHAT_SUPPORT_PRODUCT_VERSION=""9.3"". ```. - DeepVariant version: **1.6.1**. - Installation method (Docker, built from source, etc.): **Docker**. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) **Test data provided in documentation.** . **Steps to reproduce:**. - Command: . ``` . run_deepvariant --model_type=WGS \. 	--ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. 	--reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. 	--regions ""chr20:10,000,000-10,010,000"" \. 	--output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. 	--intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. 	--num_shards=12. ```. - Error trace: (if applicable). ```. I0423 14:28:39.396079 139638090712896 make_examples_core.py:301] Task 0/12: Overhead for preparing inputs: 0 seconds. 2024-04-23 14:28:39.402994: W ./third_party/nucleus/util/proto_clif_converter.h:75] Failed to cast type N6google8protobuf14DynamicMessageE. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 234, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 224, in main. make_examples_core.make_examples_runner(options). File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", line 2838, in make_examples_runner. region_processor.process(region, region_n). File ""/tmp/Bazel.runfiles_rrr7jrkj/runfiles/com_google_deepvariant/deepvariant/make_examples_core.py"", ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/812
https://github.com/google/deepvariant/issues/812:4460,usability,command,command,4460,"s/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 154, in _raw_next. not_done = self._cc_iterable.PythonNext(record). RuntimeError: PythonNext() argument read is not valid: Dynamic cast failed. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/cjm124/SWFst/DeepVariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads /work/cjm124/SWFst/DeepVariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --examples /work/cjm124/SWFst/DeepVariant/quickstart-output/intermediate_results_dir/make_examples.tfrecord@12.gz --channels insert_size --gvcf /work/cjm124/SWFst/DeepVariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@12.gz --regions chr20:10,000,000-10,010,000 --task 0. ```. **Does the quick start test work on your system?** No. Is there any way to reproduce the issue by using the quick start? . I first observed this issue when trying to use my own data, but have the same issue with quickstart and above command. I found a prior issue (#559) and tried the suggested solution of explicitly installing nucleus. The commands and error from that is below:. commands:. ```. singularity exec DeepVariant_1.6.1.sif bash. pip install --user google-nucleus. run_deepvariant --model_type=WGS \. 	--ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. 	--reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. 	--regions ""chr20:10,000,000-10,010,000"" \. 	--output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. 	--intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. 	--num_shards=12. ```. Error:. ```. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/812
https://github.com/google/deepvariant/issues/812:4569,usability,command,commands,4569,"c_iterable.PythonNext(record). RuntimeError: PythonNext() argument read is not valid: Dynamic cast failed. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/cjm124/SWFst/DeepVariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads /work/cjm124/SWFst/DeepVariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --examples /work/cjm124/SWFst/DeepVariant/quickstart-output/intermediate_results_dir/make_examples.tfrecord@12.gz --channels insert_size --gvcf /work/cjm124/SWFst/DeepVariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@12.gz --regions chr20:10,000,000-10,010,000 --task 0. ```. **Does the quick start test work on your system?** No. Is there any way to reproduce the issue by using the quick start? . I first observed this issue when trying to use my own data, but have the same issue with quickstart and above command. I found a prior issue (#559) and tried the suggested solution of explicitly installing nucleus. The commands and error from that is below:. commands:. ```. singularity exec DeepVariant_1.6.1.sif bash. pip install --user google-nucleus. run_deepvariant --model_type=WGS \. 	--ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. 	--reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. 	--regions ""chr20:10,000,000-10,010,000"" \. 	--output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. 	--intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. 	--num_shards=12. ```. Error:. ```. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/812
https://github.com/google/deepvariant/issues/812:4582,usability,error,error,4582,"ythonNext(record). RuntimeError: PythonNext() argument read is not valid: Dynamic cast failed. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/cjm124/SWFst/DeepVariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads /work/cjm124/SWFst/DeepVariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --examples /work/cjm124/SWFst/DeepVariant/quickstart-output/intermediate_results_dir/make_examples.tfrecord@12.gz --channels insert_size --gvcf /work/cjm124/SWFst/DeepVariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@12.gz --regions chr20:10,000,000-10,010,000 --task 0. ```. **Does the quick start test work on your system?** No. Is there any way to reproduce the issue by using the quick start? . I first observed this issue when trying to use my own data, but have the same issue with quickstart and above command. I found a prior issue (#559) and tried the suggested solution of explicitly installing nucleus. The commands and error from that is below:. commands:. ```. singularity exec DeepVariant_1.6.1.sif bash. pip install --user google-nucleus. run_deepvariant --model_type=WGS \. 	--ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. 	--reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. 	--regions ""chr20:10,000,000-10,010,000"" \. 	--output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. 	--intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. 	--num_shards=12. ```. Error:. ```. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tens",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/812
https://github.com/google/deepvariant/issues/812:4609,usability,command,commands,4609,"ror: PythonNext() argument read is not valid: Dynamic cast failed. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/cjm124/SWFst/DeepVariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads /work/cjm124/SWFst/DeepVariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --examples /work/cjm124/SWFst/DeepVariant/quickstart-output/intermediate_results_dir/make_examples.tfrecord@12.gz --channels insert_size --gvcf /work/cjm124/SWFst/DeepVariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@12.gz --regions chr20:10,000,000-10,010,000 --task 0. ```. **Does the quick start test work on your system?** No. Is there any way to reproduce the issue by using the quick start? . I first observed this issue when trying to use my own data, but have the same issue with quickstart and above command. I found a prior issue (#559) and tried the suggested solution of explicitly installing nucleus. The commands and error from that is below:. commands:. ```. singularity exec DeepVariant_1.6.1.sif bash. pip install --user google-nucleus. run_deepvariant --model_type=WGS \. 	--ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. 	--reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. 	--regions ""chr20:10,000,000-10,010,000"" \. 	--output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. 	--intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. 	--num_shards=12. ```. Error:. ```. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/812
https://github.com/google/deepvariant/issues/812:4684,usability,user,user,4684,"el: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /work/cjm124/SWFst/DeepVariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta --reads /work/cjm124/SWFst/DeepVariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam --examples /work/cjm124/SWFst/DeepVariant/quickstart-output/intermediate_results_dir/make_examples.tfrecord@12.gz --channels insert_size --gvcf /work/cjm124/SWFst/DeepVariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@12.gz --regions chr20:10,000,000-10,010,000 --task 0. ```. **Does the quick start test work on your system?** No. Is there any way to reproduce the issue by using the quick start? . I first observed this issue when trying to use my own data, but have the same issue with quickstart and above command. I found a prior issue (#559) and tried the suggested solution of explicitly installing nucleus. The commands and error from that is below:. commands:. ```. singularity exec DeepVariant_1.6.1.sif bash. pip install --user google-nucleus. run_deepvariant --model_type=WGS \. 	--ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. 	--reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. 	--regions ""chr20:10,000,000-10,010,000"" \. 	--output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. 	--intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. 	--num_shards=12. ```. Error:. ```. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/812
https://github.com/google/deepvariant/issues/812:5091,usability,Error,Error,5091,"WFst/DeepVariant/quickstart-output/intermediate_results_dir/gvcf.tfrecord@12.gz --regions chr20:10,000,000-10,010,000 --task 0. ```. **Does the quick start test work on your system?** No. Is there any way to reproduce the issue by using the quick start? . I first observed this issue when trying to use my own data, but have the same issue with quickstart and above command. I found a prior issue (#559) and tried the suggested solution of explicitly installing nucleus. The commands and error from that is below:. commands:. ```. singularity exec DeepVariant_1.6.1.sif bash. pip install --user google-nucleus. run_deepvariant --model_type=WGS \. 	--ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. 	--reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. 	--regions ""chr20:10,000,000-10,010,000"" \. 	--output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. 	--intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. 	--num_shards=12. ```. Error:. ```. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 15, in <module>. from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/attr_value_pb2.py"", line 15, in <module>. from tensorflow.core.framework import tensor_pb2 as tensorflow_dot",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/812
https://github.com/google/deepvariant/issues/812:5350,usability,tool,tools,5350,"irst observed this issue when trying to use my own data, but have the same issue with quickstart and above command. I found a prior issue (#559) and tried the suggested solution of explicitly installing nucleus. The commands and error from that is below:. commands:. ```. singularity exec DeepVariant_1.6.1.sif bash. pip install --user google-nucleus. run_deepvariant --model_type=WGS \. 	--ref=""${INPUT_DIR}""/ucsc.hg19.chr20.unittest.fasta \. 	--reads=""${INPUT_DIR}""/NA12878_S1.chr20.10_10p1mb.bam \. 	--regions ""chr20:10,000,000-10,010,000"" \. 	--output_vcf=""${OUTPUT_DIR}""/output.vcf.gz \. 	--output_gvcf=""${OUTPUT_DIR}""/output.g.vcf.gz \. 	--intermediate_results_dir ""${OUTPUT_DIR}/intermediate_results_dir"" \. 	--num_shards=12. ```. Error:. ```. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 49, in <module>. import tensorflow as tf. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 37, in <module>. from tensorflow.python.tools import module_util as _module_util. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/__init__.py"", line 37, in <module>. from tensorflow.python.eager import context. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py"", line 28, in <module>. from tensorflow.core.framework import function_pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/function_pb2.py"", line 15, in <module>. from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/attr_value_pb2.py"", line 15, in <module>. from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/core/framework/tensor_pb2.py"", line 15, in <module>. from tensorflow.core.framework import resource_handle_pb2 as tensorflow_dot_core_dot_framework_dot_resource__hand",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/812
https://github.com/google/deepvariant/issues/813:144,usability,command,command,144,"question for INDEL variant calling; I want to use DeepVariant to get INDEL variants only, is there a way to achieve that with `run_deepvariant` command . or `make_example` command? Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/813
https://github.com/google/deepvariant/issues/813:172,usability,command,command,172,"question for INDEL variant calling; I want to use DeepVariant to get INDEL variants only, is there a way to achieve that with `run_deepvariant` command . or `make_example` command? Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/813
https://github.com/google/deepvariant/issues/814:599,deployability,Instal,Installation,599,"Question about the time it takes for VC analysis ; Hello, I am trying to make a variant calling analysis with ONT data for Homo Sapiens. However, it is still running even though I started this analysis 6 days ago and it is still making examples. Could anyone help me to understand whether it is normal or I should re-run the analysis? The computer has 64-core Linux. It should be able to run the analysis for nearly one to two days based on my experiences with other variant callers. I would be very happy to get feedbacks from you! . Thanks a lot! Deep Variant/ Variant Calling. BIN_VERSION=1.6.1. Installation via Docker. Homo Sapiens Oxford Nanopore Whole Genome. ![Screenshot 2024-05-01 220709](https://github.com/google/deepvariant/assets/74244954/93bf098a-083d-40f5-ba41-9d876a836be3).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/814
https://github.com/google/deepvariant/issues/814:355,energy efficiency,core,core,355,"Question about the time it takes for VC analysis ; Hello, I am trying to make a variant calling analysis with ONT data for Homo Sapiens. However, it is still running even though I started this analysis 6 days ago and it is still making examples. Could anyone help me to understand whether it is normal or I should re-run the analysis? The computer has 64-core Linux. It should be able to run the analysis for nearly one to two days based on my experiences with other variant callers. I would be very happy to get feedbacks from you! . Thanks a lot! Deep Variant/ Variant Calling. BIN_VERSION=1.6.1. Installation via Docker. Homo Sapiens Oxford Nanopore Whole Genome. ![Screenshot 2024-05-01 220709](https://github.com/google/deepvariant/assets/74244954/93bf098a-083d-40f5-ba41-9d876a836be3).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/814
https://github.com/google/deepvariant/issues/814:19,performance,time,time,19,"Question about the time it takes for VC analysis ; Hello, I am trying to make a variant calling analysis with ONT data for Homo Sapiens. However, it is still running even though I started this analysis 6 days ago and it is still making examples. Could anyone help me to understand whether it is normal or I should re-run the analysis? The computer has 64-core Linux. It should be able to run the analysis for nearly one to two days based on my experiences with other variant callers. I would be very happy to get feedbacks from you! . Thanks a lot! Deep Variant/ Variant Calling. BIN_VERSION=1.6.1. Installation via Docker. Homo Sapiens Oxford Nanopore Whole Genome. ![Screenshot 2024-05-01 220709](https://github.com/google/deepvariant/assets/74244954/93bf098a-083d-40f5-ba41-9d876a836be3).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/814
https://github.com/google/deepvariant/issues/814:270,testability,understand,understand,270,"Question about the time it takes for VC analysis ; Hello, I am trying to make a variant calling analysis with ONT data for Homo Sapiens. However, it is still running even though I started this analysis 6 days ago and it is still making examples. Could anyone help me to understand whether it is normal or I should re-run the analysis? The computer has 64-core Linux. It should be able to run the analysis for nearly one to two days based on my experiences with other variant callers. I would be very happy to get feedbacks from you! . Thanks a lot! Deep Variant/ Variant Calling. BIN_VERSION=1.6.1. Installation via Docker. Homo Sapiens Oxford Nanopore Whole Genome. ![Screenshot 2024-05-01 220709](https://github.com/google/deepvariant/assets/74244954/93bf098a-083d-40f5-ba41-9d876a836be3).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/814
https://github.com/google/deepvariant/issues/814:259,usability,help,help,259,"Question about the time it takes for VC analysis ; Hello, I am trying to make a variant calling analysis with ONT data for Homo Sapiens. However, it is still running even though I started this analysis 6 days ago and it is still making examples. Could anyone help me to understand whether it is normal or I should re-run the analysis? The computer has 64-core Linux. It should be able to run the analysis for nearly one to two days based on my experiences with other variant callers. I would be very happy to get feedbacks from you! . Thanks a lot! Deep Variant/ Variant Calling. BIN_VERSION=1.6.1. Installation via Docker. Homo Sapiens Oxford Nanopore Whole Genome. ![Screenshot 2024-05-01 220709](https://github.com/google/deepvariant/assets/74244954/93bf098a-083d-40f5-ba41-9d876a836be3).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/814
https://github.com/google/deepvariant/issues/814:444,usability,experien,experiences,444,"Question about the time it takes for VC analysis ; Hello, I am trying to make a variant calling analysis with ONT data for Homo Sapiens. However, it is still running even though I started this analysis 6 days ago and it is still making examples. Could anyone help me to understand whether it is normal or I should re-run the analysis? The computer has 64-core Linux. It should be able to run the analysis for nearly one to two days based on my experiences with other variant callers. I would be very happy to get feedbacks from you! . Thanks a lot! Deep Variant/ Variant Calling. BIN_VERSION=1.6.1. Installation via Docker. Homo Sapiens Oxford Nanopore Whole Genome. ![Screenshot 2024-05-01 220709](https://github.com/google/deepvariant/assets/74244954/93bf098a-083d-40f5-ba41-9d876a836be3).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/814
https://github.com/google/deepvariant/issues/814:513,usability,feedback,feedbacks,513,"Question about the time it takes for VC analysis ; Hello, I am trying to make a variant calling analysis with ONT data for Homo Sapiens. However, it is still running even though I started this analysis 6 days ago and it is still making examples. Could anyone help me to understand whether it is normal or I should re-run the analysis? The computer has 64-core Linux. It should be able to run the analysis for nearly one to two days based on my experiences with other variant callers. I would be very happy to get feedbacks from you! . Thanks a lot! Deep Variant/ Variant Calling. BIN_VERSION=1.6.1. Installation via Docker. Homo Sapiens Oxford Nanopore Whole Genome. ![Screenshot 2024-05-01 220709](https://github.com/google/deepvariant/assets/74244954/93bf098a-083d-40f5-ba41-9d876a836be3).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/814
https://github.com/google/deepvariant/issues/815:18,availability,error,error,18,"Merging vcf files error with glnexus:v1.2.7 ; **Have you checked the FAQ? [](https://github.com/google/deepvariant/blob/r1.6.1/docs/deeptrio-wgs-case-study.md). **Describe the issue:**. Merging vcf files error. **Setup**. - Operating system: working on cluster . - DeepVariant version:latest. - Installation method (Docker):. - Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.). **Steps to reproduce:**. - Command: . ```. udocker run \. -v ""${PWD}/output"":""/output"" \. quay.io/mlin/glnexus:v1.2.7 \. /usr/local/bin/glnexus_cli \. --config DeepVariant_unfiltered \. /output/HG002.g.vcf.gz \. /output/HG003.g.vcf.gz \. /output/HG004.g.vcf.gz \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bcftools view - \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bgzip -c > output/HG002_trio_merged.vcf.gz. ```. - Error trace: (if applicable). . > Num BCF records read 118736378 query hits 14552613. > [E::bgzf_read_block] Invalid BGZF header at offset 265038798. > [E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes. > [E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes. > Error: BCF read err. ![Screenshot from 2024-05-06 15-00-29](https://github.com/google/deepvariant/assets/45700858/2c6e5565-78aa-4e55-9488-82b2f5f04514).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/815
https://github.com/google/deepvariant/issues/815:204,availability,error,error,204,"Merging vcf files error with glnexus:v1.2.7 ; **Have you checked the FAQ? [](https://github.com/google/deepvariant/blob/r1.6.1/docs/deeptrio-wgs-case-study.md). **Describe the issue:**. Merging vcf files error. **Setup**. - Operating system: working on cluster . - DeepVariant version:latest. - Installation method (Docker):. - Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.). **Steps to reproduce:**. - Command: . ```. udocker run \. -v ""${PWD}/output"":""/output"" \. quay.io/mlin/glnexus:v1.2.7 \. /usr/local/bin/glnexus_cli \. --config DeepVariant_unfiltered \. /output/HG002.g.vcf.gz \. /output/HG003.g.vcf.gz \. /output/HG004.g.vcf.gz \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bcftools view - \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bgzip -c > output/HG002_trio_merged.vcf.gz. ```. - Error trace: (if applicable). . > Num BCF records read 118736378 query hits 14552613. > [E::bgzf_read_block] Invalid BGZF header at offset 265038798. > [E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes. > [E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes. > Error: BCF read err. ![Screenshot from 2024-05-06 15-00-29](https://github.com/google/deepvariant/assets/45700858/2c6e5565-78aa-4e55-9488-82b2f5f04514).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/815
https://github.com/google/deepvariant/issues/815:224,availability,Operat,Operating,224,"Merging vcf files error with glnexus:v1.2.7 ; **Have you checked the FAQ? [](https://github.com/google/deepvariant/blob/r1.6.1/docs/deeptrio-wgs-case-study.md). **Describe the issue:**. Merging vcf files error. **Setup**. - Operating system: working on cluster . - DeepVariant version:latest. - Installation method (Docker):. - Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.). **Steps to reproduce:**. - Command: . ```. udocker run \. -v ""${PWD}/output"":""/output"" \. quay.io/mlin/glnexus:v1.2.7 \. /usr/local/bin/glnexus_cli \. --config DeepVariant_unfiltered \. /output/HG002.g.vcf.gz \. /output/HG003.g.vcf.gz \. /output/HG004.g.vcf.gz \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bcftools view - \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bgzip -c > output/HG002_trio_merged.vcf.gz. ```. - Error trace: (if applicable). . > Num BCF records read 118736378 query hits 14552613. > [E::bgzf_read_block] Invalid BGZF header at offset 265038798. > [E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes. > [E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes. > Error: BCF read err. ![Screenshot from 2024-05-06 15-00-29](https://github.com/google/deepvariant/assets/45700858/2c6e5565-78aa-4e55-9488-82b2f5f04514).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/815
https://github.com/google/deepvariant/issues/815:253,availability,cluster,cluster,253,"Merging vcf files error with glnexus:v1.2.7 ; **Have you checked the FAQ? [](https://github.com/google/deepvariant/blob/r1.6.1/docs/deeptrio-wgs-case-study.md). **Describe the issue:**. Merging vcf files error. **Setup**. - Operating system: working on cluster . - DeepVariant version:latest. - Installation method (Docker):. - Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.). **Steps to reproduce:**. - Command: . ```. udocker run \. -v ""${PWD}/output"":""/output"" \. quay.io/mlin/glnexus:v1.2.7 \. /usr/local/bin/glnexus_cli \. --config DeepVariant_unfiltered \. /output/HG002.g.vcf.gz \. /output/HG003.g.vcf.gz \. /output/HG004.g.vcf.gz \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bcftools view - \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bgzip -c > output/HG002_trio_merged.vcf.gz. ```. - Error trace: (if applicable). . > Num BCF records read 118736378 query hits 14552613. > [E::bgzf_read_block] Invalid BGZF header at offset 265038798. > [E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes. > [E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes. > Error: BCF read err. ![Screenshot from 2024-05-06 15-00-29](https://github.com/google/deepvariant/assets/45700858/2c6e5565-78aa-4e55-9488-82b2f5f04514).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/815
https://github.com/google/deepvariant/issues/815:859,availability,Error,Error,859,"Merging vcf files error with glnexus:v1.2.7 ; **Have you checked the FAQ? [](https://github.com/google/deepvariant/blob/r1.6.1/docs/deeptrio-wgs-case-study.md). **Describe the issue:**. Merging vcf files error. **Setup**. - Operating system: working on cluster . - DeepVariant version:latest. - Installation method (Docker):. - Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.). **Steps to reproduce:**. - Command: . ```. udocker run \. -v ""${PWD}/output"":""/output"" \. quay.io/mlin/glnexus:v1.2.7 \. /usr/local/bin/glnexus_cli \. --config DeepVariant_unfiltered \. /output/HG002.g.vcf.gz \. /output/HG003.g.vcf.gz \. /output/HG004.g.vcf.gz \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bcftools view - \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bgzip -c > output/HG002_trio_merged.vcf.gz. ```. - Error trace: (if applicable). . > Num BCF records read 118736378 query hits 14552613. > [E::bgzf_read_block] Invalid BGZF header at offset 265038798. > [E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes. > [E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes. > Error: BCF read err. ![Screenshot from 2024-05-06 15-00-29](https://github.com/google/deepvariant/assets/45700858/2c6e5565-78aa-4e55-9488-82b2f5f04514).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/815
https://github.com/google/deepvariant/issues/815:1037,availability,operat,operation,1037,"Merging vcf files error with glnexus:v1.2.7 ; **Have you checked the FAQ? [](https://github.com/google/deepvariant/blob/r1.6.1/docs/deeptrio-wgs-case-study.md). **Describe the issue:**. Merging vcf files error. **Setup**. - Operating system: working on cluster . - DeepVariant version:latest. - Installation method (Docker):. - Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.). **Steps to reproduce:**. - Command: . ```. udocker run \. -v ""${PWD}/output"":""/output"" \. quay.io/mlin/glnexus:v1.2.7 \. /usr/local/bin/glnexus_cli \. --config DeepVariant_unfiltered \. /output/HG002.g.vcf.gz \. /output/HG003.g.vcf.gz \. /output/HG004.g.vcf.gz \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bcftools view - \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bgzip -c > output/HG002_trio_merged.vcf.gz. ```. - Error trace: (if applicable). . > Num BCF records read 118736378 query hits 14552613. > [E::bgzf_read_block] Invalid BGZF header at offset 265038798. > [E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes. > [E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes. > Error: BCF read err. ![Screenshot from 2024-05-06 15-00-29](https://github.com/google/deepvariant/assets/45700858/2c6e5565-78aa-4e55-9488-82b2f5f04514).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/815
https://github.com/google/deepvariant/issues/815:1059,availability,error,error,1059,"Merging vcf files error with glnexus:v1.2.7 ; **Have you checked the FAQ? [](https://github.com/google/deepvariant/blob/r1.6.1/docs/deeptrio-wgs-case-study.md). **Describe the issue:**. Merging vcf files error. **Setup**. - Operating system: working on cluster . - DeepVariant version:latest. - Installation method (Docker):. - Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.). **Steps to reproduce:**. - Command: . ```. udocker run \. -v ""${PWD}/output"":""/output"" \. quay.io/mlin/glnexus:v1.2.7 \. /usr/local/bin/glnexus_cli \. --config DeepVariant_unfiltered \. /output/HG002.g.vcf.gz \. /output/HG003.g.vcf.gz \. /output/HG004.g.vcf.gz \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bcftools view - \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bgzip -c > output/HG002_trio_merged.vcf.gz. ```. - Error trace: (if applicable). . > Num BCF records read 118736378 query hits 14552613. > [E::bgzf_read_block] Invalid BGZF header at offset 265038798. > [E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes. > [E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes. > Error: BCF read err. ![Screenshot from 2024-05-06 15-00-29](https://github.com/google/deepvariant/assets/45700858/2c6e5565-78aa-4e55-9488-82b2f5f04514).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/815
https://github.com/google/deepvariant/issues/815:1116,availability,operat,operation,1116,"Merging vcf files error with glnexus:v1.2.7 ; **Have you checked the FAQ? [](https://github.com/google/deepvariant/blob/r1.6.1/docs/deeptrio-wgs-case-study.md). **Describe the issue:**. Merging vcf files error. **Setup**. - Operating system: working on cluster . - DeepVariant version:latest. - Installation method (Docker):. - Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.). **Steps to reproduce:**. - Command: . ```. udocker run \. -v ""${PWD}/output"":""/output"" \. quay.io/mlin/glnexus:v1.2.7 \. /usr/local/bin/glnexus_cli \. --config DeepVariant_unfiltered \. /output/HG002.g.vcf.gz \. /output/HG003.g.vcf.gz \. /output/HG004.g.vcf.gz \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bcftools view - \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bgzip -c > output/HG002_trio_merged.vcf.gz. ```. - Error trace: (if applicable). . > Num BCF records read 118736378 query hits 14552613. > [E::bgzf_read_block] Invalid BGZF header at offset 265038798. > [E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes. > [E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes. > Error: BCF read err. ![Screenshot from 2024-05-06 15-00-29](https://github.com/google/deepvariant/assets/45700858/2c6e5565-78aa-4e55-9488-82b2f5f04514).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/815
https://github.com/google/deepvariant/issues/815:1138,availability,error,error,1138,"Merging vcf files error with glnexus:v1.2.7 ; **Have you checked the FAQ? [](https://github.com/google/deepvariant/blob/r1.6.1/docs/deeptrio-wgs-case-study.md). **Describe the issue:**. Merging vcf files error. **Setup**. - Operating system: working on cluster . - DeepVariant version:latest. - Installation method (Docker):. - Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.). **Steps to reproduce:**. - Command: . ```. udocker run \. -v ""${PWD}/output"":""/output"" \. quay.io/mlin/glnexus:v1.2.7 \. /usr/local/bin/glnexus_cli \. --config DeepVariant_unfiltered \. /output/HG002.g.vcf.gz \. /output/HG003.g.vcf.gz \. /output/HG004.g.vcf.gz \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bcftools view - \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bgzip -c > output/HG002_trio_merged.vcf.gz. ```. - Error trace: (if applicable). . > Num BCF records read 118736378 query hits 14552613. > [E::bgzf_read_block] Invalid BGZF header at offset 265038798. > [E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes. > [E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes. > Error: BCF read err. ![Screenshot from 2024-05-06 15-00-29](https://github.com/google/deepvariant/assets/45700858/2c6e5565-78aa-4e55-9488-82b2f5f04514).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/815
https://github.com/google/deepvariant/issues/815:1169,availability,Error,Error,1169,"Merging vcf files error with glnexus:v1.2.7 ; **Have you checked the FAQ? [](https://github.com/google/deepvariant/blob/r1.6.1/docs/deeptrio-wgs-case-study.md). **Describe the issue:**. Merging vcf files error. **Setup**. - Operating system: working on cluster . - DeepVariant version:latest. - Installation method (Docker):. - Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.). **Steps to reproduce:**. - Command: . ```. udocker run \. -v ""${PWD}/output"":""/output"" \. quay.io/mlin/glnexus:v1.2.7 \. /usr/local/bin/glnexus_cli \. --config DeepVariant_unfiltered \. /output/HG002.g.vcf.gz \. /output/HG003.g.vcf.gz \. /output/HG004.g.vcf.gz \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bcftools view - \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bgzip -c > output/HG002_trio_merged.vcf.gz. ```. - Error trace: (if applicable). . > Num BCF records read 118736378 query hits 14552613. > [E::bgzf_read_block] Invalid BGZF header at offset 265038798. > [E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes. > [E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes. > Error: BCF read err. ![Screenshot from 2024-05-06 15-00-29](https://github.com/google/deepvariant/assets/45700858/2c6e5565-78aa-4e55-9488-82b2f5f04514).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/815
https://github.com/google/deepvariant/issues/815:253,deployability,cluster,cluster,253,"Merging vcf files error with glnexus:v1.2.7 ; **Have you checked the FAQ? [](https://github.com/google/deepvariant/blob/r1.6.1/docs/deeptrio-wgs-case-study.md). **Describe the issue:**. Merging vcf files error. **Setup**. - Operating system: working on cluster . - DeepVariant version:latest. - Installation method (Docker):. - Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.). **Steps to reproduce:**. - Command: . ```. udocker run \. -v ""${PWD}/output"":""/output"" \. quay.io/mlin/glnexus:v1.2.7 \. /usr/local/bin/glnexus_cli \. --config DeepVariant_unfiltered \. /output/HG002.g.vcf.gz \. /output/HG003.g.vcf.gz \. /output/HG004.g.vcf.gz \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bcftools view - \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bgzip -c > output/HG002_trio_merged.vcf.gz. ```. - Error trace: (if applicable). . > Num BCF records read 118736378 query hits 14552613. > [E::bgzf_read_block] Invalid BGZF header at offset 265038798. > [E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes. > [E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes. > Error: BCF read err. ![Screenshot from 2024-05-06 15-00-29](https://github.com/google/deepvariant/assets/45700858/2c6e5565-78aa-4e55-9488-82b2f5f04514).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/815
https://github.com/google/deepvariant/issues/815:277,deployability,version,version,277,"Merging vcf files error with glnexus:v1.2.7 ; **Have you checked the FAQ? [](https://github.com/google/deepvariant/blob/r1.6.1/docs/deeptrio-wgs-case-study.md). **Describe the issue:**. Merging vcf files error. **Setup**. - Operating system: working on cluster . - DeepVariant version:latest. - Installation method (Docker):. - Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.). **Steps to reproduce:**. - Command: . ```. udocker run \. -v ""${PWD}/output"":""/output"" \. quay.io/mlin/glnexus:v1.2.7 \. /usr/local/bin/glnexus_cli \. --config DeepVariant_unfiltered \. /output/HG002.g.vcf.gz \. /output/HG003.g.vcf.gz \. /output/HG004.g.vcf.gz \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bcftools view - \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bgzip -c > output/HG002_trio_merged.vcf.gz. ```. - Error trace: (if applicable). . > Num BCF records read 118736378 query hits 14552613. > [E::bgzf_read_block] Invalid BGZF header at offset 265038798. > [E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes. > [E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes. > Error: BCF read err. ![Screenshot from 2024-05-06 15-00-29](https://github.com/google/deepvariant/assets/45700858/2c6e5565-78aa-4e55-9488-82b2f5f04514).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/815
https://github.com/google/deepvariant/issues/815:295,deployability,Instal,Installation,295,"Merging vcf files error with glnexus:v1.2.7 ; **Have you checked the FAQ? [](https://github.com/google/deepvariant/blob/r1.6.1/docs/deeptrio-wgs-case-study.md). **Describe the issue:**. Merging vcf files error. **Setup**. - Operating system: working on cluster . - DeepVariant version:latest. - Installation method (Docker):. - Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.). **Steps to reproduce:**. - Command: . ```. udocker run \. -v ""${PWD}/output"":""/output"" \. quay.io/mlin/glnexus:v1.2.7 \. /usr/local/bin/glnexus_cli \. --config DeepVariant_unfiltered \. /output/HG002.g.vcf.gz \. /output/HG003.g.vcf.gz \. /output/HG004.g.vcf.gz \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bcftools view - \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bgzip -c > output/HG002_trio_merged.vcf.gz. ```. - Error trace: (if applicable). . > Num BCF records read 118736378 query hits 14552613. > [E::bgzf_read_block] Invalid BGZF header at offset 265038798. > [E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes. > [E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes. > Error: BCF read err. ![Screenshot from 2024-05-06 15-00-29](https://github.com/google/deepvariant/assets/45700858/2c6e5565-78aa-4e55-9488-82b2f5f04514).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/815
https://github.com/google/deepvariant/issues/815:1047,deployability,fail,failed,1047,"Merging vcf files error with glnexus:v1.2.7 ; **Have you checked the FAQ? [](https://github.com/google/deepvariant/blob/r1.6.1/docs/deeptrio-wgs-case-study.md). **Describe the issue:**. Merging vcf files error. **Setup**. - Operating system: working on cluster . - DeepVariant version:latest. - Installation method (Docker):. - Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.). **Steps to reproduce:**. - Command: . ```. udocker run \. -v ""${PWD}/output"":""/output"" \. quay.io/mlin/glnexus:v1.2.7 \. /usr/local/bin/glnexus_cli \. --config DeepVariant_unfiltered \. /output/HG002.g.vcf.gz \. /output/HG003.g.vcf.gz \. /output/HG004.g.vcf.gz \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bcftools view - \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bgzip -c > output/HG002_trio_merged.vcf.gz. ```. - Error trace: (if applicable). . > Num BCF records read 118736378 query hits 14552613. > [E::bgzf_read_block] Invalid BGZF header at offset 265038798. > [E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes. > [E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes. > Error: BCF read err. ![Screenshot from 2024-05-06 15-00-29](https://github.com/google/deepvariant/assets/45700858/2c6e5565-78aa-4e55-9488-82b2f5f04514).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/815
https://github.com/google/deepvariant/issues/815:1126,deployability,fail,failed,1126,"Merging vcf files error with glnexus:v1.2.7 ; **Have you checked the FAQ? [](https://github.com/google/deepvariant/blob/r1.6.1/docs/deeptrio-wgs-case-study.md). **Describe the issue:**. Merging vcf files error. **Setup**. - Operating system: working on cluster . - DeepVariant version:latest. - Installation method (Docker):. - Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.). **Steps to reproduce:**. - Command: . ```. udocker run \. -v ""${PWD}/output"":""/output"" \. quay.io/mlin/glnexus:v1.2.7 \. /usr/local/bin/glnexus_cli \. --config DeepVariant_unfiltered \. /output/HG002.g.vcf.gz \. /output/HG003.g.vcf.gz \. /output/HG004.g.vcf.gz \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bcftools view - \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bgzip -c > output/HG002_trio_merged.vcf.gz. ```. - Error trace: (if applicable). . > Num BCF records read 118736378 query hits 14552613. > [E::bgzf_read_block] Invalid BGZF header at offset 265038798. > [E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes. > [E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes. > Error: BCF read err. ![Screenshot from 2024-05-06 15-00-29](https://github.com/google/deepvariant/assets/45700858/2c6e5565-78aa-4e55-9488-82b2f5f04514).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/815
https://github.com/google/deepvariant/issues/815:277,integrability,version,version,277,"Merging vcf files error with glnexus:v1.2.7 ; **Have you checked the FAQ? [](https://github.com/google/deepvariant/blob/r1.6.1/docs/deeptrio-wgs-case-study.md). **Describe the issue:**. Merging vcf files error. **Setup**. - Operating system: working on cluster . - DeepVariant version:latest. - Installation method (Docker):. - Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.). **Steps to reproduce:**. - Command: . ```. udocker run \. -v ""${PWD}/output"":""/output"" \. quay.io/mlin/glnexus:v1.2.7 \. /usr/local/bin/glnexus_cli \. --config DeepVariant_unfiltered \. /output/HG002.g.vcf.gz \. /output/HG003.g.vcf.gz \. /output/HG004.g.vcf.gz \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bcftools view - \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bgzip -c > output/HG002_trio_merged.vcf.gz. ```. - Error trace: (if applicable). . > Num BCF records read 118736378 query hits 14552613. > [E::bgzf_read_block] Invalid BGZF header at offset 265038798. > [E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes. > [E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes. > Error: BCF read err. ![Screenshot from 2024-05-06 15-00-29](https://github.com/google/deepvariant/assets/45700858/2c6e5565-78aa-4e55-9488-82b2f5f04514).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/815
https://github.com/google/deepvariant/issues/815:277,modifiability,version,version,277,"Merging vcf files error with glnexus:v1.2.7 ; **Have you checked the FAQ? [](https://github.com/google/deepvariant/blob/r1.6.1/docs/deeptrio-wgs-case-study.md). **Describe the issue:**. Merging vcf files error. **Setup**. - Operating system: working on cluster . - DeepVariant version:latest. - Installation method (Docker):. - Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.). **Steps to reproduce:**. - Command: . ```. udocker run \. -v ""${PWD}/output"":""/output"" \. quay.io/mlin/glnexus:v1.2.7 \. /usr/local/bin/glnexus_cli \. --config DeepVariant_unfiltered \. /output/HG002.g.vcf.gz \. /output/HG003.g.vcf.gz \. /output/HG004.g.vcf.gz \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bcftools view - \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bgzip -c > output/HG002_trio_merged.vcf.gz. ```. - Error trace: (if applicable). . > Num BCF records read 118736378 query hits 14552613. > [E::bgzf_read_block] Invalid BGZF header at offset 265038798. > [E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes. > [E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes. > Error: BCF read err. ![Screenshot from 2024-05-06 15-00-29](https://github.com/google/deepvariant/assets/45700858/2c6e5565-78aa-4e55-9488-82b2f5f04514).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/815
https://github.com/google/deepvariant/issues/815:18,performance,error,error,18,"Merging vcf files error with glnexus:v1.2.7 ; **Have you checked the FAQ? [](https://github.com/google/deepvariant/blob/r1.6.1/docs/deeptrio-wgs-case-study.md). **Describe the issue:**. Merging vcf files error. **Setup**. - Operating system: working on cluster . - DeepVariant version:latest. - Installation method (Docker):. - Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.). **Steps to reproduce:**. - Command: . ```. udocker run \. -v ""${PWD}/output"":""/output"" \. quay.io/mlin/glnexus:v1.2.7 \. /usr/local/bin/glnexus_cli \. --config DeepVariant_unfiltered \. /output/HG002.g.vcf.gz \. /output/HG003.g.vcf.gz \. /output/HG004.g.vcf.gz \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bcftools view - \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bgzip -c > output/HG002_trio_merged.vcf.gz. ```. - Error trace: (if applicable). . > Num BCF records read 118736378 query hits 14552613. > [E::bgzf_read_block] Invalid BGZF header at offset 265038798. > [E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes. > [E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes. > Error: BCF read err. ![Screenshot from 2024-05-06 15-00-29](https://github.com/google/deepvariant/assets/45700858/2c6e5565-78aa-4e55-9488-82b2f5f04514).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/815
https://github.com/google/deepvariant/issues/815:204,performance,error,error,204,"Merging vcf files error with glnexus:v1.2.7 ; **Have you checked the FAQ? [](https://github.com/google/deepvariant/blob/r1.6.1/docs/deeptrio-wgs-case-study.md). **Describe the issue:**. Merging vcf files error. **Setup**. - Operating system: working on cluster . - DeepVariant version:latest. - Installation method (Docker):. - Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.). **Steps to reproduce:**. - Command: . ```. udocker run \. -v ""${PWD}/output"":""/output"" \. quay.io/mlin/glnexus:v1.2.7 \. /usr/local/bin/glnexus_cli \. --config DeepVariant_unfiltered \. /output/HG002.g.vcf.gz \. /output/HG003.g.vcf.gz \. /output/HG004.g.vcf.gz \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bcftools view - \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bgzip -c > output/HG002_trio_merged.vcf.gz. ```. - Error trace: (if applicable). . > Num BCF records read 118736378 query hits 14552613. > [E::bgzf_read_block] Invalid BGZF header at offset 265038798. > [E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes. > [E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes. > Error: BCF read err. ![Screenshot from 2024-05-06 15-00-29](https://github.com/google/deepvariant/assets/45700858/2c6e5565-78aa-4e55-9488-82b2f5f04514).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/815
https://github.com/google/deepvariant/issues/815:859,performance,Error,Error,859,"Merging vcf files error with glnexus:v1.2.7 ; **Have you checked the FAQ? [](https://github.com/google/deepvariant/blob/r1.6.1/docs/deeptrio-wgs-case-study.md). **Describe the issue:**. Merging vcf files error. **Setup**. - Operating system: working on cluster . - DeepVariant version:latest. - Installation method (Docker):. - Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.). **Steps to reproduce:**. - Command: . ```. udocker run \. -v ""${PWD}/output"":""/output"" \. quay.io/mlin/glnexus:v1.2.7 \. /usr/local/bin/glnexus_cli \. --config DeepVariant_unfiltered \. /output/HG002.g.vcf.gz \. /output/HG003.g.vcf.gz \. /output/HG004.g.vcf.gz \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bcftools view - \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bgzip -c > output/HG002_trio_merged.vcf.gz. ```. - Error trace: (if applicable). . > Num BCF records read 118736378 query hits 14552613. > [E::bgzf_read_block] Invalid BGZF header at offset 265038798. > [E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes. > [E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes. > Error: BCF read err. ![Screenshot from 2024-05-06 15-00-29](https://github.com/google/deepvariant/assets/45700858/2c6e5565-78aa-4e55-9488-82b2f5f04514).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/815
https://github.com/google/deepvariant/issues/815:1059,performance,error,error,1059,"Merging vcf files error with glnexus:v1.2.7 ; **Have you checked the FAQ? [](https://github.com/google/deepvariant/blob/r1.6.1/docs/deeptrio-wgs-case-study.md). **Describe the issue:**. Merging vcf files error. **Setup**. - Operating system: working on cluster . - DeepVariant version:latest. - Installation method (Docker):. - Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.). **Steps to reproduce:**. - Command: . ```. udocker run \. -v ""${PWD}/output"":""/output"" \. quay.io/mlin/glnexus:v1.2.7 \. /usr/local/bin/glnexus_cli \. --config DeepVariant_unfiltered \. /output/HG002.g.vcf.gz \. /output/HG003.g.vcf.gz \. /output/HG004.g.vcf.gz \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bcftools view - \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bgzip -c > output/HG002_trio_merged.vcf.gz. ```. - Error trace: (if applicable). . > Num BCF records read 118736378 query hits 14552613. > [E::bgzf_read_block] Invalid BGZF header at offset 265038798. > [E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes. > [E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes. > Error: BCF read err. ![Screenshot from 2024-05-06 15-00-29](https://github.com/google/deepvariant/assets/45700858/2c6e5565-78aa-4e55-9488-82b2f5f04514).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/815
https://github.com/google/deepvariant/issues/815:1138,performance,error,error,1138,"Merging vcf files error with glnexus:v1.2.7 ; **Have you checked the FAQ? [](https://github.com/google/deepvariant/blob/r1.6.1/docs/deeptrio-wgs-case-study.md). **Describe the issue:**. Merging vcf files error. **Setup**. - Operating system: working on cluster . - DeepVariant version:latest. - Installation method (Docker):. - Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.). **Steps to reproduce:**. - Command: . ```. udocker run \. -v ""${PWD}/output"":""/output"" \. quay.io/mlin/glnexus:v1.2.7 \. /usr/local/bin/glnexus_cli \. --config DeepVariant_unfiltered \. /output/HG002.g.vcf.gz \. /output/HG003.g.vcf.gz \. /output/HG004.g.vcf.gz \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bcftools view - \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bgzip -c > output/HG002_trio_merged.vcf.gz. ```. - Error trace: (if applicable). . > Num BCF records read 118736378 query hits 14552613. > [E::bgzf_read_block] Invalid BGZF header at offset 265038798. > [E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes. > [E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes. > Error: BCF read err. ![Screenshot from 2024-05-06 15-00-29](https://github.com/google/deepvariant/assets/45700858/2c6e5565-78aa-4e55-9488-82b2f5f04514).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/815
https://github.com/google/deepvariant/issues/815:1169,performance,Error,Error,1169,"Merging vcf files error with glnexus:v1.2.7 ; **Have you checked the FAQ? [](https://github.com/google/deepvariant/blob/r1.6.1/docs/deeptrio-wgs-case-study.md). **Describe the issue:**. Merging vcf files error. **Setup**. - Operating system: working on cluster . - DeepVariant version:latest. - Installation method (Docker):. - Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.). **Steps to reproduce:**. - Command: . ```. udocker run \. -v ""${PWD}/output"":""/output"" \. quay.io/mlin/glnexus:v1.2.7 \. /usr/local/bin/glnexus_cli \. --config DeepVariant_unfiltered \. /output/HG002.g.vcf.gz \. /output/HG003.g.vcf.gz \. /output/HG004.g.vcf.gz \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bcftools view - \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bgzip -c > output/HG002_trio_merged.vcf.gz. ```. - Error trace: (if applicable). . > Num BCF records read 118736378 query hits 14552613. > [E::bgzf_read_block] Invalid BGZF header at offset 265038798. > [E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes. > [E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes. > Error: BCF read err. ![Screenshot from 2024-05-06 15-00-29](https://github.com/google/deepvariant/assets/45700858/2c6e5565-78aa-4e55-9488-82b2f5f04514).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/815
https://github.com/google/deepvariant/issues/815:1047,reliability,fail,failed,1047,"Merging vcf files error with glnexus:v1.2.7 ; **Have you checked the FAQ? [](https://github.com/google/deepvariant/blob/r1.6.1/docs/deeptrio-wgs-case-study.md). **Describe the issue:**. Merging vcf files error. **Setup**. - Operating system: working on cluster . - DeepVariant version:latest. - Installation method (Docker):. - Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.). **Steps to reproduce:**. - Command: . ```. udocker run \. -v ""${PWD}/output"":""/output"" \. quay.io/mlin/glnexus:v1.2.7 \. /usr/local/bin/glnexus_cli \. --config DeepVariant_unfiltered \. /output/HG002.g.vcf.gz \. /output/HG003.g.vcf.gz \. /output/HG004.g.vcf.gz \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bcftools view - \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bgzip -c > output/HG002_trio_merged.vcf.gz. ```. - Error trace: (if applicable). . > Num BCF records read 118736378 query hits 14552613. > [E::bgzf_read_block] Invalid BGZF header at offset 265038798. > [E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes. > [E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes. > Error: BCF read err. ![Screenshot from 2024-05-06 15-00-29](https://github.com/google/deepvariant/assets/45700858/2c6e5565-78aa-4e55-9488-82b2f5f04514).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/815
https://github.com/google/deepvariant/issues/815:1126,reliability,fail,failed,1126,"Merging vcf files error with glnexus:v1.2.7 ; **Have you checked the FAQ? [](https://github.com/google/deepvariant/blob/r1.6.1/docs/deeptrio-wgs-case-study.md). **Describe the issue:**. Merging vcf files error. **Setup**. - Operating system: working on cluster . - DeepVariant version:latest. - Installation method (Docker):. - Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.). **Steps to reproduce:**. - Command: . ```. udocker run \. -v ""${PWD}/output"":""/output"" \. quay.io/mlin/glnexus:v1.2.7 \. /usr/local/bin/glnexus_cli \. --config DeepVariant_unfiltered \. /output/HG002.g.vcf.gz \. /output/HG003.g.vcf.gz \. /output/HG004.g.vcf.gz \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bcftools view - \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bgzip -c > output/HG002_trio_merged.vcf.gz. ```. - Error trace: (if applicable). . > Num BCF records read 118736378 query hits 14552613. > [E::bgzf_read_block] Invalid BGZF header at offset 265038798. > [E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes. > [E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes. > Error: BCF read err. ![Screenshot from 2024-05-06 15-00-29](https://github.com/google/deepvariant/assets/45700858/2c6e5565-78aa-4e55-9488-82b2f5f04514).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/815
https://github.com/google/deepvariant/issues/815:18,safety,error,error,18,"Merging vcf files error with glnexus:v1.2.7 ; **Have you checked the FAQ? [](https://github.com/google/deepvariant/blob/r1.6.1/docs/deeptrio-wgs-case-study.md). **Describe the issue:**. Merging vcf files error. **Setup**. - Operating system: working on cluster . - DeepVariant version:latest. - Installation method (Docker):. - Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.). **Steps to reproduce:**. - Command: . ```. udocker run \. -v ""${PWD}/output"":""/output"" \. quay.io/mlin/glnexus:v1.2.7 \. /usr/local/bin/glnexus_cli \. --config DeepVariant_unfiltered \. /output/HG002.g.vcf.gz \. /output/HG003.g.vcf.gz \. /output/HG004.g.vcf.gz \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bcftools view - \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bgzip -c > output/HG002_trio_merged.vcf.gz. ```. - Error trace: (if applicable). . > Num BCF records read 118736378 query hits 14552613. > [E::bgzf_read_block] Invalid BGZF header at offset 265038798. > [E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes. > [E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes. > Error: BCF read err. ![Screenshot from 2024-05-06 15-00-29](https://github.com/google/deepvariant/assets/45700858/2c6e5565-78aa-4e55-9488-82b2f5f04514).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/815
https://github.com/google/deepvariant/issues/815:204,safety,error,error,204,"Merging vcf files error with glnexus:v1.2.7 ; **Have you checked the FAQ? [](https://github.com/google/deepvariant/blob/r1.6.1/docs/deeptrio-wgs-case-study.md). **Describe the issue:**. Merging vcf files error. **Setup**. - Operating system: working on cluster . - DeepVariant version:latest. - Installation method (Docker):. - Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.). **Steps to reproduce:**. - Command: . ```. udocker run \. -v ""${PWD}/output"":""/output"" \. quay.io/mlin/glnexus:v1.2.7 \. /usr/local/bin/glnexus_cli \. --config DeepVariant_unfiltered \. /output/HG002.g.vcf.gz \. /output/HG003.g.vcf.gz \. /output/HG004.g.vcf.gz \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bcftools view - \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bgzip -c > output/HG002_trio_merged.vcf.gz. ```. - Error trace: (if applicable). . > Num BCF records read 118736378 query hits 14552613. > [E::bgzf_read_block] Invalid BGZF header at offset 265038798. > [E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes. > [E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes. > Error: BCF read err. ![Screenshot from 2024-05-06 15-00-29](https://github.com/google/deepvariant/assets/45700858/2c6e5565-78aa-4e55-9488-82b2f5f04514).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/815
https://github.com/google/deepvariant/issues/815:859,safety,Error,Error,859,"Merging vcf files error with glnexus:v1.2.7 ; **Have you checked the FAQ? [](https://github.com/google/deepvariant/blob/r1.6.1/docs/deeptrio-wgs-case-study.md). **Describe the issue:**. Merging vcf files error. **Setup**. - Operating system: working on cluster . - DeepVariant version:latest. - Installation method (Docker):. - Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.). **Steps to reproduce:**. - Command: . ```. udocker run \. -v ""${PWD}/output"":""/output"" \. quay.io/mlin/glnexus:v1.2.7 \. /usr/local/bin/glnexus_cli \. --config DeepVariant_unfiltered \. /output/HG002.g.vcf.gz \. /output/HG003.g.vcf.gz \. /output/HG004.g.vcf.gz \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bcftools view - \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bgzip -c > output/HG002_trio_merged.vcf.gz. ```. - Error trace: (if applicable). . > Num BCF records read 118736378 query hits 14552613. > [E::bgzf_read_block] Invalid BGZF header at offset 265038798. > [E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes. > [E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes. > Error: BCF read err. ![Screenshot from 2024-05-06 15-00-29](https://github.com/google/deepvariant/assets/45700858/2c6e5565-78aa-4e55-9488-82b2f5f04514).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/815
https://github.com/google/deepvariant/issues/815:1059,safety,error,error,1059,"Merging vcf files error with glnexus:v1.2.7 ; **Have you checked the FAQ? [](https://github.com/google/deepvariant/blob/r1.6.1/docs/deeptrio-wgs-case-study.md). **Describe the issue:**. Merging vcf files error. **Setup**. - Operating system: working on cluster . - DeepVariant version:latest. - Installation method (Docker):. - Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.). **Steps to reproduce:**. - Command: . ```. udocker run \. -v ""${PWD}/output"":""/output"" \. quay.io/mlin/glnexus:v1.2.7 \. /usr/local/bin/glnexus_cli \. --config DeepVariant_unfiltered \. /output/HG002.g.vcf.gz \. /output/HG003.g.vcf.gz \. /output/HG004.g.vcf.gz \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bcftools view - \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bgzip -c > output/HG002_trio_merged.vcf.gz. ```. - Error trace: (if applicable). . > Num BCF records read 118736378 query hits 14552613. > [E::bgzf_read_block] Invalid BGZF header at offset 265038798. > [E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes. > [E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes. > Error: BCF read err. ![Screenshot from 2024-05-06 15-00-29](https://github.com/google/deepvariant/assets/45700858/2c6e5565-78aa-4e55-9488-82b2f5f04514).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/815
https://github.com/google/deepvariant/issues/815:1138,safety,error,error,1138,"Merging vcf files error with glnexus:v1.2.7 ; **Have you checked the FAQ? [](https://github.com/google/deepvariant/blob/r1.6.1/docs/deeptrio-wgs-case-study.md). **Describe the issue:**. Merging vcf files error. **Setup**. - Operating system: working on cluster . - DeepVariant version:latest. - Installation method (Docker):. - Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.). **Steps to reproduce:**. - Command: . ```. udocker run \. -v ""${PWD}/output"":""/output"" \. quay.io/mlin/glnexus:v1.2.7 \. /usr/local/bin/glnexus_cli \. --config DeepVariant_unfiltered \. /output/HG002.g.vcf.gz \. /output/HG003.g.vcf.gz \. /output/HG004.g.vcf.gz \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bcftools view - \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bgzip -c > output/HG002_trio_merged.vcf.gz. ```. - Error trace: (if applicable). . > Num BCF records read 118736378 query hits 14552613. > [E::bgzf_read_block] Invalid BGZF header at offset 265038798. > [E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes. > [E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes. > Error: BCF read err. ![Screenshot from 2024-05-06 15-00-29](https://github.com/google/deepvariant/assets/45700858/2c6e5565-78aa-4e55-9488-82b2f5f04514).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/815
https://github.com/google/deepvariant/issues/815:1169,safety,Error,Error,1169,"Merging vcf files error with glnexus:v1.2.7 ; **Have you checked the FAQ? [](https://github.com/google/deepvariant/blob/r1.6.1/docs/deeptrio-wgs-case-study.md). **Describe the issue:**. Merging vcf files error. **Setup**. - Operating system: working on cluster . - DeepVariant version:latest. - Installation method (Docker):. - Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.). **Steps to reproduce:**. - Command: . ```. udocker run \. -v ""${PWD}/output"":""/output"" \. quay.io/mlin/glnexus:v1.2.7 \. /usr/local/bin/glnexus_cli \. --config DeepVariant_unfiltered \. /output/HG002.g.vcf.gz \. /output/HG003.g.vcf.gz \. /output/HG004.g.vcf.gz \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bcftools view - \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bgzip -c > output/HG002_trio_merged.vcf.gz. ```. - Error trace: (if applicable). . > Num BCF records read 118736378 query hits 14552613. > [E::bgzf_read_block] Invalid BGZF header at offset 265038798. > [E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes. > [E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes. > Error: BCF read err. ![Screenshot from 2024-05-06 15-00-29](https://github.com/google/deepvariant/assets/45700858/2c6e5565-78aa-4e55-9488-82b2f5f04514).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/815
https://github.com/google/deepvariant/issues/815:865,testability,trace,trace,865,"Merging vcf files error with glnexus:v1.2.7 ; **Have you checked the FAQ? [](https://github.com/google/deepvariant/blob/r1.6.1/docs/deeptrio-wgs-case-study.md). **Describe the issue:**. Merging vcf files error. **Setup**. - Operating system: working on cluster . - DeepVariant version:latest. - Installation method (Docker):. - Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.). **Steps to reproduce:**. - Command: . ```. udocker run \. -v ""${PWD}/output"":""/output"" \. quay.io/mlin/glnexus:v1.2.7 \. /usr/local/bin/glnexus_cli \. --config DeepVariant_unfiltered \. /output/HG002.g.vcf.gz \. /output/HG003.g.vcf.gz \. /output/HG004.g.vcf.gz \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bcftools view - \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bgzip -c > output/HG002_trio_merged.vcf.gz. ```. - Error trace: (if applicable). . > Num BCF records read 118736378 query hits 14552613. > [E::bgzf_read_block] Invalid BGZF header at offset 265038798. > [E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes. > [E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes. > Error: BCF read err. ![Screenshot from 2024-05-06 15-00-29](https://github.com/google/deepvariant/assets/45700858/2c6e5565-78aa-4e55-9488-82b2f5f04514).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/815
https://github.com/google/deepvariant/issues/815:18,usability,error,error,18,"Merging vcf files error with glnexus:v1.2.7 ; **Have you checked the FAQ? [](https://github.com/google/deepvariant/blob/r1.6.1/docs/deeptrio-wgs-case-study.md). **Describe the issue:**. Merging vcf files error. **Setup**. - Operating system: working on cluster . - DeepVariant version:latest. - Installation method (Docker):. - Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.). **Steps to reproduce:**. - Command: . ```. udocker run \. -v ""${PWD}/output"":""/output"" \. quay.io/mlin/glnexus:v1.2.7 \. /usr/local/bin/glnexus_cli \. --config DeepVariant_unfiltered \. /output/HG002.g.vcf.gz \. /output/HG003.g.vcf.gz \. /output/HG004.g.vcf.gz \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bcftools view - \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bgzip -c > output/HG002_trio_merged.vcf.gz. ```. - Error trace: (if applicable). . > Num BCF records read 118736378 query hits 14552613. > [E::bgzf_read_block] Invalid BGZF header at offset 265038798. > [E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes. > [E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes. > Error: BCF read err. ![Screenshot from 2024-05-06 15-00-29](https://github.com/google/deepvariant/assets/45700858/2c6e5565-78aa-4e55-9488-82b2f5f04514).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/815
https://github.com/google/deepvariant/issues/815:204,usability,error,error,204,"Merging vcf files error with glnexus:v1.2.7 ; **Have you checked the FAQ? [](https://github.com/google/deepvariant/blob/r1.6.1/docs/deeptrio-wgs-case-study.md). **Describe the issue:**. Merging vcf files error. **Setup**. - Operating system: working on cluster . - DeepVariant version:latest. - Installation method (Docker):. - Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.). **Steps to reproduce:**. - Command: . ```. udocker run \. -v ""${PWD}/output"":""/output"" \. quay.io/mlin/glnexus:v1.2.7 \. /usr/local/bin/glnexus_cli \. --config DeepVariant_unfiltered \. /output/HG002.g.vcf.gz \. /output/HG003.g.vcf.gz \. /output/HG004.g.vcf.gz \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bcftools view - \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bgzip -c > output/HG002_trio_merged.vcf.gz. ```. - Error trace: (if applicable). . > Num BCF records read 118736378 query hits 14552613. > [E::bgzf_read_block] Invalid BGZF header at offset 265038798. > [E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes. > [E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes. > Error: BCF read err. ![Screenshot from 2024-05-06 15-00-29](https://github.com/google/deepvariant/assets/45700858/2c6e5565-78aa-4e55-9488-82b2f5f04514).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/815
https://github.com/google/deepvariant/issues/815:422,usability,Command,Command,422,"Merging vcf files error with glnexus:v1.2.7 ; **Have you checked the FAQ? [](https://github.com/google/deepvariant/blob/r1.6.1/docs/deeptrio-wgs-case-study.md). **Describe the issue:**. Merging vcf files error. **Setup**. - Operating system: working on cluster . - DeepVariant version:latest. - Installation method (Docker):. - Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.). **Steps to reproduce:**. - Command: . ```. udocker run \. -v ""${PWD}/output"":""/output"" \. quay.io/mlin/glnexus:v1.2.7 \. /usr/local/bin/glnexus_cli \. --config DeepVariant_unfiltered \. /output/HG002.g.vcf.gz \. /output/HG003.g.vcf.gz \. /output/HG004.g.vcf.gz \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bcftools view - \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bgzip -c > output/HG002_trio_merged.vcf.gz. ```. - Error trace: (if applicable). . > Num BCF records read 118736378 query hits 14552613. > [E::bgzf_read_block] Invalid BGZF header at offset 265038798. > [E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes. > [E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes. > Error: BCF read err. ![Screenshot from 2024-05-06 15-00-29](https://github.com/google/deepvariant/assets/45700858/2c6e5565-78aa-4e55-9488-82b2f5f04514).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/815
https://github.com/google/deepvariant/issues/815:859,usability,Error,Error,859,"Merging vcf files error with glnexus:v1.2.7 ; **Have you checked the FAQ? [](https://github.com/google/deepvariant/blob/r1.6.1/docs/deeptrio-wgs-case-study.md). **Describe the issue:**. Merging vcf files error. **Setup**. - Operating system: working on cluster . - DeepVariant version:latest. - Installation method (Docker):. - Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.). **Steps to reproduce:**. - Command: . ```. udocker run \. -v ""${PWD}/output"":""/output"" \. quay.io/mlin/glnexus:v1.2.7 \. /usr/local/bin/glnexus_cli \. --config DeepVariant_unfiltered \. /output/HG002.g.vcf.gz \. /output/HG003.g.vcf.gz \. /output/HG004.g.vcf.gz \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bcftools view - \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bgzip -c > output/HG002_trio_merged.vcf.gz. ```. - Error trace: (if applicable). . > Num BCF records read 118736378 query hits 14552613. > [E::bgzf_read_block] Invalid BGZF header at offset 265038798. > [E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes. > [E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes. > Error: BCF read err. ![Screenshot from 2024-05-06 15-00-29](https://github.com/google/deepvariant/assets/45700858/2c6e5565-78aa-4e55-9488-82b2f5f04514).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/815
https://github.com/google/deepvariant/issues/815:1059,usability,error,error,1059,"Merging vcf files error with glnexus:v1.2.7 ; **Have you checked the FAQ? [](https://github.com/google/deepvariant/blob/r1.6.1/docs/deeptrio-wgs-case-study.md). **Describe the issue:**. Merging vcf files error. **Setup**. - Operating system: working on cluster . - DeepVariant version:latest. - Installation method (Docker):. - Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.). **Steps to reproduce:**. - Command: . ```. udocker run \. -v ""${PWD}/output"":""/output"" \. quay.io/mlin/glnexus:v1.2.7 \. /usr/local/bin/glnexus_cli \. --config DeepVariant_unfiltered \. /output/HG002.g.vcf.gz \. /output/HG003.g.vcf.gz \. /output/HG004.g.vcf.gz \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bcftools view - \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bgzip -c > output/HG002_trio_merged.vcf.gz. ```. - Error trace: (if applicable). . > Num BCF records read 118736378 query hits 14552613. > [E::bgzf_read_block] Invalid BGZF header at offset 265038798. > [E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes. > [E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes. > Error: BCF read err. ![Screenshot from 2024-05-06 15-00-29](https://github.com/google/deepvariant/assets/45700858/2c6e5565-78aa-4e55-9488-82b2f5f04514).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/815
https://github.com/google/deepvariant/issues/815:1138,usability,error,error,1138,"Merging vcf files error with glnexus:v1.2.7 ; **Have you checked the FAQ? [](https://github.com/google/deepvariant/blob/r1.6.1/docs/deeptrio-wgs-case-study.md). **Describe the issue:**. Merging vcf files error. **Setup**. - Operating system: working on cluster . - DeepVariant version:latest. - Installation method (Docker):. - Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.). **Steps to reproduce:**. - Command: . ```. udocker run \. -v ""${PWD}/output"":""/output"" \. quay.io/mlin/glnexus:v1.2.7 \. /usr/local/bin/glnexus_cli \. --config DeepVariant_unfiltered \. /output/HG002.g.vcf.gz \. /output/HG003.g.vcf.gz \. /output/HG004.g.vcf.gz \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bcftools view - \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bgzip -c > output/HG002_trio_merged.vcf.gz. ```. - Error trace: (if applicable). . > Num BCF records read 118736378 query hits 14552613. > [E::bgzf_read_block] Invalid BGZF header at offset 265038798. > [E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes. > [E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes. > Error: BCF read err. ![Screenshot from 2024-05-06 15-00-29](https://github.com/google/deepvariant/assets/45700858/2c6e5565-78aa-4e55-9488-82b2f5f04514).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/815
https://github.com/google/deepvariant/issues/815:1169,usability,Error,Error,1169,"Merging vcf files error with glnexus:v1.2.7 ; **Have you checked the FAQ? [](https://github.com/google/deepvariant/blob/r1.6.1/docs/deeptrio-wgs-case-study.md). **Describe the issue:**. Merging vcf files error. **Setup**. - Operating system: working on cluster . - DeepVariant version:latest. - Installation method (Docker):. - Type of data: (GIAB AshkenazimTrio [HG002,HG003,HG004] analysis.). **Steps to reproduce:**. - Command: . ```. udocker run \. -v ""${PWD}/output"":""/output"" \. quay.io/mlin/glnexus:v1.2.7 \. /usr/local/bin/glnexus_cli \. --config DeepVariant_unfiltered \. /output/HG002.g.vcf.gz \. /output/HG003.g.vcf.gz \. /output/HG004.g.vcf.gz \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bcftools view - \. | udocker run -i google/deepvariant:deeptrio-""${BIN_VERSION}"" \. bgzip -c > output/HG002_trio_merged.vcf.gz. ```. - Error trace: (if applicable). . > Num BCF records read 118736378 query hits 14552613. > [E::bgzf_read_block] Invalid BGZF header at offset 265038798. > [E::bgzf_read] Read block operation failed with error 2 after 0 of 32 bytes. > [E::bgzf_read] Read block operation failed with error 3 after 0 of 32 bytes. > Error: BCF read err. ![Screenshot from 2024-05-06 15-00-29](https://github.com/google/deepvariant/assets/45700858/2c6e5565-78aa-4e55-9488-82b2f5f04514).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/815
https://github.com/google/deepvariant/issues/816:123,modifiability,paramet,parameters,123,"haploid contigs and PAR region options for DeepTrio; Hi,. How do I use --haploid_contigs=""chrX,chrY"" and --par_regions_bed parameters in DeepTrio? This option is not present in DeepTrio for sex chromosomes. Regards,. Prasun.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/816
https://github.com/google/deepvariant/issues/816:217,reliability,Pra,Prasun,217,"haploid contigs and PAR region options for DeepTrio; Hi,. How do I use --haploid_contigs=""chrX,chrY"" and --par_regions_bed parameters in DeepTrio? This option is not present in DeepTrio for sex chromosomes. Regards,. Prasun.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/816
https://github.com/google/deepvariant/issues/817:314,availability,error,error,314,"[E::vcf_parse_format] Incorrect number of FORMAT fields at NC_059157.1:24900; Good morning,. i'm Ilaria, a PhD student. . I have a problem with the command bcftools consensus: . bcftools consensus newnodup.vcf.gz - f../../../referencegenome_genome -o consensus.fasta. I have the file consensus.fasta but with this error:. [E::vcf_parse_format] Incorrect number of FORMAT fields at NC_059157.1:24900. [E::vcf_parse_format] Incorrect number of FORMAT fields at NC_059158.1:490105. etc.. So, how can i fix the problem? . I used Sniffles for calling variant. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/817
https://github.com/google/deepvariant/issues/817:42,interoperability,FORMAT,FORMAT,42,"[E::vcf_parse_format] Incorrect number of FORMAT fields at NC_059157.1:24900; Good morning,. i'm Ilaria, a PhD student. . I have a problem with the command bcftools consensus: . bcftools consensus newnodup.vcf.gz - f../../../referencegenome_genome -o consensus.fasta. I have the file consensus.fasta but with this error:. [E::vcf_parse_format] Incorrect number of FORMAT fields at NC_059157.1:24900. [E::vcf_parse_format] Incorrect number of FORMAT fields at NC_059158.1:490105. etc.. So, how can i fix the problem? . I used Sniffles for calling variant. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/817
https://github.com/google/deepvariant/issues/817:364,interoperability,FORMAT,FORMAT,364,"[E::vcf_parse_format] Incorrect number of FORMAT fields at NC_059157.1:24900; Good morning,. i'm Ilaria, a PhD student. . I have a problem with the command bcftools consensus: . bcftools consensus newnodup.vcf.gz - f../../../referencegenome_genome -o consensus.fasta. I have the file consensus.fasta but with this error:. [E::vcf_parse_format] Incorrect number of FORMAT fields at NC_059157.1:24900. [E::vcf_parse_format] Incorrect number of FORMAT fields at NC_059158.1:490105. etc.. So, how can i fix the problem? . I used Sniffles for calling variant. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/817
https://github.com/google/deepvariant/issues/817:442,interoperability,FORMAT,FORMAT,442,"[E::vcf_parse_format] Incorrect number of FORMAT fields at NC_059157.1:24900; Good morning,. i'm Ilaria, a PhD student. . I have a problem with the command bcftools consensus: . bcftools consensus newnodup.vcf.gz - f../../../referencegenome_genome -o consensus.fasta. I have the file consensus.fasta but with this error:. [E::vcf_parse_format] Incorrect number of FORMAT fields at NC_059157.1:24900. [E::vcf_parse_format] Incorrect number of FORMAT fields at NC_059158.1:490105. etc.. So, how can i fix the problem? . I used Sniffles for calling variant. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/817
https://github.com/google/deepvariant/issues/817:314,performance,error,error,314,"[E::vcf_parse_format] Incorrect number of FORMAT fields at NC_059157.1:24900; Good morning,. i'm Ilaria, a PhD student. . I have a problem with the command bcftools consensus: . bcftools consensus newnodup.vcf.gz - f../../../referencegenome_genome -o consensus.fasta. I have the file consensus.fasta but with this error:. [E::vcf_parse_format] Incorrect number of FORMAT fields at NC_059157.1:24900. [E::vcf_parse_format] Incorrect number of FORMAT fields at NC_059158.1:490105. etc.. So, how can i fix the problem? . I used Sniffles for calling variant. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/817
https://github.com/google/deepvariant/issues/817:314,safety,error,error,314,"[E::vcf_parse_format] Incorrect number of FORMAT fields at NC_059157.1:24900; Good morning,. i'm Ilaria, a PhD student. . I have a problem with the command bcftools consensus: . bcftools consensus newnodup.vcf.gz - f../../../referencegenome_genome -o consensus.fasta. I have the file consensus.fasta but with this error:. [E::vcf_parse_format] Incorrect number of FORMAT fields at NC_059157.1:24900. [E::vcf_parse_format] Incorrect number of FORMAT fields at NC_059158.1:490105. etc.. So, how can i fix the problem? . I used Sniffles for calling variant. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/817
https://github.com/google/deepvariant/issues/817:148,usability,command,command,148,"[E::vcf_parse_format] Incorrect number of FORMAT fields at NC_059157.1:24900; Good morning,. i'm Ilaria, a PhD student. . I have a problem with the command bcftools consensus: . bcftools consensus newnodup.vcf.gz - f../../../referencegenome_genome -o consensus.fasta. I have the file consensus.fasta but with this error:. [E::vcf_parse_format] Incorrect number of FORMAT fields at NC_059157.1:24900. [E::vcf_parse_format] Incorrect number of FORMAT fields at NC_059158.1:490105. etc.. So, how can i fix the problem? . I used Sniffles for calling variant. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/817
https://github.com/google/deepvariant/issues/817:314,usability,error,error,314,"[E::vcf_parse_format] Incorrect number of FORMAT fields at NC_059157.1:24900; Good morning,. i'm Ilaria, a PhD student. . I have a problem with the command bcftools consensus: . bcftools consensus newnodup.vcf.gz - f../../../referencegenome_genome -o consensus.fasta. I have the file consensus.fasta but with this error:. [E::vcf_parse_format] Incorrect number of FORMAT fields at NC_059157.1:24900. [E::vcf_parse_format] Incorrect number of FORMAT fields at NC_059158.1:490105. etc.. So, how can i fix the problem? . I used Sniffles for calling variant. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/817
https://github.com/google/deepvariant/issues/818:246,availability,error,error,246,"postprocess_variants: Found multiple file patterns in input filename space; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. The postprocess_variants step fails with following error message:. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Setup**. - Operating system: CentOS Linux 7 (Core). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio Sequencing. **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1300, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:385,availability,Operat,Operating,385,"postprocess_variants: Found multiple file patterns in input filename space; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. The postprocess_variants step fails with following error message:. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Setup**. - Operating system: CentOS Linux 7 (Core). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio Sequencing. **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1300, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:600,availability,Error,Error,600,"postprocess_variants: Found multiple file patterns in input filename space; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. The postprocess_variants step fails with following error message:. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Setup**. - Operating system: CentOS Linux 7 (Core). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio Sequencing. **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1300, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:2168,availability,error,error,2168,"File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.gz"" to ""./call_variants_output@1.tfrecord.gz"" and it works. Anyway, the call of postprocess_variants.py is auto-generated by ""/opt/deepvariant/bin/run_deepvariant"". The error does not occur for every sample ... directory content of intermediate_results_dir after the error occured:. call_variants.log. call_variants_output-00000-of-00001.tfrecord.gz. gvcf.tfrecord-00000-of-00008.gz. gvcf.tfrecord-00001-of-00008.gz. gvcf.tfrecord-00002-of-00008.gz. gvcf.tfrecord-00003-of-00008.gz. gvcf.tfrecord-00004-of-00008.gz. gvcf.tfrecord-00005-of-00008.gz. gvcf.tfrecord-00006-of-00008.gz. gvcf.tfrecord-00007-of-00008.gz. make_examples.log. make_examples.tfrecord-00000-of-00008.gz. make_examples.tfrecord-00000-of-00008.gz.example_info.json. make_examples.tfrecord-00001-of-00008.gz. make_examples.tfrecord-00001-of-00008.gz.example_info.json. make_examples.tfrecord-00002-of-00008.gz. make_examples.tfrecord-00002-of-00008.gz.example_info.json. make_examples.tfrecord-00003-of-00008.gz. make_examples.tfrecord-00003-of-00008.gz.example_info.json. make_examples.tfrecord-00004-of-00008.gz. make_examples.tfrecord-00004-of-00008.gz.example_info.json. make_examples.tfrecord-00005",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:2266,availability,error,error,2266,"s.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.gz"" to ""./call_variants_output@1.tfrecord.gz"" and it works. Anyway, the call of postprocess_variants.py is auto-generated by ""/opt/deepvariant/bin/run_deepvariant"". The error does not occur for every sample ... directory content of intermediate_results_dir after the error occured:. call_variants.log. call_variants_output-00000-of-00001.tfrecord.gz. gvcf.tfrecord-00000-of-00008.gz. gvcf.tfrecord-00001-of-00008.gz. gvcf.tfrecord-00002-of-00008.gz. gvcf.tfrecord-00003-of-00008.gz. gvcf.tfrecord-00004-of-00008.gz. gvcf.tfrecord-00005-of-00008.gz. gvcf.tfrecord-00006-of-00008.gz. gvcf.tfrecord-00007-of-00008.gz. make_examples.log. make_examples.tfrecord-00000-of-00008.gz. make_examples.tfrecord-00000-of-00008.gz.example_info.json. make_examples.tfrecord-00001-of-00008.gz. make_examples.tfrecord-00001-of-00008.gz.example_info.json. make_examples.tfrecord-00002-of-00008.gz. make_examples.tfrecord-00002-of-00008.gz.example_info.json. make_examples.tfrecord-00003-of-00008.gz. make_examples.tfrecord-00003-of-00008.gz.example_info.json. make_examples.tfrecord-00004-of-00008.gz. make_examples.tfrecord-00004-of-00008.gz.example_info.json. make_examples.tfrecord-00005-of-00008.gz. make_examples.tfrecord-00005-of-00008.gz.example_info.json. make_examples.tfrecord-0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:225,deployability,fail,fails,225,"postprocess_variants: Found multiple file patterns in input filename space; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. The postprocess_variants step fails with following error message:. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Setup**. - Operating system: CentOS Linux 7 (Core). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio Sequencing. **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1300, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:440,deployability,version,version,440,"postprocess_variants: Found multiple file patterns in input filename space; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. The postprocess_variants step fails with following error message:. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Setup**. - Operating system: CentOS Linux 7 (Core). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio Sequencing. **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1300, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:458,deployability,Instal,Installation,458,"postprocess_variants: Found multiple file patterns in input filename space; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. The postprocess_variants step fails with following error message:. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Setup**. - Operating system: CentOS Linux 7 (Core). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio Sequencing. **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1300, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:770,deployability,modul,module,770,"postprocess_variants: Found multiple file patterns in input filename space; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. The postprocess_variants step fails with following error message:. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Setup**. - Operating system: CentOS Linux 7 (Core). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio Sequencing. **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1300, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:2296,deployability,log,log,2296,"le_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.gz"" to ""./call_variants_output@1.tfrecord.gz"" and it works. Anyway, the call of postprocess_variants.py is auto-generated by ""/opt/deepvariant/bin/run_deepvariant"". The error does not occur for every sample ... directory content of intermediate_results_dir after the error occured:. call_variants.log. call_variants_output-00000-of-00001.tfrecord.gz. gvcf.tfrecord-00000-of-00008.gz. gvcf.tfrecord-00001-of-00008.gz. gvcf.tfrecord-00002-of-00008.gz. gvcf.tfrecord-00003-of-00008.gz. gvcf.tfrecord-00004-of-00008.gz. gvcf.tfrecord-00005-of-00008.gz. gvcf.tfrecord-00006-of-00008.gz. gvcf.tfrecord-00007-of-00008.gz. make_examples.log. make_examples.tfrecord-00000-of-00008.gz. make_examples.tfrecord-00000-of-00008.gz.example_info.json. make_examples.tfrecord-00001-of-00008.gz. make_examples.tfrecord-00001-of-00008.gz.example_info.json. make_examples.tfrecord-00002-of-00008.gz. make_examples.tfrecord-00002-of-00008.gz.example_info.json. make_examples.tfrecord-00003-of-00008.gz. make_examples.tfrecord-00003-of-00008.gz.example_info.json. make_examples.tfrecord-00004-of-00008.gz. make_examples.tfrecord-00004-of-00008.gz.example_info.json. make_examples.tfrecord-00005-of-00008.gz. make_examples.tfrecord-00005-of-00008.gz.example_info.json. make_examples.tfrecord-00006-of-00008.gz. make_exampl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:2628,deployability,log,log,2628,"t_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.gz"" to ""./call_variants_output@1.tfrecord.gz"" and it works. Anyway, the call of postprocess_variants.py is auto-generated by ""/opt/deepvariant/bin/run_deepvariant"". The error does not occur for every sample ... directory content of intermediate_results_dir after the error occured:. call_variants.log. call_variants_output-00000-of-00001.tfrecord.gz. gvcf.tfrecord-00000-of-00008.gz. gvcf.tfrecord-00001-of-00008.gz. gvcf.tfrecord-00002-of-00008.gz. gvcf.tfrecord-00003-of-00008.gz. gvcf.tfrecord-00004-of-00008.gz. gvcf.tfrecord-00005-of-00008.gz. gvcf.tfrecord-00006-of-00008.gz. gvcf.tfrecord-00007-of-00008.gz. make_examples.log. make_examples.tfrecord-00000-of-00008.gz. make_examples.tfrecord-00000-of-00008.gz.example_info.json. make_examples.tfrecord-00001-of-00008.gz. make_examples.tfrecord-00001-of-00008.gz.example_info.json. make_examples.tfrecord-00002-of-00008.gz. make_examples.tfrecord-00002-of-00008.gz.example_info.json. make_examples.tfrecord-00003-of-00008.gz. make_examples.tfrecord-00003-of-00008.gz.example_info.json. make_examples.tfrecord-00004-of-00008.gz. make_examples.tfrecord-00004-of-00008.gz.example_info.json. make_examples.tfrecord-00005-of-00008.gz. make_examples.tfrecord-00005-of-00008.gz.example_info.json. make_examples.tfrecord-00006-of-00008.gz. make_examples.tfrecord-00006-of-00008.gz.example_info.json. make_examples.tfrecord-00007-of-00008.gz. make_examples.tfrecord-00007-of-00008.gz.example_info.json. postprocess_variants.log.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:3470,deployability,log,log,3470,"t_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.gz"" to ""./call_variants_output@1.tfrecord.gz"" and it works. Anyway, the call of postprocess_variants.py is auto-generated by ""/opt/deepvariant/bin/run_deepvariant"". The error does not occur for every sample ... directory content of intermediate_results_dir after the error occured:. call_variants.log. call_variants_output-00000-of-00001.tfrecord.gz. gvcf.tfrecord-00000-of-00008.gz. gvcf.tfrecord-00001-of-00008.gz. gvcf.tfrecord-00002-of-00008.gz. gvcf.tfrecord-00003-of-00008.gz. gvcf.tfrecord-00004-of-00008.gz. gvcf.tfrecord-00005-of-00008.gz. gvcf.tfrecord-00006-of-00008.gz. gvcf.tfrecord-00007-of-00008.gz. make_examples.log. make_examples.tfrecord-00000-of-00008.gz. make_examples.tfrecord-00000-of-00008.gz.example_info.json. make_examples.tfrecord-00001-of-00008.gz. make_examples.tfrecord-00001-of-00008.gz.example_info.json. make_examples.tfrecord-00002-of-00008.gz. make_examples.tfrecord-00002-of-00008.gz.example_info.json. make_examples.tfrecord-00003-of-00008.gz. make_examples.tfrecord-00003-of-00008.gz.example_info.json. make_examples.tfrecord-00004-of-00008.gz. make_examples.tfrecord-00004-of-00008.gz.example_info.json. make_examples.tfrecord-00005-of-00008.gz. make_examples.tfrecord-00005-of-00008.gz.example_info.json. make_examples.tfrecord-00006-of-00008.gz. make_examples.tfrecord-00006-of-00008.gz.example_info.json. make_examples.tfrecord-00007-of-00008.gz. make_examples.tfrecord-00007-of-00008.gz.example_info.json. postprocess_variants.log.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:419,energy efficiency,Core,Core,419,"postprocess_variants: Found multiple file patterns in input filename space; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. The postprocess_variants step fails with following error message:. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Setup**. - Operating system: CentOS Linux 7 (Core). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio Sequencing. **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1300, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:252,integrability,messag,message,252,"postprocess_variants: Found multiple file patterns in input filename space; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. The postprocess_variants step fails with following error message:. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Setup**. - Operating system: CentOS Linux 7 (Core). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio Sequencing. **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1300, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:440,integrability,version,version,440,"postprocess_variants: Found multiple file patterns in input filename space; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. The postprocess_variants step fails with following error message:. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Setup**. - Operating system: CentOS Linux 7 (Core). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio Sequencing. **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1300, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:252,interoperability,messag,message,252,"postprocess_variants: Found multiple file patterns in input filename space; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. The postprocess_variants step fails with following error message:. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Setup**. - Operating system: CentOS Linux 7 (Core). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio Sequencing. **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1300, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:440,modifiability,version,version,440,"postprocess_variants: Found multiple file patterns in input filename space; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. The postprocess_variants step fails with following error message:. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Setup**. - Operating system: CentOS Linux 7 (Core). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio Sequencing. **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1300, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:542,modifiability,Pac,PacBio,542,"postprocess_variants: Found multiple file patterns in input filename space; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. The postprocess_variants step fails with following error message:. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Setup**. - Operating system: CentOS Linux 7 (Core). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio Sequencing. **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1300, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:770,modifiability,modul,module,770,"postprocess_variants: Found multiple file patterns in input filename space; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. The postprocess_variants step fails with following error message:. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Setup**. - Operating system: CentOS Linux 7 (Core). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio Sequencing. **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1300, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:1904,modifiability,paramet,parameter,1904,"mp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1300, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.gz"" to ""./call_variants_output@1.tfrecord.gz"" and it works. Anyway, the call of postprocess_variants.py is auto-generated by ""/opt/deepvariant/bin/run_deepvariant"". The error does not occur for every sample ... directory content of intermediate_results_dir after the error occured:. call_variants.log. call_variants_output-00000-of-00001.tfrecord.gz. gvcf.tfrecord-00000-of-00008.gz. gvcf.tfrecord-00001-of-00008.gz. gvcf.tfrecord-00002-of-00008.gz. gvcf.tfrecord-00003-of-00008.gz. gvcf.tfrecord-00004-of-00008.gz. gvcf.tfrecord-00005-of-00008.gz. gvcf.tfrecord-00006-of-00008.gz. gvcf.tfrecord-00007-of-00008.gz. make_examples.log. make_examples.tfrecord-00000-of-00008.gz. make_examples.tfrecord-00000-of-00008.gz.example_info.json. make_examples.tfrecord-00001-of-00008.gz. make_examples.tfrecord-00001-of-00008.gz.example_info.json. make_examples.tfrecord-00002-of-00008.gz. make_examples.tfrecord-00002-o",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:246,performance,error,error,246,"postprocess_variants: Found multiple file patterns in input filename space; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. The postprocess_variants step fails with following error message:. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Setup**. - Operating system: CentOS Linux 7 (Core). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio Sequencing. **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1300, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:600,performance,Error,Error,600,"postprocess_variants: Found multiple file patterns in input filename space; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. The postprocess_variants step fails with following error message:. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Setup**. - Operating system: CentOS Linux 7 (Core). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio Sequencing. **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1300, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:2168,performance,error,error,2168,"File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.gz"" to ""./call_variants_output@1.tfrecord.gz"" and it works. Anyway, the call of postprocess_variants.py is auto-generated by ""/opt/deepvariant/bin/run_deepvariant"". The error does not occur for every sample ... directory content of intermediate_results_dir after the error occured:. call_variants.log. call_variants_output-00000-of-00001.tfrecord.gz. gvcf.tfrecord-00000-of-00008.gz. gvcf.tfrecord-00001-of-00008.gz. gvcf.tfrecord-00002-of-00008.gz. gvcf.tfrecord-00003-of-00008.gz. gvcf.tfrecord-00004-of-00008.gz. gvcf.tfrecord-00005-of-00008.gz. gvcf.tfrecord-00006-of-00008.gz. gvcf.tfrecord-00007-of-00008.gz. make_examples.log. make_examples.tfrecord-00000-of-00008.gz. make_examples.tfrecord-00000-of-00008.gz.example_info.json. make_examples.tfrecord-00001-of-00008.gz. make_examples.tfrecord-00001-of-00008.gz.example_info.json. make_examples.tfrecord-00002-of-00008.gz. make_examples.tfrecord-00002-of-00008.gz.example_info.json. make_examples.tfrecord-00003-of-00008.gz. make_examples.tfrecord-00003-of-00008.gz.example_info.json. make_examples.tfrecord-00004-of-00008.gz. make_examples.tfrecord-00004-of-00008.gz.example_info.json. make_examples.tfrecord-00005",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:2220,performance,content,content,2220,"e_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.gz"" to ""./call_variants_output@1.tfrecord.gz"" and it works. Anyway, the call of postprocess_variants.py is auto-generated by ""/opt/deepvariant/bin/run_deepvariant"". The error does not occur for every sample ... directory content of intermediate_results_dir after the error occured:. call_variants.log. call_variants_output-00000-of-00001.tfrecord.gz. gvcf.tfrecord-00000-of-00008.gz. gvcf.tfrecord-00001-of-00008.gz. gvcf.tfrecord-00002-of-00008.gz. gvcf.tfrecord-00003-of-00008.gz. gvcf.tfrecord-00004-of-00008.gz. gvcf.tfrecord-00005-of-00008.gz. gvcf.tfrecord-00006-of-00008.gz. gvcf.tfrecord-00007-of-00008.gz. make_examples.log. make_examples.tfrecord-00000-of-00008.gz. make_examples.tfrecord-00000-of-00008.gz.example_info.json. make_examples.tfrecord-00001-of-00008.gz. make_examples.tfrecord-00001-of-00008.gz.example_info.json. make_examples.tfrecord-00002-of-00008.gz. make_examples.tfrecord-00002-of-00008.gz.example_info.json. make_examples.tfrecord-00003-of-00008.gz. make_examples.tfrecord-00003-of-00008.gz.example_info.json. make_examples.tfrecord-00004-of-00008.gz. make_examples.tfrecord-00004-of-00008.gz.example_info.json. make_examples.tfrecord-00005-of-00008.gz. make_examples.tfrecord-00005-of-00008.g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:2266,performance,error,error,2266,"s.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.gz"" to ""./call_variants_output@1.tfrecord.gz"" and it works. Anyway, the call of postprocess_variants.py is auto-generated by ""/opt/deepvariant/bin/run_deepvariant"". The error does not occur for every sample ... directory content of intermediate_results_dir after the error occured:. call_variants.log. call_variants_output-00000-of-00001.tfrecord.gz. gvcf.tfrecord-00000-of-00008.gz. gvcf.tfrecord-00001-of-00008.gz. gvcf.tfrecord-00002-of-00008.gz. gvcf.tfrecord-00003-of-00008.gz. gvcf.tfrecord-00004-of-00008.gz. gvcf.tfrecord-00005-of-00008.gz. gvcf.tfrecord-00006-of-00008.gz. gvcf.tfrecord-00007-of-00008.gz. make_examples.log. make_examples.tfrecord-00000-of-00008.gz. make_examples.tfrecord-00000-of-00008.gz.example_info.json. make_examples.tfrecord-00001-of-00008.gz. make_examples.tfrecord-00001-of-00008.gz.example_info.json. make_examples.tfrecord-00002-of-00008.gz. make_examples.tfrecord-00002-of-00008.gz.example_info.json. make_examples.tfrecord-00003-of-00008.gz. make_examples.tfrecord-00003-of-00008.gz.example_info.json. make_examples.tfrecord-00004-of-00008.gz. make_examples.tfrecord-00004-of-00008.gz.example_info.json. make_examples.tfrecord-00005-of-00008.gz. make_examples.tfrecord-00005-of-00008.gz.example_info.json. make_examples.tfrecord-0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:225,reliability,fail,fails,225,"postprocess_variants: Found multiple file patterns in input filename space; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. The postprocess_variants step fails with following error message:. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Setup**. - Operating system: CentOS Linux 7 (Core). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio Sequencing. **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1300, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:1635,reliability,Doe,Does,1635,"call last):. File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1300, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.gz"" to ""./call_variants_output@1.tfrecord.gz"" and it works. Anyway, the call of postprocess_variants.py is auto-generated by ""/opt/deepvariant/bin/run_deepvariant"". The error does not occur for every sample ... directory content of intermediate_results_dir after the error occured:. call_variants.log. call_variants_output-00000-of-00001.tfrecord.gz. gvcf.tfrecord-00000-of-00008.gz. gvcf.tfrecord-00001-of-00008.gz. gvcf.tfrecord-00002-of-00008.gz. gvcf.tfrecord-00003-of-00008.gz. gvcf.tfrecord-00004-of-00008.gz. gvcf.tfrecord-00005-of-00008.gz. gvcf.tfrecord-00006-of-00008.gz. gvcf.tfrecord-00007-of-00008.gz. make_examples.log. make",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:2174,reliability,doe,does,2174,"""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.gz"" to ""./call_variants_output@1.tfrecord.gz"" and it works. Anyway, the call of postprocess_variants.py is auto-generated by ""/opt/deepvariant/bin/run_deepvariant"". The error does not occur for every sample ... directory content of intermediate_results_dir after the error occured:. call_variants.log. call_variants_output-00000-of-00001.tfrecord.gz. gvcf.tfrecord-00000-of-00008.gz. gvcf.tfrecord-00001-of-00008.gz. gvcf.tfrecord-00002-of-00008.gz. gvcf.tfrecord-00003-of-00008.gz. gvcf.tfrecord-00004-of-00008.gz. gvcf.tfrecord-00005-of-00008.gz. gvcf.tfrecord-00006-of-00008.gz. gvcf.tfrecord-00007-of-00008.gz. make_examples.log. make_examples.tfrecord-00000-of-00008.gz. make_examples.tfrecord-00000-of-00008.gz.example_info.json. make_examples.tfrecord-00001-of-00008.gz. make_examples.tfrecord-00001-of-00008.gz.example_info.json. make_examples.tfrecord-00002-of-00008.gz. make_examples.tfrecord-00002-of-00008.gz.example_info.json. make_examples.tfrecord-00003-of-00008.gz. make_examples.tfrecord-00003-of-00008.gz.example_info.json. make_examples.tfrecord-00004-of-00008.gz. make_examples.tfrecord-00004-of-00008.gz.example_info.json. make_examples.tfrecord-00005-of-0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:54,safety,input,input,54,"postprocess_variants: Found multiple file patterns in input filename space; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. The postprocess_variants step fails with following error message:. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Setup**. - Operating system: CentOS Linux 7 (Core). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio Sequencing. **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1300, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:246,safety,error,error,246,"postprocess_variants: Found multiple file patterns in input filename space; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. The postprocess_variants step fails with following error message:. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Setup**. - Operating system: CentOS Linux 7 (Core). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio Sequencing. **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1300, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:308,safety,input,input,308,"postprocess_variants: Found multiple file patterns in input filename space; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. The postprocess_variants step fails with following error message:. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Setup**. - Operating system: CentOS Linux 7 (Core). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio Sequencing. **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1300, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:600,safety,Error,Error,600,"postprocess_variants: Found multiple file patterns in input filename space; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. The postprocess_variants step fails with following error message:. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Setup**. - Operating system: CentOS Linux 7 (Core). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio Sequencing. **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1300, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:770,safety,modul,module,770,"postprocess_variants: Found multiple file patterns in input filename space; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. The postprocess_variants step fails with following error message:. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Setup**. - Operating system: CentOS Linux 7 (Core). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio Sequencing. **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1300, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:1569,safety,input,input,1569,"reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1300, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.gz"" to ""./call_variants_output@1.tfrecord.gz"" and it works. Anyway, the call of postprocess_variants.py is auto-generated by ""/opt/deepvariant/bin/run_deepvariant"". The error does not occur for every sample ... directory content of intermediate_results_dir after the error occured:. call_variants.log. call_variants_output-00000-of-00001.tfrecord.gz. gvcf.tfrecord-00000-of-00008.gz. gvcf.tfrecord-00001-of-00008.gz. gvcf.tfrecord-00002-of-00008.gz. gvcf.tfrecord-00003-of-00008.gz. gvcf.tfrecord-00004-of-00008.gz. gvcf.tfrecord-00005-of-00008.gz. gvcf.tfrecord-00006-of-0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:1656,safety,test,test,1656,"mp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1300, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.gz"" to ""./call_variants_output@1.tfrecord.gz"" and it works. Anyway, the call of postprocess_variants.py is auto-generated by ""/opt/deepvariant/bin/run_deepvariant"". The error does not occur for every sample ... directory content of intermediate_results_dir after the error occured:. call_variants.log. call_variants_output-00000-of-00001.tfrecord.gz. gvcf.tfrecord-00000-of-00008.gz. gvcf.tfrecord-00001-of-00008.gz. gvcf.tfrecord-00002-of-00008.gz. gvcf.tfrecord-00003-of-00008.gz. gvcf.tfrecord-00004-of-00008.gz. gvcf.tfrecord-00005-of-00008.gz. gvcf.tfrecord-00006-of-00008.gz. gvcf.tfrecord-00007-of-00008.gz. make_examples.log. make_examples.tfrecord-00",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:1692,safety,test,test,1692,"com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1300, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.gz"" to ""./call_variants_output@1.tfrecord.gz"" and it works. Anyway, the call of postprocess_variants.py is auto-generated by ""/opt/deepvariant/bin/run_deepvariant"". The error does not occur for every sample ... directory content of intermediate_results_dir after the error occured:. call_variants.log. call_variants_output-00000-of-00001.tfrecord.gz. gvcf.tfrecord-00000-of-00008.gz. gvcf.tfrecord-00001-of-00008.gz. gvcf.tfrecord-00002-of-00008.gz. gvcf.tfrecord-00003-of-00008.gz. gvcf.tfrecord-00004-of-00008.gz. gvcf.tfrecord-00005-of-00008.gz. gvcf.tfrecord-00006-of-00008.gz. gvcf.tfrecord-00007-of-00008.gz. make_examples.log. make_examples.tfrecord-00000-of-00008.gz. make_examples.tfrec",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:2168,safety,error,error,2168,"File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.gz"" to ""./call_variants_output@1.tfrecord.gz"" and it works. Anyway, the call of postprocess_variants.py is auto-generated by ""/opt/deepvariant/bin/run_deepvariant"". The error does not occur for every sample ... directory content of intermediate_results_dir after the error occured:. call_variants.log. call_variants_output-00000-of-00001.tfrecord.gz. gvcf.tfrecord-00000-of-00008.gz. gvcf.tfrecord-00001-of-00008.gz. gvcf.tfrecord-00002-of-00008.gz. gvcf.tfrecord-00003-of-00008.gz. gvcf.tfrecord-00004-of-00008.gz. gvcf.tfrecord-00005-of-00008.gz. gvcf.tfrecord-00006-of-00008.gz. gvcf.tfrecord-00007-of-00008.gz. make_examples.log. make_examples.tfrecord-00000-of-00008.gz. make_examples.tfrecord-00000-of-00008.gz.example_info.json. make_examples.tfrecord-00001-of-00008.gz. make_examples.tfrecord-00001-of-00008.gz.example_info.json. make_examples.tfrecord-00002-of-00008.gz. make_examples.tfrecord-00002-of-00008.gz.example_info.json. make_examples.tfrecord-00003-of-00008.gz. make_examples.tfrecord-00003-of-00008.gz.example_info.json. make_examples.tfrecord-00004-of-00008.gz. make_examples.tfrecord-00004-of-00008.gz.example_info.json. make_examples.tfrecord-00005",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:2266,safety,error,error,2266,"s.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.gz"" to ""./call_variants_output@1.tfrecord.gz"" and it works. Anyway, the call of postprocess_variants.py is auto-generated by ""/opt/deepvariant/bin/run_deepvariant"". The error does not occur for every sample ... directory content of intermediate_results_dir after the error occured:. call_variants.log. call_variants_output-00000-of-00001.tfrecord.gz. gvcf.tfrecord-00000-of-00008.gz. gvcf.tfrecord-00001-of-00008.gz. gvcf.tfrecord-00002-of-00008.gz. gvcf.tfrecord-00003-of-00008.gz. gvcf.tfrecord-00004-of-00008.gz. gvcf.tfrecord-00005-of-00008.gz. gvcf.tfrecord-00006-of-00008.gz. gvcf.tfrecord-00007-of-00008.gz. make_examples.log. make_examples.tfrecord-00000-of-00008.gz. make_examples.tfrecord-00000-of-00008.gz.example_info.json. make_examples.tfrecord-00001-of-00008.gz. make_examples.tfrecord-00001-of-00008.gz.example_info.json. make_examples.tfrecord-00002-of-00008.gz. make_examples.tfrecord-00002-of-00008.gz.example_info.json. make_examples.tfrecord-00003-of-00008.gz. make_examples.tfrecord-00003-of-00008.gz.example_info.json. make_examples.tfrecord-00004-of-00008.gz. make_examples.tfrecord-00004-of-00008.gz.example_info.json. make_examples.tfrecord-00005-of-00008.gz. make_examples.tfrecord-00005-of-00008.gz.example_info.json. make_examples.tfrecord-0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:2296,safety,log,log,2296,"le_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.gz"" to ""./call_variants_output@1.tfrecord.gz"" and it works. Anyway, the call of postprocess_variants.py is auto-generated by ""/opt/deepvariant/bin/run_deepvariant"". The error does not occur for every sample ... directory content of intermediate_results_dir after the error occured:. call_variants.log. call_variants_output-00000-of-00001.tfrecord.gz. gvcf.tfrecord-00000-of-00008.gz. gvcf.tfrecord-00001-of-00008.gz. gvcf.tfrecord-00002-of-00008.gz. gvcf.tfrecord-00003-of-00008.gz. gvcf.tfrecord-00004-of-00008.gz. gvcf.tfrecord-00005-of-00008.gz. gvcf.tfrecord-00006-of-00008.gz. gvcf.tfrecord-00007-of-00008.gz. make_examples.log. make_examples.tfrecord-00000-of-00008.gz. make_examples.tfrecord-00000-of-00008.gz.example_info.json. make_examples.tfrecord-00001-of-00008.gz. make_examples.tfrecord-00001-of-00008.gz.example_info.json. make_examples.tfrecord-00002-of-00008.gz. make_examples.tfrecord-00002-of-00008.gz.example_info.json. make_examples.tfrecord-00003-of-00008.gz. make_examples.tfrecord-00003-of-00008.gz.example_info.json. make_examples.tfrecord-00004-of-00008.gz. make_examples.tfrecord-00004-of-00008.gz.example_info.json. make_examples.tfrecord-00005-of-00008.gz. make_examples.tfrecord-00005-of-00008.gz.example_info.json. make_examples.tfrecord-00006-of-00008.gz. make_exampl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:2628,safety,log,log,2628,"t_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.gz"" to ""./call_variants_output@1.tfrecord.gz"" and it works. Anyway, the call of postprocess_variants.py is auto-generated by ""/opt/deepvariant/bin/run_deepvariant"". The error does not occur for every sample ... directory content of intermediate_results_dir after the error occured:. call_variants.log. call_variants_output-00000-of-00001.tfrecord.gz. gvcf.tfrecord-00000-of-00008.gz. gvcf.tfrecord-00001-of-00008.gz. gvcf.tfrecord-00002-of-00008.gz. gvcf.tfrecord-00003-of-00008.gz. gvcf.tfrecord-00004-of-00008.gz. gvcf.tfrecord-00005-of-00008.gz. gvcf.tfrecord-00006-of-00008.gz. gvcf.tfrecord-00007-of-00008.gz. make_examples.log. make_examples.tfrecord-00000-of-00008.gz. make_examples.tfrecord-00000-of-00008.gz.example_info.json. make_examples.tfrecord-00001-of-00008.gz. make_examples.tfrecord-00001-of-00008.gz.example_info.json. make_examples.tfrecord-00002-of-00008.gz. make_examples.tfrecord-00002-of-00008.gz.example_info.json. make_examples.tfrecord-00003-of-00008.gz. make_examples.tfrecord-00003-of-00008.gz.example_info.json. make_examples.tfrecord-00004-of-00008.gz. make_examples.tfrecord-00004-of-00008.gz.example_info.json. make_examples.tfrecord-00005-of-00008.gz. make_examples.tfrecord-00005-of-00008.gz.example_info.json. make_examples.tfrecord-00006-of-00008.gz. make_examples.tfrecord-00006-of-00008.gz.example_info.json. make_examples.tfrecord-00007-of-00008.gz. make_examples.tfrecord-00007-of-00008.gz.example_info.json. postprocess_variants.log.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:3470,safety,log,log,3470,"t_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.gz"" to ""./call_variants_output@1.tfrecord.gz"" and it works. Anyway, the call of postprocess_variants.py is auto-generated by ""/opt/deepvariant/bin/run_deepvariant"". The error does not occur for every sample ... directory content of intermediate_results_dir after the error occured:. call_variants.log. call_variants_output-00000-of-00001.tfrecord.gz. gvcf.tfrecord-00000-of-00008.gz. gvcf.tfrecord-00001-of-00008.gz. gvcf.tfrecord-00002-of-00008.gz. gvcf.tfrecord-00003-of-00008.gz. gvcf.tfrecord-00004-of-00008.gz. gvcf.tfrecord-00005-of-00008.gz. gvcf.tfrecord-00006-of-00008.gz. gvcf.tfrecord-00007-of-00008.gz. make_examples.log. make_examples.tfrecord-00000-of-00008.gz. make_examples.tfrecord-00000-of-00008.gz.example_info.json. make_examples.tfrecord-00001-of-00008.gz. make_examples.tfrecord-00001-of-00008.gz.example_info.json. make_examples.tfrecord-00002-of-00008.gz. make_examples.tfrecord-00002-of-00008.gz.example_info.json. make_examples.tfrecord-00003-of-00008.gz. make_examples.tfrecord-00003-of-00008.gz.example_info.json. make_examples.tfrecord-00004-of-00008.gz. make_examples.tfrecord-00004-of-00008.gz.example_info.json. make_examples.tfrecord-00005-of-00008.gz. make_examples.tfrecord-00005-of-00008.gz.example_info.json. make_examples.tfrecord-00006-of-00008.gz. make_examples.tfrecord-00006-of-00008.gz.example_info.json. make_examples.tfrecord-00007-of-00008.gz. make_examples.tfrecord-00007-of-00008.gz.example_info.json. postprocess_variants.log.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:2296,security,log,log,2296,"le_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.gz"" to ""./call_variants_output@1.tfrecord.gz"" and it works. Anyway, the call of postprocess_variants.py is auto-generated by ""/opt/deepvariant/bin/run_deepvariant"". The error does not occur for every sample ... directory content of intermediate_results_dir after the error occured:. call_variants.log. call_variants_output-00000-of-00001.tfrecord.gz. gvcf.tfrecord-00000-of-00008.gz. gvcf.tfrecord-00001-of-00008.gz. gvcf.tfrecord-00002-of-00008.gz. gvcf.tfrecord-00003-of-00008.gz. gvcf.tfrecord-00004-of-00008.gz. gvcf.tfrecord-00005-of-00008.gz. gvcf.tfrecord-00006-of-00008.gz. gvcf.tfrecord-00007-of-00008.gz. make_examples.log. make_examples.tfrecord-00000-of-00008.gz. make_examples.tfrecord-00000-of-00008.gz.example_info.json. make_examples.tfrecord-00001-of-00008.gz. make_examples.tfrecord-00001-of-00008.gz.example_info.json. make_examples.tfrecord-00002-of-00008.gz. make_examples.tfrecord-00002-of-00008.gz.example_info.json. make_examples.tfrecord-00003-of-00008.gz. make_examples.tfrecord-00003-of-00008.gz.example_info.json. make_examples.tfrecord-00004-of-00008.gz. make_examples.tfrecord-00004-of-00008.gz.example_info.json. make_examples.tfrecord-00005-of-00008.gz. make_examples.tfrecord-00005-of-00008.gz.example_info.json. make_examples.tfrecord-00006-of-00008.gz. make_exampl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:2628,security,log,log,2628,"t_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.gz"" to ""./call_variants_output@1.tfrecord.gz"" and it works. Anyway, the call of postprocess_variants.py is auto-generated by ""/opt/deepvariant/bin/run_deepvariant"". The error does not occur for every sample ... directory content of intermediate_results_dir after the error occured:. call_variants.log. call_variants_output-00000-of-00001.tfrecord.gz. gvcf.tfrecord-00000-of-00008.gz. gvcf.tfrecord-00001-of-00008.gz. gvcf.tfrecord-00002-of-00008.gz. gvcf.tfrecord-00003-of-00008.gz. gvcf.tfrecord-00004-of-00008.gz. gvcf.tfrecord-00005-of-00008.gz. gvcf.tfrecord-00006-of-00008.gz. gvcf.tfrecord-00007-of-00008.gz. make_examples.log. make_examples.tfrecord-00000-of-00008.gz. make_examples.tfrecord-00000-of-00008.gz.example_info.json. make_examples.tfrecord-00001-of-00008.gz. make_examples.tfrecord-00001-of-00008.gz.example_info.json. make_examples.tfrecord-00002-of-00008.gz. make_examples.tfrecord-00002-of-00008.gz.example_info.json. make_examples.tfrecord-00003-of-00008.gz. make_examples.tfrecord-00003-of-00008.gz.example_info.json. make_examples.tfrecord-00004-of-00008.gz. make_examples.tfrecord-00004-of-00008.gz.example_info.json. make_examples.tfrecord-00005-of-00008.gz. make_examples.tfrecord-00005-of-00008.gz.example_info.json. make_examples.tfrecord-00006-of-00008.gz. make_examples.tfrecord-00006-of-00008.gz.example_info.json. make_examples.tfrecord-00007-of-00008.gz. make_examples.tfrecord-00007-of-00008.gz.example_info.json. postprocess_variants.log.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:3470,security,log,log,3470,"t_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.gz"" to ""./call_variants_output@1.tfrecord.gz"" and it works. Anyway, the call of postprocess_variants.py is auto-generated by ""/opt/deepvariant/bin/run_deepvariant"". The error does not occur for every sample ... directory content of intermediate_results_dir after the error occured:. call_variants.log. call_variants_output-00000-of-00001.tfrecord.gz. gvcf.tfrecord-00000-of-00008.gz. gvcf.tfrecord-00001-of-00008.gz. gvcf.tfrecord-00002-of-00008.gz. gvcf.tfrecord-00003-of-00008.gz. gvcf.tfrecord-00004-of-00008.gz. gvcf.tfrecord-00005-of-00008.gz. gvcf.tfrecord-00006-of-00008.gz. gvcf.tfrecord-00007-of-00008.gz. make_examples.log. make_examples.tfrecord-00000-of-00008.gz. make_examples.tfrecord-00000-of-00008.gz.example_info.json. make_examples.tfrecord-00001-of-00008.gz. make_examples.tfrecord-00001-of-00008.gz.example_info.json. make_examples.tfrecord-00002-of-00008.gz. make_examples.tfrecord-00002-of-00008.gz.example_info.json. make_examples.tfrecord-00003-of-00008.gz. make_examples.tfrecord-00003-of-00008.gz.example_info.json. make_examples.tfrecord-00004-of-00008.gz. make_examples.tfrecord-00004-of-00008.gz.example_info.json. make_examples.tfrecord-00005-of-00008.gz. make_examples.tfrecord-00005-of-00008.gz.example_info.json. make_examples.tfrecord-00006-of-00008.gz. make_examples.tfrecord-00006-of-00008.gz.example_info.json. make_examples.tfrecord-00007-of-00008.gz. make_examples.tfrecord-00007-of-00008.gz.example_info.json. postprocess_variants.log.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:606,testability,trace,trace,606,"postprocess_variants: Found multiple file patterns in input filename space; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. The postprocess_variants step fails with following error message:. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Setup**. - Operating system: CentOS Linux 7 (Core). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio Sequencing. **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1300, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:614,testability,Trace,Traceback,614,"postprocess_variants: Found multiple file patterns in input filename space; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. The postprocess_variants step fails with following error message:. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Setup**. - Operating system: CentOS Linux 7 (Core). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio Sequencing. **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1300, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:1656,testability,test,test,1656,"mp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1300, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.gz"" to ""./call_variants_output@1.tfrecord.gz"" and it works. Anyway, the call of postprocess_variants.py is auto-generated by ""/opt/deepvariant/bin/run_deepvariant"". The error does not occur for every sample ... directory content of intermediate_results_dir after the error occured:. call_variants.log. call_variants_output-00000-of-00001.tfrecord.gz. gvcf.tfrecord-00000-of-00008.gz. gvcf.tfrecord-00001-of-00008.gz. gvcf.tfrecord-00002-of-00008.gz. gvcf.tfrecord-00003-of-00008.gz. gvcf.tfrecord-00004-of-00008.gz. gvcf.tfrecord-00005-of-00008.gz. gvcf.tfrecord-00006-of-00008.gz. gvcf.tfrecord-00007-of-00008.gz. make_examples.log. make_examples.tfrecord-00",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:1692,testability,test,test,1692,"com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1300, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.gz"" to ""./call_variants_output@1.tfrecord.gz"" and it works. Anyway, the call of postprocess_variants.py is auto-generated by ""/opt/deepvariant/bin/run_deepvariant"". The error does not occur for every sample ... directory content of intermediate_results_dir after the error occured:. call_variants.log. call_variants_output-00000-of-00001.tfrecord.gz. gvcf.tfrecord-00000-of-00008.gz. gvcf.tfrecord-00001-of-00008.gz. gvcf.tfrecord-00002-of-00008.gz. gvcf.tfrecord-00003-of-00008.gz. gvcf.tfrecord-00004-of-00008.gz. gvcf.tfrecord-00005-of-00008.gz. gvcf.tfrecord-00006-of-00008.gz. gvcf.tfrecord-00007-of-00008.gz. make_examples.log. make_examples.tfrecord-00000-of-00008.gz. make_examples.tfrec",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:1870,testability,context,context,1870,"un. _run_main(main, args). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1300, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.gz"" to ""./call_variants_output@1.tfrecord.gz"" and it works. Anyway, the call of postprocess_variants.py is auto-generated by ""/opt/deepvariant/bin/run_deepvariant"". The error does not occur for every sample ... directory content of intermediate_results_dir after the error occured:. call_variants.log. call_variants_output-00000-of-00001.tfrecord.gz. gvcf.tfrecord-00000-of-00008.gz. gvcf.tfrecord-00001-of-00008.gz. gvcf.tfrecord-00002-of-00008.gz. gvcf.tfrecord-00003-of-00008.gz. gvcf.tfrecord-00004-of-00008.gz. gvcf.tfrecord-00005-of-00008.gz. gvcf.tfrecord-00006-of-00008.gz. gvcf.tfrecord-00007-of-00008.gz. make_examples.log. make_examples.tfrecord-00000-of-00008.gz. make_examples.tfrecord-00000-of-00008.gz.example_info.json. make_examples.tfrecord-00001-of-00008.gz. make_examples.tfrecord-00001-of-00008.gz.example_info.json. make_examples.tfrecord-00002-of-00008",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:2296,testability,log,log,2296,"le_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.gz"" to ""./call_variants_output@1.tfrecord.gz"" and it works. Anyway, the call of postprocess_variants.py is auto-generated by ""/opt/deepvariant/bin/run_deepvariant"". The error does not occur for every sample ... directory content of intermediate_results_dir after the error occured:. call_variants.log. call_variants_output-00000-of-00001.tfrecord.gz. gvcf.tfrecord-00000-of-00008.gz. gvcf.tfrecord-00001-of-00008.gz. gvcf.tfrecord-00002-of-00008.gz. gvcf.tfrecord-00003-of-00008.gz. gvcf.tfrecord-00004-of-00008.gz. gvcf.tfrecord-00005-of-00008.gz. gvcf.tfrecord-00006-of-00008.gz. gvcf.tfrecord-00007-of-00008.gz. make_examples.log. make_examples.tfrecord-00000-of-00008.gz. make_examples.tfrecord-00000-of-00008.gz.example_info.json. make_examples.tfrecord-00001-of-00008.gz. make_examples.tfrecord-00001-of-00008.gz.example_info.json. make_examples.tfrecord-00002-of-00008.gz. make_examples.tfrecord-00002-of-00008.gz.example_info.json. make_examples.tfrecord-00003-of-00008.gz. make_examples.tfrecord-00003-of-00008.gz.example_info.json. make_examples.tfrecord-00004-of-00008.gz. make_examples.tfrecord-00004-of-00008.gz.example_info.json. make_examples.tfrecord-00005-of-00008.gz. make_examples.tfrecord-00005-of-00008.gz.example_info.json. make_examples.tfrecord-00006-of-00008.gz. make_exampl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:2628,testability,log,log,2628,"t_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.gz"" to ""./call_variants_output@1.tfrecord.gz"" and it works. Anyway, the call of postprocess_variants.py is auto-generated by ""/opt/deepvariant/bin/run_deepvariant"". The error does not occur for every sample ... directory content of intermediate_results_dir after the error occured:. call_variants.log. call_variants_output-00000-of-00001.tfrecord.gz. gvcf.tfrecord-00000-of-00008.gz. gvcf.tfrecord-00001-of-00008.gz. gvcf.tfrecord-00002-of-00008.gz. gvcf.tfrecord-00003-of-00008.gz. gvcf.tfrecord-00004-of-00008.gz. gvcf.tfrecord-00005-of-00008.gz. gvcf.tfrecord-00006-of-00008.gz. gvcf.tfrecord-00007-of-00008.gz. make_examples.log. make_examples.tfrecord-00000-of-00008.gz. make_examples.tfrecord-00000-of-00008.gz.example_info.json. make_examples.tfrecord-00001-of-00008.gz. make_examples.tfrecord-00001-of-00008.gz.example_info.json. make_examples.tfrecord-00002-of-00008.gz. make_examples.tfrecord-00002-of-00008.gz.example_info.json. make_examples.tfrecord-00003-of-00008.gz. make_examples.tfrecord-00003-of-00008.gz.example_info.json. make_examples.tfrecord-00004-of-00008.gz. make_examples.tfrecord-00004-of-00008.gz.example_info.json. make_examples.tfrecord-00005-of-00008.gz. make_examples.tfrecord-00005-of-00008.gz.example_info.json. make_examples.tfrecord-00006-of-00008.gz. make_examples.tfrecord-00006-of-00008.gz.example_info.json. make_examples.tfrecord-00007-of-00008.gz. make_examples.tfrecord-00007-of-00008.gz.example_info.json. postprocess_variants.log.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:3470,testability,log,log,3470,"t_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.gz"" to ""./call_variants_output@1.tfrecord.gz"" and it works. Anyway, the call of postprocess_variants.py is auto-generated by ""/opt/deepvariant/bin/run_deepvariant"". The error does not occur for every sample ... directory content of intermediate_results_dir after the error occured:. call_variants.log. call_variants_output-00000-of-00001.tfrecord.gz. gvcf.tfrecord-00000-of-00008.gz. gvcf.tfrecord-00001-of-00008.gz. gvcf.tfrecord-00002-of-00008.gz. gvcf.tfrecord-00003-of-00008.gz. gvcf.tfrecord-00004-of-00008.gz. gvcf.tfrecord-00005-of-00008.gz. gvcf.tfrecord-00006-of-00008.gz. gvcf.tfrecord-00007-of-00008.gz. make_examples.log. make_examples.tfrecord-00000-of-00008.gz. make_examples.tfrecord-00000-of-00008.gz.example_info.json. make_examples.tfrecord-00001-of-00008.gz. make_examples.tfrecord-00001-of-00008.gz.example_info.json. make_examples.tfrecord-00002-of-00008.gz. make_examples.tfrecord-00002-of-00008.gz.example_info.json. make_examples.tfrecord-00003-of-00008.gz. make_examples.tfrecord-00003-of-00008.gz.example_info.json. make_examples.tfrecord-00004-of-00008.gz. make_examples.tfrecord-00004-of-00008.gz.example_info.json. make_examples.tfrecord-00005-of-00008.gz. make_examples.tfrecord-00005-of-00008.gz.example_info.json. make_examples.tfrecord-00006-of-00008.gz. make_examples.tfrecord-00006-of-00008.gz.example_info.json. make_examples.tfrecord-00007-of-00008.gz. make_examples.tfrecord-00007-of-00008.gz.example_info.json. postprocess_variants.log.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:54,usability,input,input,54,"postprocess_variants: Found multiple file patterns in input filename space; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. The postprocess_variants step fails with following error message:. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Setup**. - Operating system: CentOS Linux 7 (Core). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio Sequencing. **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1300, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:246,usability,error,error,246,"postprocess_variants: Found multiple file patterns in input filename space; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. The postprocess_variants step fails with following error message:. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Setup**. - Operating system: CentOS Linux 7 (Core). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio Sequencing. **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1300, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:308,usability,input,input,308,"postprocess_variants: Found multiple file patterns in input filename space; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. The postprocess_variants step fails with following error message:. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Setup**. - Operating system: CentOS Linux 7 (Core). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio Sequencing. **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1300, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:588,usability,Command,Command,588,"postprocess_variants: Found multiple file patterns in input filename space; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. The postprocess_variants step fails with following error message:. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Setup**. - Operating system: CentOS Linux 7 (Core). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio Sequencing. **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1300, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:600,usability,Error,Error,600,"postprocess_variants: Found multiple file patterns in input filename space; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. The postprocess_variants step fails with following error message:. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Setup**. - Operating system: CentOS Linux 7 (Core). - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): singularity. - Type of data: PacBio Sequencing. **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1300, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:1569,usability,input,input,1569,"reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1300, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.gz"" to ""./call_variants_output@1.tfrecord.gz"" and it works. Anyway, the call of postprocess_variants.py is auto-generated by ""/opt/deepvariant/bin/run_deepvariant"". The error does not occur for every sample ... directory content of intermediate_results_dir after the error occured:. call_variants.log. call_variants_output-00000-of-00001.tfrecord.gz. gvcf.tfrecord-00000-of-00008.gz. gvcf.tfrecord-00001-of-00008.gz. gvcf.tfrecord-00002-of-00008.gz. gvcf.tfrecord-00003-of-00008.gz. gvcf.tfrecord-00004-of-00008.gz. gvcf.tfrecord-00005-of-00008.gz. gvcf.tfrecord-00006-of-0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:2168,usability,error,error,2168,"File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.gz"" to ""./call_variants_output@1.tfrecord.gz"" and it works. Anyway, the call of postprocess_variants.py is auto-generated by ""/opt/deepvariant/bin/run_deepvariant"". The error does not occur for every sample ... directory content of intermediate_results_dir after the error occured:. call_variants.log. call_variants_output-00000-of-00001.tfrecord.gz. gvcf.tfrecord-00000-of-00008.gz. gvcf.tfrecord-00001-of-00008.gz. gvcf.tfrecord-00002-of-00008.gz. gvcf.tfrecord-00003-of-00008.gz. gvcf.tfrecord-00004-of-00008.gz. gvcf.tfrecord-00005-of-00008.gz. gvcf.tfrecord-00006-of-00008.gz. gvcf.tfrecord-00007-of-00008.gz. make_examples.log. make_examples.tfrecord-00000-of-00008.gz. make_examples.tfrecord-00000-of-00008.gz.example_info.json. make_examples.tfrecord-00001-of-00008.gz. make_examples.tfrecord-00001-of-00008.gz.example_info.json. make_examples.tfrecord-00002-of-00008.gz. make_examples.tfrecord-00002-of-00008.gz.example_info.json. make_examples.tfrecord-00003-of-00008.gz. make_examples.tfrecord-00003-of-00008.gz.example_info.json. make_examples.tfrecord-00004-of-00008.gz. make_examples.tfrecord-00004-of-00008.gz.example_info.json. make_examples.tfrecord-00005",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/818:2266,usability,error,error,2266,"s.py"", line 1203, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_t3t5ek8u/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1179, in get_cvo_paths_and_first_record. raise ValueError(. ValueError: ('Found multiple file patterns in input filename space: ', './call_variants_output.tfrecord.gz'). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? ??? **Any additional context:**. Yes. I can change the parameter ""--infile"" of the postprocess_variants.py call from ""./call_variants_output.tfrecord.gz"" to ""./call_variants_output@1.tfrecord.gz"" and it works. Anyway, the call of postprocess_variants.py is auto-generated by ""/opt/deepvariant/bin/run_deepvariant"". The error does not occur for every sample ... directory content of intermediate_results_dir after the error occured:. call_variants.log. call_variants_output-00000-of-00001.tfrecord.gz. gvcf.tfrecord-00000-of-00008.gz. gvcf.tfrecord-00001-of-00008.gz. gvcf.tfrecord-00002-of-00008.gz. gvcf.tfrecord-00003-of-00008.gz. gvcf.tfrecord-00004-of-00008.gz. gvcf.tfrecord-00005-of-00008.gz. gvcf.tfrecord-00006-of-00008.gz. gvcf.tfrecord-00007-of-00008.gz. make_examples.log. make_examples.tfrecord-00000-of-00008.gz. make_examples.tfrecord-00000-of-00008.gz.example_info.json. make_examples.tfrecord-00001-of-00008.gz. make_examples.tfrecord-00001-of-00008.gz.example_info.json. make_examples.tfrecord-00002-of-00008.gz. make_examples.tfrecord-00002-of-00008.gz.example_info.json. make_examples.tfrecord-00003-of-00008.gz. make_examples.tfrecord-00003-of-00008.gz.example_info.json. make_examples.tfrecord-00004-of-00008.gz. make_examples.tfrecord-00004-of-00008.gz.example_info.json. make_examples.tfrecord-00005-of-00008.gz. make_examples.tfrecord-00005-of-00008.gz.example_info.json. make_examples.tfrecord-0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/818
https://github.com/google/deepvariant/issues/819:284,availability,error,error,284,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:649,availability,Error,Error,649,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:1232,deployability,instal,installed,1232,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:86,energy efficiency,gpu,gpu,86,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:119,energy efficiency,gpu,gpu,119,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:191,energy efficiency,gpu,gpu,191,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:228,energy efficiency,gpu,gpu,228,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:245,energy efficiency,GPU,GPU,245,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:532,energy efficiency,GPU,GPU,532,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:594,energy efficiency,gpu,gpus,594,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:626,energy efficiency,gpu,gpu,626,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:787,energy efficiency,load,load,787,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:1154,energy efficiency,GPU,GPU,1154,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:290,integrability,messag,message,290,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:655,integrability,messag,message,655,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:12,interoperability,Incompatib,Incompatible,12,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:290,interoperability,messag,message,290,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:448,interoperability,incompatib,incompatible,448,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:655,interoperability,messag,message,655,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:742,interoperability,platform,platform,742,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:872,interoperability,share,shared,872,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:86,performance,gpu,gpu,86,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:119,performance,gpu,gpu,119,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:191,performance,gpu,gpu,191,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:228,performance,gpu,gpu,228,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:245,performance,GPU,GPU,245,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:284,performance,error,error,284,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:532,performance,GPU,GPU,532,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:594,performance,gpu,gpus,594,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:626,performance,gpu,gpu,626,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:649,performance,Error,Error,649,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:787,performance,load,load,787,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:1154,performance,GPU,GPU,1154,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:284,safety,error,error,284,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:492,safety,prevent,preventing,492,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:649,safety,Error,Error,649,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:492,security,preven,preventing,492,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:284,usability,error,error,284,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:539,usability,Command,Command,539,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:638,usability,help,help,638,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/819:649,usability,Error,Error,649,"Issues with Incompatible TensorRT libraries in docker image google/deepvariant:latest-gpu and google/deepvariant:1.6.1-gpu ; Hello,. I've been trying to set up the **google/deepvariant:1.6.1-gpu** or **google/deepvariant:latest-gpu** image on a GPU instance, but I've encountered the error message mentioned below when running the **run_deepvariant** or **train** scripts, and despite generating the flags (screenshot) as expected, I believe those incompatible/missing TensorRT libraries are preventing these scripts from using the GPU. **Command used:** . ` sudo docker run --runtime=nvidia --gpus 1 google/deepvariant:1.6.1-gpu train --help. `. **Error message:**. ```. 2024-05-08 15:11:26.358196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-05-08 15:11:26.358229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. ```. ![image](https://github.com/google/deepvariant/assets/169280348/fd17bf4e-0b6c-46b7-b5e8-74a3525d07a5).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/819
https://github.com/google/deepvariant/issues/820:1194,availability,Operat,Operating,1194,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected; Hi , when i run call_variant , it arises this warn which means can't use the gpu,but i can make sure that the tensorflow can use the gpu.There are the screen shots of the warn and the existence of the gpu. - the gpu existence. ![image](https://github.com/google/deepvariant/assets/71956115/367b1a98-123c-48fb-b170-3f8e4aae7d30). ```python. tensorflow.test.is_gpu_available(). WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.config.list_physical_devices('GPU')` instead. 2024-05-12 21:36:00.744470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 15089 MB memory: -> device: 0, name: Vega 20, pci bus id: 0000:26:00.0. True. ```. - the warn . ![image](https://github.com/google/deepvariant/assets/71956115/246d5cfd-a9b3-4ac5-aea7-bf4c89401c76). ```shell. warnings.warn(. 2024-05-12 21:43:29.067332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ```. - Operating system: Linux . - DeepVariant version: 1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/820
https://github.com/google/deepvariant/issues/820:577,deployability,version,version,577,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected; Hi , when i run call_variant , it arises this warn which means can't use the gpu,but i can make sure that the tensorflow can use the gpu.There are the screen shots of the warn and the existence of the gpu. - the gpu existence. ![image](https://github.com/google/deepvariant/assets/71956115/367b1a98-123c-48fb-b170-3f8e4aae7d30). ```python. tensorflow.test.is_gpu_available(). WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.config.list_physical_devices('GPU')` instead. 2024-05-12 21:36:00.744470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 15089 MB memory: -> device: 0, name: Vega 20, pci bus id: 0000:26:00.0. True. ```. - the warn . ![image](https://github.com/google/deepvariant/assets/71956115/246d5cfd-a9b3-4ac5-aea7-bf4c89401c76). ```shell. warnings.warn(. 2024-05-12 21:43:29.067332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ```. - Operating system: Linux . - DeepVariant version: 1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/820
https://github.com/google/deepvariant/issues/820:603,deployability,updat,updating,603,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected; Hi , when i run call_variant , it arises this warn which means can't use the gpu,but i can make sure that the tensorflow can use the gpu.There are the screen shots of the warn and the existence of the gpu. - the gpu existence. ![image](https://github.com/google/deepvariant/assets/71956115/367b1a98-123c-48fb-b170-3f8e4aae7d30). ```python. tensorflow.test.is_gpu_available(). WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.config.list_physical_devices('GPU')` instead. 2024-05-12 21:36:00.744470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 15089 MB memory: -> device: 0, name: Vega 20, pci bus id: 0000:26:00.0. True. ```. - the warn . ![image](https://github.com/google/deepvariant/assets/71956115/246d5cfd-a9b3-4ac5-aea7-bf4c89401c76). ```shell. warnings.warn(. 2024-05-12 21:43:29.067332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ```. - Operating system: Linux . - DeepVariant version: 1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/820
https://github.com/google/deepvariant/issues/820:1106,deployability,fail,failed,1106,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected; Hi , when i run call_variant , it arises this warn which means can't use the gpu,but i can make sure that the tensorflow can use the gpu.There are the screen shots of the warn and the existence of the gpu. - the gpu existence. ![image](https://github.com/google/deepvariant/assets/71956115/367b1a98-123c-48fb-b170-3f8e4aae7d30). ```python. tensorflow.test.is_gpu_available(). WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.config.list_physical_devices('GPU')` instead. 2024-05-12 21:36:00.744470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 15089 MB memory: -> device: 0, name: Vega 20, pci bus id: 0000:26:00.0. True. ```. - the warn . ![image](https://github.com/google/deepvariant/assets/71956115/246d5cfd-a9b3-4ac5-aea7-bf4c89401c76). ```shell. warnings.warn(. 2024-05-12 21:43:29.067332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ```. - Operating system: Linux . - DeepVariant version: 1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/820
https://github.com/google/deepvariant/issues/820:1234,deployability,version,version,1234,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected; Hi , when i run call_variant , it arises this warn which means can't use the gpu,but i can make sure that the tensorflow can use the gpu.There are the screen shots of the warn and the existence of the gpu. - the gpu existence. ![image](https://github.com/google/deepvariant/assets/71956115/367b1a98-123c-48fb-b170-3f8e4aae7d30). ```python. tensorflow.test.is_gpu_available(). WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.config.list_physical_devices('GPU')` instead. 2024-05-12 21:36:00.744470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 15089 MB memory: -> device: 0, name: Vega 20, pci bus id: 0000:26:00.0. True. ```. - the warn . ![image](https://github.com/google/deepvariant/assets/71956115/246d5cfd-a9b3-4ac5-aea7-bf4c89401c76). ```shell. warnings.warn(. 2024-05-12 21:43:29.067332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ```. - Operating system: Linux . - DeepVariant version: 1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/820
https://github.com/google/deepvariant/issues/820:1256,deployability,Instal,Installation,1256,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected; Hi , when i run call_variant , it arises this warn which means can't use the gpu,but i can make sure that the tensorflow can use the gpu.There are the screen shots of the warn and the existence of the gpu. - the gpu existence. ![image](https://github.com/google/deepvariant/assets/71956115/367b1a98-123c-48fb-b170-3f8e4aae7d30). ```python. tensorflow.test.is_gpu_available(). WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.config.list_physical_devices('GPU')` instead. 2024-05-12 21:36:00.744470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 15089 MB memory: -> device: 0, name: Vega 20, pci bus id: 0000:26:00.0. True. ```. - the warn . ![image](https://github.com/google/deepvariant/assets/71956115/246d5cfd-a9b3-4ac5-aea7-bf4c89401c76). ```shell. warnings.warn(. 2024-05-12 21:43:29.067332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ```. - Operating system: Linux . - DeepVariant version: 1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/820
https://github.com/google/deepvariant/issues/820:135,energy efficiency,gpu,gpu,135,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected; Hi , when i run call_variant , it arises this warn which means can't use the gpu,but i can make sure that the tensorflow can use the gpu.There are the screen shots of the warn and the existence of the gpu. - the gpu existence. ![image](https://github.com/google/deepvariant/assets/71956115/367b1a98-123c-48fb-b170-3f8e4aae7d30). ```python. tensorflow.test.is_gpu_available(). WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.config.list_physical_devices('GPU')` instead. 2024-05-12 21:36:00.744470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 15089 MB memory: -> device: 0, name: Vega 20, pci bus id: 0000:26:00.0. True. ```. - the warn . ![image](https://github.com/google/deepvariant/assets/71956115/246d5cfd-a9b3-4ac5-aea7-bf4c89401c76). ```shell. warnings.warn(. 2024-05-12 21:43:29.067332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ```. - Operating system: Linux . - DeepVariant version: 1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/820
https://github.com/google/deepvariant/issues/820:191,energy efficiency,gpu,gpu,191,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected; Hi , when i run call_variant , it arises this warn which means can't use the gpu,but i can make sure that the tensorflow can use the gpu.There are the screen shots of the warn and the existence of the gpu. - the gpu existence. ![image](https://github.com/google/deepvariant/assets/71956115/367b1a98-123c-48fb-b170-3f8e4aae7d30). ```python. tensorflow.test.is_gpu_available(). WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.config.list_physical_devices('GPU')` instead. 2024-05-12 21:36:00.744470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 15089 MB memory: -> device: 0, name: Vega 20, pci bus id: 0000:26:00.0. True. ```. - the warn . ![image](https://github.com/google/deepvariant/assets/71956115/246d5cfd-a9b3-4ac5-aea7-bf4c89401c76). ```shell. warnings.warn(. 2024-05-12 21:43:29.067332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ```. - Operating system: Linux . - DeepVariant version: 1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/820
https://github.com/google/deepvariant/issues/820:259,energy efficiency,gpu,gpu,259,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected; Hi , when i run call_variant , it arises this warn which means can't use the gpu,but i can make sure that the tensorflow can use the gpu.There are the screen shots of the warn and the existence of the gpu. - the gpu existence. ![image](https://github.com/google/deepvariant/assets/71956115/367b1a98-123c-48fb-b170-3f8e4aae7d30). ```python. tensorflow.test.is_gpu_available(). WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.config.list_physical_devices('GPU')` instead. 2024-05-12 21:36:00.744470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 15089 MB memory: -> device: 0, name: Vega 20, pci bus id: 0000:26:00.0. True. ```. - the warn . ![image](https://github.com/google/deepvariant/assets/71956115/246d5cfd-a9b3-4ac5-aea7-bf4c89401c76). ```shell. warnings.warn(. 2024-05-12 21:43:29.067332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ```. - Operating system: Linux . - DeepVariant version: 1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/820
https://github.com/google/deepvariant/issues/820:270,energy efficiency,gpu,gpu,270,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected; Hi , when i run call_variant , it arises this warn which means can't use the gpu,but i can make sure that the tensorflow can use the gpu.There are the screen shots of the warn and the existence of the gpu. - the gpu existence. ![image](https://github.com/google/deepvariant/assets/71956115/367b1a98-123c-48fb-b170-3f8e4aae7d30). ```python. tensorflow.test.is_gpu_available(). WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.config.list_physical_devices('GPU')` instead. 2024-05-12 21:36:00.744470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 15089 MB memory: -> device: 0, name: Vega 20, pci bus id: 0000:26:00.0. True. ```. - the warn . ![image](https://github.com/google/deepvariant/assets/71956115/246d5cfd-a9b3-4ac5-aea7-bf4c89401c76). ```shell. warnings.warn(. 2024-05-12 21:43:29.067332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ```. - Operating system: Linux . - DeepVariant version: 1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/820
https://github.com/google/deepvariant/issues/820:652,energy efficiency,GPU,GPU,652,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected; Hi , when i run call_variant , it arises this warn which means can't use the gpu,but i can make sure that the tensorflow can use the gpu.There are the screen shots of the warn and the existence of the gpu. - the gpu existence. ![image](https://github.com/google/deepvariant/assets/71956115/367b1a98-123c-48fb-b170-3f8e4aae7d30). ```python. tensorflow.test.is_gpu_available(). WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.config.list_physical_devices('GPU')` instead. 2024-05-12 21:36:00.744470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 15089 MB memory: -> device: 0, name: Vega 20, pci bus id: 0000:26:00.0. True. ```. - the warn . ![image](https://github.com/google/deepvariant/assets/71956115/246d5cfd-a9b3-4ac5-aea7-bf4c89401c76). ```shell. warnings.warn(. 2024-05-12 21:43:29.067332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ```. - Operating system: Linux . - DeepVariant version: 1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/820
https://github.com/google/deepvariant/issues/820:709,energy efficiency,core,core,709,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected; Hi , when i run call_variant , it arises this warn which means can't use the gpu,but i can make sure that the tensorflow can use the gpu.There are the screen shots of the warn and the existence of the gpu. - the gpu existence. ![image](https://github.com/google/deepvariant/assets/71956115/367b1a98-123c-48fb-b170-3f8e4aae7d30). ```python. tensorflow.test.is_gpu_available(). WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.config.list_physical_devices('GPU')` instead. 2024-05-12 21:36:00.744470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 15089 MB memory: -> device: 0, name: Vega 20, pci bus id: 0000:26:00.0. True. ```. - the warn . ![image](https://github.com/google/deepvariant/assets/71956115/246d5cfd-a9b3-4ac5-aea7-bf4c89401c76). ```shell. warnings.warn(. 2024-05-12 21:43:29.067332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ```. - Operating system: Linux . - DeepVariant version: 1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/820
https://github.com/google/deepvariant/issues/820:729,energy efficiency,gpu,gpu,729,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected; Hi , when i run call_variant , it arises this warn which means can't use the gpu,but i can make sure that the tensorflow can use the gpu.There are the screen shots of the warn and the existence of the gpu. - the gpu existence. ![image](https://github.com/google/deepvariant/assets/71956115/367b1a98-123c-48fb-b170-3f8e4aae7d30). ```python. tensorflow.test.is_gpu_available(). WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.config.list_physical_devices('GPU')` instead. 2024-05-12 21:36:00.744470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 15089 MB memory: -> device: 0, name: Vega 20, pci bus id: 0000:26:00.0. True. ```. - the warn . ![image](https://github.com/google/deepvariant/assets/71956115/246d5cfd-a9b3-4ac5-aea7-bf4c89401c76). ```shell. warnings.warn(. 2024-05-12 21:43:29.067332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ```. - Operating system: Linux . - DeepVariant version: 1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/820
https://github.com/google/deepvariant/issues/820:776,energy efficiency,GPU,GPU,776,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected; Hi , when i run call_variant , it arises this warn which means can't use the gpu,but i can make sure that the tensorflow can use the gpu.There are the screen shots of the warn and the existence of the gpu. - the gpu existence. ![image](https://github.com/google/deepvariant/assets/71956115/367b1a98-123c-48fb-b170-3f8e4aae7d30). ```python. tensorflow.test.is_gpu_available(). WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.config.list_physical_devices('GPU')` instead. 2024-05-12 21:36:00.744470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 15089 MB memory: -> device: 0, name: Vega 20, pci bus id: 0000:26:00.0. True. ```. - the warn . ![image](https://github.com/google/deepvariant/assets/71956115/246d5cfd-a9b3-4ac5-aea7-bf4c89401c76). ```shell. warnings.warn(. 2024-05-12 21:43:29.067332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ```. - Operating system: Linux . - DeepVariant version: 1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/820
https://github.com/google/deepvariant/issues/820:1249,energy efficiency,gpu,gpu,1249,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected; Hi , when i run call_variant , it arises this warn which means can't use the gpu,but i can make sure that the tensorflow can use the gpu.There are the screen shots of the warn and the existence of the gpu. - the gpu existence. ![image](https://github.com/google/deepvariant/assets/71956115/367b1a98-123c-48fb-b170-3f8e4aae7d30). ```python. tensorflow.test.is_gpu_available(). WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.config.list_physical_devices('GPU')` instead. 2024-05-12 21:36:00.744470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 15089 MB memory: -> device: 0, name: Vega 20, pci bus id: 0000:26:00.0. True. ```. - the warn . ![image](https://github.com/google/deepvariant/assets/71956115/246d5cfd-a9b3-4ac5-aea7-bf4c89401c76). ```shell. warnings.warn(. 2024-05-12 21:43:29.067332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ```. - Operating system: Linux . - DeepVariant version: 1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/820
https://github.com/google/deepvariant/issues/820:577,integrability,version,version,577,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected; Hi , when i run call_variant , it arises this warn which means can't use the gpu,but i can make sure that the tensorflow can use the gpu.There are the screen shots of the warn and the existence of the gpu. - the gpu existence. ![image](https://github.com/google/deepvariant/assets/71956115/367b1a98-123c-48fb-b170-3f8e4aae7d30). ```python. tensorflow.test.is_gpu_available(). WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.config.list_physical_devices('GPU')` instead. 2024-05-12 21:36:00.744470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 15089 MB memory: -> device: 0, name: Vega 20, pci bus id: 0000:26:00.0. True. ```. - the warn . ![image](https://github.com/google/deepvariant/assets/71956115/246d5cfd-a9b3-4ac5-aea7-bf4c89401c76). ```shell. warnings.warn(. 2024-05-12 21:43:29.067332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ```. - Operating system: Linux . - DeepVariant version: 1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/820
https://github.com/google/deepvariant/issues/820:1234,integrability,version,version,1234,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected; Hi , when i run call_variant , it arises this warn which means can't use the gpu,but i can make sure that the tensorflow can use the gpu.There are the screen shots of the warn and the existence of the gpu. - the gpu existence. ![image](https://github.com/google/deepvariant/assets/71956115/367b1a98-123c-48fb-b170-3f8e4aae7d30). ```python. tensorflow.test.is_gpu_available(). WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.config.list_physical_devices('GPU')` instead. 2024-05-12 21:36:00.744470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 15089 MB memory: -> device: 0, name: Vega 20, pci bus id: 0000:26:00.0. True. ```. - the warn . ![image](https://github.com/google/deepvariant/assets/71956115/246d5cfd-a9b3-4ac5-aea7-bf4c89401c76). ```shell. warnings.warn(. 2024-05-12 21:43:29.067332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ```. - Operating system: Linux . - DeepVariant version: 1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/820
https://github.com/google/deepvariant/issues/820:577,modifiability,version,version,577,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected; Hi , when i run call_variant , it arises this warn which means can't use the gpu,but i can make sure that the tensorflow can use the gpu.There are the screen shots of the warn and the existence of the gpu. - the gpu existence. ![image](https://github.com/google/deepvariant/assets/71956115/367b1a98-123c-48fb-b170-3f8e4aae7d30). ```python. tensorflow.test.is_gpu_available(). WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.config.list_physical_devices('GPU')` instead. 2024-05-12 21:36:00.744470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 15089 MB memory: -> device: 0, name: Vega 20, pci bus id: 0000:26:00.0. True. ```. - the warn . ![image](https://github.com/google/deepvariant/assets/71956115/246d5cfd-a9b3-4ac5-aea7-bf4c89401c76). ```shell. warnings.warn(. 2024-05-12 21:43:29.067332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ```. - Operating system: Linux . - DeepVariant version: 1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/820
https://github.com/google/deepvariant/issues/820:1234,modifiability,version,version,1234,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected; Hi , when i run call_variant , it arises this warn which means can't use the gpu,but i can make sure that the tensorflow can use the gpu.There are the screen shots of the warn and the existence of the gpu. - the gpu existence. ![image](https://github.com/google/deepvariant/assets/71956115/367b1a98-123c-48fb-b170-3f8e4aae7d30). ```python. tensorflow.test.is_gpu_available(). WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.config.list_physical_devices('GPU')` instead. 2024-05-12 21:36:00.744470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 15089 MB memory: -> device: 0, name: Vega 20, pci bus id: 0000:26:00.0. True. ```. - the warn . ![image](https://github.com/google/deepvariant/assets/71956115/246d5cfd-a9b3-4ac5-aea7-bf4c89401c76). ```shell. warnings.warn(. 2024-05-12 21:43:29.067332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ```. - Operating system: Linux . - DeepVariant version: 1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/820
https://github.com/google/deepvariant/issues/820:135,performance,gpu,gpu,135,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected; Hi , when i run call_variant , it arises this warn which means can't use the gpu,but i can make sure that the tensorflow can use the gpu.There are the screen shots of the warn and the existence of the gpu. - the gpu existence. ![image](https://github.com/google/deepvariant/assets/71956115/367b1a98-123c-48fb-b170-3f8e4aae7d30). ```python. tensorflow.test.is_gpu_available(). WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.config.list_physical_devices('GPU')` instead. 2024-05-12 21:36:00.744470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 15089 MB memory: -> device: 0, name: Vega 20, pci bus id: 0000:26:00.0. True. ```. - the warn . ![image](https://github.com/google/deepvariant/assets/71956115/246d5cfd-a9b3-4ac5-aea7-bf4c89401c76). ```shell. warnings.warn(. 2024-05-12 21:43:29.067332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ```. - Operating system: Linux . - DeepVariant version: 1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/820
https://github.com/google/deepvariant/issues/820:191,performance,gpu,gpu,191,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected; Hi , when i run call_variant , it arises this warn which means can't use the gpu,but i can make sure that the tensorflow can use the gpu.There are the screen shots of the warn and the existence of the gpu. - the gpu existence. ![image](https://github.com/google/deepvariant/assets/71956115/367b1a98-123c-48fb-b170-3f8e4aae7d30). ```python. tensorflow.test.is_gpu_available(). WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.config.list_physical_devices('GPU')` instead. 2024-05-12 21:36:00.744470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 15089 MB memory: -> device: 0, name: Vega 20, pci bus id: 0000:26:00.0. True. ```. - the warn . ![image](https://github.com/google/deepvariant/assets/71956115/246d5cfd-a9b3-4ac5-aea7-bf4c89401c76). ```shell. warnings.warn(. 2024-05-12 21:43:29.067332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ```. - Operating system: Linux . - DeepVariant version: 1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/820
https://github.com/google/deepvariant/issues/820:259,performance,gpu,gpu,259,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected; Hi , when i run call_variant , it arises this warn which means can't use the gpu,but i can make sure that the tensorflow can use the gpu.There are the screen shots of the warn and the existence of the gpu. - the gpu existence. ![image](https://github.com/google/deepvariant/assets/71956115/367b1a98-123c-48fb-b170-3f8e4aae7d30). ```python. tensorflow.test.is_gpu_available(). WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.config.list_physical_devices('GPU')` instead. 2024-05-12 21:36:00.744470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 15089 MB memory: -> device: 0, name: Vega 20, pci bus id: 0000:26:00.0. True. ```. - the warn . ![image](https://github.com/google/deepvariant/assets/71956115/246d5cfd-a9b3-4ac5-aea7-bf4c89401c76). ```shell. warnings.warn(. 2024-05-12 21:43:29.067332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ```. - Operating system: Linux . - DeepVariant version: 1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/820
https://github.com/google/deepvariant/issues/820:270,performance,gpu,gpu,270,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected; Hi , when i run call_variant , it arises this warn which means can't use the gpu,but i can make sure that the tensorflow can use the gpu.There are the screen shots of the warn and the existence of the gpu. - the gpu existence. ![image](https://github.com/google/deepvariant/assets/71956115/367b1a98-123c-48fb-b170-3f8e4aae7d30). ```python. tensorflow.test.is_gpu_available(). WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.config.list_physical_devices('GPU')` instead. 2024-05-12 21:36:00.744470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 15089 MB memory: -> device: 0, name: Vega 20, pci bus id: 0000:26:00.0. True. ```. - the warn . ![image](https://github.com/google/deepvariant/assets/71956115/246d5cfd-a9b3-4ac5-aea7-bf4c89401c76). ```shell. warnings.warn(. 2024-05-12 21:43:29.067332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ```. - Operating system: Linux . - DeepVariant version: 1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/820
https://github.com/google/deepvariant/issues/820:652,performance,GPU,GPU,652,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected; Hi , when i run call_variant , it arises this warn which means can't use the gpu,but i can make sure that the tensorflow can use the gpu.There are the screen shots of the warn and the existence of the gpu. - the gpu existence. ![image](https://github.com/google/deepvariant/assets/71956115/367b1a98-123c-48fb-b170-3f8e4aae7d30). ```python. tensorflow.test.is_gpu_available(). WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.config.list_physical_devices('GPU')` instead. 2024-05-12 21:36:00.744470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 15089 MB memory: -> device: 0, name: Vega 20, pci bus id: 0000:26:00.0. True. ```. - the warn . ![image](https://github.com/google/deepvariant/assets/71956115/246d5cfd-a9b3-4ac5-aea7-bf4c89401c76). ```shell. warnings.warn(. 2024-05-12 21:43:29.067332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ```. - Operating system: Linux . - DeepVariant version: 1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/820
https://github.com/google/deepvariant/issues/820:729,performance,gpu,gpu,729,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected; Hi , when i run call_variant , it arises this warn which means can't use the gpu,but i can make sure that the tensorflow can use the gpu.There are the screen shots of the warn and the existence of the gpu. - the gpu existence. ![image](https://github.com/google/deepvariant/assets/71956115/367b1a98-123c-48fb-b170-3f8e4aae7d30). ```python. tensorflow.test.is_gpu_available(). WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.config.list_physical_devices('GPU')` instead. 2024-05-12 21:36:00.744470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 15089 MB memory: -> device: 0, name: Vega 20, pci bus id: 0000:26:00.0. True. ```. - the warn . ![image](https://github.com/google/deepvariant/assets/71956115/246d5cfd-a9b3-4ac5-aea7-bf4c89401c76). ```shell. warnings.warn(. 2024-05-12 21:43:29.067332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ```. - Operating system: Linux . - DeepVariant version: 1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/820
https://github.com/google/deepvariant/issues/820:776,performance,GPU,GPU,776,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected; Hi , when i run call_variant , it arises this warn which means can't use the gpu,but i can make sure that the tensorflow can use the gpu.There are the screen shots of the warn and the existence of the gpu. - the gpu existence. ![image](https://github.com/google/deepvariant/assets/71956115/367b1a98-123c-48fb-b170-3f8e4aae7d30). ```python. tensorflow.test.is_gpu_available(). WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.config.list_physical_devices('GPU')` instead. 2024-05-12 21:36:00.744470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 15089 MB memory: -> device: 0, name: Vega 20, pci bus id: 0000:26:00.0. True. ```. - the warn . ![image](https://github.com/google/deepvariant/assets/71956115/246d5cfd-a9b3-4ac5-aea7-bf4c89401c76). ```shell. warnings.warn(. 2024-05-12 21:43:29.067332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ```. - Operating system: Linux . - DeepVariant version: 1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/820
https://github.com/google/deepvariant/issues/820:796,performance,memor,memory,796,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected; Hi , when i run call_variant , it arises this warn which means can't use the gpu,but i can make sure that the tensorflow can use the gpu.There are the screen shots of the warn and the existence of the gpu. - the gpu existence. ![image](https://github.com/google/deepvariant/assets/71956115/367b1a98-123c-48fb-b170-3f8e4aae7d30). ```python. tensorflow.test.is_gpu_available(). WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.config.list_physical_devices('GPU')` instead. 2024-05-12 21:36:00.744470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 15089 MB memory: -> device: 0, name: Vega 20, pci bus id: 0000:26:00.0. True. ```. - the warn . ![image](https://github.com/google/deepvariant/assets/71956115/246d5cfd-a9b3-4ac5-aea7-bf4c89401c76). ```shell. warnings.warn(. 2024-05-12 21:43:29.067332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ```. - Operating system: Linux . - DeepVariant version: 1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/820
https://github.com/google/deepvariant/issues/820:1249,performance,gpu,gpu,1249,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected; Hi , when i run call_variant , it arises this warn which means can't use the gpu,but i can make sure that the tensorflow can use the gpu.There are the screen shots of the warn and the existence of the gpu. - the gpu existence. ![image](https://github.com/google/deepvariant/assets/71956115/367b1a98-123c-48fb-b170-3f8e4aae7d30). ```python. tensorflow.test.is_gpu_available(). WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.config.list_physical_devices('GPU')` instead. 2024-05-12 21:36:00.744470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 15089 MB memory: -> device: 0, name: Vega 20, pci bus id: 0000:26:00.0. True. ```. - the warn . ![image](https://github.com/google/deepvariant/assets/71956115/246d5cfd-a9b3-4ac5-aea7-bf4c89401c76). ```shell. warnings.warn(. 2024-05-12 21:43:29.067332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ```. - Operating system: Linux . - DeepVariant version: 1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/820
https://github.com/google/deepvariant/issues/820:1106,reliability,fail,failed,1106,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected; Hi , when i run call_variant , it arises this warn which means can't use the gpu,but i can make sure that the tensorflow can use the gpu.There are the screen shots of the warn and the existence of the gpu. - the gpu existence. ![image](https://github.com/google/deepvariant/assets/71956115/367b1a98-123c-48fb-b170-3f8e4aae7d30). ```python. tensorflow.test.is_gpu_available(). WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.config.list_physical_devices('GPU')` instead. 2024-05-12 21:36:00.744470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 15089 MB memory: -> device: 0, name: Vega 20, pci bus id: 0000:26:00.0. True. ```. - the warn . ![image](https://github.com/google/deepvariant/assets/71956115/246d5cfd-a9b3-4ac5-aea7-bf4c89401c76). ```shell. warnings.warn(. 2024-05-12 21:43:29.067332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ```. - Operating system: Linux . - DeepVariant version: 1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/820
https://github.com/google/deepvariant/issues/820:48,safety,detect,detected,48,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected; Hi , when i run call_variant , it arises this warn which means can't use the gpu,but i can make sure that the tensorflow can use the gpu.There are the screen shots of the warn and the existence of the gpu. - the gpu existence. ![image](https://github.com/google/deepvariant/assets/71956115/367b1a98-123c-48fb-b170-3f8e4aae7d30). ```python. tensorflow.test.is_gpu_available(). WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.config.list_physical_devices('GPU')` instead. 2024-05-12 21:36:00.744470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 15089 MB memory: -> device: 0, name: Vega 20, pci bus id: 0000:26:00.0. True. ```. - the warn . ![image](https://github.com/google/deepvariant/assets/71956115/246d5cfd-a9b3-4ac5-aea7-bf4c89401c76). ```shell. warnings.warn(. 2024-05-12 21:43:29.067332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ```. - Operating system: Linux . - DeepVariant version: 1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/820
https://github.com/google/deepvariant/issues/820:409,safety,test,test,409,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected; Hi , when i run call_variant , it arises this warn which means can't use the gpu,but i can make sure that the tensorflow can use the gpu.There are the screen shots of the warn and the existence of the gpu. - the gpu existence. ![image](https://github.com/google/deepvariant/assets/71956115/367b1a98-123c-48fb-b170-3f8e4aae7d30). ```python. tensorflow.test.is_gpu_available(). WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.config.list_physical_devices('GPU')` instead. 2024-05-12 21:36:00.744470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 15089 MB memory: -> device: 0, name: Vega 20, pci bus id: 0000:26:00.0. True. ```. - the warn . ![image](https://github.com/google/deepvariant/assets/71956115/246d5cfd-a9b3-4ac5-aea7-bf4c89401c76). ```shell. warnings.warn(. 2024-05-12 21:43:29.067332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ```. - Operating system: Linux . - DeepVariant version: 1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/820
https://github.com/google/deepvariant/issues/820:603,safety,updat,updating,603,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected; Hi , when i run call_variant , it arises this warn which means can't use the gpu,but i can make sure that the tensorflow can use the gpu.There are the screen shots of the warn and the existence of the gpu. - the gpu existence. ![image](https://github.com/google/deepvariant/assets/71956115/367b1a98-123c-48fb-b170-3f8e4aae7d30). ```python. tensorflow.test.is_gpu_available(). WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.config.list_physical_devices('GPU')` instead. 2024-05-12 21:36:00.744470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 15089 MB memory: -> device: 0, name: Vega 20, pci bus id: 0000:26:00.0. True. ```. - the warn . ![image](https://github.com/google/deepvariant/assets/71956115/246d5cfd-a9b3-4ac5-aea7-bf4c89401c76). ```shell. warnings.warn(. 2024-05-12 21:43:29.067332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ```. - Operating system: Linux . - DeepVariant version: 1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/820
https://github.com/google/deepvariant/issues/820:1177,safety,detect,detected,1177,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected; Hi , when i run call_variant , it arises this warn which means can't use the gpu,but i can make sure that the tensorflow can use the gpu.There are the screen shots of the warn and the existence of the gpu. - the gpu existence. ![image](https://github.com/google/deepvariant/assets/71956115/367b1a98-123c-48fb-b170-3f8e4aae7d30). ```python. tensorflow.test.is_gpu_available(). WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.config.list_physical_devices('GPU')` instead. 2024-05-12 21:36:00.744470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 15089 MB memory: -> device: 0, name: Vega 20, pci bus id: 0000:26:00.0. True. ```. - the warn . ![image](https://github.com/google/deepvariant/assets/71956115/246d5cfd-a9b3-4ac5-aea7-bf4c89401c76). ```shell. warnings.warn(. 2024-05-12 21:43:29.067332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ```. - Operating system: Linux . - DeepVariant version: 1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/820
https://github.com/google/deepvariant/issues/820:48,security,detect,detected,48,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected; Hi , when i run call_variant , it arises this warn which means can't use the gpu,but i can make sure that the tensorflow can use the gpu.There are the screen shots of the warn and the existence of the gpu. - the gpu existence. ![image](https://github.com/google/deepvariant/assets/71956115/367b1a98-123c-48fb-b170-3f8e4aae7d30). ```python. tensorflow.test.is_gpu_available(). WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.config.list_physical_devices('GPU')` instead. 2024-05-12 21:36:00.744470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 15089 MB memory: -> device: 0, name: Vega 20, pci bus id: 0000:26:00.0. True. ```. - the warn . ![image](https://github.com/google/deepvariant/assets/71956115/246d5cfd-a9b3-4ac5-aea7-bf4c89401c76). ```shell. warnings.warn(. 2024-05-12 21:43:29.067332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ```. - Operating system: Linux . - DeepVariant version: 1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/820
https://github.com/google/deepvariant/issues/820:603,security,updat,updating,603,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected; Hi , when i run call_variant , it arises this warn which means can't use the gpu,but i can make sure that the tensorflow can use the gpu.There are the screen shots of the warn and the existence of the gpu. - the gpu existence. ![image](https://github.com/google/deepvariant/assets/71956115/367b1a98-123c-48fb-b170-3f8e4aae7d30). ```python. tensorflow.test.is_gpu_available(). WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.config.list_physical_devices('GPU')` instead. 2024-05-12 21:36:00.744470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 15089 MB memory: -> device: 0, name: Vega 20, pci bus id: 0000:26:00.0. True. ```. - the warn . ![image](https://github.com/google/deepvariant/assets/71956115/246d5cfd-a9b3-4ac5-aea7-bf4c89401c76). ```shell. warnings.warn(. 2024-05-12 21:43:29.067332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ```. - Operating system: Linux . - DeepVariant version: 1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/820
https://github.com/google/deepvariant/issues/820:1177,security,detect,detected,1177,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected; Hi , when i run call_variant , it arises this warn which means can't use the gpu,but i can make sure that the tensorflow can use the gpu.There are the screen shots of the warn and the existence of the gpu. - the gpu existence. ![image](https://github.com/google/deepvariant/assets/71956115/367b1a98-123c-48fb-b170-3f8e4aae7d30). ```python. tensorflow.test.is_gpu_available(). WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.config.list_physical_devices('GPU')` instead. 2024-05-12 21:36:00.744470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 15089 MB memory: -> device: 0, name: Vega 20, pci bus id: 0000:26:00.0. True. ```. - the warn . ![image](https://github.com/google/deepvariant/assets/71956115/246d5cfd-a9b3-4ac5-aea7-bf4c89401c76). ```shell. warnings.warn(. 2024-05-12 21:43:29.067332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ```. - Operating system: Linux . - DeepVariant version: 1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/820
https://github.com/google/deepvariant/issues/820:409,testability,test,test,409,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected; Hi , when i run call_variant , it arises this warn which means can't use the gpu,but i can make sure that the tensorflow can use the gpu.There are the screen shots of the warn and the existence of the gpu. - the gpu existence. ![image](https://github.com/google/deepvariant/assets/71956115/367b1a98-123c-48fb-b170-3f8e4aae7d30). ```python. tensorflow.test.is_gpu_available(). WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.config.list_physical_devices('GPU')` instead. 2024-05-12 21:36:00.744470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 15089 MB memory: -> device: 0, name: Vega 20, pci bus id: 0000:26:00.0. True. ```. - the warn . ![image](https://github.com/google/deepvariant/assets/71956115/246d5cfd-a9b3-4ac5-aea7-bf4c89401c76). ```shell. warnings.warn(. 2024-05-12 21:43:29.067332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ```. - Operating system: Linux . - DeepVariant version: 1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/820
https://github.com/google/deepvariant/issues/820:1347,testability,instrument,instrument,1347,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected; Hi , when i run call_variant , it arises this warn which means can't use the gpu,but i can make sure that the tensorflow can use the gpu.There are the screen shots of the warn and the existence of the gpu. - the gpu existence. ![image](https://github.com/google/deepvariant/assets/71956115/367b1a98-123c-48fb-b170-3f8e4aae7d30). ```python. tensorflow.test.is_gpu_available(). WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.config.list_physical_devices('GPU')` instead. 2024-05-12 21:36:00.744470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 15089 MB memory: -> device: 0, name: Vega 20, pci bus id: 0000:26:00.0. True. ```. - the warn . ![image](https://github.com/google/deepvariant/assets/71956115/246d5cfd-a9b3-4ac5-aea7-bf4c89401c76). ```shell. warnings.warn(. 2024-05-12 21:43:29.067332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ```. - Operating system: Linux . - DeepVariant version: 1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/820
https://github.com/google/deepvariant/issues/820:796,usability,memor,memory,796,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected; Hi , when i run call_variant , it arises this warn which means can't use the gpu,but i can make sure that the tensorflow can use the gpu.There are the screen shots of the warn and the existence of the gpu. - the gpu existence. ![image](https://github.com/google/deepvariant/assets/71956115/367b1a98-123c-48fb-b170-3f8e4aae7d30). ```python. tensorflow.test.is_gpu_available(). WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.config.list_physical_devices('GPU')` instead. 2024-05-12 21:36:00.744470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 15089 MB memory: -> device: 0, name: Vega 20, pci bus id: 0000:26:00.0. True. ```. - the warn . ![image](https://github.com/google/deepvariant/assets/71956115/246d5cfd-a9b3-4ac5-aea7-bf4c89401c76). ```shell. warnings.warn(. 2024-05-12 21:43:29.067332: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ```. - Operating system: Linux . - DeepVariant version: 1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/820
https://github.com/google/deepvariant/issues/821:121,availability,avail,available,121,"Info ONT R10.4.1 data; Hi,. I was wondering if the RAW data used to train the ONT model on R10.4.1 chemistry is publicly available. The ones on the GIAB FTP server are all R9.4.1. If so, could you point me to where these files are located? Thank you in advance for any help :).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/821
https://github.com/google/deepvariant/issues/821:82,energy efficiency,model,model,82,"Info ONT R10.4.1 data; Hi,. I was wondering if the RAW data used to train the ONT model on R10.4.1 chemistry is publicly available. The ones on the GIAB FTP server are all R9.4.1. If so, could you point me to where these files are located? Thank you in advance for any help :).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/821
https://github.com/google/deepvariant/issues/821:112,integrability,pub,publicly,112,"Info ONT R10.4.1 data; Hi,. I was wondering if the RAW data used to train the ONT model on R10.4.1 chemistry is publicly available. The ones on the GIAB FTP server are all R9.4.1. If so, could you point me to where these files are located? Thank you in advance for any help :).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/821
https://github.com/google/deepvariant/issues/821:121,reliability,availab,available,121,"Info ONT R10.4.1 data; Hi,. I was wondering if the RAW data used to train the ONT model on R10.4.1 chemistry is publicly available. The ones on the GIAB FTP server are all R9.4.1. If so, could you point me to where these files are located? Thank you in advance for any help :).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/821
https://github.com/google/deepvariant/issues/821:121,safety,avail,available,121,"Info ONT R10.4.1 data; Hi,. I was wondering if the RAW data used to train the ONT model on R10.4.1 chemistry is publicly available. The ones on the GIAB FTP server are all R9.4.1. If so, could you point me to where these files are located? Thank you in advance for any help :).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/821
https://github.com/google/deepvariant/issues/821:82,security,model,model,82,"Info ONT R10.4.1 data; Hi,. I was wondering if the RAW data used to train the ONT model on R10.4.1 chemistry is publicly available. The ones on the GIAB FTP server are all R9.4.1. If so, could you point me to where these files are located? Thank you in advance for any help :).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/821
https://github.com/google/deepvariant/issues/821:121,security,availab,available,121,"Info ONT R10.4.1 data; Hi,. I was wondering if the RAW data used to train the ONT model on R10.4.1 chemistry is publicly available. The ones on the GIAB FTP server are all R9.4.1. If so, could you point me to where these files are located? Thank you in advance for any help :).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/821
https://github.com/google/deepvariant/issues/821:269,usability,help,help,269,"Info ONT R10.4.1 data; Hi,. I was wondering if the RAW data used to train the ONT model on R10.4.1 chemistry is publicly available. The ones on the GIAB FTP server are all R9.4.1. If so, could you point me to where these files are located? Thank you in advance for any help :).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/821
https://github.com/google/deepvariant/issues/822:0,availability,error,error,0,"error while running deepvariant with a bam file with phasing information ; **Describe the issue:**. Hello, i am trying to recreate the steps done in this post: https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/. I have a bam file with phasing information which a got by running whatshap on the data and now i want use deepvariant for a second time just like the steps in the post. . I have a illumina bam file which i phased with nanopore data. I run this command: . singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads whatshap/HG003.GRCh38.chr20.haplotagged.bam \. --use_hp_information \. --output_vcf deepvariant2/output.vcf.gz \. --num_shards $(nproc) \. --regions chr20. And get this error : . NotImplementedError: The --use_hp_information flag has been deprecated. DeepVariant now phases internally for PacBio mode. I get what deprecated means but what is the thing i have to do to specify to deepvariant that my bam file is phased because i dont think it is using the haplotagged info in the bam file now? **Setup**. - DeepVariant version: latest. - Installation method : source. - Type of data: bam file with phasing information by whatshap.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/822
https://github.com/google/deepvariant/issues/822:875,availability,error,error,875,"error while running deepvariant with a bam file with phasing information ; **Describe the issue:**. Hello, i am trying to recreate the steps done in this post: https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/. I have a bam file with phasing information which a got by running whatshap on the data and now i want use deepvariant for a second time just like the steps in the post. . I have a illumina bam file which i phased with nanopore data. I run this command: . singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads whatshap/HG003.GRCh38.chr20.haplotagged.bam \. --use_hp_information \. --output_vcf deepvariant2/output.vcf.gz \. --num_shards $(nproc) \. --regions chr20. And get this error : . NotImplementedError: The --use_hp_information flag has been deprecated. DeepVariant now phases internally for PacBio mode. I get what deprecated means but what is the thing i have to do to specify to deepvariant that my bam file is phased because i dont think it is using the haplotagged info in the bam file now? **Setup**. - DeepVariant version: latest. - Installation method : source. - Type of data: bam file with phasing information by whatshap.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/822
https://github.com/google/deepvariant/issues/822:1224,deployability,version,version,1224,"error while running deepvariant with a bam file with phasing information ; **Describe the issue:**. Hello, i am trying to recreate the steps done in this post: https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/. I have a bam file with phasing information which a got by running whatshap on the data and now i want use deepvariant for a second time just like the steps in the post. . I have a illumina bam file which i phased with nanopore data. I run this command: . singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads whatshap/HG003.GRCh38.chr20.haplotagged.bam \. --use_hp_information \. --output_vcf deepvariant2/output.vcf.gz \. --num_shards $(nproc) \. --regions chr20. And get this error : . NotImplementedError: The --use_hp_information flag has been deprecated. DeepVariant now phases internally for PacBio mode. I get what deprecated means but what is the thing i have to do to specify to deepvariant that my bam file is phased because i dont think it is using the haplotagged info in the bam file now? **Setup**. - DeepVariant version: latest. - Installation method : source. - Type of data: bam file with phasing information by whatshap.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/822
https://github.com/google/deepvariant/issues/822:1243,deployability,Instal,Installation,1243,"error while running deepvariant with a bam file with phasing information ; **Describe the issue:**. Hello, i am trying to recreate the steps done in this post: https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/. I have a bam file with phasing information which a got by running whatshap on the data and now i want use deepvariant for a second time just like the steps in the post. . I have a illumina bam file which i phased with nanopore data. I run this command: . singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads whatshap/HG003.GRCh38.chr20.haplotagged.bam \. --use_hp_information \. --output_vcf deepvariant2/output.vcf.gz \. --num_shards $(nproc) \. --regions chr20. And get this error : . NotImplementedError: The --use_hp_information flag has been deprecated. DeepVariant now phases internally for PacBio mode. I get what deprecated means but what is the thing i have to do to specify to deepvariant that my bam file is phased because i dont think it is using the haplotagged info in the bam file now? **Setup**. - DeepVariant version: latest. - Installation method : source. - Type of data: bam file with phasing information by whatshap.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/822
https://github.com/google/deepvariant/issues/822:1224,integrability,version,version,1224,"error while running deepvariant with a bam file with phasing information ; **Describe the issue:**. Hello, i am trying to recreate the steps done in this post: https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/. I have a bam file with phasing information which a got by running whatshap on the data and now i want use deepvariant for a second time just like the steps in the post. . I have a illumina bam file which i phased with nanopore data. I run this command: . singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads whatshap/HG003.GRCh38.chr20.haplotagged.bam \. --use_hp_information \. --output_vcf deepvariant2/output.vcf.gz \. --num_shards $(nproc) \. --regions chr20. And get this error : . NotImplementedError: The --use_hp_information flag has been deprecated. DeepVariant now phases internally for PacBio mode. I get what deprecated means but what is the thing i have to do to specify to deepvariant that my bam file is phased because i dont think it is using the haplotagged info in the bam file now? **Setup**. - DeepVariant version: latest. - Installation method : source. - Type of data: bam file with phasing information by whatshap.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/822
https://github.com/google/deepvariant/issues/822:512,interoperability,bind,bind,512,"error while running deepvariant with a bam file with phasing information ; **Describe the issue:**. Hello, i am trying to recreate the steps done in this post: https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/. I have a bam file with phasing information which a got by running whatshap on the data and now i want use deepvariant for a second time just like the steps in the post. . I have a illumina bam file which i phased with nanopore data. I run this command: . singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads whatshap/HG003.GRCh38.chr20.haplotagged.bam \. --use_hp_information \. --output_vcf deepvariant2/output.vcf.gz \. --num_shards $(nproc) \. --regions chr20. And get this error : . NotImplementedError: The --use_hp_information flag has been deprecated. DeepVariant now phases internally for PacBio mode. I get what deprecated means but what is the thing i have to do to specify to deepvariant that my bam file is phased because i dont think it is using the haplotagged info in the bam file now? **Setup**. - DeepVariant version: latest. - Installation method : source. - Type of data: bam file with phasing information by whatshap.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/822
https://github.com/google/deepvariant/issues/822:1074,interoperability,specif,specify,1074,"error while running deepvariant with a bam file with phasing information ; **Describe the issue:**. Hello, i am trying to recreate the steps done in this post: https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/. I have a bam file with phasing information which a got by running whatshap on the data and now i want use deepvariant for a second time just like the steps in the post. . I have a illumina bam file which i phased with nanopore data. I run this command: . singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads whatshap/HG003.GRCh38.chr20.haplotagged.bam \. --use_hp_information \. --output_vcf deepvariant2/output.vcf.gz \. --num_shards $(nproc) \. --regions chr20. And get this error : . NotImplementedError: The --use_hp_information flag has been deprecated. DeepVariant now phases internally for PacBio mode. I get what deprecated means but what is the thing i have to do to specify to deepvariant that my bam file is phased because i dont think it is using the haplotagged info in the bam file now? **Setup**. - DeepVariant version: latest. - Installation method : source. - Type of data: bam file with phasing information by whatshap.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/822
https://github.com/google/deepvariant/issues/822:512,modifiability,bind,bind,512,"error while running deepvariant with a bam file with phasing information ; **Describe the issue:**. Hello, i am trying to recreate the steps done in this post: https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/. I have a bam file with phasing information which a got by running whatshap on the data and now i want use deepvariant for a second time just like the steps in the post. . I have a illumina bam file which i phased with nanopore data. I run this command: . singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads whatshap/HG003.GRCh38.chr20.haplotagged.bam \. --use_hp_information \. --output_vcf deepvariant2/output.vcf.gz \. --num_shards $(nproc) \. --regions chr20. And get this error : . NotImplementedError: The --use_hp_information flag has been deprecated. DeepVariant now phases internally for PacBio mode. I get what deprecated means but what is the thing i have to do to specify to deepvariant that my bam file is phased because i dont think it is using the haplotagged info in the bam file now? **Setup**. - DeepVariant version: latest. - Installation method : source. - Type of data: bam file with phasing information by whatshap.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/822
https://github.com/google/deepvariant/issues/822:636,modifiability,PAC,PACBIO,636,"error while running deepvariant with a bam file with phasing information ; **Describe the issue:**. Hello, i am trying to recreate the steps done in this post: https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/. I have a bam file with phasing information which a got by running whatshap on the data and now i want use deepvariant for a second time just like the steps in the post. . I have a illumina bam file which i phased with nanopore data. I run this command: . singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads whatshap/HG003.GRCh38.chr20.haplotagged.bam \. --use_hp_information \. --output_vcf deepvariant2/output.vcf.gz \. --num_shards $(nproc) \. --regions chr20. And get this error : . NotImplementedError: The --use_hp_information flag has been deprecated. DeepVariant now phases internally for PacBio mode. I get what deprecated means but what is the thing i have to do to specify to deepvariant that my bam file is phased because i dont think it is using the haplotagged info in the bam file now? **Setup**. - DeepVariant version: latest. - Installation method : source. - Type of data: bam file with phasing information by whatshap.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/822
https://github.com/google/deepvariant/issues/822:995,modifiability,Pac,PacBio,995,"error while running deepvariant with a bam file with phasing information ; **Describe the issue:**. Hello, i am trying to recreate the steps done in this post: https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/. I have a bam file with phasing information which a got by running whatshap on the data and now i want use deepvariant for a second time just like the steps in the post. . I have a illumina bam file which i phased with nanopore data. I run this command: . singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads whatshap/HG003.GRCh38.chr20.haplotagged.bam \. --use_hp_information \. --output_vcf deepvariant2/output.vcf.gz \. --num_shards $(nproc) \. --regions chr20. And get this error : . NotImplementedError: The --use_hp_information flag has been deprecated. DeepVariant now phases internally for PacBio mode. I get what deprecated means but what is the thing i have to do to specify to deepvariant that my bam file is phased because i dont think it is using the haplotagged info in the bam file now? **Setup**. - DeepVariant version: latest. - Installation method : source. - Type of data: bam file with phasing information by whatshap.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/822
https://github.com/google/deepvariant/issues/822:1224,modifiability,version,version,1224,"error while running deepvariant with a bam file with phasing information ; **Describe the issue:**. Hello, i am trying to recreate the steps done in this post: https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/. I have a bam file with phasing information which a got by running whatshap on the data and now i want use deepvariant for a second time just like the steps in the post. . I have a illumina bam file which i phased with nanopore data. I run this command: . singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads whatshap/HG003.GRCh38.chr20.haplotagged.bam \. --use_hp_information \. --output_vcf deepvariant2/output.vcf.gz \. --num_shards $(nproc) \. --regions chr20. And get this error : . NotImplementedError: The --use_hp_information flag has been deprecated. DeepVariant now phases internally for PacBio mode. I get what deprecated means but what is the thing i have to do to specify to deepvariant that my bam file is phased because i dont think it is using the haplotagged info in the bam file now? **Setup**. - DeepVariant version: latest. - Installation method : source. - Type of data: bam file with phasing information by whatshap.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/822
https://github.com/google/deepvariant/issues/822:0,performance,error,error,0,"error while running deepvariant with a bam file with phasing information ; **Describe the issue:**. Hello, i am trying to recreate the steps done in this post: https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/. I have a bam file with phasing information which a got by running whatshap on the data and now i want use deepvariant for a second time just like the steps in the post. . I have a illumina bam file which i phased with nanopore data. I run this command: . singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads whatshap/HG003.GRCh38.chr20.haplotagged.bam \. --use_hp_information \. --output_vcf deepvariant2/output.vcf.gz \. --num_shards $(nproc) \. --regions chr20. And get this error : . NotImplementedError: The --use_hp_information flag has been deprecated. DeepVariant now phases internally for PacBio mode. I get what deprecated means but what is the thing i have to do to specify to deepvariant that my bam file is phased because i dont think it is using the haplotagged info in the bam file now? **Setup**. - DeepVariant version: latest. - Installation method : source. - Type of data: bam file with phasing information by whatshap.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/822
https://github.com/google/deepvariant/issues/822:369,performance,time,time,369,"error while running deepvariant with a bam file with phasing information ; **Describe the issue:**. Hello, i am trying to recreate the steps done in this post: https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/. I have a bam file with phasing information which a got by running whatshap on the data and now i want use deepvariant for a second time just like the steps in the post. . I have a illumina bam file which i phased with nanopore data. I run this command: . singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads whatshap/HG003.GRCh38.chr20.haplotagged.bam \. --use_hp_information \. --output_vcf deepvariant2/output.vcf.gz \. --num_shards $(nproc) \. --regions chr20. And get this error : . NotImplementedError: The --use_hp_information flag has been deprecated. DeepVariant now phases internally for PacBio mode. I get what deprecated means but what is the thing i have to do to specify to deepvariant that my bam file is phased because i dont think it is using the haplotagged info in the bam file now? **Setup**. - DeepVariant version: latest. - Installation method : source. - Type of data: bam file with phasing information by whatshap.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/822
https://github.com/google/deepvariant/issues/822:875,performance,error,error,875,"error while running deepvariant with a bam file with phasing information ; **Describe the issue:**. Hello, i am trying to recreate the steps done in this post: https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/. I have a bam file with phasing information which a got by running whatshap on the data and now i want use deepvariant for a second time just like the steps in the post. . I have a illumina bam file which i phased with nanopore data. I run this command: . singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads whatshap/HG003.GRCh38.chr20.haplotagged.bam \. --use_hp_information \. --output_vcf deepvariant2/output.vcf.gz \. --num_shards $(nproc) \. --regions chr20. And get this error : . NotImplementedError: The --use_hp_information flag has been deprecated. DeepVariant now phases internally for PacBio mode. I get what deprecated means but what is the thing i have to do to specify to deepvariant that my bam file is phased because i dont think it is using the haplotagged info in the bam file now? **Setup**. - DeepVariant version: latest. - Installation method : source. - Type of data: bam file with phasing information by whatshap.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/822
https://github.com/google/deepvariant/issues/822:0,safety,error,error,0,"error while running deepvariant with a bam file with phasing information ; **Describe the issue:**. Hello, i am trying to recreate the steps done in this post: https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/. I have a bam file with phasing information which a got by running whatshap on the data and now i want use deepvariant for a second time just like the steps in the post. . I have a illumina bam file which i phased with nanopore data. I run this command: . singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads whatshap/HG003.GRCh38.chr20.haplotagged.bam \. --use_hp_information \. --output_vcf deepvariant2/output.vcf.gz \. --num_shards $(nproc) \. --regions chr20. And get this error : . NotImplementedError: The --use_hp_information flag has been deprecated. DeepVariant now phases internally for PacBio mode. I get what deprecated means but what is the thing i have to do to specify to deepvariant that my bam file is phased because i dont think it is using the haplotagged info in the bam file now? **Setup**. - DeepVariant version: latest. - Installation method : source. - Type of data: bam file with phasing information by whatshap.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/822
https://github.com/google/deepvariant/issues/822:875,safety,error,error,875,"error while running deepvariant with a bam file with phasing information ; **Describe the issue:**. Hello, i am trying to recreate the steps done in this post: https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/. I have a bam file with phasing information which a got by running whatshap on the data and now i want use deepvariant for a second time just like the steps in the post. . I have a illumina bam file which i phased with nanopore data. I run this command: . singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads whatshap/HG003.GRCh38.chr20.haplotagged.bam \. --use_hp_information \. --output_vcf deepvariant2/output.vcf.gz \. --num_shards $(nproc) \. --regions chr20. And get this error : . NotImplementedError: The --use_hp_information flag has been deprecated. DeepVariant now phases internally for PacBio mode. I get what deprecated means but what is the thing i have to do to specify to deepvariant that my bam file is phased because i dont think it is using the haplotagged info in the bam file now? **Setup**. - DeepVariant version: latest. - Installation method : source. - Type of data: bam file with phasing information by whatshap.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/822
https://github.com/google/deepvariant/issues/822:0,usability,error,error,0,"error while running deepvariant with a bam file with phasing information ; **Describe the issue:**. Hello, i am trying to recreate the steps done in this post: https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/. I have a bam file with phasing information which a got by running whatshap on the data and now i want use deepvariant for a second time just like the steps in the post. . I have a illumina bam file which i phased with nanopore data. I run this command: . singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads whatshap/HG003.GRCh38.chr20.haplotagged.bam \. --use_hp_information \. --output_vcf deepvariant2/output.vcf.gz \. --num_shards $(nproc) \. --regions chr20. And get this error : . NotImplementedError: The --use_hp_information flag has been deprecated. DeepVariant now phases internally for PacBio mode. I get what deprecated means but what is the thing i have to do to specify to deepvariant that my bam file is phased because i dont think it is using the haplotagged info in the bam file now? **Setup**. - DeepVariant version: latest. - Installation method : source. - Type of data: bam file with phasing information by whatshap.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/822
https://github.com/google/deepvariant/issues/822:482,usability,command,command,482,"error while running deepvariant with a bam file with phasing information ; **Describe the issue:**. Hello, i am trying to recreate the steps done in this post: https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/. I have a bam file with phasing information which a got by running whatshap on the data and now i want use deepvariant for a second time just like the steps in the post. . I have a illumina bam file which i phased with nanopore data. I run this command: . singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads whatshap/HG003.GRCh38.chr20.haplotagged.bam \. --use_hp_information \. --output_vcf deepvariant2/output.vcf.gz \. --num_shards $(nproc) \. --regions chr20. And get this error : . NotImplementedError: The --use_hp_information flag has been deprecated. DeepVariant now phases internally for PacBio mode. I get what deprecated means but what is the thing i have to do to specify to deepvariant that my bam file is phased because i dont think it is using the haplotagged info in the bam file now? **Setup**. - DeepVariant version: latest. - Installation method : source. - Type of data: bam file with phasing information by whatshap.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/822
https://github.com/google/deepvariant/issues/822:875,usability,error,error,875,"error while running deepvariant with a bam file with phasing information ; **Describe the issue:**. Hello, i am trying to recreate the steps done in this post: https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/. I have a bam file with phasing information which a got by running whatshap on the data and now i want use deepvariant for a second time just like the steps in the post. . I have a illumina bam file which i phased with nanopore data. I run this command: . singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads whatshap/HG003.GRCh38.chr20.haplotagged.bam \. --use_hp_information \. --output_vcf deepvariant2/output.vcf.gz \. --num_shards $(nproc) \. --regions chr20. And get this error : . NotImplementedError: The --use_hp_information flag has been deprecated. DeepVariant now phases internally for PacBio mode. I get what deprecated means but what is the thing i have to do to specify to deepvariant that my bam file is phased because i dont think it is using the haplotagged info in the bam file now? **Setup**. - DeepVariant version: latest. - Installation method : source. - Type of data: bam file with phasing information by whatshap.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/822
https://github.com/google/deepvariant/issues/823:0,availability,Error,Error,0,"Error while using deepvariant with a bam file that is phased; Describe the issue:. Hello, i am trying to recreate the steps done in this post: https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/. I have a bam file with phasing information which a got by running whatshap on the data and now i want use deepvariant for a second time just like the steps in the post. I have a illumina bam file which i phased with nanopore data. I run this command:. singularity exec --bind /usr/lib/locale/. docker://google/deepvariant:${BIN_VERSION}. /opt/deepvariant/bin/run_deepvariant. --model_type PACBIO. --ref reference/GRCh38_no_alt_analysis_set.fasta. --reads whatshap/HG003.GRCh38.chr20.haplotagged.bam. --use_hp_information. --output_vcf deepvariant2/output.vcf.gz. --num_shards $(nproc). --regions chr20. And get this error :. NotImplementedError: The --use_hp_information flag has been deprecated. DeepVariant now phases internally for PacBio mode. I get what deprecated means but what is the thing i have to do to specify to deepvariant that my bam file is phased because i dont think it is using the haplotagged info in the bam file now? Setup. DeepVariant version: latest. Installation method : source. Type of data: bam file with phasing information by whatshap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/823
https://github.com/google/deepvariant/issues/823:837,availability,error,error,837,"Error while using deepvariant with a bam file that is phased; Describe the issue:. Hello, i am trying to recreate the steps done in this post: https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/. I have a bam file with phasing information which a got by running whatshap on the data and now i want use deepvariant for a second time just like the steps in the post. I have a illumina bam file which i phased with nanopore data. I run this command:. singularity exec --bind /usr/lib/locale/. docker://google/deepvariant:${BIN_VERSION}. /opt/deepvariant/bin/run_deepvariant. --model_type PACBIO. --ref reference/GRCh38_no_alt_analysis_set.fasta. --reads whatshap/HG003.GRCh38.chr20.haplotagged.bam. --use_hp_information. --output_vcf deepvariant2/output.vcf.gz. --num_shards $(nproc). --regions chr20. And get this error :. NotImplementedError: The --use_hp_information flag has been deprecated. DeepVariant now phases internally for PacBio mode. I get what deprecated means but what is the thing i have to do to specify to deepvariant that my bam file is phased because i dont think it is using the haplotagged info in the bam file now? Setup. DeepVariant version: latest. Installation method : source. Type of data: bam file with phasing information by whatshap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/823
https://github.com/google/deepvariant/issues/823:1179,deployability,version,version,1179,"Error while using deepvariant with a bam file that is phased; Describe the issue:. Hello, i am trying to recreate the steps done in this post: https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/. I have a bam file with phasing information which a got by running whatshap on the data and now i want use deepvariant for a second time just like the steps in the post. I have a illumina bam file which i phased with nanopore data. I run this command:. singularity exec --bind /usr/lib/locale/. docker://google/deepvariant:${BIN_VERSION}. /opt/deepvariant/bin/run_deepvariant. --model_type PACBIO. --ref reference/GRCh38_no_alt_analysis_set.fasta. --reads whatshap/HG003.GRCh38.chr20.haplotagged.bam. --use_hp_information. --output_vcf deepvariant2/output.vcf.gz. --num_shards $(nproc). --regions chr20. And get this error :. NotImplementedError: The --use_hp_information flag has been deprecated. DeepVariant now phases internally for PacBio mode. I get what deprecated means but what is the thing i have to do to specify to deepvariant that my bam file is phased because i dont think it is using the haplotagged info in the bam file now? Setup. DeepVariant version: latest. Installation method : source. Type of data: bam file with phasing information by whatshap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/823
https://github.com/google/deepvariant/issues/823:1196,deployability,Instal,Installation,1196,"Error while using deepvariant with a bam file that is phased; Describe the issue:. Hello, i am trying to recreate the steps done in this post: https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/. I have a bam file with phasing information which a got by running whatshap on the data and now i want use deepvariant for a second time just like the steps in the post. I have a illumina bam file which i phased with nanopore data. I run this command:. singularity exec --bind /usr/lib/locale/. docker://google/deepvariant:${BIN_VERSION}. /opt/deepvariant/bin/run_deepvariant. --model_type PACBIO. --ref reference/GRCh38_no_alt_analysis_set.fasta. --reads whatshap/HG003.GRCh38.chr20.haplotagged.bam. --use_hp_information. --output_vcf deepvariant2/output.vcf.gz. --num_shards $(nproc). --regions chr20. And get this error :. NotImplementedError: The --use_hp_information flag has been deprecated. DeepVariant now phases internally for PacBio mode. I get what deprecated means but what is the thing i have to do to specify to deepvariant that my bam file is phased because i dont think it is using the haplotagged info in the bam file now? Setup. DeepVariant version: latest. Installation method : source. Type of data: bam file with phasing information by whatshap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/823
https://github.com/google/deepvariant/issues/823:1179,integrability,version,version,1179,"Error while using deepvariant with a bam file that is phased; Describe the issue:. Hello, i am trying to recreate the steps done in this post: https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/. I have a bam file with phasing information which a got by running whatshap on the data and now i want use deepvariant for a second time just like the steps in the post. I have a illumina bam file which i phased with nanopore data. I run this command:. singularity exec --bind /usr/lib/locale/. docker://google/deepvariant:${BIN_VERSION}. /opt/deepvariant/bin/run_deepvariant. --model_type PACBIO. --ref reference/GRCh38_no_alt_analysis_set.fasta. --reads whatshap/HG003.GRCh38.chr20.haplotagged.bam. --use_hp_information. --output_vcf deepvariant2/output.vcf.gz. --num_shards $(nproc). --regions chr20. And get this error :. NotImplementedError: The --use_hp_information flag has been deprecated. DeepVariant now phases internally for PacBio mode. I get what deprecated means but what is the thing i have to do to specify to deepvariant that my bam file is phased because i dont think it is using the haplotagged info in the bam file now? Setup. DeepVariant version: latest. Installation method : source. Type of data: bam file with phasing information by whatshap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/823
https://github.com/google/deepvariant/issues/823:492,interoperability,bind,bind,492,"Error while using deepvariant with a bam file that is phased; Describe the issue:. Hello, i am trying to recreate the steps done in this post: https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/. I have a bam file with phasing information which a got by running whatshap on the data and now i want use deepvariant for a second time just like the steps in the post. I have a illumina bam file which i phased with nanopore data. I run this command:. singularity exec --bind /usr/lib/locale/. docker://google/deepvariant:${BIN_VERSION}. /opt/deepvariant/bin/run_deepvariant. --model_type PACBIO. --ref reference/GRCh38_no_alt_analysis_set.fasta. --reads whatshap/HG003.GRCh38.chr20.haplotagged.bam. --use_hp_information. --output_vcf deepvariant2/output.vcf.gz. --num_shards $(nproc). --regions chr20. And get this error :. NotImplementedError: The --use_hp_information flag has been deprecated. DeepVariant now phases internally for PacBio mode. I get what deprecated means but what is the thing i have to do to specify to deepvariant that my bam file is phased because i dont think it is using the haplotagged info in the bam file now? Setup. DeepVariant version: latest. Installation method : source. Type of data: bam file with phasing information by whatshap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/823
https://github.com/google/deepvariant/issues/823:1035,interoperability,specif,specify,1035,"Error while using deepvariant with a bam file that is phased; Describe the issue:. Hello, i am trying to recreate the steps done in this post: https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/. I have a bam file with phasing information which a got by running whatshap on the data and now i want use deepvariant for a second time just like the steps in the post. I have a illumina bam file which i phased with nanopore data. I run this command:. singularity exec --bind /usr/lib/locale/. docker://google/deepvariant:${BIN_VERSION}. /opt/deepvariant/bin/run_deepvariant. --model_type PACBIO. --ref reference/GRCh38_no_alt_analysis_set.fasta. --reads whatshap/HG003.GRCh38.chr20.haplotagged.bam. --use_hp_information. --output_vcf deepvariant2/output.vcf.gz. --num_shards $(nproc). --regions chr20. And get this error :. NotImplementedError: The --use_hp_information flag has been deprecated. DeepVariant now phases internally for PacBio mode. I get what deprecated means but what is the thing i have to do to specify to deepvariant that my bam file is phased because i dont think it is using the haplotagged info in the bam file now? Setup. DeepVariant version: latest. Installation method : source. Type of data: bam file with phasing information by whatshap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/823
https://github.com/google/deepvariant/issues/823:492,modifiability,bind,bind,492,"Error while using deepvariant with a bam file that is phased; Describe the issue:. Hello, i am trying to recreate the steps done in this post: https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/. I have a bam file with phasing information which a got by running whatshap on the data and now i want use deepvariant for a second time just like the steps in the post. I have a illumina bam file which i phased with nanopore data. I run this command:. singularity exec --bind /usr/lib/locale/. docker://google/deepvariant:${BIN_VERSION}. /opt/deepvariant/bin/run_deepvariant. --model_type PACBIO. --ref reference/GRCh38_no_alt_analysis_set.fasta. --reads whatshap/HG003.GRCh38.chr20.haplotagged.bam. --use_hp_information. --output_vcf deepvariant2/output.vcf.gz. --num_shards $(nproc). --regions chr20. And get this error :. NotImplementedError: The --use_hp_information flag has been deprecated. DeepVariant now phases internally for PacBio mode. I get what deprecated means but what is the thing i have to do to specify to deepvariant that my bam file is phased because i dont think it is using the haplotagged info in the bam file now? Setup. DeepVariant version: latest. Installation method : source. Type of data: bam file with phasing information by whatshap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/823
https://github.com/google/deepvariant/issues/823:610,modifiability,PAC,PACBIO,610,"Error while using deepvariant with a bam file that is phased; Describe the issue:. Hello, i am trying to recreate the steps done in this post: https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/. I have a bam file with phasing information which a got by running whatshap on the data and now i want use deepvariant for a second time just like the steps in the post. I have a illumina bam file which i phased with nanopore data. I run this command:. singularity exec --bind /usr/lib/locale/. docker://google/deepvariant:${BIN_VERSION}. /opt/deepvariant/bin/run_deepvariant. --model_type PACBIO. --ref reference/GRCh38_no_alt_analysis_set.fasta. --reads whatshap/HG003.GRCh38.chr20.haplotagged.bam. --use_hp_information. --output_vcf deepvariant2/output.vcf.gz. --num_shards $(nproc). --regions chr20. And get this error :. NotImplementedError: The --use_hp_information flag has been deprecated. DeepVariant now phases internally for PacBio mode. I get what deprecated means but what is the thing i have to do to specify to deepvariant that my bam file is phased because i dont think it is using the haplotagged info in the bam file now? Setup. DeepVariant version: latest. Installation method : source. Type of data: bam file with phasing information by whatshap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/823
https://github.com/google/deepvariant/issues/823:956,modifiability,Pac,PacBio,956,"Error while using deepvariant with a bam file that is phased; Describe the issue:. Hello, i am trying to recreate the steps done in this post: https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/. I have a bam file with phasing information which a got by running whatshap on the data and now i want use deepvariant for a second time just like the steps in the post. I have a illumina bam file which i phased with nanopore data. I run this command:. singularity exec --bind /usr/lib/locale/. docker://google/deepvariant:${BIN_VERSION}. /opt/deepvariant/bin/run_deepvariant. --model_type PACBIO. --ref reference/GRCh38_no_alt_analysis_set.fasta. --reads whatshap/HG003.GRCh38.chr20.haplotagged.bam. --use_hp_information. --output_vcf deepvariant2/output.vcf.gz. --num_shards $(nproc). --regions chr20. And get this error :. NotImplementedError: The --use_hp_information flag has been deprecated. DeepVariant now phases internally for PacBio mode. I get what deprecated means but what is the thing i have to do to specify to deepvariant that my bam file is phased because i dont think it is using the haplotagged info in the bam file now? Setup. DeepVariant version: latest. Installation method : source. Type of data: bam file with phasing information by whatshap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/823
https://github.com/google/deepvariant/issues/823:1179,modifiability,version,version,1179,"Error while using deepvariant with a bam file that is phased; Describe the issue:. Hello, i am trying to recreate the steps done in this post: https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/. I have a bam file with phasing information which a got by running whatshap on the data and now i want use deepvariant for a second time just like the steps in the post. I have a illumina bam file which i phased with nanopore data. I run this command:. singularity exec --bind /usr/lib/locale/. docker://google/deepvariant:${BIN_VERSION}. /opt/deepvariant/bin/run_deepvariant. --model_type PACBIO. --ref reference/GRCh38_no_alt_analysis_set.fasta. --reads whatshap/HG003.GRCh38.chr20.haplotagged.bam. --use_hp_information. --output_vcf deepvariant2/output.vcf.gz. --num_shards $(nproc). --regions chr20. And get this error :. NotImplementedError: The --use_hp_information flag has been deprecated. DeepVariant now phases internally for PacBio mode. I get what deprecated means but what is the thing i have to do to specify to deepvariant that my bam file is phased because i dont think it is using the haplotagged info in the bam file now? Setup. DeepVariant version: latest. Installation method : source. Type of data: bam file with phasing information by whatshap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/823
https://github.com/google/deepvariant/issues/823:0,performance,Error,Error,0,"Error while using deepvariant with a bam file that is phased; Describe the issue:. Hello, i am trying to recreate the steps done in this post: https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/. I have a bam file with phasing information which a got by running whatshap on the data and now i want use deepvariant for a second time just like the steps in the post. I have a illumina bam file which i phased with nanopore data. I run this command:. singularity exec --bind /usr/lib/locale/. docker://google/deepvariant:${BIN_VERSION}. /opt/deepvariant/bin/run_deepvariant. --model_type PACBIO. --ref reference/GRCh38_no_alt_analysis_set.fasta. --reads whatshap/HG003.GRCh38.chr20.haplotagged.bam. --use_hp_information. --output_vcf deepvariant2/output.vcf.gz. --num_shards $(nproc). --regions chr20. And get this error :. NotImplementedError: The --use_hp_information flag has been deprecated. DeepVariant now phases internally for PacBio mode. I get what deprecated means but what is the thing i have to do to specify to deepvariant that my bam file is phased because i dont think it is using the haplotagged info in the bam file now? Setup. DeepVariant version: latest. Installation method : source. Type of data: bam file with phasing information by whatshap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/823
https://github.com/google/deepvariant/issues/823:352,performance,time,time,352,"Error while using deepvariant with a bam file that is phased; Describe the issue:. Hello, i am trying to recreate the steps done in this post: https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/. I have a bam file with phasing information which a got by running whatshap on the data and now i want use deepvariant for a second time just like the steps in the post. I have a illumina bam file which i phased with nanopore data. I run this command:. singularity exec --bind /usr/lib/locale/. docker://google/deepvariant:${BIN_VERSION}. /opt/deepvariant/bin/run_deepvariant. --model_type PACBIO. --ref reference/GRCh38_no_alt_analysis_set.fasta. --reads whatshap/HG003.GRCh38.chr20.haplotagged.bam. --use_hp_information. --output_vcf deepvariant2/output.vcf.gz. --num_shards $(nproc). --regions chr20. And get this error :. NotImplementedError: The --use_hp_information flag has been deprecated. DeepVariant now phases internally for PacBio mode. I get what deprecated means but what is the thing i have to do to specify to deepvariant that my bam file is phased because i dont think it is using the haplotagged info in the bam file now? Setup. DeepVariant version: latest. Installation method : source. Type of data: bam file with phasing information by whatshap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/823
https://github.com/google/deepvariant/issues/823:837,performance,error,error,837,"Error while using deepvariant with a bam file that is phased; Describe the issue:. Hello, i am trying to recreate the steps done in this post: https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/. I have a bam file with phasing information which a got by running whatshap on the data and now i want use deepvariant for a second time just like the steps in the post. I have a illumina bam file which i phased with nanopore data. I run this command:. singularity exec --bind /usr/lib/locale/. docker://google/deepvariant:${BIN_VERSION}. /opt/deepvariant/bin/run_deepvariant. --model_type PACBIO. --ref reference/GRCh38_no_alt_analysis_set.fasta. --reads whatshap/HG003.GRCh38.chr20.haplotagged.bam. --use_hp_information. --output_vcf deepvariant2/output.vcf.gz. --num_shards $(nproc). --regions chr20. And get this error :. NotImplementedError: The --use_hp_information flag has been deprecated. DeepVariant now phases internally for PacBio mode. I get what deprecated means but what is the thing i have to do to specify to deepvariant that my bam file is phased because i dont think it is using the haplotagged info in the bam file now? Setup. DeepVariant version: latest. Installation method : source. Type of data: bam file with phasing information by whatshap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/823
https://github.com/google/deepvariant/issues/823:0,safety,Error,Error,0,"Error while using deepvariant with a bam file that is phased; Describe the issue:. Hello, i am trying to recreate the steps done in this post: https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/. I have a bam file with phasing information which a got by running whatshap on the data and now i want use deepvariant for a second time just like the steps in the post. I have a illumina bam file which i phased with nanopore data. I run this command:. singularity exec --bind /usr/lib/locale/. docker://google/deepvariant:${BIN_VERSION}. /opt/deepvariant/bin/run_deepvariant. --model_type PACBIO. --ref reference/GRCh38_no_alt_analysis_set.fasta. --reads whatshap/HG003.GRCh38.chr20.haplotagged.bam. --use_hp_information. --output_vcf deepvariant2/output.vcf.gz. --num_shards $(nproc). --regions chr20. And get this error :. NotImplementedError: The --use_hp_information flag has been deprecated. DeepVariant now phases internally for PacBio mode. I get what deprecated means but what is the thing i have to do to specify to deepvariant that my bam file is phased because i dont think it is using the haplotagged info in the bam file now? Setup. DeepVariant version: latest. Installation method : source. Type of data: bam file with phasing information by whatshap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/823
https://github.com/google/deepvariant/issues/823:837,safety,error,error,837,"Error while using deepvariant with a bam file that is phased; Describe the issue:. Hello, i am trying to recreate the steps done in this post: https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/. I have a bam file with phasing information which a got by running whatshap on the data and now i want use deepvariant for a second time just like the steps in the post. I have a illumina bam file which i phased with nanopore data. I run this command:. singularity exec --bind /usr/lib/locale/. docker://google/deepvariant:${BIN_VERSION}. /opt/deepvariant/bin/run_deepvariant. --model_type PACBIO. --ref reference/GRCh38_no_alt_analysis_set.fasta. --reads whatshap/HG003.GRCh38.chr20.haplotagged.bam. --use_hp_information. --output_vcf deepvariant2/output.vcf.gz. --num_shards $(nproc). --regions chr20. And get this error :. NotImplementedError: The --use_hp_information flag has been deprecated. DeepVariant now phases internally for PacBio mode. I get what deprecated means but what is the thing i have to do to specify to deepvariant that my bam file is phased because i dont think it is using the haplotagged info in the bam file now? Setup. DeepVariant version: latest. Installation method : source. Type of data: bam file with phasing information by whatshap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/823
https://github.com/google/deepvariant/issues/823:0,usability,Error,Error,0,"Error while using deepvariant with a bam file that is phased; Describe the issue:. Hello, i am trying to recreate the steps done in this post: https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/. I have a bam file with phasing information which a got by running whatshap on the data and now i want use deepvariant for a second time just like the steps in the post. I have a illumina bam file which i phased with nanopore data. I run this command:. singularity exec --bind /usr/lib/locale/. docker://google/deepvariant:${BIN_VERSION}. /opt/deepvariant/bin/run_deepvariant. --model_type PACBIO. --ref reference/GRCh38_no_alt_analysis_set.fasta. --reads whatshap/HG003.GRCh38.chr20.haplotagged.bam. --use_hp_information. --output_vcf deepvariant2/output.vcf.gz. --num_shards $(nproc). --regions chr20. And get this error :. NotImplementedError: The --use_hp_information flag has been deprecated. DeepVariant now phases internally for PacBio mode. I get what deprecated means but what is the thing i have to do to specify to deepvariant that my bam file is phased because i dont think it is using the haplotagged info in the bam file now? Setup. DeepVariant version: latest. Installation method : source. Type of data: bam file with phasing information by whatshap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/823
https://github.com/google/deepvariant/issues/823:463,usability,command,command,463,"Error while using deepvariant with a bam file that is phased; Describe the issue:. Hello, i am trying to recreate the steps done in this post: https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/. I have a bam file with phasing information which a got by running whatshap on the data and now i want use deepvariant for a second time just like the steps in the post. I have a illumina bam file which i phased with nanopore data. I run this command:. singularity exec --bind /usr/lib/locale/. docker://google/deepvariant:${BIN_VERSION}. /opt/deepvariant/bin/run_deepvariant. --model_type PACBIO. --ref reference/GRCh38_no_alt_analysis_set.fasta. --reads whatshap/HG003.GRCh38.chr20.haplotagged.bam. --use_hp_information. --output_vcf deepvariant2/output.vcf.gz. --num_shards $(nproc). --regions chr20. And get this error :. NotImplementedError: The --use_hp_information flag has been deprecated. DeepVariant now phases internally for PacBio mode. I get what deprecated means but what is the thing i have to do to specify to deepvariant that my bam file is phased because i dont think it is using the haplotagged info in the bam file now? Setup. DeepVariant version: latest. Installation method : source. Type of data: bam file with phasing information by whatshap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/823
https://github.com/google/deepvariant/issues/823:837,usability,error,error,837,"Error while using deepvariant with a bam file that is phased; Describe the issue:. Hello, i am trying to recreate the steps done in this post: https://google.github.io/deepvariant/posts/2021-02-08-the-haplotype-channel/. I have a bam file with phasing information which a got by running whatshap on the data and now i want use deepvariant for a second time just like the steps in the post. I have a illumina bam file which i phased with nanopore data. I run this command:. singularity exec --bind /usr/lib/locale/. docker://google/deepvariant:${BIN_VERSION}. /opt/deepvariant/bin/run_deepvariant. --model_type PACBIO. --ref reference/GRCh38_no_alt_analysis_set.fasta. --reads whatshap/HG003.GRCh38.chr20.haplotagged.bam. --use_hp_information. --output_vcf deepvariant2/output.vcf.gz. --num_shards $(nproc). --regions chr20. And get this error :. NotImplementedError: The --use_hp_information flag has been deprecated. DeepVariant now phases internally for PacBio mode. I get what deprecated means but what is the thing i have to do to specify to deepvariant that my bam file is phased because i dont think it is using the haplotagged info in the bam file now? Setup. DeepVariant version: latest. Installation method : source. Type of data: bam file with phasing information by whatshap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/823
https://github.com/google/deepvariant/issues/824:284,availability,Operat,Operating,284,"Homozygous GT value while IGV shows otherwise; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. Although some variants are clearly heterozygous in IGV, deepvariant GT shows a homozygous genotype. **Setup**. - Operating system: linux. - DeepVariant version: 1.6.1. - Installation method : Docker. - Type of data: illumina, WES, hg38. **Steps to reproduce:**. ```. docker run --rm -i \. -v ${ref_dir}:/opt/ref \. -v ${kit_dir}:/opt/kit \. -v ${input_dir}:/opt/sample \. ${deepvariant_docker} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/opt/ref/${ref_fasta}"" \. --reads=""/opt/sample/${input_bam_file}"" \. --regions=""/opt/kit/${kit_bed_file}"" \. --output_vcf=""/opt/sample/${input_bam_file/.bam/.dv.vcf}"" \. --num_shards=""${threads}"". ```. Here are 5 selected variants called by 5 different versions of deepvariant:. ```. v0.10.0 chr12 11353713 . T C 57.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:54:43:27,15:0.348837:57,0,55. v1.1.0 chr12 11353713 . T C 36.6 PASS . GT:GQ:DP:AD:VAF:PL 0/1:34:44:28,15:0.340909:36,0,38. v1.4.0 chr12 11353713 . T C 23.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:21:44:28,15:0.340909:23,0,25. v1.5.0 chr12 11353713 . T C 24.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:17:44:28,15:0.340909:24,0,17. v1.6.1 chr12 11353713 . T C 24.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:5:44:28,15:0.340909:22,3,0. -----------------------------. v0.10.0 chr3 195779035 . G A 3.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:4:33:24,8:0.242424:1,0,38. v1.1.0 chr3 195779035 . G A 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:41:33:24,8:0.242424:0,43,45. v1.4.0 chr3 195779035 . G A 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:23:33:24,8:0.242424:0,32,22. v1.5.0 chr3 195779035 . G A 0.1 RefCall . GT:GQ:DP:AD:VAF:PL ./.:16:33:24,8:0.242424:0,26,16. v1.6.1 chr3 195779035 . G A 13.7 PASS . GT:GQ:DP:AD:VAF:PL 1/1:14:33:24,8:0.242424:13,28,0. -----------------------------. v0.10.0 chr6 159711482 . C T 46.5 PASS . GT:GQ:DP:AD:VAF:PL 0/1:36:70:38,32:0.457143:46,0,36. v",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/824
https://github.com/google/deepvariant/issues/824:323,deployability,version,version,323,"Homozygous GT value while IGV shows otherwise; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. Although some variants are clearly heterozygous in IGV, deepvariant GT shows a homozygous genotype. **Setup**. - Operating system: linux. - DeepVariant version: 1.6.1. - Installation method : Docker. - Type of data: illumina, WES, hg38. **Steps to reproduce:**. ```. docker run --rm -i \. -v ${ref_dir}:/opt/ref \. -v ${kit_dir}:/opt/kit \. -v ${input_dir}:/opt/sample \. ${deepvariant_docker} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/opt/ref/${ref_fasta}"" \. --reads=""/opt/sample/${input_bam_file}"" \. --regions=""/opt/kit/${kit_bed_file}"" \. --output_vcf=""/opt/sample/${input_bam_file/.bam/.dv.vcf}"" \. --num_shards=""${threads}"". ```. Here are 5 selected variants called by 5 different versions of deepvariant:. ```. v0.10.0 chr12 11353713 . T C 57.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:54:43:27,15:0.348837:57,0,55. v1.1.0 chr12 11353713 . T C 36.6 PASS . GT:GQ:DP:AD:VAF:PL 0/1:34:44:28,15:0.340909:36,0,38. v1.4.0 chr12 11353713 . T C 23.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:21:44:28,15:0.340909:23,0,25. v1.5.0 chr12 11353713 . T C 24.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:17:44:28,15:0.340909:24,0,17. v1.6.1 chr12 11353713 . T C 24.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:5:44:28,15:0.340909:22,3,0. -----------------------------. v0.10.0 chr3 195779035 . G A 3.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:4:33:24,8:0.242424:1,0,38. v1.1.0 chr3 195779035 . G A 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:41:33:24,8:0.242424:0,43,45. v1.4.0 chr3 195779035 . G A 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:23:33:24,8:0.242424:0,32,22. v1.5.0 chr3 195779035 . G A 0.1 RefCall . GT:GQ:DP:AD:VAF:PL ./.:16:33:24,8:0.242424:0,26,16. v1.6.1 chr3 195779035 . G A 13.7 PASS . GT:GQ:DP:AD:VAF:PL 1/1:14:33:24,8:0.242424:13,28,0. -----------------------------. v0.10.0 chr6 159711482 . C T 46.5 PASS . GT:GQ:DP:AD:VAF:PL 0/1:36:70:38,32:0.457143:46,0,36. v",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/824
https://github.com/google/deepvariant/issues/824:341,deployability,Instal,Installation,341,"Homozygous GT value while IGV shows otherwise; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. Although some variants are clearly heterozygous in IGV, deepvariant GT shows a homozygous genotype. **Setup**. - Operating system: linux. - DeepVariant version: 1.6.1. - Installation method : Docker. - Type of data: illumina, WES, hg38. **Steps to reproduce:**. ```. docker run --rm -i \. -v ${ref_dir}:/opt/ref \. -v ${kit_dir}:/opt/kit \. -v ${input_dir}:/opt/sample \. ${deepvariant_docker} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/opt/ref/${ref_fasta}"" \. --reads=""/opt/sample/${input_bam_file}"" \. --regions=""/opt/kit/${kit_bed_file}"" \. --output_vcf=""/opt/sample/${input_bam_file/.bam/.dv.vcf}"" \. --num_shards=""${threads}"". ```. Here are 5 selected variants called by 5 different versions of deepvariant:. ```. v0.10.0 chr12 11353713 . T C 57.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:54:43:27,15:0.348837:57,0,55. v1.1.0 chr12 11353713 . T C 36.6 PASS . GT:GQ:DP:AD:VAF:PL 0/1:34:44:28,15:0.340909:36,0,38. v1.4.0 chr12 11353713 . T C 23.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:21:44:28,15:0.340909:23,0,25. v1.5.0 chr12 11353713 . T C 24.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:17:44:28,15:0.340909:24,0,17. v1.6.1 chr12 11353713 . T C 24.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:5:44:28,15:0.340909:22,3,0. -----------------------------. v0.10.0 chr3 195779035 . G A 3.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:4:33:24,8:0.242424:1,0,38. v1.1.0 chr3 195779035 . G A 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:41:33:24,8:0.242424:0,43,45. v1.4.0 chr3 195779035 . G A 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:23:33:24,8:0.242424:0,32,22. v1.5.0 chr3 195779035 . G A 0.1 RefCall . GT:GQ:DP:AD:VAF:PL ./.:16:33:24,8:0.242424:0,26,16. v1.6.1 chr3 195779035 . G A 13.7 PASS . GT:GQ:DP:AD:VAF:PL 1/1:14:33:24,8:0.242424:13,28,0. -----------------------------. v0.10.0 chr6 159711482 . C T 46.5 PASS . GT:GQ:DP:AD:VAF:PL 0/1:36:70:38,32:0.457143:46,0,36. v",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/824
https://github.com/google/deepvariant/issues/824:888,deployability,version,versions,888,"Homozygous GT value while IGV shows otherwise; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. Although some variants are clearly heterozygous in IGV, deepvariant GT shows a homozygous genotype. **Setup**. - Operating system: linux. - DeepVariant version: 1.6.1. - Installation method : Docker. - Type of data: illumina, WES, hg38. **Steps to reproduce:**. ```. docker run --rm -i \. -v ${ref_dir}:/opt/ref \. -v ${kit_dir}:/opt/kit \. -v ${input_dir}:/opt/sample \. ${deepvariant_docker} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/opt/ref/${ref_fasta}"" \. --reads=""/opt/sample/${input_bam_file}"" \. --regions=""/opt/kit/${kit_bed_file}"" \. --output_vcf=""/opt/sample/${input_bam_file/.bam/.dv.vcf}"" \. --num_shards=""${threads}"". ```. Here are 5 selected variants called by 5 different versions of deepvariant:. ```. v0.10.0 chr12 11353713 . T C 57.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:54:43:27,15:0.348837:57,0,55. v1.1.0 chr12 11353713 . T C 36.6 PASS . GT:GQ:DP:AD:VAF:PL 0/1:34:44:28,15:0.340909:36,0,38. v1.4.0 chr12 11353713 . T C 23.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:21:44:28,15:0.340909:23,0,25. v1.5.0 chr12 11353713 . T C 24.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:17:44:28,15:0.340909:24,0,17. v1.6.1 chr12 11353713 . T C 24.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:5:44:28,15:0.340909:22,3,0. -----------------------------. v0.10.0 chr3 195779035 . G A 3.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:4:33:24,8:0.242424:1,0,38. v1.1.0 chr3 195779035 . G A 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:41:33:24,8:0.242424:0,43,45. v1.4.0 chr3 195779035 . G A 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:23:33:24,8:0.242424:0,32,22. v1.5.0 chr3 195779035 . G A 0.1 RefCall . GT:GQ:DP:AD:VAF:PL ./.:16:33:24,8:0.242424:0,26,16. v1.6.1 chr3 195779035 . G A 13.7 PASS . GT:GQ:DP:AD:VAF:PL 1/1:14:33:24,8:0.242424:13,28,0. -----------------------------. v0.10.0 chr6 159711482 . C T 46.5 PASS . GT:GQ:DP:AD:VAF:PL 0/1:36:70:38,32:0.457143:46,0,36. v",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/824
https://github.com/google/deepvariant/issues/824:3388,deployability,version,versions,3388,"---. v0.10.0 chr3 195779035 . G A 3.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:4:33:24,8:0.242424:1,0,38. v1.1.0 chr3 195779035 . G A 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:41:33:24,8:0.242424:0,43,45. v1.4.0 chr3 195779035 . G A 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:23:33:24,8:0.242424:0,32,22. v1.5.0 chr3 195779035 . G A 0.1 RefCall . GT:GQ:DP:AD:VAF:PL ./.:16:33:24,8:0.242424:0,26,16. v1.6.1 chr3 195779035 . G A 13.7 PASS . GT:GQ:DP:AD:VAF:PL 1/1:14:33:24,8:0.242424:13,28,0. -----------------------------. v0.10.0 chr6 159711482 . C T 46.5 PASS . GT:GQ:DP:AD:VAF:PL 0/1:36:70:38,32:0.457143:46,0,36. v1.1.0 chr6 159711482 . C T 6.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:7:80:46,34:0.425:5,0,20. v1.4.0 chr6 159711482 . C T 1.8 RefCall . GT:GQ:DP:AD:VAF:PL ./.:5:80:46,34:0.425:0,3,9. v1.5.0 chr6 159711482 . C T 2.3 RefCall . GT:GQ:DP:AD:VAF:PL ./.:4:80:46,34:0.425:0,2,8. v1.6.1 chr6 159711482 . C T 9.9 PASS . GT:GQ:DP:AD:VAF:PL 1/1:3:80:46,34:0.425:6,0,0. -----------------------------. v0.10.0 chr14 106592660 . G A 64.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:59:93:38,55:0.591398:64,0,60. v1.1.0 chr14 106592660 . G A 30.5 PASS . GT:GQ:DP:AD:VAF:PL 1/1:8:95:38,57:0.6:29,6,0. v1.4.0 chr14 106592660 . G A 4.6 PASS . GT:GQ:DP:AD:VAF:PL 0/1:3:95:38,57:0.6:1,0,5. v1.5.0 chr14 106592660 . G A 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:43:95:38,57:0.6:0,44,48. v1.6.1 chr14 106592660 . G A 23.7 PASS . GT:GQ:DP:AD:VAF:PL 1/1:5:95:38,57:0.6:22,3,0. -----------------------------. v0.10.0 chr1 1668449 . A G 47.2 PASS . GT:GQ:DP:AD:VAF:PL 0/1:45:158:71,87:0.550633:47,0,49. v1.1.0 chr1 1668449 . A G 23.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:7:164:75,89:0.542683:22,0,5. v1.4.0 chr1 1668449 . A G 40 PASS . GT:GQ:DP:AD:VAF:PL 1/1:32:164:75,89:0.542683:40,32,0. v1.5.0 chr1 1668449 . A G 41.9 PASS . GT:GQ:DP:AD:VAF:PL 1/1:31:164:75,89:0.542683:41,31,0. v1.6.1 chr1 1668449 . A G 43.7 PASS . GT:GQ:DP:AD:VAF:PL 1/1:29:164:75,89:0.542683:43,28,0. ```. As you can see specially in 1.6.1 the genotype is GT:1/1 while earlier versions were GT:0/1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/824
https://github.com/google/deepvariant/issues/824:323,integrability,version,version,323,"Homozygous GT value while IGV shows otherwise; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. Although some variants are clearly heterozygous in IGV, deepvariant GT shows a homozygous genotype. **Setup**. - Operating system: linux. - DeepVariant version: 1.6.1. - Installation method : Docker. - Type of data: illumina, WES, hg38. **Steps to reproduce:**. ```. docker run --rm -i \. -v ${ref_dir}:/opt/ref \. -v ${kit_dir}:/opt/kit \. -v ${input_dir}:/opt/sample \. ${deepvariant_docker} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/opt/ref/${ref_fasta}"" \. --reads=""/opt/sample/${input_bam_file}"" \. --regions=""/opt/kit/${kit_bed_file}"" \. --output_vcf=""/opt/sample/${input_bam_file/.bam/.dv.vcf}"" \. --num_shards=""${threads}"". ```. Here are 5 selected variants called by 5 different versions of deepvariant:. ```. v0.10.0 chr12 11353713 . T C 57.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:54:43:27,15:0.348837:57,0,55. v1.1.0 chr12 11353713 . T C 36.6 PASS . GT:GQ:DP:AD:VAF:PL 0/1:34:44:28,15:0.340909:36,0,38. v1.4.0 chr12 11353713 . T C 23.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:21:44:28,15:0.340909:23,0,25. v1.5.0 chr12 11353713 . T C 24.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:17:44:28,15:0.340909:24,0,17. v1.6.1 chr12 11353713 . T C 24.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:5:44:28,15:0.340909:22,3,0. -----------------------------. v0.10.0 chr3 195779035 . G A 3.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:4:33:24,8:0.242424:1,0,38. v1.1.0 chr3 195779035 . G A 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:41:33:24,8:0.242424:0,43,45. v1.4.0 chr3 195779035 . G A 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:23:33:24,8:0.242424:0,32,22. v1.5.0 chr3 195779035 . G A 0.1 RefCall . GT:GQ:DP:AD:VAF:PL ./.:16:33:24,8:0.242424:0,26,16. v1.6.1 chr3 195779035 . G A 13.7 PASS . GT:GQ:DP:AD:VAF:PL 1/1:14:33:24,8:0.242424:13,28,0. -----------------------------. v0.10.0 chr6 159711482 . C T 46.5 PASS . GT:GQ:DP:AD:VAF:PL 0/1:36:70:38,32:0.457143:46,0,36. v",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/824
https://github.com/google/deepvariant/issues/824:888,integrability,version,versions,888,"Homozygous GT value while IGV shows otherwise; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. Although some variants are clearly heterozygous in IGV, deepvariant GT shows a homozygous genotype. **Setup**. - Operating system: linux. - DeepVariant version: 1.6.1. - Installation method : Docker. - Type of data: illumina, WES, hg38. **Steps to reproduce:**. ```. docker run --rm -i \. -v ${ref_dir}:/opt/ref \. -v ${kit_dir}:/opt/kit \. -v ${input_dir}:/opt/sample \. ${deepvariant_docker} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/opt/ref/${ref_fasta}"" \. --reads=""/opt/sample/${input_bam_file}"" \. --regions=""/opt/kit/${kit_bed_file}"" \. --output_vcf=""/opt/sample/${input_bam_file/.bam/.dv.vcf}"" \. --num_shards=""${threads}"". ```. Here are 5 selected variants called by 5 different versions of deepvariant:. ```. v0.10.0 chr12 11353713 . T C 57.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:54:43:27,15:0.348837:57,0,55. v1.1.0 chr12 11353713 . T C 36.6 PASS . GT:GQ:DP:AD:VAF:PL 0/1:34:44:28,15:0.340909:36,0,38. v1.4.0 chr12 11353713 . T C 23.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:21:44:28,15:0.340909:23,0,25. v1.5.0 chr12 11353713 . T C 24.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:17:44:28,15:0.340909:24,0,17. v1.6.1 chr12 11353713 . T C 24.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:5:44:28,15:0.340909:22,3,0. -----------------------------. v0.10.0 chr3 195779035 . G A 3.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:4:33:24,8:0.242424:1,0,38. v1.1.0 chr3 195779035 . G A 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:41:33:24,8:0.242424:0,43,45. v1.4.0 chr3 195779035 . G A 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:23:33:24,8:0.242424:0,32,22. v1.5.0 chr3 195779035 . G A 0.1 RefCall . GT:GQ:DP:AD:VAF:PL ./.:16:33:24,8:0.242424:0,26,16. v1.6.1 chr3 195779035 . G A 13.7 PASS . GT:GQ:DP:AD:VAF:PL 1/1:14:33:24,8:0.242424:13,28,0. -----------------------------. v0.10.0 chr6 159711482 . C T 46.5 PASS . GT:GQ:DP:AD:VAF:PL 0/1:36:70:38,32:0.457143:46,0,36. v",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/824
https://github.com/google/deepvariant/issues/824:3388,integrability,version,versions,3388,"---. v0.10.0 chr3 195779035 . G A 3.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:4:33:24,8:0.242424:1,0,38. v1.1.0 chr3 195779035 . G A 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:41:33:24,8:0.242424:0,43,45. v1.4.0 chr3 195779035 . G A 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:23:33:24,8:0.242424:0,32,22. v1.5.0 chr3 195779035 . G A 0.1 RefCall . GT:GQ:DP:AD:VAF:PL ./.:16:33:24,8:0.242424:0,26,16. v1.6.1 chr3 195779035 . G A 13.7 PASS . GT:GQ:DP:AD:VAF:PL 1/1:14:33:24,8:0.242424:13,28,0. -----------------------------. v0.10.0 chr6 159711482 . C T 46.5 PASS . GT:GQ:DP:AD:VAF:PL 0/1:36:70:38,32:0.457143:46,0,36. v1.1.0 chr6 159711482 . C T 6.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:7:80:46,34:0.425:5,0,20. v1.4.0 chr6 159711482 . C T 1.8 RefCall . GT:GQ:DP:AD:VAF:PL ./.:5:80:46,34:0.425:0,3,9. v1.5.0 chr6 159711482 . C T 2.3 RefCall . GT:GQ:DP:AD:VAF:PL ./.:4:80:46,34:0.425:0,2,8. v1.6.1 chr6 159711482 . C T 9.9 PASS . GT:GQ:DP:AD:VAF:PL 1/1:3:80:46,34:0.425:6,0,0. -----------------------------. v0.10.0 chr14 106592660 . G A 64.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:59:93:38,55:0.591398:64,0,60. v1.1.0 chr14 106592660 . G A 30.5 PASS . GT:GQ:DP:AD:VAF:PL 1/1:8:95:38,57:0.6:29,6,0. v1.4.0 chr14 106592660 . G A 4.6 PASS . GT:GQ:DP:AD:VAF:PL 0/1:3:95:38,57:0.6:1,0,5. v1.5.0 chr14 106592660 . G A 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:43:95:38,57:0.6:0,44,48. v1.6.1 chr14 106592660 . G A 23.7 PASS . GT:GQ:DP:AD:VAF:PL 1/1:5:95:38,57:0.6:22,3,0. -----------------------------. v0.10.0 chr1 1668449 . A G 47.2 PASS . GT:GQ:DP:AD:VAF:PL 0/1:45:158:71,87:0.550633:47,0,49. v1.1.0 chr1 1668449 . A G 23.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:7:164:75,89:0.542683:22,0,5. v1.4.0 chr1 1668449 . A G 40 PASS . GT:GQ:DP:AD:VAF:PL 1/1:32:164:75,89:0.542683:40,32,0. v1.5.0 chr1 1668449 . A G 41.9 PASS . GT:GQ:DP:AD:VAF:PL 1/1:31:164:75,89:0.542683:41,31,0. v1.6.1 chr1 1668449 . A G 43.7 PASS . GT:GQ:DP:AD:VAF:PL 1/1:29:164:75,89:0.542683:43,28,0. ```. As you can see specially in 1.6.1 the genotype is GT:1/1 while earlier versions were GT:0/1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/824
https://github.com/google/deepvariant/issues/824:323,modifiability,version,version,323,"Homozygous GT value while IGV shows otherwise; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. Although some variants are clearly heterozygous in IGV, deepvariant GT shows a homozygous genotype. **Setup**. - Operating system: linux. - DeepVariant version: 1.6.1. - Installation method : Docker. - Type of data: illumina, WES, hg38. **Steps to reproduce:**. ```. docker run --rm -i \. -v ${ref_dir}:/opt/ref \. -v ${kit_dir}:/opt/kit \. -v ${input_dir}:/opt/sample \. ${deepvariant_docker} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/opt/ref/${ref_fasta}"" \. --reads=""/opt/sample/${input_bam_file}"" \. --regions=""/opt/kit/${kit_bed_file}"" \. --output_vcf=""/opt/sample/${input_bam_file/.bam/.dv.vcf}"" \. --num_shards=""${threads}"". ```. Here are 5 selected variants called by 5 different versions of deepvariant:. ```. v0.10.0 chr12 11353713 . T C 57.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:54:43:27,15:0.348837:57,0,55. v1.1.0 chr12 11353713 . T C 36.6 PASS . GT:GQ:DP:AD:VAF:PL 0/1:34:44:28,15:0.340909:36,0,38. v1.4.0 chr12 11353713 . T C 23.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:21:44:28,15:0.340909:23,0,25. v1.5.0 chr12 11353713 . T C 24.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:17:44:28,15:0.340909:24,0,17. v1.6.1 chr12 11353713 . T C 24.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:5:44:28,15:0.340909:22,3,0. -----------------------------. v0.10.0 chr3 195779035 . G A 3.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:4:33:24,8:0.242424:1,0,38. v1.1.0 chr3 195779035 . G A 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:41:33:24,8:0.242424:0,43,45. v1.4.0 chr3 195779035 . G A 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:23:33:24,8:0.242424:0,32,22. v1.5.0 chr3 195779035 . G A 0.1 RefCall . GT:GQ:DP:AD:VAF:PL ./.:16:33:24,8:0.242424:0,26,16. v1.6.1 chr3 195779035 . G A 13.7 PASS . GT:GQ:DP:AD:VAF:PL 1/1:14:33:24,8:0.242424:13,28,0. -----------------------------. v0.10.0 chr6 159711482 . C T 46.5 PASS . GT:GQ:DP:AD:VAF:PL 0/1:36:70:38,32:0.457143:46,0,36. v",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/824
https://github.com/google/deepvariant/issues/824:888,modifiability,version,versions,888,"Homozygous GT value while IGV shows otherwise; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. Although some variants are clearly heterozygous in IGV, deepvariant GT shows a homozygous genotype. **Setup**. - Operating system: linux. - DeepVariant version: 1.6.1. - Installation method : Docker. - Type of data: illumina, WES, hg38. **Steps to reproduce:**. ```. docker run --rm -i \. -v ${ref_dir}:/opt/ref \. -v ${kit_dir}:/opt/kit \. -v ${input_dir}:/opt/sample \. ${deepvariant_docker} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/opt/ref/${ref_fasta}"" \. --reads=""/opt/sample/${input_bam_file}"" \. --regions=""/opt/kit/${kit_bed_file}"" \. --output_vcf=""/opt/sample/${input_bam_file/.bam/.dv.vcf}"" \. --num_shards=""${threads}"". ```. Here are 5 selected variants called by 5 different versions of deepvariant:. ```. v0.10.0 chr12 11353713 . T C 57.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:54:43:27,15:0.348837:57,0,55. v1.1.0 chr12 11353713 . T C 36.6 PASS . GT:GQ:DP:AD:VAF:PL 0/1:34:44:28,15:0.340909:36,0,38. v1.4.0 chr12 11353713 . T C 23.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:21:44:28,15:0.340909:23,0,25. v1.5.0 chr12 11353713 . T C 24.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:17:44:28,15:0.340909:24,0,17. v1.6.1 chr12 11353713 . T C 24.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:5:44:28,15:0.340909:22,3,0. -----------------------------. v0.10.0 chr3 195779035 . G A 3.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:4:33:24,8:0.242424:1,0,38. v1.1.0 chr3 195779035 . G A 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:41:33:24,8:0.242424:0,43,45. v1.4.0 chr3 195779035 . G A 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:23:33:24,8:0.242424:0,32,22. v1.5.0 chr3 195779035 . G A 0.1 RefCall . GT:GQ:DP:AD:VAF:PL ./.:16:33:24,8:0.242424:0,26,16. v1.6.1 chr3 195779035 . G A 13.7 PASS . GT:GQ:DP:AD:VAF:PL 1/1:14:33:24,8:0.242424:13,28,0. -----------------------------. v0.10.0 chr6 159711482 . C T 46.5 PASS . GT:GQ:DP:AD:VAF:PL 0/1:36:70:38,32:0.457143:46,0,36. v",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/824
https://github.com/google/deepvariant/issues/824:3388,modifiability,version,versions,3388,"---. v0.10.0 chr3 195779035 . G A 3.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:4:33:24,8:0.242424:1,0,38. v1.1.0 chr3 195779035 . G A 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:41:33:24,8:0.242424:0,43,45. v1.4.0 chr3 195779035 . G A 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:23:33:24,8:0.242424:0,32,22. v1.5.0 chr3 195779035 . G A 0.1 RefCall . GT:GQ:DP:AD:VAF:PL ./.:16:33:24,8:0.242424:0,26,16. v1.6.1 chr3 195779035 . G A 13.7 PASS . GT:GQ:DP:AD:VAF:PL 1/1:14:33:24,8:0.242424:13,28,0. -----------------------------. v0.10.0 chr6 159711482 . C T 46.5 PASS . GT:GQ:DP:AD:VAF:PL 0/1:36:70:38,32:0.457143:46,0,36. v1.1.0 chr6 159711482 . C T 6.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:7:80:46,34:0.425:5,0,20. v1.4.0 chr6 159711482 . C T 1.8 RefCall . GT:GQ:DP:AD:VAF:PL ./.:5:80:46,34:0.425:0,3,9. v1.5.0 chr6 159711482 . C T 2.3 RefCall . GT:GQ:DP:AD:VAF:PL ./.:4:80:46,34:0.425:0,2,8. v1.6.1 chr6 159711482 . C T 9.9 PASS . GT:GQ:DP:AD:VAF:PL 1/1:3:80:46,34:0.425:6,0,0. -----------------------------. v0.10.0 chr14 106592660 . G A 64.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:59:93:38,55:0.591398:64,0,60. v1.1.0 chr14 106592660 . G A 30.5 PASS . GT:GQ:DP:AD:VAF:PL 1/1:8:95:38,57:0.6:29,6,0. v1.4.0 chr14 106592660 . G A 4.6 PASS . GT:GQ:DP:AD:VAF:PL 0/1:3:95:38,57:0.6:1,0,5. v1.5.0 chr14 106592660 . G A 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:43:95:38,57:0.6:0,44,48. v1.6.1 chr14 106592660 . G A 23.7 PASS . GT:GQ:DP:AD:VAF:PL 1/1:5:95:38,57:0.6:22,3,0. -----------------------------. v0.10.0 chr1 1668449 . A G 47.2 PASS . GT:GQ:DP:AD:VAF:PL 0/1:45:158:71,87:0.550633:47,0,49. v1.1.0 chr1 1668449 . A G 23.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:7:164:75,89:0.542683:22,0,5. v1.4.0 chr1 1668449 . A G 40 PASS . GT:GQ:DP:AD:VAF:PL 1/1:32:164:75,89:0.542683:40,32,0. v1.5.0 chr1 1668449 . A G 41.9 PASS . GT:GQ:DP:AD:VAF:PL 1/1:31:164:75,89:0.542683:41,31,0. v1.6.1 chr1 1668449 . A G 43.7 PASS . GT:GQ:DP:AD:VAF:PL 1/1:29:164:75,89:0.542683:43,28,0. ```. As you can see specially in 1.6.1 the genotype is GT:1/1 while earlier versions were GT:0/1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/824
https://github.com/google/deepvariant/issues/824:198,usability,clear,clearly,198,"Homozygous GT value while IGV shows otherwise; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. Although some variants are clearly heterozygous in IGV, deepvariant GT shows a homozygous genotype. **Setup**. - Operating system: linux. - DeepVariant version: 1.6.1. - Installation method : Docker. - Type of data: illumina, WES, hg38. **Steps to reproduce:**. ```. docker run --rm -i \. -v ${ref_dir}:/opt/ref \. -v ${kit_dir}:/opt/kit \. -v ${input_dir}:/opt/sample \. ${deepvariant_docker} \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/opt/ref/${ref_fasta}"" \. --reads=""/opt/sample/${input_bam_file}"" \. --regions=""/opt/kit/${kit_bed_file}"" \. --output_vcf=""/opt/sample/${input_bam_file/.bam/.dv.vcf}"" \. --num_shards=""${threads}"". ```. Here are 5 selected variants called by 5 different versions of deepvariant:. ```. v0.10.0 chr12 11353713 . T C 57.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:54:43:27,15:0.348837:57,0,55. v1.1.0 chr12 11353713 . T C 36.6 PASS . GT:GQ:DP:AD:VAF:PL 0/1:34:44:28,15:0.340909:36,0,38. v1.4.0 chr12 11353713 . T C 23.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:21:44:28,15:0.340909:23,0,25. v1.5.0 chr12 11353713 . T C 24.3 PASS . GT:GQ:DP:AD:VAF:PL 0/1:17:44:28,15:0.340909:24,0,17. v1.6.1 chr12 11353713 . T C 24.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:5:44:28,15:0.340909:22,3,0. -----------------------------. v0.10.0 chr3 195779035 . G A 3.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:4:33:24,8:0.242424:1,0,38. v1.1.0 chr3 195779035 . G A 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:41:33:24,8:0.242424:0,43,45. v1.4.0 chr3 195779035 . G A 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:23:33:24,8:0.242424:0,32,22. v1.5.0 chr3 195779035 . G A 0.1 RefCall . GT:GQ:DP:AD:VAF:PL ./.:16:33:24,8:0.242424:0,26,16. v1.6.1 chr3 195779035 . G A 13.7 PASS . GT:GQ:DP:AD:VAF:PL 1/1:14:33:24,8:0.242424:13,28,0. -----------------------------. v0.10.0 chr6 159711482 . C T 46.5 PASS . GT:GQ:DP:AD:VAF:PL 0/1:36:70:38,32:0.457143:46,0,36. v",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/824
https://github.com/google/deepvariant/issues/825:450,availability,Operat,Operating,450,"Fix male VCF after calling without --haploid_contigs=""chrX,chrY"" and/or --par_regions_bed parameters; If I generated a VCF file for a trio (with a father using deeptrio) or a solo male (using deepvariant) without --haploid_contigs=""chrX,chrY"" and/or --par_regions_bed parameters. Can I fix the VCF after the run is finished, let's say by targeted calling? And as a suggestion, it would be nice if the algorithm takes care of this automatically :). - Operating system: Linux. - DeepVariant version: 1.6.0 and 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PacBio, Hg38.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/825
https://github.com/google/deepvariant/issues/825:430,deployability,automat,automatically,430,"Fix male VCF after calling without --haploid_contigs=""chrX,chrY"" and/or --par_regions_bed parameters; If I generated a VCF file for a trio (with a father using deeptrio) or a solo male (using deepvariant) without --haploid_contigs=""chrX,chrY"" and/or --par_regions_bed parameters. Can I fix the VCF after the run is finished, let's say by targeted calling? And as a suggestion, it would be nice if the algorithm takes care of this automatically :). - Operating system: Linux. - DeepVariant version: 1.6.0 and 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PacBio, Hg38.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/825
https://github.com/google/deepvariant/issues/825:489,deployability,version,version,489,"Fix male VCF after calling without --haploid_contigs=""chrX,chrY"" and/or --par_regions_bed parameters; If I generated a VCF file for a trio (with a father using deeptrio) or a solo male (using deepvariant) without --haploid_contigs=""chrX,chrY"" and/or --par_regions_bed parameters. Can I fix the VCF after the run is finished, let's say by targeted calling? And as a suggestion, it would be nice if the algorithm takes care of this automatically :). - Operating system: Linux. - DeepVariant version: 1.6.0 and 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PacBio, Hg38.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/825
https://github.com/google/deepvariant/issues/825:517,deployability,Instal,Installation,517,"Fix male VCF after calling without --haploid_contigs=""chrX,chrY"" and/or --par_regions_bed parameters; If I generated a VCF file for a trio (with a father using deeptrio) or a solo male (using deepvariant) without --haploid_contigs=""chrX,chrY"" and/or --par_regions_bed parameters. Can I fix the VCF after the run is finished, let's say by targeted calling? And as a suggestion, it would be nice if the algorithm takes care of this automatically :). - Operating system: Linux. - DeepVariant version: 1.6.0 and 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PacBio, Hg38.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/825
https://github.com/google/deepvariant/issues/825:489,integrability,version,version,489,"Fix male VCF after calling without --haploid_contigs=""chrX,chrY"" and/or --par_regions_bed parameters; If I generated a VCF file for a trio (with a father using deeptrio) or a solo male (using deepvariant) without --haploid_contigs=""chrX,chrY"" and/or --par_regions_bed parameters. Can I fix the VCF after the run is finished, let's say by targeted calling? And as a suggestion, it would be nice if the algorithm takes care of this automatically :). - Operating system: Linux. - DeepVariant version: 1.6.0 and 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PacBio, Hg38.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/825
https://github.com/google/deepvariant/issues/825:90,modifiability,paramet,parameters,90,"Fix male VCF after calling without --haploid_contigs=""chrX,chrY"" and/or --par_regions_bed parameters; If I generated a VCF file for a trio (with a father using deeptrio) or a solo male (using deepvariant) without --haploid_contigs=""chrX,chrY"" and/or --par_regions_bed parameters. Can I fix the VCF after the run is finished, let's say by targeted calling? And as a suggestion, it would be nice if the algorithm takes care of this automatically :). - Operating system: Linux. - DeepVariant version: 1.6.0 and 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PacBio, Hg38.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/825
https://github.com/google/deepvariant/issues/825:268,modifiability,paramet,parameters,268,"Fix male VCF after calling without --haploid_contigs=""chrX,chrY"" and/or --par_regions_bed parameters; If I generated a VCF file for a trio (with a father using deeptrio) or a solo male (using deepvariant) without --haploid_contigs=""chrX,chrY"" and/or --par_regions_bed parameters. Can I fix the VCF after the run is finished, let's say by targeted calling? And as a suggestion, it would be nice if the algorithm takes care of this automatically :). - Operating system: Linux. - DeepVariant version: 1.6.0 and 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PacBio, Hg38.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/825
https://github.com/google/deepvariant/issues/825:489,modifiability,version,version,489,"Fix male VCF after calling without --haploid_contigs=""chrX,chrY"" and/or --par_regions_bed parameters; If I generated a VCF file for a trio (with a father using deeptrio) or a solo male (using deepvariant) without --haploid_contigs=""chrX,chrY"" and/or --par_regions_bed parameters. Can I fix the VCF after the run is finished, let's say by targeted calling? And as a suggestion, it would be nice if the algorithm takes care of this automatically :). - Operating system: Linux. - DeepVariant version: 1.6.0 and 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PacBio, Hg38.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/825
https://github.com/google/deepvariant/issues/825:689,modifiability,Pac,PacBio,689,"Fix male VCF after calling without --haploid_contigs=""chrX,chrY"" and/or --par_regions_bed parameters; If I generated a VCF file for a trio (with a father using deeptrio) or a solo male (using deepvariant) without --haploid_contigs=""chrX,chrY"" and/or --par_regions_bed parameters. Can I fix the VCF after the run is finished, let's say by targeted calling? And as a suggestion, it would be nice if the algorithm takes care of this automatically :). - Operating system: Linux. - DeepVariant version: 1.6.0 and 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PacBio, Hg38.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/825
https://github.com/google/deepvariant/issues/825:430,testability,automat,automatically,430,"Fix male VCF after calling without --haploid_contigs=""chrX,chrY"" and/or --par_regions_bed parameters; If I generated a VCF file for a trio (with a father using deeptrio) or a solo male (using deepvariant) without --haploid_contigs=""chrX,chrY"" and/or --par_regions_bed parameters. Can I fix the VCF after the run is finished, let's say by targeted calling? And as a suggestion, it would be nice if the algorithm takes care of this automatically :). - Operating system: Linux. - DeepVariant version: 1.6.0 and 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PacBio, Hg38.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/825
https://github.com/google/deepvariant/issues/825:608,testability,instrument,instrument,608,"Fix male VCF after calling without --haploid_contigs=""chrX,chrY"" and/or --par_regions_bed parameters; If I generated a VCF file for a trio (with a father using deeptrio) or a solo male (using deepvariant) without --haploid_contigs=""chrX,chrY"" and/or --par_regions_bed parameters. Can I fix the VCF after the run is finished, let's say by targeted calling? And as a suggestion, it would be nice if the algorithm takes care of this automatically :). - Operating system: Linux. - DeepVariant version: 1.6.0 and 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) PacBio, Hg38.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/825
https://github.com/google/deepvariant/issues/826:228,energy efficiency,Current,Currently,228,"gvcf with true depth and not (only) min_dp; Dear team deepvariant, . I am wondering (I cannot find anything in the documentation) how it would be possible to get the true depth per site in the gvcf file and not only the min_dp. Currently I am converting the gvcf into vcf for comparisons, but is there a way to calculate back what the true depth is for a site by adding some additional output to the gvcf file? . Kind regards, . Eva",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/826
https://github.com/google/deepvariant/issues/826:49,security,team,team,49,"gvcf with true depth and not (only) min_dp; Dear team deepvariant, . I am wondering (I cannot find anything in the documentation) how it would be possible to get the true depth per site in the gvcf file and not only the min_dp. Currently I am converting the gvcf into vcf for comparisons, but is there a way to calculate back what the true depth is for a site by adding some additional output to the gvcf file? . Kind regards, . Eva",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/826
https://github.com/google/deepvariant/issues/826:115,usability,document,documentation,115,"gvcf with true depth and not (only) min_dp; Dear team deepvariant, . I am wondering (I cannot find anything in the documentation) how it would be possible to get the true depth per site in the gvcf file and not only the min_dp. Currently I am converting the gvcf into vcf for comparisons, but is there a way to calculate back what the true depth is for a site by adding some additional output to the gvcf file? . Kind regards, . Eva",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/826
https://github.com/google/deepvariant/issues/827:4,usability,progress,progress,4,"any progress on somatic SNV calling?; hello, i saw a comment from 2022 that this was not developed, i wonder if you are moving towards this. thanks. christos.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/827
https://github.com/google/deepvariant/issues/828:34,energy efficiency,model,model,34,"Use haplotagged bam file with WES model type ; Dear developers, . I am in the process of seeing if by adding phasing information I can increase the accuracy of my variants. I have a Illumina haplotagged bam file which i phased with Nanopore data with the WhatsHap phasing tool. When I run the phased illumina file through deepvariant I obtain the same results as the unphased illumina file. . I seem to have lost the phasing information in the VCF file that comes out of deepvariant and have no changes between the two VCFs when looking at BCFtools stats function. When running Deepvariant i use the WES model as a parameter. My question now is whether Deepvariant's WES or WGS model does anything with the given phasing information or is it only possible with the PACBIO or ONT_R104 model? kind regards,. Ewoud",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/828
https://github.com/google/deepvariant/issues/828:604,energy efficiency,model,model,604,"Use haplotagged bam file with WES model type ; Dear developers, . I am in the process of seeing if by adding phasing information I can increase the accuracy of my variants. I have a Illumina haplotagged bam file which i phased with Nanopore data with the WhatsHap phasing tool. When I run the phased illumina file through deepvariant I obtain the same results as the unphased illumina file. . I seem to have lost the phasing information in the VCF file that comes out of deepvariant and have no changes between the two VCFs when looking at BCFtools stats function. When running Deepvariant i use the WES model as a parameter. My question now is whether Deepvariant's WES or WGS model does anything with the given phasing information or is it only possible with the PACBIO or ONT_R104 model? kind regards,. Ewoud",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/828
https://github.com/google/deepvariant/issues/828:678,energy efficiency,model,model,678,"Use haplotagged bam file with WES model type ; Dear developers, . I am in the process of seeing if by adding phasing information I can increase the accuracy of my variants. I have a Illumina haplotagged bam file which i phased with Nanopore data with the WhatsHap phasing tool. When I run the phased illumina file through deepvariant I obtain the same results as the unphased illumina file. . I seem to have lost the phasing information in the VCF file that comes out of deepvariant and have no changes between the two VCFs when looking at BCFtools stats function. When running Deepvariant i use the WES model as a parameter. My question now is whether Deepvariant's WES or WGS model does anything with the given phasing information or is it only possible with the PACBIO or ONT_R104 model? kind regards,. Ewoud",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/828
https://github.com/google/deepvariant/issues/828:784,energy efficiency,model,model,784,"Use haplotagged bam file with WES model type ; Dear developers, . I am in the process of seeing if by adding phasing information I can increase the accuracy of my variants. I have a Illumina haplotagged bam file which i phased with Nanopore data with the WhatsHap phasing tool. When I run the phased illumina file through deepvariant I obtain the same results as the unphased illumina file. . I seem to have lost the phasing information in the VCF file that comes out of deepvariant and have no changes between the two VCFs when looking at BCFtools stats function. When running Deepvariant i use the WES model as a parameter. My question now is whether Deepvariant's WES or WGS model does anything with the given phasing information or is it only possible with the PACBIO or ONT_R104 model? kind regards,. Ewoud",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/828
https://github.com/google/deepvariant/issues/828:615,modifiability,paramet,parameter,615,"Use haplotagged bam file with WES model type ; Dear developers, . I am in the process of seeing if by adding phasing information I can increase the accuracy of my variants. I have a Illumina haplotagged bam file which i phased with Nanopore data with the WhatsHap phasing tool. When I run the phased illumina file through deepvariant I obtain the same results as the unphased illumina file. . I seem to have lost the phasing information in the VCF file that comes out of deepvariant and have no changes between the two VCFs when looking at BCFtools stats function. When running Deepvariant i use the WES model as a parameter. My question now is whether Deepvariant's WES or WGS model does anything with the given phasing information or is it only possible with the PACBIO or ONT_R104 model? kind regards,. Ewoud",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/828
https://github.com/google/deepvariant/issues/828:765,modifiability,PAC,PACBIO,765,"Use haplotagged bam file with WES model type ; Dear developers, . I am in the process of seeing if by adding phasing information I can increase the accuracy of my variants. I have a Illumina haplotagged bam file which i phased with Nanopore data with the WhatsHap phasing tool. When I run the phased illumina file through deepvariant I obtain the same results as the unphased illumina file. . I seem to have lost the phasing information in the VCF file that comes out of deepvariant and have no changes between the two VCFs when looking at BCFtools stats function. When running Deepvariant i use the WES model as a parameter. My question now is whether Deepvariant's WES or WGS model does anything with the given phasing information or is it only possible with the PACBIO or ONT_R104 model? kind regards,. Ewoud",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/828
https://github.com/google/deepvariant/issues/828:684,reliability,doe,does,684,"Use haplotagged bam file with WES model type ; Dear developers, . I am in the process of seeing if by adding phasing information I can increase the accuracy of my variants. I have a Illumina haplotagged bam file which i phased with Nanopore data with the WhatsHap phasing tool. When I run the phased illumina file through deepvariant I obtain the same results as the unphased illumina file. . I seem to have lost the phasing information in the VCF file that comes out of deepvariant and have no changes between the two VCFs when looking at BCFtools stats function. When running Deepvariant i use the WES model as a parameter. My question now is whether Deepvariant's WES or WGS model does anything with the given phasing information or is it only possible with the PACBIO or ONT_R104 model? kind regards,. Ewoud",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/828
https://github.com/google/deepvariant/issues/828:34,security,model,model,34,"Use haplotagged bam file with WES model type ; Dear developers, . I am in the process of seeing if by adding phasing information I can increase the accuracy of my variants. I have a Illumina haplotagged bam file which i phased with Nanopore data with the WhatsHap phasing tool. When I run the phased illumina file through deepvariant I obtain the same results as the unphased illumina file. . I seem to have lost the phasing information in the VCF file that comes out of deepvariant and have no changes between the two VCFs when looking at BCFtools stats function. When running Deepvariant i use the WES model as a parameter. My question now is whether Deepvariant's WES or WGS model does anything with the given phasing information or is it only possible with the PACBIO or ONT_R104 model? kind regards,. Ewoud",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/828
https://github.com/google/deepvariant/issues/828:604,security,model,model,604,"Use haplotagged bam file with WES model type ; Dear developers, . I am in the process of seeing if by adding phasing information I can increase the accuracy of my variants. I have a Illumina haplotagged bam file which i phased with Nanopore data with the WhatsHap phasing tool. When I run the phased illumina file through deepvariant I obtain the same results as the unphased illumina file. . I seem to have lost the phasing information in the VCF file that comes out of deepvariant and have no changes between the two VCFs when looking at BCFtools stats function. When running Deepvariant i use the WES model as a parameter. My question now is whether Deepvariant's WES or WGS model does anything with the given phasing information or is it only possible with the PACBIO or ONT_R104 model? kind regards,. Ewoud",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/828
https://github.com/google/deepvariant/issues/828:678,security,model,model,678,"Use haplotagged bam file with WES model type ; Dear developers, . I am in the process of seeing if by adding phasing information I can increase the accuracy of my variants. I have a Illumina haplotagged bam file which i phased with Nanopore data with the WhatsHap phasing tool. When I run the phased illumina file through deepvariant I obtain the same results as the unphased illumina file. . I seem to have lost the phasing information in the VCF file that comes out of deepvariant and have no changes between the two VCFs when looking at BCFtools stats function. When running Deepvariant i use the WES model as a parameter. My question now is whether Deepvariant's WES or WGS model does anything with the given phasing information or is it only possible with the PACBIO or ONT_R104 model? kind regards,. Ewoud",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/828
https://github.com/google/deepvariant/issues/828:784,security,model,model,784,"Use haplotagged bam file with WES model type ; Dear developers, . I am in the process of seeing if by adding phasing information I can increase the accuracy of my variants. I have a Illumina haplotagged bam file which i phased with Nanopore data with the WhatsHap phasing tool. When I run the phased illumina file through deepvariant I obtain the same results as the unphased illumina file. . I seem to have lost the phasing information in the VCF file that comes out of deepvariant and have no changes between the two VCFs when looking at BCFtools stats function. When running Deepvariant i use the WES model as a parameter. My question now is whether Deepvariant's WES or WGS model does anything with the given phasing information or is it only possible with the PACBIO or ONT_R104 model? kind regards,. Ewoud",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/828
https://github.com/google/deepvariant/issues/828:272,usability,tool,tool,272,"Use haplotagged bam file with WES model type ; Dear developers, . I am in the process of seeing if by adding phasing information I can increase the accuracy of my variants. I have a Illumina haplotagged bam file which i phased with Nanopore data with the WhatsHap phasing tool. When I run the phased illumina file through deepvariant I obtain the same results as the unphased illumina file. . I seem to have lost the phasing information in the VCF file that comes out of deepvariant and have no changes between the two VCFs when looking at BCFtools stats function. When running Deepvariant i use the WES model as a parameter. My question now is whether Deepvariant's WES or WGS model does anything with the given phasing information or is it only possible with the PACBIO or ONT_R104 model? kind regards,. Ewoud",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/828
https://github.com/google/deepvariant/issues/829:240,availability,error,error,240,"docker: invalid reference format.; Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. ""). it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/829
https://github.com/google/deepvariant/issues/829:301,availability,error,error,301,"docker: invalid reference format.; Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. ""). it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/829
https://github.com/google/deepvariant/issues/829:26,interoperability,format,format,26,"docker: invalid reference format.; Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. ""). it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/829
https://github.com/google/deepvariant/issues/829:349,interoperability,format,format,349,"docker: invalid reference format.; Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. ""). it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/829
https://github.com/google/deepvariant/issues/829:423,interoperability,format,format,423,"docker: invalid reference format.; Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. ""). it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/829
https://github.com/google/deepvariant/issues/829:2222,interoperability,format,format,2222,"mmand, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. ""). it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stats --sample_name MITO60 --output_vcf /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result/ --model_type ONT_R104. docker: invalid reference format. See 'docker run --help'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/829
https://github.com/google/deepvariant/issues/829:413,modifiability,paramet,parameter,413,"docker: invalid reference format.; Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. ""). it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/829
https://github.com/google/deepvariant/issues/829:75,performance,time,time,75,"docker: invalid reference format.; Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. ""). it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/829
https://github.com/google/deepvariant/issues/829:240,performance,error,error,240,"docker: invalid reference format.; Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. ""). it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/829
https://github.com/google/deepvariant/issues/829:301,performance,error,error,301,"docker: invalid reference format.; Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. ""). it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/829
https://github.com/google/deepvariant/issues/829:240,safety,error,error,240,"docker: invalid reference format.; Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. ""). it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/829
https://github.com/google/deepvariant/issues/829:301,safety,error,error,301,"docker: invalid reference format.; Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. ""). it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/829
https://github.com/google/deepvariant/issues/829:61,usability,command,command,61,"docker: invalid reference format.; Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. ""). it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/829
https://github.com/google/deepvariant/issues/829:197,usability,command,command,197,"docker: invalid reference format.; Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. ""). it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/829
https://github.com/google/deepvariant/issues/829:240,usability,error,error,240,"docker: invalid reference format.; Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. ""). it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/829
https://github.com/google/deepvariant/issues/829:252,usability,command,command,252,"docker: invalid reference format.; Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. ""). it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/829
https://github.com/google/deepvariant/issues/829:301,usability,error,error,301,"docker: invalid reference format.; Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. ""). it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/829
https://github.com/google/deepvariant/issues/829:375,usability,help,help,375,"docker: invalid reference format.; Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. ""). it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/829
https://github.com/google/deepvariant/issues/829:536,usability,Support,Supports,536,"docker: invalid reference format.; Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. ""). it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/829
https://github.com/google/deepvariant/issues/829:671,usability,help,help,671,"docker: invalid reference format.; Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. ""). it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/829
https://github.com/google/deepvariant/issues/829:686,usability,help,help,686,"docker: invalid reference format.; Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. ""). it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/829
https://github.com/google/deepvariant/issues/829:736,usability,command,command,736,"docker: invalid reference format.; Hello,. I am using docker command first time, so not much aware of it, i am trying to run deepvariant, tried out almost all possible method to make changes in my command, but i might be missing some minor error in my command, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. ""). it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/829
https://github.com/google/deepvariant/issues/829:2248,usability,help,help,2248,"mmand, which i may not be able to rectify, The error i am getting is docker: invalid reference format. See 'docker run --help'. (For this i followed the given parameter format in run_deepvariant "" --ref: Required. Genome reference to use. Must have an associated FAI index as well. Supports text or gzipped references. Should match the reference used to align the BAM file. provided to --reads. ""). it would be great help if anyone help me to sort out this issue. I am attaching my command here. docker run -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3 -v /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result:/media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result -v /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker:/media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker google/deepvariant:{BIN_VERSION=""1.6.1""} python /media/manish/Data/Jyoti_Mridha_AIC/Program/deepvariant-1.6.1/scripts/run_deepvariant.py --reads /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/Batch1_3runs/1_minimap2_freebayes_Final/Direct_minimap/Bam/run3/MITO60_sorted.bam --ref /media/manish/Data/Jyoti_Mridha_AIC/My_S/Nanopore_Mito/Mito_Genome_hg38/zip_ref_docker/hg38_chrM.fa.gz --report_title MITO60_Stats --sample_name MITO60 --output_vcf /media/manish/Data/Jyoti_Mridha_AIC/Nanopore_Sequencing/Jyoti_mito_Analysis_GATK/1_FINAL_NANOPORE/deepvariants_Trial/deepvariant_result/ --model_type ONT_R104. docker: invalid reference format. See 'docker run --help'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/829
https://github.com/google/deepvariant/issues/830:602,availability,operat,operations,602,"google/deepvariant:1.6.1 docker says version 1.6.0; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. When I check the version of google/deepvariant:1.6.1 it says 1.6.0, and the docker image has `ENV VERSION=1.6.0`. ```. docker run google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --version. 2024-06-13 12:25:30.001574: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. DeepVariant version 1.6.0. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/830
https://github.com/google/deepvariant/issues/830:668,availability,operat,operations,668,"google/deepvariant:1.6.1 docker says version 1.6.0; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. When I check the version of google/deepvariant:1.6.1 it says 1.6.0, and the docker image has `ENV VERSION=1.6.0`. ```. docker run google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --version. 2024-06-13 12:25:30.001574: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. DeepVariant version 1.6.0. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/830
https://github.com/google/deepvariant/issues/830:37,deployability,version,version,37,"google/deepvariant:1.6.1 docker says version 1.6.0; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. When I check the version of google/deepvariant:1.6.1 it says 1.6.0, and the docker image has `ENV VERSION=1.6.0`. ```. docker run google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --version. 2024-06-13 12:25:30.001574: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. DeepVariant version 1.6.0. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/830
https://github.com/google/deepvariant/issues/830:188,deployability,version,version,188,"google/deepvariant:1.6.1 docker says version 1.6.0; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. When I check the version of google/deepvariant:1.6.1 it says 1.6.0, and the docker image has `ENV VERSION=1.6.0`. ```. docker run google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --version. 2024-06-13 12:25:30.001574: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. DeepVariant version 1.6.0. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/830
https://github.com/google/deepvariant/issues/830:269,deployability,VERSION,VERSION,269,"google/deepvariant:1.6.1 docker says version 1.6.0; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. When I check the version of google/deepvariant:1.6.1 it says 1.6.0, and the docker image has `ENV VERSION=1.6.0`. ```. docker run google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --version. 2024-06-13 12:25:30.001574: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. DeepVariant version 1.6.0. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/830
https://github.com/google/deepvariant/issues/830:365,deployability,version,version,365,"google/deepvariant:1.6.1 docker says version 1.6.0; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. When I check the version of google/deepvariant:1.6.1 it says 1.6.0, and the docker image has `ENV VERSION=1.6.0`. ```. docker run google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --version. 2024-06-13 12:25:30.001574: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. DeepVariant version 1.6.0. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/830
https://github.com/google/deepvariant/issues/830:748,deployability,version,version,748,"google/deepvariant:1.6.1 docker says version 1.6.0; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. When I check the version of google/deepvariant:1.6.1 it says 1.6.0, and the docker image has `ENV VERSION=1.6.0`. ```. docker run google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --version. 2024-06-13 12:25:30.001574: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. DeepVariant version 1.6.0. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/830
https://github.com/google/deepvariant/issues/830:415,energy efficiency,core,core,415,"google/deepvariant:1.6.1 docker says version 1.6.0; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. When I check the version of google/deepvariant:1.6.1 it says 1.6.0, and the docker image has `ENV VERSION=1.6.0`. ```. docker run google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --version. 2024-06-13 12:25:30.001574: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. DeepVariant version 1.6.0. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/830
https://github.com/google/deepvariant/issues/830:481,energy efficiency,optim,optimized,481,"google/deepvariant:1.6.1 docker says version 1.6.0; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. When I check the version of google/deepvariant:1.6.1 it says 1.6.0, and the docker image has `ENV VERSION=1.6.0`. ```. docker run google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --version. 2024-06-13 12:25:30.001574: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. DeepVariant version 1.6.0. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/830
https://github.com/google/deepvariant/issues/830:561,energy efficiency,CPU,CPU,561,"google/deepvariant:1.6.1 docker says version 1.6.0; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. When I check the version of google/deepvariant:1.6.1 it says 1.6.0, and the docker image has `ENV VERSION=1.6.0`. ```. docker run google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --version. 2024-06-13 12:25:30.001574: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. DeepVariant version 1.6.0. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/830
https://github.com/google/deepvariant/issues/830:37,integrability,version,version,37,"google/deepvariant:1.6.1 docker says version 1.6.0; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. When I check the version of google/deepvariant:1.6.1 it says 1.6.0, and the docker image has `ENV VERSION=1.6.0`. ```. docker run google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --version. 2024-06-13 12:25:30.001574: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. DeepVariant version 1.6.0. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/830
https://github.com/google/deepvariant/issues/830:188,integrability,version,version,188,"google/deepvariant:1.6.1 docker says version 1.6.0; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. When I check the version of google/deepvariant:1.6.1 it says 1.6.0, and the docker image has `ENV VERSION=1.6.0`. ```. docker run google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --version. 2024-06-13 12:25:30.001574: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. DeepVariant version 1.6.0. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/830
https://github.com/google/deepvariant/issues/830:269,integrability,VERSION,VERSION,269,"google/deepvariant:1.6.1 docker says version 1.6.0; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. When I check the version of google/deepvariant:1.6.1 it says 1.6.0, and the docker image has `ENV VERSION=1.6.0`. ```. docker run google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --version. 2024-06-13 12:25:30.001574: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. DeepVariant version 1.6.0. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/830
https://github.com/google/deepvariant/issues/830:365,integrability,version,version,365,"google/deepvariant:1.6.1 docker says version 1.6.0; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. When I check the version of google/deepvariant:1.6.1 it says 1.6.0, and the docker image has `ENV VERSION=1.6.0`. ```. docker run google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --version. 2024-06-13 12:25:30.001574: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. DeepVariant version 1.6.0. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/830
https://github.com/google/deepvariant/issues/830:748,integrability,version,version,748,"google/deepvariant:1.6.1 docker says version 1.6.0; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. When I check the version of google/deepvariant:1.6.1 it says 1.6.0, and the docker image has `ENV VERSION=1.6.0`. ```. docker run google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --version. 2024-06-13 12:25:30.001574: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. DeepVariant version 1.6.0. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/830
https://github.com/google/deepvariant/issues/830:420,interoperability,platform,platform,420,"google/deepvariant:1.6.1 docker says version 1.6.0; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. When I check the version of google/deepvariant:1.6.1 it says 1.6.0, and the docker image has `ENV VERSION=1.6.0`. ```. docker run google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --version. 2024-06-13 12:25:30.001574: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. DeepVariant version 1.6.0. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/830
https://github.com/google/deepvariant/issues/830:37,modifiability,version,version,37,"google/deepvariant:1.6.1 docker says version 1.6.0; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. When I check the version of google/deepvariant:1.6.1 it says 1.6.0, and the docker image has `ENV VERSION=1.6.0`. ```. docker run google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --version. 2024-06-13 12:25:30.001574: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. DeepVariant version 1.6.0. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/830
https://github.com/google/deepvariant/issues/830:188,modifiability,version,version,188,"google/deepvariant:1.6.1 docker says version 1.6.0; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. When I check the version of google/deepvariant:1.6.1 it says 1.6.0, and the docker image has `ENV VERSION=1.6.0`. ```. docker run google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --version. 2024-06-13 12:25:30.001574: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. DeepVariant version 1.6.0. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/830
https://github.com/google/deepvariant/issues/830:269,modifiability,VERSION,VERSION,269,"google/deepvariant:1.6.1 docker says version 1.6.0; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. When I check the version of google/deepvariant:1.6.1 it says 1.6.0, and the docker image has `ENV VERSION=1.6.0`. ```. docker run google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --version. 2024-06-13 12:25:30.001574: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. DeepVariant version 1.6.0. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/830
https://github.com/google/deepvariant/issues/830:365,modifiability,version,version,365,"google/deepvariant:1.6.1 docker says version 1.6.0; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. When I check the version of google/deepvariant:1.6.1 it says 1.6.0, and the docker image has `ENV VERSION=1.6.0`. ```. docker run google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --version. 2024-06-13 12:25:30.001574: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. DeepVariant version 1.6.0. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/830
https://github.com/google/deepvariant/issues/830:748,modifiability,version,version,748,"google/deepvariant:1.6.1 docker says version 1.6.0; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. When I check the version of google/deepvariant:1.6.1 it says 1.6.0, and the docker image has `ENV VERSION=1.6.0`. ```. docker run google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --version. 2024-06-13 12:25:30.001574: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. DeepVariant version 1.6.0. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/830
https://github.com/google/deepvariant/issues/830:481,performance,optimiz,optimized,481,"google/deepvariant:1.6.1 docker says version 1.6.0; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. When I check the version of google/deepvariant:1.6.1 it says 1.6.0, and the docker image has `ENV VERSION=1.6.0`. ```. docker run google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --version. 2024-06-13 12:25:30.001574: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. DeepVariant version 1.6.0. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/830
https://github.com/google/deepvariant/issues/830:515,performance,Network,Network,515,"google/deepvariant:1.6.1 docker says version 1.6.0; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. When I check the version of google/deepvariant:1.6.1 it says 1.6.0, and the docker image has `ENV VERSION=1.6.0`. ```. docker run google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --version. 2024-06-13 12:25:30.001574: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. DeepVariant version 1.6.0. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/830
https://github.com/google/deepvariant/issues/830:561,performance,CPU,CPU,561,"google/deepvariant:1.6.1 docker says version 1.6.0; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. When I check the version of google/deepvariant:1.6.1 it says 1.6.0, and the docker image has `ENV VERSION=1.6.0`. ```. docker run google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --version. 2024-06-13 12:25:30.001574: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. DeepVariant version 1.6.0. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/830
https://github.com/google/deepvariant/issues/830:581,performance,perform,performance-critical,581,"google/deepvariant:1.6.1 docker says version 1.6.0; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. When I check the version of google/deepvariant:1.6.1 it says 1.6.0, and the docker image has `ENV VERSION=1.6.0`. ```. docker run google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --version. 2024-06-13 12:25:30.001574: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. DeepVariant version 1.6.0. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/830
https://github.com/google/deepvariant/issues/830:515,security,Network,Network,515,"google/deepvariant:1.6.1 docker says version 1.6.0; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. When I check the version of google/deepvariant:1.6.1 it says 1.6.0, and the docker image has `ENV VERSION=1.6.0`. ```. docker run google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --version. 2024-06-13 12:25:30.001574: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. DeepVariant version 1.6.0. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/830
https://github.com/google/deepvariant/issues/830:581,usability,perform,performance-critical,581,"google/deepvariant:1.6.1 docker says version 1.6.0; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. **Describe the issue:**. When I check the version of google/deepvariant:1.6.1 it says 1.6.0, and the docker image has `ENV VERSION=1.6.0`. ```. docker run google/deepvariant:1.6.1 /opt/deepvariant/bin/run_deepvariant --version. 2024-06-13 12:25:30.001574: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. DeepVariant version 1.6.0. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/830
https://github.com/google/deepvariant/issues/831:10,availability,error,error,10,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:595,availability,ping,pinging,595,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:933,availability,ping,pinging,933,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:1271,availability,ping,pinging,1271,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:1609,availability,ping,pinging,1609,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:533,deployability,fail,failed,533,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:603,deployability,contain,container,603,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:871,deployability,fail,failed,871,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:941,deployability,contain,container,941,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:1209,deployability,fail,failed,1209,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:1279,deployability,contain,container,1279,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:1547,deployability,fail,failed,1547,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:1617,deployability,contain,container,1617,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:75,integrability,pub,pub,75,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:613,interoperability,registr,registry,613,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:622,interoperability,registr,registry-,622,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:657,interoperability,registr,registry-,657,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:701,interoperability,registr,registry-,701,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:951,interoperability,registr,registry,951,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:960,interoperability,registr,registry-,960,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:995,interoperability,registr,registry-,995,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:1039,interoperability,registr,registry-,1039,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:1289,interoperability,registr,registry,1289,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:1298,interoperability,registr,registry-,1298,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:1333,interoperability,registr,registry-,1333,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:1377,interoperability,registr,registry-,1377,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:1627,interoperability,registr,registry,1627,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:1636,interoperability,registr,registry-,1636,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:1671,interoperability,registr,registry-,1671,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:1715,interoperability,registr,registry-,1715,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:2,performance,time,timeout,2,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:10,performance,error,error,10,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:795,performance,i/o,i/o,795,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:799,performance,time,timeout,799,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:1133,performance,i/o,i/o,1133,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:1137,performance,time,timeout,1137,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:1471,performance,i/o,i/o,1471,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:1475,performance,time,timeout,1475,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:1809,performance,i/o,i/o,1809,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:1813,performance,time,timeout,1813,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:533,reliability,fail,failed,533,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:871,reliability,fail,failed,871,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:1209,reliability,fail,failed,1209,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:1547,reliability,fail,failed,1547,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:2,safety,timeout,timeout,2,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:10,safety,error,error,10,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:799,safety,timeout,timeout,799,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:1137,safety,timeout,timeout,1137,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:1475,safety,timeout,timeout,1475,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:1813,safety,timeout,timeout,1813,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:547,security,checksum,checksum,547,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:885,security,checksum,checksum,885,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:1223,security,checksum,checksum,1223,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:1561,security,checksum,checksum,1561,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/831:10,usability,error,error,10,"A timeout error occurs; singularity run -B /slurm/home/yrd/sunlab/yangfeng/pub/WW/WGS/deepvirant/deepvariant_1.6.1.sif \. docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$reference \. --reads=$sample_dir2 \. --output_vcf=""${OUTPUT_DIR}""/${NameN}.vcf.gz \. --output_gvcf=""${OUTPUT_DIR}""/${NameN}.g.vcf.gz \. --intermediate_results_dir ""${OUTPUT_DIR}/${NameN}_intermediate_results_dir"" \. --num_shards=60. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58057->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:57892->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:49924->114.114.114.114:53: i/o timeout. FATAL: Unable to handle docker://google/deepvariant:1.6.1 uri: failed to get checksum for docker://google/deepvariant:1.6.1: pinging container registry registry-1.docker.io: Get ""https://registry-1.docker.io/v2/"": dial tcp: lookup registry-1.docker.io on 114.114.114.114:53: read udp 172.16.10.108:58178->114.114.114.114:53: i/o timeout.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/831
https://github.com/google/deepvariant/issues/832:156,deployability,automat,automatically,156,"training with multi-gpu; Hi,. I was wondering if training with multiple GPUs is supported and, if so, if there is any specific flag to use or if it will be automatically activated when there is more than one GPU in your working environment. Thank you in advance,. Regards",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/832
https://github.com/google/deepvariant/issues/832:20,energy efficiency,gpu,gpu,20,"training with multi-gpu; Hi,. I was wondering if training with multiple GPUs is supported and, if so, if there is any specific flag to use or if it will be automatically activated when there is more than one GPU in your working environment. Thank you in advance,. Regards",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/832
https://github.com/google/deepvariant/issues/832:72,energy efficiency,GPU,GPUs,72,"training with multi-gpu; Hi,. I was wondering if training with multiple GPUs is supported and, if so, if there is any specific flag to use or if it will be automatically activated when there is more than one GPU in your working environment. Thank you in advance,. Regards",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/832
https://github.com/google/deepvariant/issues/832:208,energy efficiency,GPU,GPU,208,"training with multi-gpu; Hi,. I was wondering if training with multiple GPUs is supported and, if so, if there is any specific flag to use or if it will be automatically activated when there is more than one GPU in your working environment. Thank you in advance,. Regards",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/832
https://github.com/google/deepvariant/issues/832:118,interoperability,specif,specific,118,"training with multi-gpu; Hi,. I was wondering if training with multiple GPUs is supported and, if so, if there is any specific flag to use or if it will be automatically activated when there is more than one GPU in your working environment. Thank you in advance,. Regards",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/832
https://github.com/google/deepvariant/issues/832:20,performance,gpu,gpu,20,"training with multi-gpu; Hi,. I was wondering if training with multiple GPUs is supported and, if so, if there is any specific flag to use or if it will be automatically activated when there is more than one GPU in your working environment. Thank you in advance,. Regards",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/832
https://github.com/google/deepvariant/issues/832:72,performance,GPU,GPUs,72,"training with multi-gpu; Hi,. I was wondering if training with multiple GPUs is supported and, if so, if there is any specific flag to use or if it will be automatically activated when there is more than one GPU in your working environment. Thank you in advance,. Regards",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/832
https://github.com/google/deepvariant/issues/832:208,performance,GPU,GPU,208,"training with multi-gpu; Hi,. I was wondering if training with multiple GPUs is supported and, if so, if there is any specific flag to use or if it will be automatically activated when there is more than one GPU in your working environment. Thank you in advance,. Regards",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/832
https://github.com/google/deepvariant/issues/832:156,testability,automat,automatically,156,"training with multi-gpu; Hi,. I was wondering if training with multiple GPUs is supported and, if so, if there is any specific flag to use or if it will be automatically activated when there is more than one GPU in your working environment. Thank you in advance,. Regards",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/832
https://github.com/google/deepvariant/issues/832:80,usability,support,supported,80,"training with multi-gpu; Hi,. I was wondering if training with multiple GPUs is supported and, if so, if there is any specific flag to use or if it will be automatically activated when there is more than one GPU in your working environment. Thank you in advance,. Regards",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/832
https://github.com/google/deepvariant/issues/833:0,availability,Error,Error,0,"Error encountered while running on downsampled BAM; Dear Developers,. Thank you very much for the amazing tool! I recently encountered an issue while running DeepVariant on a GIAB sample. I managed to run DeepVariant open another sample successfully so I believe there may be something wrong in the current sample input. It would be most helpful and appreciated if you could kindly take a look at the error messages. **Setup**. - Operating system: CentOS 7 x86_64. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity (v3.10.0). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:35,availability,down,downsampled,35,"Error encountered while running on downsampled BAM; Dear Developers,. Thank you very much for the amazing tool! I recently encountered an issue while running DeepVariant on a GIAB sample. I managed to run DeepVariant open another sample successfully so I believe there may be something wrong in the current sample input. It would be most helpful and appreciated if you could kindly take a look at the error messages. **Setup**. - Operating system: CentOS 7 x86_64. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity (v3.10.0). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:401,availability,error,error,401,"Error encountered while running on downsampled BAM; Dear Developers,. Thank you very much for the amazing tool! I recently encountered an issue while running DeepVariant on a GIAB sample. I managed to run DeepVariant open another sample successfully so I believe there may be something wrong in the current sample input. It would be most helpful and appreciated if you could kindly take a look at the error messages. **Setup**. - Operating system: CentOS 7 x86_64. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity (v3.10.0). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:430,availability,Operat,Operating,430,"Error encountered while running on downsampled BAM; Dear Developers,. Thank you very much for the amazing tool! I recently encountered an issue while running DeepVariant on a GIAB sample. I managed to run DeepVariant open another sample successfully so I believe there may be something wrong in the current sample input. It would be most helpful and appreciated if you could kindly take a look at the error messages. **Setup**. - Operating system: CentOS 7 x86_64. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity (v3.10.0). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:698,availability,down,downsampled,698,"Error encountered while running on downsampled BAM; Dear Developers,. Thank you very much for the amazing tool! I recently encountered an issue while running DeepVariant on a GIAB sample. I managed to run DeepVariant open another sample successfully so I believe there may be something wrong in the current sample input. It would be most helpful and appreciated if you could kindly take a look at the error messages. **Setup**. - Operating system: CentOS 7 x86_64. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity (v3.10.0). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:1672,availability,Error,Error,1672,"tudies?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_varian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:1686,availability,Error,Error,1686," BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Sha",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:1740,availability,error,error,1740,"uce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.06",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:2133,availability,mainten,maintenance,2133,"01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/lo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:2217,availability,down,downstream,2217,"ools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:2932,availability,error,error,2932,"/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/function_def_to_graph.py"", line 87 in func. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/function_deserialization.py"", line 416 i. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 154 in __init__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 958 in load_partial. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 828 in load. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 596 in call_. File ""/tmp/Bazel.run",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:190,deployability,manag,managed,190,"Error encountered while running on downsampled BAM; Dear Developers,. Thank you very much for the amazing tool! I recently encountered an issue while running DeepVariant on a GIAB sample. I managed to run DeepVariant open another sample successfully so I believe there may be something wrong in the current sample input. It would be most helpful and appreciated if you could kindly take a look at the error messages. **Setup**. - Operating system: CentOS 7 x86_64. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity (v3.10.0). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:479,deployability,version,version,479,"Error encountered while running on downsampled BAM; Dear Developers,. Thank you very much for the amazing tool! I recently encountered an issue while running DeepVariant on a GIAB sample. I managed to run DeepVariant open another sample successfully so I believe there may be something wrong in the current sample input. It would be most helpful and appreciated if you could kindly take a look at the error messages. **Setup**. - Operating system: CentOS 7 x86_64. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity (v3.10.0). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:497,deployability,Instal,Installation,497,"Error encountered while running on downsampled BAM; Dear Developers,. Thank you very much for the amazing tool! I recently encountered an issue while running DeepVariant on a GIAB sample. I managed to run DeepVariant open another sample successfully so I believe there may be something wrong in the current sample input. It would be most helpful and appreciated if you could kindly take a look at the error messages. **Setup**. - Operating system: CentOS 7 x86_64. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity (v3.10.0). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:1185,deployability,contain,contain,1185," managed to run DeepVariant open another sample successfully so I believe there may be something wrong in the current sample input. It would be most helpful and appreciated if you could kindly take a look at the error messages. **Setup**. - Operating system: CentOS 7 x86_64. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity (v3.10.0). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:1559,deployability,log,log,1559,"ty (v3.10.0). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370]",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:1731,deployability,log,log,1731," to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:2149,deployability,releas,release,2149,"she/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:2246,deployability,depend,dependencies,2246,".6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/us",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:2880,deployability,fail,failed,2880,"utput.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/function_def_to_graph.py"", line 87 in func. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/function_deserialization.py"", line 416 i. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 154 in __init__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 958 in load_partial. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 828 in load. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_v",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:190,energy efficiency,manag,managed,190,"Error encountered while running on downsampled BAM; Dear Developers,. Thank you very much for the amazing tool! I recently encountered an issue while running DeepVariant on a GIAB sample. I managed to run DeepVariant open another sample successfully so I believe there may be something wrong in the current sample input. It would be most helpful and appreciated if you could kindly take a look at the error messages. **Setup**. - Operating system: CentOS 7 x86_64. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity (v3.10.0). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:299,energy efficiency,current,current,299,"Error encountered while running on downsampled BAM; Dear Developers,. Thank you very much for the amazing tool! I recently encountered an issue while running DeepVariant on a GIAB sample. I managed to run DeepVariant open another sample successfully so I believe there may be something wrong in the current sample input. It would be most helpful and appreciated if you could kindly take a look at the error messages. **Setup**. - Operating system: CentOS 7 x86_64. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity (v3.10.0). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:2795,energy efficiency,model,model,2795,"ommand:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/function_def_to_graph.py"", line 87 in func. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/function_deserialization.py"", line 416 i. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 154 in __init__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 958 in load_partial. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 828 in load. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:2948,energy efficiency,Current,Current,2948,"3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/function_def_to_graph.py"", line 87 in func. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/function_deserialization.py"", line 416 i. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 154 in __init__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 958 in load_partial. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 828 in load. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 596 in call_. File ""/tmp/Bazel.runfiles_vitt1d55/ru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:3552,energy efficiency,load,load,3552,"py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/function_def_to_graph.py"", line 87 in func. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/function_deserialization.py"", line 416 i. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 154 in __init__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 958 in load_partial. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 828 in load. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 596 in call_. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768 in main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789 in <modu. real 0m5.038s. user 0m3.921s. sys 0m1.122s. Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:3659,energy efficiency,load,load,3659,"60 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/function_def_to_graph.py"", line 87 in func. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/function_deserialization.py"", line 416 i. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 154 in __init__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 958 in load_partial. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 828 in load. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 596 in call_. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768 in main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789 in <modu. real 0m5.038s. user 0m3.921s. sys 0m1.122s. Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessing/process.py"", line 108, in run. self._target(*self._args, **self._kwargs). File ""/tmp/Bazel.runfiles_vitt1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:3770,energy efficiency,load,load,3770,"ants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/function_def_to_graph.py"", line 87 in func. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/function_deserialization.py"", line 416 i. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 154 in __init__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 958 in load_partial. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 828 in load. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 596 in call_. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768 in main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789 in <modu. real 0m5.038s. user 0m3.921s. sys 0m1.122s. Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessing/process.py"", line 108, in run. self._target(*self._args, **self._kwargs). File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 454, in post. File ""/usr/lib/python3.8/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:3792,energy efficiency,load,load,3792," model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/function_def_to_graph.py"", line 87 in func. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/function_deserialization.py"", line 416 i. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 154 in __init__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 958 in load_partial. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 828 in load. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 596 in call_. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768 in main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789 in <modu. real 0m5.038s. user 0m3.921s. sys 0m1.122s. Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessing/process.py"", line 108, in run. self._target(*self._args, **self._kwargs). File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 454, in post. File ""/usr/lib/python3.8/multiprocessing/queues",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:407,integrability,messag,messages,407,"Error encountered while running on downsampled BAM; Dear Developers,. Thank you very much for the amazing tool! I recently encountered an issue while running DeepVariant on a GIAB sample. I managed to run DeepVariant open another sample successfully so I believe there may be something wrong in the current sample input. It would be most helpful and appreciated if you could kindly take a look at the error messages. **Setup**. - Operating system: CentOS 7 x86_64. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity (v3.10.0). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:479,integrability,version,version,479,"Error encountered while running on downsampled BAM; Dear Developers,. Thank you very much for the amazing tool! I recently encountered an issue while running DeepVariant on a GIAB sample. I managed to run DeepVariant open another sample successfully so I believe there may be something wrong in the current sample input. It would be most helpful and appreciated if you could kindly take a look at the error messages. **Setup**. - Operating system: CentOS 7 x86_64. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity (v3.10.0). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:2246,integrability,depend,dependencies,2246,".6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/us",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:2270,integrability,repositor,repositories,2270,"iant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/usr/local/lib/python3.8/di",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:4788,integrability,queue,queues,4788,"l first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/function_def_to_graph.py"", line 87 in func. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/function_deserialization.py"", line 416 i. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 154 in __init__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 958 in load_partial. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 828 in load. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 596 in call_. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768 in main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789 in <modu. real 0m5.038s. user 0m3.921s. sys 0m1.122s. Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessing/process.py"", line 108, in run. self._target(*self._args, **self._kwargs). File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 454, in post. File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 108, in get. raise Empty. _queue.Empty. INFO: Cleaning up image... ```. Please let me know if I could provide the input BAM for testing/debugging. Thank you for your time. Best regards,. Louis.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:407,interoperability,messag,messages,407,"Error encountered while running on downsampled BAM; Dear Developers,. Thank you very much for the amazing tool! I recently encountered an issue while running DeepVariant on a GIAB sample. I managed to run DeepVariant open another sample successfully so I believe there may be something wrong in the current sample input. It would be most helpful and appreciated if you could kindly take a look at the error messages. **Setup**. - Operating system: CentOS 7 x86_64. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity (v3.10.0). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:2270,interoperability,repositor,repositories,2270,"iant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/usr/local/lib/python3.8/di",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:2853,interoperability,platform,platform,2853,"file ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/function_def_to_graph.py"", line 87 in func. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/function_deserialization.py"", line 416 i. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 154 in __init__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 958 in load_partial. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 828 in load. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:479,modifiability,version,version,479,"Error encountered while running on downsampled BAM; Dear Developers,. Thank you very much for the amazing tool! I recently encountered an issue while running DeepVariant on a GIAB sample. I managed to run DeepVariant open another sample successfully so I believe there may be something wrong in the current sample input. It would be most helpful and appreciated if you could kindly take a look at the error messages. **Setup**. - Operating system: CentOS 7 x86_64. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity (v3.10.0). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:1961,modifiability,pac,packages,1961,"eletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:2246,modifiability,depend,dependencies,2246,".6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/us",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:3045,modifiability,pac,packages,3045,") has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/function_def_to_graph.py"", line 87 in func. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/function_deserialization.py"", line 416 i. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 154 in __init__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 958 in load_partial. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 828 in load. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 596 in call_. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768 in main. File ""/tmp/Bazel.r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:3162,modifiability,pac,packages,3162,"l a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/function_def_to_graph.py"", line 87 in func. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/function_deserialization.py"", line 416 i. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 154 in __init__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 958 in load_partial. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 828 in load. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 596 in call_. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768 in main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/ab",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:3279,modifiability,pac,packages,3279,"in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/function_def_to_graph.py"", line 87 in func. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/function_deserialization.py"", line 416 i. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 154 in __init__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 958 in load_partial. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 828 in load. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 596 in call_. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768 in main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:3396,modifiability,pac,packages,3396,"rnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/function_def_to_graph.py"", line 87 in func. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/function_deserialization.py"", line 416 i. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 154 in __init__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 958 in load_partial. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 828 in load. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 596 in call_. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768 in main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789 in <modu. real 0m5.038s. user 0m3.921s. sys 0m1.122s. Process ForkProcess-1:. Traceback (m",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:3513,modifiability,pac,packages,3513,"57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/function_def_to_graph.py"", line 87 in func. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/function_deserialization.py"", line 416 i. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 154 in __init__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 958 in load_partial. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 828 in load. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 596 in call_. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768 in main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789 in <modu. real 0m5.038s. user 0m3.921s. sys 0m1.122s. Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). Fi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:3620,modifiability,pac,packages,3620,"o. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/function_def_to_graph.py"", line 87 in func. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/function_deserialization.py"", line 416 i. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 154 in __init__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 958 in load_partial. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 828 in load. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 596 in call_. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768 in main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789 in <modu. real 0m5.038s. user 0m3.921s. sys 0m1.122s. Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessing/process.py"", line 108, in run. self._target(*self._args, **self._kwa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:3731,modifiability,pac,packages,3731,"57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/function_def_to_graph.py"", line 87 in func. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/function_deserialization.py"", line 416 i. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 154 in __init__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 958 in load_partial. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 828 in load. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 596 in call_. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768 in main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789 in <modu. real 0m5.038s. user 0m3.921s. sys 0m1.122s. Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessing/process.py"", line 108, in run. self._target(*self._args, **self._kwargs). File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 45",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:0,performance,Error,Error,0,"Error encountered while running on downsampled BAM; Dear Developers,. Thank you very much for the amazing tool! I recently encountered an issue while running DeepVariant on a GIAB sample. I managed to run DeepVariant open another sample successfully so I believe there may be something wrong in the current sample input. It would be most helpful and appreciated if you could kindly take a look at the error messages. **Setup**. - Operating system: CentOS 7 x86_64. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity (v3.10.0). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:401,performance,error,error,401,"Error encountered while running on downsampled BAM; Dear Developers,. Thank you very much for the amazing tool! I recently encountered an issue while running DeepVariant on a GIAB sample. I managed to run DeepVariant open another sample successfully so I believe there may be something wrong in the current sample input. It would be most helpful and appreciated if you could kindly take a look at the error messages. **Setup**. - Operating system: CentOS 7 x86_64. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity (v3.10.0). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:1672,performance,Error,Error,1672,"tudies?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_varian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:1686,performance,Error,Error,1686," BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Sha",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:1740,performance,error,error,1740,"uce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.06",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:1812,performance,time,time,1812,"b/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:2932,performance,error,error,2932,"/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/function_def_to_graph.py"", line 87 in func. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/function_deserialization.py"", line 416 i. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 154 in __init__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 958 in load_partial. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 828 in load. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 596 in call_. File ""/tmp/Bazel.run",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:3552,performance,load,load,3552,"py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/function_def_to_graph.py"", line 87 in func. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/function_deserialization.py"", line 416 i. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 154 in __init__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 958 in load_partial. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 828 in load. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 596 in call_. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768 in main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789 in <modu. real 0m5.038s. user 0m3.921s. sys 0m1.122s. Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:3659,performance,load,load,3659,"60 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/function_def_to_graph.py"", line 87 in func. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/function_deserialization.py"", line 416 i. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 154 in __init__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 958 in load_partial. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 828 in load. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 596 in call_. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768 in main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789 in <modu. real 0m5.038s. user 0m3.921s. sys 0m1.122s. Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessing/process.py"", line 108, in run. self._target(*self._args, **self._kwargs). File ""/tmp/Bazel.runfiles_vitt1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:3770,performance,load,load,3770,"ants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/function_def_to_graph.py"", line 87 in func. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/function_deserialization.py"", line 416 i. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 154 in __init__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 958 in load_partial. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 828 in load. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 596 in call_. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768 in main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789 in <modu. real 0m5.038s. user 0m3.921s. sys 0m1.122s. Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessing/process.py"", line 108, in run. self._target(*self._args, **self._kwargs). File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 454, in post. File ""/usr/lib/python3.8/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:3792,performance,load,load,3792," model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/function_def_to_graph.py"", line 87 in func. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/function_deserialization.py"", line 416 i. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 154 in __init__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 958 in load_partial. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 828 in load. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 596 in call_. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768 in main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789 in <modu. real 0m5.038s. user 0m3.921s. sys 0m1.122s. Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessing/process.py"", line 108, in run. self._target(*self._args, **self._kwargs). File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 454, in post. File ""/usr/lib/python3.8/multiprocessing/queues",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:4788,performance,queue,queues,4788,"l first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/function_def_to_graph.py"", line 87 in func. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/function_deserialization.py"", line 416 i. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 154 in __init__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 958 in load_partial. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 828 in load. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 596 in call_. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768 in main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789 in <modu. real 0m5.038s. user 0m3.921s. sys 0m1.122s. Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessing/process.py"", line 108, in run. self._target(*self._args, **self._kwargs). File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 454, in post. File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 108, in get. raise Empty. _queue.Empty. INFO: Cleaning up image... ```. Please let me know if I could provide the input BAM for testing/debugging. Thank you for your time. Best regards,. Louis.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:4971,performance,time,time,4971,"l first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/function_def_to_graph.py"", line 87 in func. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/function_deserialization.py"", line 416 i. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 154 in __init__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 958 in load_partial. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 828 in load. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 596 in call_. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768 in main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789 in <modu. real 0m5.038s. user 0m3.921s. sys 0m1.122s. Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessing/process.py"", line 108, in run. self._target(*self._args, **self._kwargs). File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 454, in post. File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 108, in get. raise Empty. _queue.Empty. INFO: Cleaning up image... ```. Please let me know if I could provide the input BAM for testing/debugging. Thank you for your time. Best regards,. Louis.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:2133,reliability,mainten,maintenance,2133,"01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/lo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:2880,reliability,fail,failed,2880,"utput.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/function_def_to_graph.py"", line 87 in func. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/function_deserialization.py"", line 416 i. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 154 in __init__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 958 in load_partial. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 828 in load. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_v",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:0,safety,Error,Error,0,"Error encountered while running on downsampled BAM; Dear Developers,. Thank you very much for the amazing tool! I recently encountered an issue while running DeepVariant on a GIAB sample. I managed to run DeepVariant open another sample successfully so I believe there may be something wrong in the current sample input. It would be most helpful and appreciated if you could kindly take a look at the error messages. **Setup**. - Operating system: CentOS 7 x86_64. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity (v3.10.0). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:190,safety,manag,managed,190,"Error encountered while running on downsampled BAM; Dear Developers,. Thank you very much for the amazing tool! I recently encountered an issue while running DeepVariant on a GIAB sample. I managed to run DeepVariant open another sample successfully so I believe there may be something wrong in the current sample input. It would be most helpful and appreciated if you could kindly take a look at the error messages. **Setup**. - Operating system: CentOS 7 x86_64. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity (v3.10.0). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:314,safety,input,input,314,"Error encountered while running on downsampled BAM; Dear Developers,. Thank you very much for the amazing tool! I recently encountered an issue while running DeepVariant on a GIAB sample. I managed to run DeepVariant open another sample successfully so I believe there may be something wrong in the current sample input. It would be most helpful and appreciated if you could kindly take a look at the error messages. **Setup**. - Operating system: CentOS 7 x86_64. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity (v3.10.0). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:401,safety,error,error,401,"Error encountered while running on downsampled BAM; Dear Developers,. Thank you very much for the amazing tool! I recently encountered an issue while running DeepVariant on a GIAB sample. I managed to run DeepVariant open another sample successfully so I believe there may be something wrong in the current sample input. It would be most helpful and appreciated if you could kindly take a look at the error messages. **Setup**. - Operating system: CentOS 7 x86_64. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity (v3.10.0). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:684,safety,Input,Input,684,"Error encountered while running on downsampled BAM; Dear Developers,. Thank you very much for the amazing tool! I recently encountered an issue while running DeepVariant on a GIAB sample. I managed to run DeepVariant open another sample successfully so I believe there may be something wrong in the current sample input. It would be most helpful and appreciated if you could kindly take a look at the error messages. **Setup**. - Operating system: CentOS 7 x86_64. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity (v3.10.0). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:1559,safety,log,log,1559,"ty (v3.10.0). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370]",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:1672,safety,Error,Error,1672,"tudies?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_varian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:1686,safety,Error,Error,1686," BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Sha",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:1731,safety,log,log,1731," to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:1740,safety,error,error,1740,"uce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.06",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:2246,safety,depend,dependencies,2246,".6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/us",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:2695,safety,input,input,2695,"below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/function_def_to_graph.py"", line 87 in func. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/function_deserialization.py"", line 416 i. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 154 in __init__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 958 in load_partial. Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:2932,safety,error,error,2932,"/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/function_def_to_graph.py"", line 87 in func. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/function_deserialization.py"", line 416 i. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 154 in __init__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 958 in load_partial. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 828 in load. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 596 in call_. File ""/tmp/Bazel.run",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:4919,safety,input,input,4919,"l first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/function_def_to_graph.py"", line 87 in func. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/function_deserialization.py"", line 416 i. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 154 in __init__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 958 in load_partial. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 828 in load. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 596 in call_. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768 in main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789 in <modu. real 0m5.038s. user 0m3.921s. sys 0m1.122s. Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessing/process.py"", line 108, in run. self._target(*self._args, **self._kwargs). File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 454, in post. File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 108, in get. raise Empty. _queue.Empty. INFO: Cleaning up image... ```. Please let me know if I could provide the input BAM for testing/debugging. Thank you for your time. Best regards,. Louis.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:4933,safety,test,testing,4933,"l first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/function_def_to_graph.py"", line 87 in func. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/function_deserialization.py"", line 416 i. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 154 in __init__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 958 in load_partial. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 828 in load. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 596 in call_. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768 in main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789 in <modu. real 0m5.038s. user 0m3.921s. sys 0m1.122s. Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessing/process.py"", line 108, in run. self._target(*self._args, **self._kwargs). File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 454, in post. File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 108, in get. raise Empty. _queue.Empty. INFO: Cleaning up image... ```. Please let me know if I could provide the input BAM for testing/debugging. Thank you for your time. Best regards,. Louis.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:1559,security,log,log,1559,"ty (v3.10.0). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370]",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:1731,security,log,log,1731," to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:2210,security,modif,modify,2210,"ouisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:2795,security,model,model,2795,"ommand:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/function_def_to_graph.py"", line 87 in func. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/function_deserialization.py"", line 416 i. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 154 in __init__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 958 in load_partial. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 828 in load. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:603,testability,instrument,instrument,603,"Error encountered while running on downsampled BAM; Dear Developers,. Thank you very much for the amazing tool! I recently encountered an issue while running DeepVariant on a GIAB sample. I managed to run DeepVariant open another sample successfully so I believe there may be something wrong in the current sample input. It would be most helpful and appreciated if you could kindly take a look at the error messages. **Setup**. - Operating system: CentOS 7 x86_64. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity (v3.10.0). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:1559,testability,log,log,1559,"ty (v3.10.0). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370]",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:1678,testability,trace,trace,1678,"?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:1692,testability,trace,trace,1692,"as downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:1731,testability,log,log,1731," to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:2170,testability,plan,planned,2170,"37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/ten",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:2246,testability,depend,dependencies,2246,".6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/us",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:4388,testability,Trace,Traceback,4388,"l first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/function_def_to_graph.py"", line 87 in func. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/function_deserialization.py"", line 416 i. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 154 in __init__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 958 in load_partial. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 828 in load. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 596 in call_. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768 in main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789 in <modu. real 0m5.038s. user 0m3.921s. sys 0m1.122s. Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessing/process.py"", line 108, in run. self._target(*self._args, **self._kwargs). File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 454, in post. File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 108, in get. raise Empty. _queue.Empty. INFO: Cleaning up image... ```. Please let me know if I could provide the input BAM for testing/debugging. Thank you for your time. Best regards,. Louis.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:4933,testability,test,testing,4933,"l first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/function_def_to_graph.py"", line 87 in func. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/function_deserialization.py"", line 416 i. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 154 in __init__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 958 in load_partial. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 828 in load. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 596 in call_. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768 in main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789 in <modu. real 0m5.038s. user 0m3.921s. sys 0m1.122s. Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessing/process.py"", line 108, in run. self._target(*self._args, **self._kwargs). File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 454, in post. File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 108, in get. raise Empty. _queue.Empty. INFO: Cleaning up image... ```. Please let me know if I could provide the input BAM for testing/debugging. Thank you for your time. Best regards,. Louis.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:0,usability,Error,Error,0,"Error encountered while running on downsampled BAM; Dear Developers,. Thank you very much for the amazing tool! I recently encountered an issue while running DeepVariant on a GIAB sample. I managed to run DeepVariant open another sample successfully so I believe there may be something wrong in the current sample input. It would be most helpful and appreciated if you could kindly take a look at the error messages. **Setup**. - Operating system: CentOS 7 x86_64. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity (v3.10.0). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:106,usability,tool,tool,106,"Error encountered while running on downsampled BAM; Dear Developers,. Thank you very much for the amazing tool! I recently encountered an issue while running DeepVariant on a GIAB sample. I managed to run DeepVariant open another sample successfully so I believe there may be something wrong in the current sample input. It would be most helpful and appreciated if you could kindly take a look at the error messages. **Setup**. - Operating system: CentOS 7 x86_64. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity (v3.10.0). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:314,usability,input,input,314,"Error encountered while running on downsampled BAM; Dear Developers,. Thank you very much for the amazing tool! I recently encountered an issue while running DeepVariant on a GIAB sample. I managed to run DeepVariant open another sample successfully so I believe there may be something wrong in the current sample input. It would be most helpful and appreciated if you could kindly take a look at the error messages. **Setup**. - Operating system: CentOS 7 x86_64. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity (v3.10.0). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:338,usability,help,helpful,338,"Error encountered while running on downsampled BAM; Dear Developers,. Thank you very much for the amazing tool! I recently encountered an issue while running DeepVariant on a GIAB sample. I managed to run DeepVariant open another sample successfully so I believe there may be something wrong in the current sample input. It would be most helpful and appreciated if you could kindly take a look at the error messages. **Setup**. - Operating system: CentOS 7 x86_64. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity (v3.10.0). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:401,usability,error,error,401,"Error encountered while running on downsampled BAM; Dear Developers,. Thank you very much for the amazing tool! I recently encountered an issue while running DeepVariant on a GIAB sample. I managed to run DeepVariant open another sample successfully so I believe there may be something wrong in the current sample input. It would be most helpful and appreciated if you could kindly take a look at the error messages. **Setup**. - Operating system: CentOS 7 x86_64. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity (v3.10.0). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:684,usability,Input,Input,684,"Error encountered while running on downsampled BAM; Dear Developers,. Thank you very much for the amazing tool! I recently encountered an issue while running DeepVariant on a GIAB sample. I managed to run DeepVariant open another sample successfully so I believe there may be something wrong in the current sample input. It would be most helpful and appreciated if you could kindly take a look at the error messages. **Setup**. - Operating system: CentOS 7 x86_64. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity (v3.10.0). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:753,usability,Command,Command,753,"Error encountered while running on downsampled BAM; Dear Developers,. Thank you very much for the amazing tool! I recently encountered an issue while running DeepVariant on a GIAB sample. I managed to run DeepVariant open another sample successfully so I believe there may be something wrong in the current sample input. It would be most helpful and appreciated if you could kindly take a look at the error messages. **Setup**. - Operating system: CentOS 7 x86_64. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity (v3.10.0). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:1221,usability,tool,tools,1221,"other sample successfully so I believe there may be something wrong in the current sample input. It would be most helpful and appreciated if you could kindly take a look at the error messages. **Setup**. - Operating system: CentOS 7 x86_64. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity (v3.10.0). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:1672,usability,Error,Error,1672,"tudies?) Input BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_varian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:1686,usability,Error,Error,1686," BAM was downsampled 10-fold to 30X. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Sha",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:1740,usability,error,error,1740,"uce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.06",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:1797,usability,command,command,1797,"cale/:/usr/lib/locale/ \. -B /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/novoalign_bam/:/input_reads \. -B /paedyl01/disk1/louisshe/out/GIAB/HG005/heterozygous_deletions/heterozygous_sites/:/output \. -B /tmp:/tmp \. -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:2013,usability,User,UserWarning,2013,". -B /paedyl01/disk1/louisshe/ref/hs37d5:/ref/hs37d5 \. -B /paedyl01/disk1/louisshe/ref/hg19:/ref/hg19 \. --home /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:2125,usability,minim,minimal,2125,"me /paedyl01/disk1/louisshe/ref/GIAB/HG005/hs37d5/ \. --contain \. /paedyl01/disk1/louisshe/tools/DeepVariant/deepvariant_1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/ref/hs37d5/hs37d5.fa \. --reads=/input_reads/HG005.hs37d5.30x.bam \. --output_vcf=/output/HG005.dv.vcf.gz \. --output_gvcf=/output/HG005.dv.g.vcf.gz \. --num_shards=10 \. --intermediate_results_dir=/tmp \. --logging_dir=/output/log \. --dry_run=false \. --par_regions_bed=/ref/hg19/ucsc.hg19.par.bed \. --haploid_contigs=""chrX,chrY"". ```. - Error trace:. Error trace below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:2695,usability,input,input,2695,"below is from `HG005_deppvariant.log`. No error prompts prior to this step. ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/call_variants_output.tfrecord.gz"" --examples ""/tmp/make_examp. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/function_def_to_graph.py"", line 87 in func. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/function_deserialization.py"", line 416 i. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 154 in __init__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 958 in load_partial. Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:2932,usability,error,error,2932,"/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:. TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Ker. For more information see: https://github.com/tensorflow/addons/issues/2807. warnings.warn(. I0619 14:57:56.059498 47403021002560 call_variants.py:563] Total 1 writing processes started. I0619 14:57:56.063244 47403021002560 dv_utils.py:370] From /tmp/make_examples.tfrecord-00000-of-00010.gz.example_info. I0619 14:57:56.063441 47403021002560 call_variants.py:588] Shape of input examples: [100, 221, 7]. I0619 14:57:56.063909 47403021002560 call_variants.py:592] Use saved model: True. 2024-06-19 14:57:57.916727: F tensorflow/tsl/platform/env.cc:391] Check failed: -1 != path_length (-1 vs. -1). Fatal Python error: Aborted. Current thread 0x00002b1ce03a6740 (most recent call first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/function_def_to_graph.py"", line 87 in func. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/function_deserialization.py"", line 416 i. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 154 in __init__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 958 in load_partial. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 828 in load. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 596 in call_. File ""/tmp/Bazel.run",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:4335,usability,user,user,4335,"l first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/function_def_to_graph.py"", line 87 in func. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/function_deserialization.py"", line 416 i. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 154 in __init__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 958 in load_partial. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 828 in load. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 596 in call_. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768 in main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789 in <modu. real 0m5.038s. user 0m3.921s. sys 0m1.122s. Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessing/process.py"", line 108, in run. self._target(*self._args, **self._kwargs). File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 454, in post. File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 108, in get. raise Empty. _queue.Empty. INFO: Cleaning up image... ```. Please let me know if I could provide the input BAM for testing/debugging. Thank you for your time. Best regards,. Louis.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/833:4919,usability,input,input,4919,"l first):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 500 in _import_graph_de. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 414 in import_graph_def. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/function_def_to_graph.py"", line 87 in func. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/function_deserialization.py"", line 416 i. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 154 in __init__. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 958 in load_partial. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/saved_model/load.py"", line 828 in load. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 596 in call_. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 768 in main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 258 in _run_main. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/absl_py/absl/app.py"", line 312 in run. File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 789 in <modu. real 0m5.038s. user 0m3.921s. sys 0m1.122s. Process ForkProcess-1:. Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/process.py"", line 315, in _bootstrap. self.run(). File ""/usr/lib/python3.8/multiprocessing/process.py"", line 108, in run. self._target(*self._args, **self._kwargs). File ""/tmp/Bazel.runfiles_vitt1d55/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 454, in post. File ""/usr/lib/python3.8/multiprocessing/queues.py"", line 108, in get. raise Empty. _queue.Empty. INFO: Cleaning up image... ```. Please let me know if I could provide the input BAM for testing/debugging. Thank you for your time. Best regards,. Louis.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/833
https://github.com/google/deepvariant/issues/834:89,availability,avail,available,89,"run DeepVariant on ARM64; I need to run DeepVariant on ARM64 architecture. . Is there an available Docker image for this, or what steps should I take to achieve it? Thank you ~",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/834
https://github.com/google/deepvariant/issues/834:61,interoperability,architectur,architecture,61,"run DeepVariant on ARM64; I need to run DeepVariant on ARM64 architecture. . Is there an available Docker image for this, or what steps should I take to achieve it? Thank you ~",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/834
https://github.com/google/deepvariant/issues/834:89,reliability,availab,available,89,"run DeepVariant on ARM64; I need to run DeepVariant on ARM64 architecture. . Is there an available Docker image for this, or what steps should I take to achieve it? Thank you ~",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/834
https://github.com/google/deepvariant/issues/834:89,safety,avail,available,89,"run DeepVariant on ARM64; I need to run DeepVariant on ARM64 architecture. . Is there an available Docker image for this, or what steps should I take to achieve it? Thank you ~",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/834
https://github.com/google/deepvariant/issues/834:89,security,availab,available,89,"run DeepVariant on ARM64; I need to run DeepVariant on ARM64 architecture. . Is there an available Docker image for this, or what steps should I take to achieve it? Thank you ~",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/834
https://github.com/google/deepvariant/issues/835:137,availability,Error,Error,137,"Cannot install latest DeepVariant via Conda; **Describe the issue:**. Cannot install latest DeepVariant via Conda in my new environment. Error prompts, similar to that of #736. If having everything in default, I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:305,availability,Operat,Operating,305,"Cannot install latest DeepVariant via Conda; **Describe the issue:**. Cannot install latest DeepVariant via Conda in my new environment. Error prompts, similar to that of #736. If having everything in default, I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:380,availability,unavail,unavailable,380,"Cannot install latest DeepVariant via Conda; **Describe the issue:**. Cannot install latest DeepVariant via Conda in my new environment. Error prompts, similar to that of #736. If having everything in default, I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:681,availability,Error,Error,681,"Cannot install latest DeepVariant via Conda; **Describe the issue:**. Cannot install latest DeepVariant via Conda in my new environment. Error prompts, similar to that of #736. If having everything in default, I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:7,deployability,instal,install,7,"Cannot install latest DeepVariant via Conda; **Describe the issue:**. Cannot install latest DeepVariant via Conda in my new environment. Error prompts, similar to that of #736. If having everything in default, I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:77,deployability,instal,install,77,"Cannot install latest DeepVariant via Conda; **Describe the issue:**. Cannot install latest DeepVariant via Conda in my new environment. Error prompts, similar to that of #736. If having everything in default, I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:266,deployability,updat,update,266,"Cannot install latest DeepVariant via Conda; **Describe the issue:**. Cannot install latest DeepVariant via Conda in my new environment. Error prompts, similar to that of #736. If having everything in default, I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:336,deployability,releas,release,336,"Cannot install latest DeepVariant via Conda; **Describe the issue:**. Cannot install latest DeepVariant via Conda in my new environment. Error prompts, similar to that of #736. If having everything in default, I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:408,deployability,version,version,408,"Cannot install latest DeepVariant via Conda; **Describe the issue:**. Cannot install latest DeepVariant via Conda in my new environment. Error prompts, similar to that of #736. If having everything in default, I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:423,deployability,instal,installable,423,"Cannot install latest DeepVariant via Conda; **Describe the issue:**. Cannot install latest DeepVariant via Conda in my new environment. Error prompts, similar to that of #736. If having everything in default, I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:469,deployability,Instal,Installation,469,"Cannot install latest DeepVariant via Conda; **Describe the issue:**. Cannot install latest DeepVariant via Conda in my new environment. Error prompts, similar to that of #736. If having everything in default, I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:633,deployability,version,version,633,"Cannot install latest DeepVariant via Conda; **Describe the issue:**. Cannot install latest DeepVariant via Conda in my new environment. Error prompts, similar to that of #736. If having everything in default, I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:658,deployability,instal,install,658,"Cannot install latest DeepVariant via Conda; **Describe the issue:**. Cannot install latest DeepVariant via Conda in my new environment. Error prompts, similar to that of #736. If having everything in default, I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:840,deployability,depend,dependency,840,"Cannot install latest DeepVariant via Conda; **Describe the issue:**. Cannot install latest DeepVariant via Conda in my new environment. Error prompts, similar to that of #736. If having everything in default, I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:987,deployability,fail,failed,987,"Cannot install latest DeepVariant via Conda; **Describe the issue:**. Cannot install latest DeepVariant via Conda in my new environment. Error prompts, similar to that of #736. If having everything in default, I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:1163,deployability,instal,installed,1163,"of #736. If having everything in default, I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conflicts with any installable versions previously reported;. > └─ pin-1 is not installable because it requires. > └─ python 3.8.* , which conflicts with any installable ve",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:1282,deployability,instal,installable,1282,", I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conflicts with any installable versions previously reported;. > └─ pin-1 is not installable because it requires. > └─ python 3.8.* , which conflicts with any installable versions previously reported. Thanks guys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:1437,deployability,instal,installable,1437,", I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conflicts with any installable versions previously reported;. > └─ pin-1 is not installable because it requires. > └─ python 3.8.* , which conflicts with any installable versions previously reported. Thanks guys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:1449,deployability,version,versions,1449,", I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conflicts with any installable versions previously reported;. > └─ pin-1 is not installable because it requires. > └─ python 3.8.* , which conflicts with any installable versions previously reported. Thanks guys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:1582,deployability,instal,installable,1582,", I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conflicts with any installable versions previously reported;. > └─ pin-1 is not installable because it requires. > └─ python 3.8.* , which conflicts with any installable versions previously reported. Thanks guys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:1594,deployability,version,versions,1594,", I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conflicts with any installable versions previously reported;. > └─ pin-1 is not installable because it requires. > └─ python 3.8.* , which conflicts with any installable versions previously reported. Thanks guys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:1739,deployability,instal,installed,1739,", I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conflicts with any installable versions previously reported;. > └─ pin-1 is not installable because it requires. > └─ python 3.8.* , which conflicts with any installable versions previously reported. Thanks guys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:1853,deployability,instal,installable,1853,", I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conflicts with any installable versions previously reported;. > └─ pin-1 is not installable because it requires. > └─ python 3.8.* , which conflicts with any installable versions previously reported. Thanks guys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:1865,deployability,version,versions,1865,", I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conflicts with any installable versions previously reported;. > └─ pin-1 is not installable because it requires. > └─ python 3.8.* , which conflicts with any installable versions previously reported. Thanks guys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:2015,deployability,instal,installable,2015,", I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conflicts with any installable versions previously reported;. > └─ pin-1 is not installable because it requires. > └─ python 3.8.* , which conflicts with any installable versions previously reported. Thanks guys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:2027,deployability,version,versions,2027,", I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conflicts with any installable versions previously reported;. > └─ pin-1 is not installable because it requires. > └─ python 3.8.* , which conflicts with any installable versions previously reported. Thanks guys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:2076,deployability,instal,installable,2076,", I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conflicts with any installable versions previously reported;. > └─ pin-1 is not installable because it requires. > └─ python 3.8.* , which conflicts with any installable versions previously reported. Thanks guys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:2154,deployability,instal,installable,2154,", I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conflicts with any installable versions previously reported;. > └─ pin-1 is not installable because it requires. > └─ python 3.8.* , which conflicts with any installable versions previously reported. Thanks guys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:2166,deployability,version,versions,2166,", I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conflicts with any installable versions previously reported;. > └─ pin-1 is not installable because it requires. > └─ python 3.8.* , which conflicts with any installable versions previously reported. Thanks guys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:625,energy efficiency,current,current,625,"Cannot install latest DeepVariant via Conda; **Describe the issue:**. Cannot install latest DeepVariant via Conda in my new environment. Error prompts, similar to that of #736. If having everything in default, I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:1972,energy efficiency,estimat,estimator,1972,", I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conflicts with any installable versions previously reported;. > └─ pin-1 is not installable because it requires. > └─ python 3.8.* , which conflicts with any installable versions previously reported. Thanks guys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:408,integrability,version,version,408,"Cannot install latest DeepVariant via Conda; **Describe the issue:**. Cannot install latest DeepVariant via Conda in my new environment. Error prompts, similar to that of #736. If having everything in default, I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:633,integrability,version,version,633,"Cannot install latest DeepVariant via Conda; **Describe the issue:**. Cannot install latest DeepVariant via Conda in my new environment. Error prompts, similar to that of #736. If having everything in default, I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:840,integrability,depend,dependency,840,"Cannot install latest DeepVariant via Conda; **Describe the issue:**. Cannot install latest DeepVariant via Conda in my new environment. Error prompts, similar to that of #736. If having everything in default, I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:1449,integrability,version,versions,1449,", I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conflicts with any installable versions previously reported;. > └─ pin-1 is not installable because it requires. > └─ python 3.8.* , which conflicts with any installable versions previously reported. Thanks guys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:1594,integrability,version,versions,1594,", I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conflicts with any installable versions previously reported;. > └─ pin-1 is not installable because it requires. > └─ python 3.8.* , which conflicts with any installable versions previously reported. Thanks guys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:1865,integrability,version,versions,1865,", I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conflicts with any installable versions previously reported;. > └─ pin-1 is not installable because it requires. > └─ python 3.8.* , which conflicts with any installable versions previously reported. Thanks guys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:2027,integrability,version,versions,2027,", I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conflicts with any installable versions previously reported;. > └─ pin-1 is not installable because it requires. > └─ python 3.8.* , which conflicts with any installable versions previously reported. Thanks guys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:2166,integrability,version,versions,2166,", I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conflicts with any installable versions previously reported;. > └─ pin-1 is not installable because it requires. > └─ python 3.8.* , which conflicts with any installable versions previously reported. Thanks guys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:1248,interoperability,incompatib,incompatible,1248,", I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conflicts with any installable versions previously reported;. > └─ pin-1 is not installable because it requires. > └─ python 3.8.* , which conflicts with any installable versions previously reported. Thanks guys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:1418,interoperability,conflict,conflicts,1418,", I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conflicts with any installable versions previously reported;. > └─ pin-1 is not installable because it requires. > └─ python 3.8.* , which conflicts with any installable versions previously reported. Thanks guys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:1563,interoperability,conflict,conflicts,1563,", I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conflicts with any installable versions previously reported;. > └─ pin-1 is not installable because it requires. > └─ python 3.8.* , which conflicts with any installable versions previously reported. Thanks guys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:1834,interoperability,conflict,conflicts,1834,", I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conflicts with any installable versions previously reported;. > └─ pin-1 is not installable because it requires. > └─ python 3.8.* , which conflicts with any installable versions previously reported. Thanks guys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:1996,interoperability,conflict,conflicts,1996,", I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conflicts with any installable versions previously reported;. > └─ pin-1 is not installable because it requires. > └─ python 3.8.* , which conflicts with any installable versions previously reported. Thanks guys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:2135,interoperability,conflict,conflicts,2135,", I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conflicts with any installable versions previously reported;. > └─ pin-1 is not installable because it requires. > └─ python 3.8.* , which conflicts with any installable versions previously reported. Thanks guys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:408,modifiability,version,version,408,"Cannot install latest DeepVariant via Conda; **Describe the issue:**. Cannot install latest DeepVariant via Conda in my new environment. Error prompts, similar to that of #736. If having everything in default, I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:633,modifiability,version,version,633,"Cannot install latest DeepVariant via Conda; **Describe the issue:**. Cannot install latest DeepVariant via Conda in my new environment. Error prompts, similar to that of #736. If having everything in default, I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:840,modifiability,depend,dependency,840,"Cannot install latest DeepVariant via Conda; **Describe the issue:**. Cannot install latest DeepVariant via Conda in my new environment. Error prompts, similar to that of #736. If having everything in default, I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:1070,modifiability,pac,package,1070,"ot install latest DeepVariant via Conda in my new environment. Error prompts, similar to that of #736. If having everything in default, I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conflicts with any installable versions previously reported;. > └─ pin-1 is no",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:1235,modifiability,pac,packages,1235,", I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conflicts with any installable versions previously reported;. > └─ pin-1 is not installable because it requires. > └─ python 3.8.* , which conflicts with any installable versions previously reported. Thanks guys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:1449,modifiability,version,versions,1449,", I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conflicts with any installable versions previously reported;. > └─ pin-1 is not installable because it requires. > └─ python 3.8.* , which conflicts with any installable versions previously reported. Thanks guys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:1594,modifiability,version,versions,1594,", I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conflicts with any installable versions previously reported;. > └─ pin-1 is not installable because it requires. > └─ python 3.8.* , which conflicts with any installable versions previously reported. Thanks guys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:1865,modifiability,version,versions,1865,", I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conflicts with any installable versions previously reported;. > └─ pin-1 is not installable because it requires. > └─ python 3.8.* , which conflicts with any installable versions previously reported. Thanks guys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:2027,modifiability,version,versions,2027,", I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conflicts with any installable versions previously reported;. > └─ pin-1 is not installable because it requires. > └─ python 3.8.* , which conflicts with any installable versions previously reported. Thanks guys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:2166,modifiability,version,versions,2166,", I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conflicts with any installable versions previously reported;. > └─ pin-1 is not installable because it requires. > └─ python 3.8.* , which conflicts with any installable versions previously reported. Thanks guys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:137,performance,Error,Error,137,"Cannot install latest DeepVariant via Conda; **Describe the issue:**. Cannot install latest DeepVariant via Conda in my new environment. Error prompts, similar to that of #736. If having everything in default, I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:681,performance,Error,Error,681,"Cannot install latest DeepVariant via Conda; **Describe the issue:**. Cannot install latest DeepVariant via Conda in my new environment. Error prompts, similar to that of #736. If having everything in default, I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:987,reliability,fail,failed,987,"Cannot install latest DeepVariant via Conda; **Describe the issue:**. Cannot install latest DeepVariant via Conda in my new environment. Error prompts, similar to that of #736. If having everything in default, I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:137,safety,Error,Error,137,"Cannot install latest DeepVariant via Conda; **Describe the issue:**. Cannot install latest DeepVariant via Conda in my new environment. Error prompts, similar to that of #736. If having everything in default, I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:266,safety,updat,update,266,"Cannot install latest DeepVariant via Conda; **Describe the issue:**. Cannot install latest DeepVariant via Conda in my new environment. Error prompts, similar to that of #736. If having everything in default, I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:681,safety,Error,Error,681,"Cannot install latest DeepVariant via Conda; **Describe the issue:**. Cannot install latest DeepVariant via Conda in my new environment. Error prompts, similar to that of #736. If having everything in default, I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:840,safety,depend,dependency,840,"Cannot install latest DeepVariant via Conda; **Describe the issue:**. Cannot install latest DeepVariant via Conda in my new environment. Error prompts, similar to that of #736. If having everything in default, I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:266,security,updat,update,266,"Cannot install latest DeepVariant via Conda; **Describe the issue:**. Cannot install latest DeepVariant via Conda in my new environment. Error prompts, similar to that of #736. If having everything in default, I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:354,security,ssh,ssh,354,"Cannot install latest DeepVariant via Conda; **Describe the issue:**. Cannot install latest DeepVariant via Conda in my new environment. Error prompts, similar to that of #736. If having everything in default, I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:687,testability,trace,trace,687,"Cannot install latest DeepVariant via Conda; **Describe the issue:**. Cannot install latest DeepVariant via Conda in my new environment. Error prompts, similar to that of #736. If having everything in default, I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:840,testability,depend,dependency,840,"Cannot install latest DeepVariant via Conda; **Describe the issue:**. Cannot install latest DeepVariant via Conda in my new environment. Error prompts, similar to that of #736. If having everything in default, I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:137,usability,Error,Error,137,"Cannot install latest DeepVariant via Conda; **Describe the issue:**. Cannot install latest DeepVariant via Conda in my new environment. Error prompts, similar to that of #736. If having everything in default, I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:579,usability,Command,Command,579,"Cannot install latest DeepVariant via Conda; **Describe the issue:**. Cannot install latest DeepVariant via Conda in my new environment. Error prompts, similar to that of #736. If having everything in default, I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/835:681,usability,Error,Error,681,"Cannot install latest DeepVariant via Conda; **Describe the issue:**. Cannot install latest DeepVariant via Conda in my new environment. Error prompts, similar to that of #736. If having everything in default, I can have python=2.7 and deepvariant=0.7.0; but cannot update to 1.15 or latest. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (ssh to university, docker unavailable). - DeepVariant version: 0.7.0 installable, but cannot get 1.15 or latest. - Installation method (Docker, built from source, etc.): conda. - Type of data: N/A. **Steps to reproduce:**. - Command:. $ create -n deepvariant python=3.8 (current version 3.8.19). $ conda install deepvariant. - Error trace: (if applicable). > #warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > warning libmamba Added empty dependency for problem type SOLVER_RULE_UPDATE. > warning libmamba Problem type not implemented SOLVER_RULE_STRICT_REPO_PRIORITY _- many times_. > failed. > . > LibMambaUnsatisfiableError: Encountered problems while solving:. > - package deepvariant-0.4.1-np113py27_0 requires python 2.7*, but none of the providers can be installed. > . > Could not solve for environment specs. > The following packages are incompatible. > ├─ deepvariant is installable with the potential options. > │ ├─ deepvariant [0.10.0|0.7.2|0.8.0|0.9.0] would require. > │ │ └─ tensorflow 1.12.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.10.0|1.0.0] would require. > │ │ └─ tensorflow 2.0.* , which conflicts with any installable versions previously reported;. > │ ├─ deepvariant [0.4.1|0.6.0|0.6.1|0.7.0] would require. > │ │ └─ python [2.7* |>=2.7,<2.8.0a0 ], which can be installed;. > │ ├─ deepvariant [0.7.1|0.7.2] would require. > │ │ └─ tensorflow 1.11.* , which conflicts with any installable versions previously reported;. > │ └─ deepvariant [1.0.0|1.1.0|...|1.5.0] would require. > │ └─ tensorflow-estimator 2.0.* , which conf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/835
https://github.com/google/deepvariant/issues/836:68,energy efficiency,current,currently,68,"Indel calling for long read sequencing; Describe the issue:. We are currently using two different long-read sequencing systems: PacBio Direct and PacBio Capture. . We are encountering two specific issues:. 1. **PacBio Direct Data (top track)**: Despite having reads shown in both the IGV and VCF files, the genotype (GT) is marked as ""./.,"" and the genotype quality (GQ) is very low. This indel locus has higher coverage (141x) than the average coverage across the genome (128x). 2.**For the PacBio Capture data (bottom track)** has an average genome coverage of 2897x. Even after setting the mapping quality to >30, the read count at this indel locus is still 3000x, which is significantly higher than the read count indicated in the VCF file. Why is there such a discrepancy between the read counts in IGV and VCF? . I have used the default parameters (--model_type PACBIO) for both dataset. Thank you. ![Long read_DeepVariant](https://github.com/google/deepvariant/assets/125016914/cdbf09eb-feff-4cd4-b2c7-b1118798e2a3).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/836
https://github.com/google/deepvariant/issues/836:188,interoperability,specif,specific,188,"Indel calling for long read sequencing; Describe the issue:. We are currently using two different long-read sequencing systems: PacBio Direct and PacBio Capture. . We are encountering two specific issues:. 1. **PacBio Direct Data (top track)**: Despite having reads shown in both the IGV and VCF files, the genotype (GT) is marked as ""./.,"" and the genotype quality (GQ) is very low. This indel locus has higher coverage (141x) than the average coverage across the genome (128x). 2.**For the PacBio Capture data (bottom track)** has an average genome coverage of 2897x. Even after setting the mapping quality to >30, the read count at this indel locus is still 3000x, which is significantly higher than the read count indicated in the VCF file. Why is there such a discrepancy between the read counts in IGV and VCF? . I have used the default parameters (--model_type PACBIO) for both dataset. Thank you. ![Long read_DeepVariant](https://github.com/google/deepvariant/assets/125016914/cdbf09eb-feff-4cd4-b2c7-b1118798e2a3).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/836
https://github.com/google/deepvariant/issues/836:128,modifiability,Pac,PacBio,128,"Indel calling for long read sequencing; Describe the issue:. We are currently using two different long-read sequencing systems: PacBio Direct and PacBio Capture. . We are encountering two specific issues:. 1. **PacBio Direct Data (top track)**: Despite having reads shown in both the IGV and VCF files, the genotype (GT) is marked as ""./.,"" and the genotype quality (GQ) is very low. This indel locus has higher coverage (141x) than the average coverage across the genome (128x). 2.**For the PacBio Capture data (bottom track)** has an average genome coverage of 2897x. Even after setting the mapping quality to >30, the read count at this indel locus is still 3000x, which is significantly higher than the read count indicated in the VCF file. Why is there such a discrepancy between the read counts in IGV and VCF? . I have used the default parameters (--model_type PACBIO) for both dataset. Thank you. ![Long read_DeepVariant](https://github.com/google/deepvariant/assets/125016914/cdbf09eb-feff-4cd4-b2c7-b1118798e2a3).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/836
https://github.com/google/deepvariant/issues/836:146,modifiability,Pac,PacBio,146,"Indel calling for long read sequencing; Describe the issue:. We are currently using two different long-read sequencing systems: PacBio Direct and PacBio Capture. . We are encountering two specific issues:. 1. **PacBio Direct Data (top track)**: Despite having reads shown in both the IGV and VCF files, the genotype (GT) is marked as ""./.,"" and the genotype quality (GQ) is very low. This indel locus has higher coverage (141x) than the average coverage across the genome (128x). 2.**For the PacBio Capture data (bottom track)** has an average genome coverage of 2897x. Even after setting the mapping quality to >30, the read count at this indel locus is still 3000x, which is significantly higher than the read count indicated in the VCF file. Why is there such a discrepancy between the read counts in IGV and VCF? . I have used the default parameters (--model_type PACBIO) for both dataset. Thank you. ![Long read_DeepVariant](https://github.com/google/deepvariant/assets/125016914/cdbf09eb-feff-4cd4-b2c7-b1118798e2a3).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/836
https://github.com/google/deepvariant/issues/836:211,modifiability,Pac,PacBio,211,"Indel calling for long read sequencing; Describe the issue:. We are currently using two different long-read sequencing systems: PacBio Direct and PacBio Capture. . We are encountering two specific issues:. 1. **PacBio Direct Data (top track)**: Despite having reads shown in both the IGV and VCF files, the genotype (GT) is marked as ""./.,"" and the genotype quality (GQ) is very low. This indel locus has higher coverage (141x) than the average coverage across the genome (128x). 2.**For the PacBio Capture data (bottom track)** has an average genome coverage of 2897x. Even after setting the mapping quality to >30, the read count at this indel locus is still 3000x, which is significantly higher than the read count indicated in the VCF file. Why is there such a discrepancy between the read counts in IGV and VCF? . I have used the default parameters (--model_type PACBIO) for both dataset. Thank you. ![Long read_DeepVariant](https://github.com/google/deepvariant/assets/125016914/cdbf09eb-feff-4cd4-b2c7-b1118798e2a3).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/836
https://github.com/google/deepvariant/issues/836:492,modifiability,Pac,PacBio,492,"Indel calling for long read sequencing; Describe the issue:. We are currently using two different long-read sequencing systems: PacBio Direct and PacBio Capture. . We are encountering two specific issues:. 1. **PacBio Direct Data (top track)**: Despite having reads shown in both the IGV and VCF files, the genotype (GT) is marked as ""./.,"" and the genotype quality (GQ) is very low. This indel locus has higher coverage (141x) than the average coverage across the genome (128x). 2.**For the PacBio Capture data (bottom track)** has an average genome coverage of 2897x. Even after setting the mapping quality to >30, the read count at this indel locus is still 3000x, which is significantly higher than the read count indicated in the VCF file. Why is there such a discrepancy between the read counts in IGV and VCF? . I have used the default parameters (--model_type PACBIO) for both dataset. Thank you. ![Long read_DeepVariant](https://github.com/google/deepvariant/assets/125016914/cdbf09eb-feff-4cd4-b2c7-b1118798e2a3).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/836
https://github.com/google/deepvariant/issues/836:843,modifiability,paramet,parameters,843,"Indel calling for long read sequencing; Describe the issue:. We are currently using two different long-read sequencing systems: PacBio Direct and PacBio Capture. . We are encountering two specific issues:. 1. **PacBio Direct Data (top track)**: Despite having reads shown in both the IGV and VCF files, the genotype (GT) is marked as ""./.,"" and the genotype quality (GQ) is very low. This indel locus has higher coverage (141x) than the average coverage across the genome (128x). 2.**For the PacBio Capture data (bottom track)** has an average genome coverage of 2897x. Even after setting the mapping quality to >30, the read count at this indel locus is still 3000x, which is significantly higher than the read count indicated in the VCF file. Why is there such a discrepancy between the read counts in IGV and VCF? . I have used the default parameters (--model_type PACBIO) for both dataset. Thank you. ![Long read_DeepVariant](https://github.com/google/deepvariant/assets/125016914/cdbf09eb-feff-4cd4-b2c7-b1118798e2a3).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/836
https://github.com/google/deepvariant/issues/836:868,modifiability,PAC,PACBIO,868,"Indel calling for long read sequencing; Describe the issue:. We are currently using two different long-read sequencing systems: PacBio Direct and PacBio Capture. . We are encountering two specific issues:. 1. **PacBio Direct Data (top track)**: Despite having reads shown in both the IGV and VCF files, the genotype (GT) is marked as ""./.,"" and the genotype quality (GQ) is very low. This indel locus has higher coverage (141x) than the average coverage across the genome (128x). 2.**For the PacBio Capture data (bottom track)** has an average genome coverage of 2897x. Even after setting the mapping quality to >30, the read count at this indel locus is still 3000x, which is significantly higher than the read count indicated in the VCF file. Why is there such a discrepancy between the read counts in IGV and VCF? . I have used the default parameters (--model_type PACBIO) for both dataset. Thank you. ![Long read_DeepVariant](https://github.com/google/deepvariant/assets/125016914/cdbf09eb-feff-4cd4-b2c7-b1118798e2a3).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/836
https://github.com/google/deepvariant/issues/836:677,security,sign,significantly,677,"Indel calling for long read sequencing; Describe the issue:. We are currently using two different long-read sequencing systems: PacBio Direct and PacBio Capture. . We are encountering two specific issues:. 1. **PacBio Direct Data (top track)**: Despite having reads shown in both the IGV and VCF files, the genotype (GT) is marked as ""./.,"" and the genotype quality (GQ) is very low. This indel locus has higher coverage (141x) than the average coverage across the genome (128x). 2.**For the PacBio Capture data (bottom track)** has an average genome coverage of 2897x. Even after setting the mapping quality to >30, the read count at this indel locus is still 3000x, which is significantly higher than the read count indicated in the VCF file. Why is there such a discrepancy between the read counts in IGV and VCF? . I have used the default parameters (--model_type PACBIO) for both dataset. Thank you. ![Long read_DeepVariant](https://github.com/google/deepvariant/assets/125016914/cdbf09eb-feff-4cd4-b2c7-b1118798e2a3).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/836
https://github.com/google/deepvariant/issues/836:412,testability,coverag,coverage,412,"Indel calling for long read sequencing; Describe the issue:. We are currently using two different long-read sequencing systems: PacBio Direct and PacBio Capture. . We are encountering two specific issues:. 1. **PacBio Direct Data (top track)**: Despite having reads shown in both the IGV and VCF files, the genotype (GT) is marked as ""./.,"" and the genotype quality (GQ) is very low. This indel locus has higher coverage (141x) than the average coverage across the genome (128x). 2.**For the PacBio Capture data (bottom track)** has an average genome coverage of 2897x. Even after setting the mapping quality to >30, the read count at this indel locus is still 3000x, which is significantly higher than the read count indicated in the VCF file. Why is there such a discrepancy between the read counts in IGV and VCF? . I have used the default parameters (--model_type PACBIO) for both dataset. Thank you. ![Long read_DeepVariant](https://github.com/google/deepvariant/assets/125016914/cdbf09eb-feff-4cd4-b2c7-b1118798e2a3).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/836
https://github.com/google/deepvariant/issues/836:445,testability,coverag,coverage,445,"Indel calling for long read sequencing; Describe the issue:. We are currently using two different long-read sequencing systems: PacBio Direct and PacBio Capture. . We are encountering two specific issues:. 1. **PacBio Direct Data (top track)**: Despite having reads shown in both the IGV and VCF files, the genotype (GT) is marked as ""./.,"" and the genotype quality (GQ) is very low. This indel locus has higher coverage (141x) than the average coverage across the genome (128x). 2.**For the PacBio Capture data (bottom track)** has an average genome coverage of 2897x. Even after setting the mapping quality to >30, the read count at this indel locus is still 3000x, which is significantly higher than the read count indicated in the VCF file. Why is there such a discrepancy between the read counts in IGV and VCF? . I have used the default parameters (--model_type PACBIO) for both dataset. Thank you. ![Long read_DeepVariant](https://github.com/google/deepvariant/assets/125016914/cdbf09eb-feff-4cd4-b2c7-b1118798e2a3).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/836
https://github.com/google/deepvariant/issues/836:551,testability,coverag,coverage,551,"Indel calling for long read sequencing; Describe the issue:. We are currently using two different long-read sequencing systems: PacBio Direct and PacBio Capture. . We are encountering two specific issues:. 1. **PacBio Direct Data (top track)**: Despite having reads shown in both the IGV and VCF files, the genotype (GT) is marked as ""./.,"" and the genotype quality (GQ) is very low. This indel locus has higher coverage (141x) than the average coverage across the genome (128x). 2.**For the PacBio Capture data (bottom track)** has an average genome coverage of 2897x. Even after setting the mapping quality to >30, the read count at this indel locus is still 3000x, which is significantly higher than the read count indicated in the VCF file. Why is there such a discrepancy between the read counts in IGV and VCF? . I have used the default parameters (--model_type PACBIO) for both dataset. Thank you. ![Long read_DeepVariant](https://github.com/google/deepvariant/assets/125016914/cdbf09eb-feff-4cd4-b2c7-b1118798e2a3).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/836
https://github.com/google/deepvariant/issues/836:718,usability,indicat,indicated,718,"Indel calling for long read sequencing; Describe the issue:. We are currently using two different long-read sequencing systems: PacBio Direct and PacBio Capture. . We are encountering two specific issues:. 1. **PacBio Direct Data (top track)**: Despite having reads shown in both the IGV and VCF files, the genotype (GT) is marked as ""./.,"" and the genotype quality (GQ) is very low. This indel locus has higher coverage (141x) than the average coverage across the genome (128x). 2.**For the PacBio Capture data (bottom track)** has an average genome coverage of 2897x. Even after setting the mapping quality to >30, the read count at this indel locus is still 3000x, which is significantly higher than the read count indicated in the VCF file. Why is there such a discrepancy between the read counts in IGV and VCF? . I have used the default parameters (--model_type PACBIO) for both dataset. Thank you. ![Long read_DeepVariant](https://github.com/google/deepvariant/assets/125016914/cdbf09eb-feff-4cd4-b2c7-b1118798e2a3).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/836
https://github.com/google/deepvariant/issues/837:137,availability,error,error,137,"training on google engine; I'm attempting to train DeepVariant on a Google VM. However, when I run the training command, I encounter the error below. All the paths are correct (of course I have edited the pbtxt file to match the path were shuffled example are stored), and everything works when I run the command on my local machine with my GPU or on our cluster with CPUs. The only difference is that the shuffled examples are stored on a mounted bucket with gcsfuse when I run the command on the Google VM. The bucket is mounted using the following command: `sudo gcsfuse -o allow_other`. I have also tried to use singularity, but I got the same error. I've tried to find a solution through various online resources, but nothing has helped so far. `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 121, in train. tune_dataset_config = data_providers.read_dataset_config(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/data_providers.py"", line 634, in read_dataset_config. dataset_config = text_format.Parse(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 648, in Parse. return ParseLines(text.split(b'\n' if isinstance(text, bytes) else u'\n'),. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 722, in ParseLines. return parser.ParseLines(lines, message). File ""/tmp/Bazel.runfiles_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/837
https://github.com/google/deepvariant/issues/837:355,availability,cluster,cluster,355,"training on google engine; I'm attempting to train DeepVariant on a Google VM. However, when I run the training command, I encounter the error below. All the paths are correct (of course I have edited the pbtxt file to match the path were shuffled example are stored), and everything works when I run the command on my local machine with my GPU or on our cluster with CPUs. The only difference is that the shuffled examples are stored on a mounted bucket with gcsfuse when I run the command on the Google VM. The bucket is mounted using the following command: `sudo gcsfuse -o allow_other`. I have also tried to use singularity, but I got the same error. I've tried to find a solution through various online resources, but nothing has helped so far. `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 121, in train. tune_dataset_config = data_providers.read_dataset_config(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/data_providers.py"", line 634, in read_dataset_config. dataset_config = text_format.Parse(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 648, in Parse. return ParseLines(text.split(b'\n' if isinstance(text, bytes) else u'\n'),. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 722, in ParseLines. return parser.ParseLines(lines, message). File ""/tmp/Bazel.runfiles_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/837
https://github.com/google/deepvariant/issues/837:648,availability,error,error,648,"training on google engine; I'm attempting to train DeepVariant on a Google VM. However, when I run the training command, I encounter the error below. All the paths are correct (of course I have edited the pbtxt file to match the path were shuffled example are stored), and everything works when I run the command on my local machine with my GPU or on our cluster with CPUs. The only difference is that the shuffled examples are stored on a mounted bucket with gcsfuse when I run the command on the Google VM. The bucket is mounted using the following command: `sudo gcsfuse -o allow_other`. I have also tried to use singularity, but I got the same error. I've tried to find a solution through various online resources, but nothing has helped so far. `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 121, in train. tune_dataset_config = data_providers.read_dataset_config(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/data_providers.py"", line 634, in read_dataset_config. dataset_config = text_format.Parse(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 648, in Parse. return ParseLines(text.split(b'\n' if isinstance(text, bytes) else u'\n'),. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 722, in ParseLines. return parser.ParseLines(lines, message). File ""/tmp/Bazel.runfiles_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/837
https://github.com/google/deepvariant/issues/837:355,deployability,cluster,cluster,355,"training on google engine; I'm attempting to train DeepVariant on a Google VM. However, when I run the training command, I encounter the error below. All the paths are correct (of course I have edited the pbtxt file to match the path were shuffled example are stored), and everything works when I run the command on my local machine with my GPU or on our cluster with CPUs. The only difference is that the shuffled examples are stored on a mounted bucket with gcsfuse when I run the command on the Google VM. The bucket is mounted using the following command: `sudo gcsfuse -o allow_other`. I have also tried to use singularity, but I got the same error. I've tried to find a solution through various online resources, but nothing has helped so far. `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 121, in train. tune_dataset_config = data_providers.read_dataset_config(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/data_providers.py"", line 634, in read_dataset_config. dataset_config = text_format.Parse(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 648, in Parse. return ParseLines(text.split(b'\n' if isinstance(text, bytes) else u'\n'),. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 722, in ParseLines. return parser.ParseLines(lines, message). File ""/tmp/Bazel.runfiles_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/837
https://github.com/google/deepvariant/issues/837:708,deployability,resourc,resources,708,"training on google engine; I'm attempting to train DeepVariant on a Google VM. However, when I run the training command, I encounter the error below. All the paths are correct (of course I have edited the pbtxt file to match the path were shuffled example are stored), and everything works when I run the command on my local machine with my GPU or on our cluster with CPUs. The only difference is that the shuffled examples are stored on a mounted bucket with gcsfuse when I run the command on the Google VM. The bucket is mounted using the following command: `sudo gcsfuse -o allow_other`. I have also tried to use singularity, but I got the same error. I've tried to find a solution through various online resources, but nothing has helped so far. `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 121, in train. tune_dataset_config = data_providers.read_dataset_config(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/data_providers.py"", line 634, in read_dataset_config. dataset_config = text_format.Parse(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 648, in Parse. return ParseLines(text.split(b'\n' if isinstance(text, bytes) else u'\n'),. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 722, in ParseLines. return parser.ParseLines(lines, message). File ""/tmp/Bazel.runfiles_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/837
https://github.com/google/deepvariant/issues/837:891,deployability,modul,module,891,"training on google engine; I'm attempting to train DeepVariant on a Google VM. However, when I run the training command, I encounter the error below. All the paths are correct (of course I have edited the pbtxt file to match the path were shuffled example are stored), and everything works when I run the command on my local machine with my GPU or on our cluster with CPUs. The only difference is that the shuffled examples are stored on a mounted bucket with gcsfuse when I run the command on the Google VM. The bucket is mounted using the following command: `sudo gcsfuse -o allow_other`. I have also tried to use singularity, but I got the same error. I've tried to find a solution through various online resources, but nothing has helped so far. `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 121, in train. tune_dataset_config = data_providers.read_dataset_config(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/data_providers.py"", line 634, in read_dataset_config. dataset_config = text_format.Parse(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 648, in Parse. return ParseLines(text.split(b'\n' if isinstance(text, bytes) else u'\n'),. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 722, in ParseLines. return parser.ParseLines(lines, message). File ""/tmp/Bazel.runfiles_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/837
https://github.com/google/deepvariant/issues/837:341,energy efficiency,GPU,GPU,341,"training on google engine; I'm attempting to train DeepVariant on a Google VM. However, when I run the training command, I encounter the error below. All the paths are correct (of course I have edited the pbtxt file to match the path were shuffled example are stored), and everything works when I run the command on my local machine with my GPU or on our cluster with CPUs. The only difference is that the shuffled examples are stored on a mounted bucket with gcsfuse when I run the command on the Google VM. The bucket is mounted using the following command: `sudo gcsfuse -o allow_other`. I have also tried to use singularity, but I got the same error. I've tried to find a solution through various online resources, but nothing has helped so far. `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 121, in train. tune_dataset_config = data_providers.read_dataset_config(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/data_providers.py"", line 634, in read_dataset_config. dataset_config = text_format.Parse(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 648, in Parse. return ParseLines(text.split(b'\n' if isinstance(text, bytes) else u'\n'),. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 722, in ParseLines. return parser.ParseLines(lines, message). File ""/tmp/Bazel.runfiles_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/837
https://github.com/google/deepvariant/issues/837:368,energy efficiency,CPU,CPUs,368,"training on google engine; I'm attempting to train DeepVariant on a Google VM. However, when I run the training command, I encounter the error below. All the paths are correct (of course I have edited the pbtxt file to match the path were shuffled example are stored), and everything works when I run the command on my local machine with my GPU or on our cluster with CPUs. The only difference is that the shuffled examples are stored on a mounted bucket with gcsfuse when I run the command on the Google VM. The bucket is mounted using the following command: `sudo gcsfuse -o allow_other`. I have also tried to use singularity, but I got the same error. I've tried to find a solution through various online resources, but nothing has helped so far. `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 121, in train. tune_dataset_config = data_providers.read_dataset_config(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/data_providers.py"", line 634, in read_dataset_config. dataset_config = text_format.Parse(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 648, in Parse. return ParseLines(text.split(b'\n' if isinstance(text, bytes) else u'\n'),. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 722, in ParseLines. return parser.ParseLines(lines, message). File ""/tmp/Bazel.runfiles_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/837
https://github.com/google/deepvariant/issues/837:708,energy efficiency,resourc,resources,708,"training on google engine; I'm attempting to train DeepVariant on a Google VM. However, when I run the training command, I encounter the error below. All the paths are correct (of course I have edited the pbtxt file to match the path were shuffled example are stored), and everything works when I run the command on my local machine with my GPU or on our cluster with CPUs. The only difference is that the shuffled examples are stored on a mounted bucket with gcsfuse when I run the command on the Google VM. The bucket is mounted using the following command: `sudo gcsfuse -o allow_other`. I have also tried to use singularity, but I got the same error. I've tried to find a solution through various online resources, but nothing has helped so far. `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 121, in train. tune_dataset_config = data_providers.read_dataset_config(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/data_providers.py"", line 634, in read_dataset_config. dataset_config = text_format.Parse(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 648, in Parse. return ParseLines(text.split(b'\n' if isinstance(text, bytes) else u'\n'),. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 722, in ParseLines. return parser.ParseLines(lines, message). File ""/tmp/Bazel.runfiles_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/837
https://github.com/google/deepvariant/issues/837:1964,integrability,messag,message,1964,"rity, but I got the same error. I've tried to find a solution through various online resources, but nothing has helped so far. `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 121, in train. tune_dataset_config = data_providers.read_dataset_config(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/data_providers.py"", line 634, in read_dataset_config. dataset_config = text_format.Parse(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 648, in Parse. return ParseLines(text.split(b'\n' if isinstance(text, bytes) else u'\n'),. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 722, in ParseLines. return parser.ParseLines(lines, message). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 776, in ParseLines. self._ParseOrMerge(lines, message). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 804, in _ParseOrMerge. self._MergeField(tokenizer, message). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 894, in _MergeField. raise tokenizer.ParseErrorPreviousToken(. google.protobuf.text_format.ParseError: 13:1 : Message type ""learning.genomics.deepvariant.DeepVariantDatasetConfig"" has no field named ""s2"".`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/837
https://github.com/google/deepvariant/issues/837:2129,integrability,messag,message,2129,"rity, but I got the same error. I've tried to find a solution through various online resources, but nothing has helped so far. `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 121, in train. tune_dataset_config = data_providers.read_dataset_config(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/data_providers.py"", line 634, in read_dataset_config. dataset_config = text_format.Parse(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 648, in Parse. return ParseLines(text.split(b'\n' if isinstance(text, bytes) else u'\n'),. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 722, in ParseLines. return parser.ParseLines(lines, message). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 776, in ParseLines. self._ParseOrMerge(lines, message). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 804, in _ParseOrMerge. self._MergeField(tokenizer, message). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 894, in _MergeField. raise tokenizer.ParseErrorPreviousToken(. google.protobuf.text_format.ParseError: 13:1 : Message type ""learning.genomics.deepvariant.DeepVariantDatasetConfig"" has no field named ""s2"".`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/837
https://github.com/google/deepvariant/issues/837:2299,integrability,messag,message,2299,"rity, but I got the same error. I've tried to find a solution through various online resources, but nothing has helped so far. `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 121, in train. tune_dataset_config = data_providers.read_dataset_config(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/data_providers.py"", line 634, in read_dataset_config. dataset_config = text_format.Parse(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 648, in Parse. return ParseLines(text.split(b'\n' if isinstance(text, bytes) else u'\n'),. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 722, in ParseLines. return parser.ParseLines(lines, message). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 776, in ParseLines. self._ParseOrMerge(lines, message). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 804, in _ParseOrMerge. self._MergeField(tokenizer, message). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 894, in _MergeField. raise tokenizer.ParseErrorPreviousToken(. google.protobuf.text_format.ParseError: 13:1 : Message type ""learning.genomics.deepvariant.DeepVariantDatasetConfig"" has no field named ""s2"".`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/837
https://github.com/google/deepvariant/issues/837:2528,integrability,Messag,Message,2528,"rity, but I got the same error. I've tried to find a solution through various online resources, but nothing has helped so far. `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 121, in train. tune_dataset_config = data_providers.read_dataset_config(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/data_providers.py"", line 634, in read_dataset_config. dataset_config = text_format.Parse(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 648, in Parse. return ParseLines(text.split(b'\n' if isinstance(text, bytes) else u'\n'),. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 722, in ParseLines. return parser.ParseLines(lines, message). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 776, in ParseLines. self._ParseOrMerge(lines, message). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 804, in _ParseOrMerge. self._MergeField(tokenizer, message). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 894, in _MergeField. raise tokenizer.ParseErrorPreviousToken(. google.protobuf.text_format.ParseError: 13:1 : Message type ""learning.genomics.deepvariant.DeepVariantDatasetConfig"" has no field named ""s2"".`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/837
https://github.com/google/deepvariant/issues/837:1964,interoperability,messag,message,1964,"rity, but I got the same error. I've tried to find a solution through various online resources, but nothing has helped so far. `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 121, in train. tune_dataset_config = data_providers.read_dataset_config(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/data_providers.py"", line 634, in read_dataset_config. dataset_config = text_format.Parse(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 648, in Parse. return ParseLines(text.split(b'\n' if isinstance(text, bytes) else u'\n'),. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 722, in ParseLines. return parser.ParseLines(lines, message). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 776, in ParseLines. self._ParseOrMerge(lines, message). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 804, in _ParseOrMerge. self._MergeField(tokenizer, message). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 894, in _MergeField. raise tokenizer.ParseErrorPreviousToken(. google.protobuf.text_format.ParseError: 13:1 : Message type ""learning.genomics.deepvariant.DeepVariantDatasetConfig"" has no field named ""s2"".`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/837
https://github.com/google/deepvariant/issues/837:2129,interoperability,messag,message,2129,"rity, but I got the same error. I've tried to find a solution through various online resources, but nothing has helped so far. `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 121, in train. tune_dataset_config = data_providers.read_dataset_config(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/data_providers.py"", line 634, in read_dataset_config. dataset_config = text_format.Parse(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 648, in Parse. return ParseLines(text.split(b'\n' if isinstance(text, bytes) else u'\n'),. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 722, in ParseLines. return parser.ParseLines(lines, message). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 776, in ParseLines. self._ParseOrMerge(lines, message). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 804, in _ParseOrMerge. self._MergeField(tokenizer, message). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 894, in _MergeField. raise tokenizer.ParseErrorPreviousToken(. google.protobuf.text_format.ParseError: 13:1 : Message type ""learning.genomics.deepvariant.DeepVariantDatasetConfig"" has no field named ""s2"".`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/837
https://github.com/google/deepvariant/issues/837:2299,interoperability,messag,message,2299,"rity, but I got the same error. I've tried to find a solution through various online resources, but nothing has helped so far. `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 121, in train. tune_dataset_config = data_providers.read_dataset_config(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/data_providers.py"", line 634, in read_dataset_config. dataset_config = text_format.Parse(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 648, in Parse. return ParseLines(text.split(b'\n' if isinstance(text, bytes) else u'\n'),. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 722, in ParseLines. return parser.ParseLines(lines, message). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 776, in ParseLines. self._ParseOrMerge(lines, message). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 804, in _ParseOrMerge. self._MergeField(tokenizer, message). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 894, in _MergeField. raise tokenizer.ParseErrorPreviousToken(. google.protobuf.text_format.ParseError: 13:1 : Message type ""learning.genomics.deepvariant.DeepVariantDatasetConfig"" has no field named ""s2"".`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/837
https://github.com/google/deepvariant/issues/837:2528,interoperability,Messag,Message,2528,"rity, but I got the same error. I've tried to find a solution through various online resources, but nothing has helped so far. `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 121, in train. tune_dataset_config = data_providers.read_dataset_config(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/data_providers.py"", line 634, in read_dataset_config. dataset_config = text_format.Parse(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 648, in Parse. return ParseLines(text.split(b'\n' if isinstance(text, bytes) else u'\n'),. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 722, in ParseLines. return parser.ParseLines(lines, message). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 776, in ParseLines. self._ParseOrMerge(lines, message). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 804, in _ParseOrMerge. self._MergeField(tokenizer, message). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 894, in _MergeField. raise tokenizer.ParseErrorPreviousToken(. google.protobuf.text_format.ParseError: 13:1 : Message type ""learning.genomics.deepvariant.DeepVariantDatasetConfig"" has no field named ""s2"".`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/837
https://github.com/google/deepvariant/issues/837:891,modifiability,modul,module,891,"training on google engine; I'm attempting to train DeepVariant on a Google VM. However, when I run the training command, I encounter the error below. All the paths are correct (of course I have edited the pbtxt file to match the path were shuffled example are stored), and everything works when I run the command on my local machine with my GPU or on our cluster with CPUs. The only difference is that the shuffled examples are stored on a mounted bucket with gcsfuse when I run the command on the Google VM. The bucket is mounted using the following command: `sudo gcsfuse -o allow_other`. I have also tried to use singularity, but I got the same error. I've tried to find a solution through various online resources, but nothing has helped so far. `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 121, in train. tune_dataset_config = data_providers.read_dataset_config(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/data_providers.py"", line 634, in read_dataset_config. dataset_config = text_format.Parse(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 648, in Parse. return ParseLines(text.split(b'\n' if isinstance(text, bytes) else u'\n'),. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 722, in ParseLines. return parser.ParseLines(lines, message). File ""/tmp/Bazel.runfiles_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/837
https://github.com/google/deepvariant/issues/837:137,performance,error,error,137,"training on google engine; I'm attempting to train DeepVariant on a Google VM. However, when I run the training command, I encounter the error below. All the paths are correct (of course I have edited the pbtxt file to match the path were shuffled example are stored), and everything works when I run the command on my local machine with my GPU or on our cluster with CPUs. The only difference is that the shuffled examples are stored on a mounted bucket with gcsfuse when I run the command on the Google VM. The bucket is mounted using the following command: `sudo gcsfuse -o allow_other`. I have also tried to use singularity, but I got the same error. I've tried to find a solution through various online resources, but nothing has helped so far. `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 121, in train. tune_dataset_config = data_providers.read_dataset_config(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/data_providers.py"", line 634, in read_dataset_config. dataset_config = text_format.Parse(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 648, in Parse. return ParseLines(text.split(b'\n' if isinstance(text, bytes) else u'\n'),. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 722, in ParseLines. return parser.ParseLines(lines, message). File ""/tmp/Bazel.runfiles_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/837
https://github.com/google/deepvariant/issues/837:341,performance,GPU,GPU,341,"training on google engine; I'm attempting to train DeepVariant on a Google VM. However, when I run the training command, I encounter the error below. All the paths are correct (of course I have edited the pbtxt file to match the path were shuffled example are stored), and everything works when I run the command on my local machine with my GPU or on our cluster with CPUs. The only difference is that the shuffled examples are stored on a mounted bucket with gcsfuse when I run the command on the Google VM. The bucket is mounted using the following command: `sudo gcsfuse -o allow_other`. I have also tried to use singularity, but I got the same error. I've tried to find a solution through various online resources, but nothing has helped so far. `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 121, in train. tune_dataset_config = data_providers.read_dataset_config(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/data_providers.py"", line 634, in read_dataset_config. dataset_config = text_format.Parse(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 648, in Parse. return ParseLines(text.split(b'\n' if isinstance(text, bytes) else u'\n'),. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 722, in ParseLines. return parser.ParseLines(lines, message). File ""/tmp/Bazel.runfiles_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/837
https://github.com/google/deepvariant/issues/837:368,performance,CPU,CPUs,368,"training on google engine; I'm attempting to train DeepVariant on a Google VM. However, when I run the training command, I encounter the error below. All the paths are correct (of course I have edited the pbtxt file to match the path were shuffled example are stored), and everything works when I run the command on my local machine with my GPU or on our cluster with CPUs. The only difference is that the shuffled examples are stored on a mounted bucket with gcsfuse when I run the command on the Google VM. The bucket is mounted using the following command: `sudo gcsfuse -o allow_other`. I have also tried to use singularity, but I got the same error. I've tried to find a solution through various online resources, but nothing has helped so far. `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 121, in train. tune_dataset_config = data_providers.read_dataset_config(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/data_providers.py"", line 634, in read_dataset_config. dataset_config = text_format.Parse(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 648, in Parse. return ParseLines(text.split(b'\n' if isinstance(text, bytes) else u'\n'),. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 722, in ParseLines. return parser.ParseLines(lines, message). File ""/tmp/Bazel.runfiles_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/837
https://github.com/google/deepvariant/issues/837:648,performance,error,error,648,"training on google engine; I'm attempting to train DeepVariant on a Google VM. However, when I run the training command, I encounter the error below. All the paths are correct (of course I have edited the pbtxt file to match the path were shuffled example are stored), and everything works when I run the command on my local machine with my GPU or on our cluster with CPUs. The only difference is that the shuffled examples are stored on a mounted bucket with gcsfuse when I run the command on the Google VM. The bucket is mounted using the following command: `sudo gcsfuse -o allow_other`. I have also tried to use singularity, but I got the same error. I've tried to find a solution through various online resources, but nothing has helped so far. `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 121, in train. tune_dataset_config = data_providers.read_dataset_config(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/data_providers.py"", line 634, in read_dataset_config. dataset_config = text_format.Parse(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 648, in Parse. return ParseLines(text.split(b'\n' if isinstance(text, bytes) else u'\n'),. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 722, in ParseLines. return parser.ParseLines(lines, message). File ""/tmp/Bazel.runfiles_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/837
https://github.com/google/deepvariant/issues/837:708,performance,resourc,resources,708,"training on google engine; I'm attempting to train DeepVariant on a Google VM. However, when I run the training command, I encounter the error below. All the paths are correct (of course I have edited the pbtxt file to match the path were shuffled example are stored), and everything works when I run the command on my local machine with my GPU or on our cluster with CPUs. The only difference is that the shuffled examples are stored on a mounted bucket with gcsfuse when I run the command on the Google VM. The bucket is mounted using the following command: `sudo gcsfuse -o allow_other`. I have also tried to use singularity, but I got the same error. I've tried to find a solution through various online resources, but nothing has helped so far. `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 121, in train. tune_dataset_config = data_providers.read_dataset_config(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/data_providers.py"", line 634, in read_dataset_config. dataset_config = text_format.Parse(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 648, in Parse. return ParseLines(text.split(b'\n' if isinstance(text, bytes) else u'\n'),. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 722, in ParseLines. return parser.ParseLines(lines, message). File ""/tmp/Bazel.runfiles_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/837
https://github.com/google/deepvariant/issues/837:137,safety,error,error,137,"training on google engine; I'm attempting to train DeepVariant on a Google VM. However, when I run the training command, I encounter the error below. All the paths are correct (of course I have edited the pbtxt file to match the path were shuffled example are stored), and everything works when I run the command on my local machine with my GPU or on our cluster with CPUs. The only difference is that the shuffled examples are stored on a mounted bucket with gcsfuse when I run the command on the Google VM. The bucket is mounted using the following command: `sudo gcsfuse -o allow_other`. I have also tried to use singularity, but I got the same error. I've tried to find a solution through various online resources, but nothing has helped so far. `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 121, in train. tune_dataset_config = data_providers.read_dataset_config(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/data_providers.py"", line 634, in read_dataset_config. dataset_config = text_format.Parse(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 648, in Parse. return ParseLines(text.split(b'\n' if isinstance(text, bytes) else u'\n'),. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 722, in ParseLines. return parser.ParseLines(lines, message). File ""/tmp/Bazel.runfiles_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/837
https://github.com/google/deepvariant/issues/837:648,safety,error,error,648,"training on google engine; I'm attempting to train DeepVariant on a Google VM. However, when I run the training command, I encounter the error below. All the paths are correct (of course I have edited the pbtxt file to match the path were shuffled example are stored), and everything works when I run the command on my local machine with my GPU or on our cluster with CPUs. The only difference is that the shuffled examples are stored on a mounted bucket with gcsfuse when I run the command on the Google VM. The bucket is mounted using the following command: `sudo gcsfuse -o allow_other`. I have also tried to use singularity, but I got the same error. I've tried to find a solution through various online resources, but nothing has helped so far. `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 121, in train. tune_dataset_config = data_providers.read_dataset_config(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/data_providers.py"", line 634, in read_dataset_config. dataset_config = text_format.Parse(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 648, in Parse. return ParseLines(text.split(b'\n' if isinstance(text, bytes) else u'\n'),. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 722, in ParseLines. return parser.ParseLines(lines, message). File ""/tmp/Bazel.runfiles_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/837
https://github.com/google/deepvariant/issues/837:708,safety,resourc,resources,708,"training on google engine; I'm attempting to train DeepVariant on a Google VM. However, when I run the training command, I encounter the error below. All the paths are correct (of course I have edited the pbtxt file to match the path were shuffled example are stored), and everything works when I run the command on my local machine with my GPU or on our cluster with CPUs. The only difference is that the shuffled examples are stored on a mounted bucket with gcsfuse when I run the command on the Google VM. The bucket is mounted using the following command: `sudo gcsfuse -o allow_other`. I have also tried to use singularity, but I got the same error. I've tried to find a solution through various online resources, but nothing has helped so far. `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 121, in train. tune_dataset_config = data_providers.read_dataset_config(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/data_providers.py"", line 634, in read_dataset_config. dataset_config = text_format.Parse(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 648, in Parse. return ParseLines(text.split(b'\n' if isinstance(text, bytes) else u'\n'),. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 722, in ParseLines. return parser.ParseLines(lines, message). File ""/tmp/Bazel.runfiles_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/837
https://github.com/google/deepvariant/issues/837:891,safety,modul,module,891,"training on google engine; I'm attempting to train DeepVariant on a Google VM. However, when I run the training command, I encounter the error below. All the paths are correct (of course I have edited the pbtxt file to match the path were shuffled example are stored), and everything works when I run the command on my local machine with my GPU or on our cluster with CPUs. The only difference is that the shuffled examples are stored on a mounted bucket with gcsfuse when I run the command on the Google VM. The bucket is mounted using the following command: `sudo gcsfuse -o allow_other`. I have also tried to use singularity, but I got the same error. I've tried to find a solution through various online resources, but nothing has helped so far. `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 121, in train. tune_dataset_config = data_providers.read_dataset_config(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/data_providers.py"", line 634, in read_dataset_config. dataset_config = text_format.Parse(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 648, in Parse. return ParseLines(text.split(b'\n' if isinstance(text, bytes) else u'\n'),. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 722, in ParseLines. return parser.ParseLines(lines, message). File ""/tmp/Bazel.runfiles_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/837
https://github.com/google/deepvariant/issues/837:2288,security,token,tokenizer,2288,"rity, but I got the same error. I've tried to find a solution through various online resources, but nothing has helped so far. `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 121, in train. tune_dataset_config = data_providers.read_dataset_config(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/data_providers.py"", line 634, in read_dataset_config. dataset_config = text_format.Parse(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 648, in Parse. return ParseLines(text.split(b'\n' if isinstance(text, bytes) else u'\n'),. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 722, in ParseLines. return parser.ParseLines(lines, message). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 776, in ParseLines. self._ParseOrMerge(lines, message). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 804, in _ParseOrMerge. self._MergeField(tokenizer, message). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 894, in _MergeField. raise tokenizer.ParseErrorPreviousToken(. google.protobuf.text_format.ParseError: 13:1 : Message type ""learning.genomics.deepvariant.DeepVariantDatasetConfig"" has no field named ""s2"".`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/837
https://github.com/google/deepvariant/issues/837:2445,security,token,tokenizer,2445,"rity, but I got the same error. I've tried to find a solution through various online resources, but nothing has helped so far. `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 121, in train. tune_dataset_config = data_providers.read_dataset_config(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/data_providers.py"", line 634, in read_dataset_config. dataset_config = text_format.Parse(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 648, in Parse. return ParseLines(text.split(b'\n' if isinstance(text, bytes) else u'\n'),. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 722, in ParseLines. return parser.ParseLines(lines, message). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 776, in ParseLines. self._ParseOrMerge(lines, message). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 804, in _ParseOrMerge. self._MergeField(tokenizer, message). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 894, in _MergeField. raise tokenizer.ParseErrorPreviousToken(. google.protobuf.text_format.ParseError: 13:1 : Message type ""learning.genomics.deepvariant.DeepVariantDatasetConfig"" has no field named ""s2"".`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/837
https://github.com/google/deepvariant/issues/837:708,testability,resourc,resources,708,"training on google engine; I'm attempting to train DeepVariant on a Google VM. However, when I run the training command, I encounter the error below. All the paths are correct (of course I have edited the pbtxt file to match the path were shuffled example are stored), and everything works when I run the command on my local machine with my GPU or on our cluster with CPUs. The only difference is that the shuffled examples are stored on a mounted bucket with gcsfuse when I run the command on the Google VM. The bucket is mounted using the following command: `sudo gcsfuse -o allow_other`. I have also tried to use singularity, but I got the same error. I've tried to find a solution through various online resources, but nothing has helped so far. `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 121, in train. tune_dataset_config = data_providers.read_dataset_config(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/data_providers.py"", line 634, in read_dataset_config. dataset_config = text_format.Parse(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 648, in Parse. return ParseLines(text.split(b'\n' if isinstance(text, bytes) else u'\n'),. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 722, in ParseLines. return parser.ParseLines(lines, message). File ""/tmp/Bazel.runfiles_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/837
https://github.com/google/deepvariant/issues/837:751,testability,Trace,Traceback,751,"training on google engine; I'm attempting to train DeepVariant on a Google VM. However, when I run the training command, I encounter the error below. All the paths are correct (of course I have edited the pbtxt file to match the path were shuffled example are stored), and everything works when I run the command on my local machine with my GPU or on our cluster with CPUs. The only difference is that the shuffled examples are stored on a mounted bucket with gcsfuse when I run the command on the Google VM. The bucket is mounted using the following command: `sudo gcsfuse -o allow_other`. I have also tried to use singularity, but I got the same error. I've tried to find a solution through various online resources, but nothing has helped so far. `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 121, in train. tune_dataset_config = data_providers.read_dataset_config(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/data_providers.py"", line 634, in read_dataset_config. dataset_config = text_format.Parse(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 648, in Parse. return ParseLines(text.split(b'\n' if isinstance(text, bytes) else u'\n'),. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 722, in ParseLines. return parser.ParseLines(lines, message). File ""/tmp/Bazel.runfiles_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/837
https://github.com/google/deepvariant/issues/837:112,usability,command,command,112,"training on google engine; I'm attempting to train DeepVariant on a Google VM. However, when I run the training command, I encounter the error below. All the paths are correct (of course I have edited the pbtxt file to match the path were shuffled example are stored), and everything works when I run the command on my local machine with my GPU or on our cluster with CPUs. The only difference is that the shuffled examples are stored on a mounted bucket with gcsfuse when I run the command on the Google VM. The bucket is mounted using the following command: `sudo gcsfuse -o allow_other`. I have also tried to use singularity, but I got the same error. I've tried to find a solution through various online resources, but nothing has helped so far. `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 121, in train. tune_dataset_config = data_providers.read_dataset_config(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/data_providers.py"", line 634, in read_dataset_config. dataset_config = text_format.Parse(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 648, in Parse. return ParseLines(text.split(b'\n' if isinstance(text, bytes) else u'\n'),. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 722, in ParseLines. return parser.ParseLines(lines, message). File ""/tmp/Bazel.runfiles_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/837
https://github.com/google/deepvariant/issues/837:137,usability,error,error,137,"training on google engine; I'm attempting to train DeepVariant on a Google VM. However, when I run the training command, I encounter the error below. All the paths are correct (of course I have edited the pbtxt file to match the path were shuffled example are stored), and everything works when I run the command on my local machine with my GPU or on our cluster with CPUs. The only difference is that the shuffled examples are stored on a mounted bucket with gcsfuse when I run the command on the Google VM. The bucket is mounted using the following command: `sudo gcsfuse -o allow_other`. I have also tried to use singularity, but I got the same error. I've tried to find a solution through various online resources, but nothing has helped so far. `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 121, in train. tune_dataset_config = data_providers.read_dataset_config(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/data_providers.py"", line 634, in read_dataset_config. dataset_config = text_format.Parse(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 648, in Parse. return ParseLines(text.split(b'\n' if isinstance(text, bytes) else u'\n'),. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 722, in ParseLines. return parser.ParseLines(lines, message). File ""/tmp/Bazel.runfiles_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/837
https://github.com/google/deepvariant/issues/837:305,usability,command,command,305,"training on google engine; I'm attempting to train DeepVariant on a Google VM. However, when I run the training command, I encounter the error below. All the paths are correct (of course I have edited the pbtxt file to match the path were shuffled example are stored), and everything works when I run the command on my local machine with my GPU or on our cluster with CPUs. The only difference is that the shuffled examples are stored on a mounted bucket with gcsfuse when I run the command on the Google VM. The bucket is mounted using the following command: `sudo gcsfuse -o allow_other`. I have also tried to use singularity, but I got the same error. I've tried to find a solution through various online resources, but nothing has helped so far. `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 121, in train. tune_dataset_config = data_providers.read_dataset_config(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/data_providers.py"", line 634, in read_dataset_config. dataset_config = text_format.Parse(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 648, in Parse. return ParseLines(text.split(b'\n' if isinstance(text, bytes) else u'\n'),. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 722, in ParseLines. return parser.ParseLines(lines, message). File ""/tmp/Bazel.runfiles_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/837
https://github.com/google/deepvariant/issues/837:483,usability,command,command,483,"training on google engine; I'm attempting to train DeepVariant on a Google VM. However, when I run the training command, I encounter the error below. All the paths are correct (of course I have edited the pbtxt file to match the path were shuffled example are stored), and everything works when I run the command on my local machine with my GPU or on our cluster with CPUs. The only difference is that the shuffled examples are stored on a mounted bucket with gcsfuse when I run the command on the Google VM. The bucket is mounted using the following command: `sudo gcsfuse -o allow_other`. I have also tried to use singularity, but I got the same error. I've tried to find a solution through various online resources, but nothing has helped so far. `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 121, in train. tune_dataset_config = data_providers.read_dataset_config(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/data_providers.py"", line 634, in read_dataset_config. dataset_config = text_format.Parse(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 648, in Parse. return ParseLines(text.split(b'\n' if isinstance(text, bytes) else u'\n'),. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 722, in ParseLines. return parser.ParseLines(lines, message). File ""/tmp/Bazel.runfiles_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/837
https://github.com/google/deepvariant/issues/837:551,usability,command,command,551,"training on google engine; I'm attempting to train DeepVariant on a Google VM. However, when I run the training command, I encounter the error below. All the paths are correct (of course I have edited the pbtxt file to match the path were shuffled example are stored), and everything works when I run the command on my local machine with my GPU or on our cluster with CPUs. The only difference is that the shuffled examples are stored on a mounted bucket with gcsfuse when I run the command on the Google VM. The bucket is mounted using the following command: `sudo gcsfuse -o allow_other`. I have also tried to use singularity, but I got the same error. I've tried to find a solution through various online resources, but nothing has helped so far. `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 121, in train. tune_dataset_config = data_providers.read_dataset_config(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/data_providers.py"", line 634, in read_dataset_config. dataset_config = text_format.Parse(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 648, in Parse. return ParseLines(text.split(b'\n' if isinstance(text, bytes) else u'\n'),. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 722, in ParseLines. return parser.ParseLines(lines, message). File ""/tmp/Bazel.runfiles_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/837
https://github.com/google/deepvariant/issues/837:648,usability,error,error,648,"training on google engine; I'm attempting to train DeepVariant on a Google VM. However, when I run the training command, I encounter the error below. All the paths are correct (of course I have edited the pbtxt file to match the path were shuffled example are stored), and everything works when I run the command on my local machine with my GPU or on our cluster with CPUs. The only difference is that the shuffled examples are stored on a mounted bucket with gcsfuse when I run the command on the Google VM. The bucket is mounted using the following command: `sudo gcsfuse -o allow_other`. I have also tried to use singularity, but I got the same error. I've tried to find a solution through various online resources, but nothing has helped so far. `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 121, in train. tune_dataset_config = data_providers.read_dataset_config(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/data_providers.py"", line 634, in read_dataset_config. dataset_config = text_format.Parse(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 648, in Parse. return ParseLines(text.split(b'\n' if isinstance(text, bytes) else u'\n'),. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 722, in ParseLines. return parser.ParseLines(lines, message). File ""/tmp/Bazel.runfiles_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/837
https://github.com/google/deepvariant/issues/837:735,usability,help,helped,735,"training on google engine; I'm attempting to train DeepVariant on a Google VM. However, when I run the training command, I encounter the error below. All the paths are correct (of course I have edited the pbtxt file to match the path were shuffled example are stored), and everything works when I run the command on my local machine with my GPU or on our cluster with CPUs. The only difference is that the shuffled examples are stored on a mounted bucket with gcsfuse when I run the command on the Google VM. The bucket is mounted using the following command: `sudo gcsfuse -o allow_other`. I have also tried to use singularity, but I got the same error. I've tried to find a solution through various online resources, but nothing has helped so far. `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 121, in train. tune_dataset_config = data_providers.read_dataset_config(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/data_providers.py"", line 634, in read_dataset_config. dataset_config = text_format.Parse(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 648, in Parse. return ParseLines(text.split(b'\n' if isinstance(text, bytes) else u'\n'),. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 722, in ParseLines. return parser.ParseLines(lines, message). File ""/tmp/Bazel.runfiles_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/837
https://github.com/google/deepvariant/issues/837:2542,usability,learn,learning,2542,"rity, but I got the same error. I've tried to find a solution through various online resources, but nothing has helped so far. `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/train.py"", line 121, in train. tune_dataset_config = data_providers.read_dataset_config(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_deepvariant/deepvariant/data_providers.py"", line 634, in read_dataset_config. dataset_config = text_format.Parse(. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 648, in Parse. return ParseLines(text.split(b'\n' if isinstance(text, bytes) else u'\n'),. File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 722, in ParseLines. return parser.ParseLines(lines, message). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 776, in ParseLines. self._ParseOrMerge(lines, message). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 804, in _ParseOrMerge. self._MergeField(tokenizer, message). File ""/tmp/Bazel.runfiles_ebq8nvgq/runfiles/com_google_protobuf/python/google/protobuf/text_format.py"", line 894, in _MergeField. raise tokenizer.ParseErrorPreviousToken(. google.protobuf.text_format.ParseError: 13:1 : Message type ""learning.genomics.deepvariant.DeepVariantDatasetConfig"" has no field named ""s2"".`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/837
https://github.com/google/deepvariant/issues/838:168,availability,consist,consist,168,"Deepvariant genotype; Hi,. Thanks for the great tool. I got the following variant lines. I wonder how should I handle them since they are germline calls. The input bam consist of only disease causing tandem repeat regions. Would I get the following lines if I run whole genome bam? If so, how should I handle these cases? ```. chr8	118316369	.	CA	C,CAAAAAAAAAAA,CAAAAAAAAAAAA	34.6	PASS	.	GT:GQ:DP:AD:VAF:PL:PS	2|1:4:36:5,9,7,5:0.25,0.194444,0.138889:32,12,45,12,0,46,6,4,46,46:118261886. chr8	118620399	.	CAAAA	C,CA,CAAA	33.3	PASS	.	GT:GQ:DP:AD:VAF:PL:PS	3|1:4:25:2,8,3,6:0.32,0.12,0.24:30,8,43,3,43,43,8,0,10,41:118384801. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/838
https://github.com/google/deepvariant/issues/838:158,safety,input,input,158,"Deepvariant genotype; Hi,. Thanks for the great tool. I got the following variant lines. I wonder how should I handle them since they are germline calls. The input bam consist of only disease causing tandem repeat regions. Would I get the following lines if I run whole genome bam? If so, how should I handle these cases? ```. chr8	118316369	.	CA	C,CAAAAAAAAAAA,CAAAAAAAAAAAA	34.6	PASS	.	GT:GQ:DP:AD:VAF:PL:PS	2|1:4:36:5,9,7,5:0.25,0.194444,0.138889:32,12,45,12,0,46,6,4,46,46:118261886. chr8	118620399	.	CAAAA	C,CA,CAAA	33.3	PASS	.	GT:GQ:DP:AD:VAF:PL:PS	3|1:4:25:2,8,3,6:0.32,0.12,0.24:30,8,43,3,43,43,8,0,10,41:118384801. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/838
https://github.com/google/deepvariant/issues/838:48,usability,tool,tool,48,"Deepvariant genotype; Hi,. Thanks for the great tool. I got the following variant lines. I wonder how should I handle them since they are germline calls. The input bam consist of only disease causing tandem repeat regions. Would I get the following lines if I run whole genome bam? If so, how should I handle these cases? ```. chr8	118316369	.	CA	C,CAAAAAAAAAAA,CAAAAAAAAAAAA	34.6	PASS	.	GT:GQ:DP:AD:VAF:PL:PS	2|1:4:36:5,9,7,5:0.25,0.194444,0.138889:32,12,45,12,0,46,6,4,46,46:118261886. chr8	118620399	.	CAAAA	C,CA,CAAA	33.3	PASS	.	GT:GQ:DP:AD:VAF:PL:PS	3|1:4:25:2,8,3,6:0.32,0.12,0.24:30,8,43,3,43,43,8,0,10,41:118384801. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/838
https://github.com/google/deepvariant/issues/838:158,usability,input,input,158,"Deepvariant genotype; Hi,. Thanks for the great tool. I got the following variant lines. I wonder how should I handle them since they are germline calls. The input bam consist of only disease causing tandem repeat regions. Would I get the following lines if I run whole genome bam? If so, how should I handle these cases? ```. chr8	118316369	.	CA	C,CAAAAAAAAAAA,CAAAAAAAAAAAA	34.6	PASS	.	GT:GQ:DP:AD:VAF:PL:PS	2|1:4:36:5,9,7,5:0.25,0.194444,0.138889:32,12,45,12,0,46,6,4,46,46:118261886. chr8	118620399	.	CAAAA	C,CA,CAAA	33.3	PASS	.	GT:GQ:DP:AD:VAF:PL:PS	3|1:4:25:2,8,3,6:0.32,0.12,0.24:30,8,43,3,43,43,8,0,10,41:118384801. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/838
https://github.com/google/deepvariant/issues/838:168,usability,consist,consist,168,"Deepvariant genotype; Hi,. Thanks for the great tool. I got the following variant lines. I wonder how should I handle them since they are germline calls. The input bam consist of only disease causing tandem repeat regions. Would I get the following lines if I run whole genome bam? If so, how should I handle these cases? ```. chr8	118316369	.	CA	C,CAAAAAAAAAAA,CAAAAAAAAAAAA	34.6	PASS	.	GT:GQ:DP:AD:VAF:PL:PS	2|1:4:36:5,9,7,5:0.25,0.194444,0.138889:32,12,45,12,0,46,6,4,46,46:118261886. chr8	118620399	.	CAAAA	C,CA,CAAA	33.3	PASS	.	GT:GQ:DP:AD:VAF:PL:PS	3|1:4:25:2,8,3,6:0.32,0.12,0.24:30,8,43,3,43,43,8,0,10,41:118384801. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/838
https://github.com/google/deepvariant/issues/839:160,availability,Operat,Operating,160,"AttributeError issue ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): singularity image built form Docker Hub. - Type of data: bacteria whole genome. **Steps to reproduce:**. - Command:. smakemake pipeline. rule run_deepvariant:. output:. vcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.vcf.gz"",. gvcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.g.vcf.gz"". input:. reference_fasta = ""/project/databases/bacteroides_genome/reference_genomic.fna"",. reads = rules.sam2bam.output.sorted_bam. params:. inter_dir = ""../../results/deepVariant/{dataset}/{sample}/intermediate"",. log_dir = ""../../results/deepVariant/{dataset}/{sample}/log"",. work_dir = ""/project/"",. deepvariant = ""/project/software/deepVariant.sif"". shell:. """""". module load singularity/3.7.0. singularity exec -B {params.work_dir} {params.deepvariant} /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref={input.reference_fasta} \. --reads={input.reads} \. --output_vcf={output.vcf} \. --output_gvcf={output.vcf} \. --make_examples_extra_args --channels=insert_size \. --intermediate_results_dir {params.inter_dir} \. --num_shards=6 \. --logging_dir={params.log_dir}. """""". - Error trace: . ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz"" --outfile_base ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant"". I0626 19:01:30.369722 139699125458752 genomics_reader.py:222] Reading ../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:1414,availability,Error,Error,1414,"e. rule run_deepvariant:. output:. vcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.vcf.gz"",. gvcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.g.vcf.gz"". input:. reference_fasta = ""/project/databases/bacteroides_genome/reference_genomic.fna"",. reads = rules.sam2bam.output.sorted_bam. params:. inter_dir = ""../../results/deepVariant/{dataset}/{sample}/intermediate"",. log_dir = ""../../results/deepVariant/{dataset}/{sample}/log"",. work_dir = ""/project/"",. deepvariant = ""/project/software/deepVariant.sif"". shell:. """""". module load singularity/3.7.0. singularity exec -B {params.work_dir} {params.deepvariant} /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref={input.reference_fasta} \. --reads={input.reads} \. --output_vcf={output.vcf} \. --output_gvcf={output.vcf} \. --make_examples_extra_args --channels=insert_size \. --intermediate_results_dir {params.inter_dir} \. --num_shards=6 \. --logging_dir={params.log_dir}. """""". - Error trace: . ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz"" --outfile_base ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant"". I0626 19:01:30.369722 139699125458752 genomics_reader.py:222] Reading ../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", line 103, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.ex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:212,deployability,version,version,212,"AttributeError issue ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): singularity image built form Docker Hub. - Type of data: bacteria whole genome. **Steps to reproduce:**. - Command:. smakemake pipeline. rule run_deepvariant:. output:. vcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.vcf.gz"",. gvcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.g.vcf.gz"". input:. reference_fasta = ""/project/databases/bacteroides_genome/reference_genomic.fna"",. reads = rules.sam2bam.output.sorted_bam. params:. inter_dir = ""../../results/deepVariant/{dataset}/{sample}/intermediate"",. log_dir = ""../../results/deepVariant/{dataset}/{sample}/log"",. work_dir = ""/project/"",. deepvariant = ""/project/software/deepVariant.sif"". shell:. """""". module load singularity/3.7.0. singularity exec -B {params.work_dir} {params.deepvariant} /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref={input.reference_fasta} \. --reads={input.reads} \. --output_vcf={output.vcf} \. --output_gvcf={output.vcf} \. --make_examples_extra_args --channels=insert_size \. --intermediate_results_dir {params.inter_dir} \. --num_shards=6 \. --logging_dir={params.log_dir}. """""". - Error trace: . ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz"" --outfile_base ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant"". I0626 19:01:30.369722 139699125458752 genomics_reader.py:222] Reading ../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:228,deployability,Instal,Installation,228,"AttributeError issue ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): singularity image built form Docker Hub. - Type of data: bacteria whole genome. **Steps to reproduce:**. - Command:. smakemake pipeline. rule run_deepvariant:. output:. vcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.vcf.gz"",. gvcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.g.vcf.gz"". input:. reference_fasta = ""/project/databases/bacteroides_genome/reference_genomic.fna"",. reads = rules.sam2bam.output.sorted_bam. params:. inter_dir = ""../../results/deepVariant/{dataset}/{sample}/intermediate"",. log_dir = ""../../results/deepVariant/{dataset}/{sample}/log"",. work_dir = ""/project/"",. deepvariant = ""/project/software/deepVariant.sif"". shell:. """""". module load singularity/3.7.0. singularity exec -B {params.work_dir} {params.deepvariant} /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref={input.reference_fasta} \. --reads={input.reads} \. --output_vcf={output.vcf} \. --output_gvcf={output.vcf} \. --make_examples_extra_args --channels=insert_size \. --intermediate_results_dir {params.inter_dir} \. --num_shards=6 \. --logging_dir={params.log_dir}. """""". - Error trace: . ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz"" --outfile_base ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant"". I0626 19:01:30.369722 139699125458752 genomics_reader.py:222] Reading ../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:410,deployability,pipelin,pipeline,410,"AttributeError issue ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): singularity image built form Docker Hub. - Type of data: bacteria whole genome. **Steps to reproduce:**. - Command:. smakemake pipeline. rule run_deepvariant:. output:. vcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.vcf.gz"",. gvcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.g.vcf.gz"". input:. reference_fasta = ""/project/databases/bacteroides_genome/reference_genomic.fna"",. reads = rules.sam2bam.output.sorted_bam. params:. inter_dir = ""../../results/deepVariant/{dataset}/{sample}/intermediate"",. log_dir = ""../../results/deepVariant/{dataset}/{sample}/log"",. work_dir = ""/project/"",. deepvariant = ""/project/software/deepVariant.sif"". shell:. """""". module load singularity/3.7.0. singularity exec -B {params.work_dir} {params.deepvariant} /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref={input.reference_fasta} \. --reads={input.reads} \. --output_vcf={output.vcf} \. --output_gvcf={output.vcf} \. --make_examples_extra_args --channels=insert_size \. --intermediate_results_dir {params.inter_dir} \. --num_shards=6 \. --logging_dir={params.log_dir}. """""". - Error trace: . ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz"" --outfile_base ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant"". I0626 19:01:30.369722 139699125458752 genomics_reader.py:222] Reading ../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:892,deployability,log,log,892,"AttributeError issue ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): singularity image built form Docker Hub. - Type of data: bacteria whole genome. **Steps to reproduce:**. - Command:. smakemake pipeline. rule run_deepvariant:. output:. vcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.vcf.gz"",. gvcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.g.vcf.gz"". input:. reference_fasta = ""/project/databases/bacteroides_genome/reference_genomic.fna"",. reads = rules.sam2bam.output.sorted_bam. params:. inter_dir = ""../../results/deepVariant/{dataset}/{sample}/intermediate"",. log_dir = ""../../results/deepVariant/{dataset}/{sample}/log"",. work_dir = ""/project/"",. deepvariant = ""/project/software/deepVariant.sif"". shell:. """""". module load singularity/3.7.0. singularity exec -B {params.work_dir} {params.deepvariant} /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref={input.reference_fasta} \. --reads={input.reads} \. --output_vcf={output.vcf} \. --output_gvcf={output.vcf} \. --make_examples_extra_args --channels=insert_size \. --intermediate_results_dir {params.inter_dir} \. --num_shards=6 \. --logging_dir={params.log_dir}. """""". - Error trace: . ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz"" --outfile_base ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant"". I0626 19:01:30.369722 139699125458752 genomics_reader.py:222] Reading ../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:988,deployability,modul,module,988,"AttributeError issue ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): singularity image built form Docker Hub. - Type of data: bacteria whole genome. **Steps to reproduce:**. - Command:. smakemake pipeline. rule run_deepvariant:. output:. vcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.vcf.gz"",. gvcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.g.vcf.gz"". input:. reference_fasta = ""/project/databases/bacteroides_genome/reference_genomic.fna"",. reads = rules.sam2bam.output.sorted_bam. params:. inter_dir = ""../../results/deepVariant/{dataset}/{sample}/intermediate"",. log_dir = ""../../results/deepVariant/{dataset}/{sample}/log"",. work_dir = ""/project/"",. deepvariant = ""/project/software/deepVariant.sif"". shell:. """""". module load singularity/3.7.0. singularity exec -B {params.work_dir} {params.deepvariant} /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref={input.reference_fasta} \. --reads={input.reads} \. --output_vcf={output.vcf} \. --output_gvcf={output.vcf} \. --make_examples_extra_args --channels=insert_size \. --intermediate_results_dir {params.inter_dir} \. --num_shards=6 \. --logging_dir={params.log_dir}. """""". - Error trace: . ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz"" --outfile_base ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant"". I0626 19:01:30.369722 139699125458752 genomics_reader.py:222] Reading ../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:2013,deployability,modul,module,2013,"0. singularity exec -B {params.work_dir} {params.deepvariant} /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref={input.reference_fasta} \. --reads={input.reads} \. --output_vcf={output.vcf} \. --output_gvcf={output.vcf} \. --make_examples_extra_args --channels=insert_size \. --intermediate_results_dir {params.inter_dir} \. --num_shards=6 \. --logging_dir={params.log_dir}. """""". - Error trace: . ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz"" --outfile_base ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant"". I0626 19:01:30.369722 139699125458752 genomics_reader.py:222] Reading ../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", line 103, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", line 93, in main. vcf_stats.create_vcf_report(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats.py"", line 392, in create_vcf_report. vcf_stats_vis.create_visual_report(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 543, in create_visual_report. _save_html(basename, all_charts). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:3291,deployability,api,api,3291,"run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", line 93, in main. vcf_stats.create_vcf_report(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats.py"", line 392, in create_vcf_report. vcf_stats_vis.create_visual_report(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 543, in create_visual_report. _save_html(basename, all_charts). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 532, in _save_html. html_string = _altair_chart_to_html(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 513, in _altair_chart_to_html. altair_chart.save(. File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 476, in save. result = save(**kwds). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/save.py"", line 79, in save. spec = chart.to_dict(). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:3516,deployability,api,api,3516,"ats_report.py"", line 93, in main. vcf_stats.create_vcf_report(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats.py"", line 392, in create_vcf_report. vcf_stats_vis.create_visual_report(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 543, in create_visual_report. _save_html(basename, all_charts). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 532, in _save_html. html_string = _altair_chart_to_html(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 513, in _altair_chart_to_html. altair_chart.save(. File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 476, in save. result = save(**kwds). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/save.py"", line 79, in save. spec = chart.to_dict(). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:4460,deployability,api,api,4460,"/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, dat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:5404,deployability,api,api,5404,"/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. return curried.pipe(data, limit_rows(max_rows=max_rows), to_values). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/data.py"", line 149, in to_values. data = sanitize_dataframe(data). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/core.py"", line 283, in sanitize_dataframe. for col_name, dtype in df.dtypes.iteritems():. File """,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:995,energy efficiency,load,load,995,"AttributeError issue ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): singularity image built form Docker Hub. - Type of data: bacteria whole genome. **Steps to reproduce:**. - Command:. smakemake pipeline. rule run_deepvariant:. output:. vcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.vcf.gz"",. gvcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.g.vcf.gz"". input:. reference_fasta = ""/project/databases/bacteroides_genome/reference_genomic.fna"",. reads = rules.sam2bam.output.sorted_bam. params:. inter_dir = ""../../results/deepVariant/{dataset}/{sample}/intermediate"",. log_dir = ""../../results/deepVariant/{dataset}/{sample}/log"",. work_dir = ""/project/"",. deepvariant = ""/project/software/deepVariant.sif"". shell:. """""". module load singularity/3.7.0. singularity exec -B {params.work_dir} {params.deepvariant} /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref={input.reference_fasta} \. --reads={input.reads} \. --output_vcf={output.vcf} \. --output_gvcf={output.vcf} \. --make_examples_extra_args --channels=insert_size \. --intermediate_results_dir {params.inter_dir} \. --num_shards=6 \. --logging_dir={params.log_dir}. """""". - Error trace: . ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz"" --outfile_base ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant"". I0626 19:01:30.369722 139699125458752 genomics_reader.py:222] Reading ../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:6310,energy efficiency,core,core,6310,"line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. return curried.pipe(data, limit_rows(max_rows=max_rows), to_values). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/data.py"", line 149, in to_values. data = sanitize_dataframe(data). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/core.py"", line 283, in sanitize_dataframe. for col_name, dtype in df.dtypes.iteritems():. File ""/home/hangyin_umass_edu/.local/lib/python3.8/site-packages/pandas/core/generic.py"", line 5989, in __getattr__. return object.__getattribute__(self, name). AttributeError: 'Series' object has no attribute 'iteritems'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:6472,energy efficiency,core,core,6472,"line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. return curried.pipe(data, limit_rows(max_rows=max_rows), to_values). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/data.py"", line 149, in to_values. data = sanitize_dataframe(data). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/core.py"", line 283, in sanitize_dataframe. for col_name, dtype in df.dtypes.iteritems():. File ""/home/hangyin_umass_edu/.local/lib/python3.8/site-packages/pandas/core/generic.py"", line 5989, in __getattr__. return object.__getattribute__(self, name). AttributeError: 'Series' object has no attribute 'iteritems'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:212,integrability,version,version,212,"AttributeError issue ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): singularity image built form Docker Hub. - Type of data: bacteria whole genome. **Steps to reproduce:**. - Command:. smakemake pipeline. rule run_deepvariant:. output:. vcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.vcf.gz"",. gvcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.g.vcf.gz"". input:. reference_fasta = ""/project/databases/bacteroides_genome/reference_genomic.fna"",. reads = rules.sam2bam.output.sorted_bam. params:. inter_dir = ""../../results/deepVariant/{dataset}/{sample}/intermediate"",. log_dir = ""../../results/deepVariant/{dataset}/{sample}/log"",. work_dir = ""/project/"",. deepvariant = ""/project/software/deepVariant.sif"". shell:. """""". module load singularity/3.7.0. singularity exec -B {params.work_dir} {params.deepvariant} /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref={input.reference_fasta} \. --reads={input.reads} \. --output_vcf={output.vcf} \. --output_gvcf={output.vcf} \. --make_examples_extra_args --channels=insert_size \. --intermediate_results_dir {params.inter_dir} \. --num_shards=6 \. --logging_dir={params.log_dir}. """""". - Error trace: . ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz"" --outfile_base ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant"". I0626 19:01:30.369722 139699125458752 genomics_reader.py:222] Reading ../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:410,integrability,pipelin,pipeline,410,"AttributeError issue ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): singularity image built form Docker Hub. - Type of data: bacteria whole genome. **Steps to reproduce:**. - Command:. smakemake pipeline. rule run_deepvariant:. output:. vcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.vcf.gz"",. gvcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.g.vcf.gz"". input:. reference_fasta = ""/project/databases/bacteroides_genome/reference_genomic.fna"",. reads = rules.sam2bam.output.sorted_bam. params:. inter_dir = ""../../results/deepVariant/{dataset}/{sample}/intermediate"",. log_dir = ""../../results/deepVariant/{dataset}/{sample}/log"",. work_dir = ""/project/"",. deepvariant = ""/project/software/deepVariant.sif"". shell:. """""". module load singularity/3.7.0. singularity exec -B {params.work_dir} {params.deepvariant} /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref={input.reference_fasta} \. --reads={input.reads} \. --output_vcf={output.vcf} \. --output_gvcf={output.vcf} \. --make_examples_extra_args --channels=insert_size \. --intermediate_results_dir {params.inter_dir} \. --num_shards=6 \. --logging_dir={params.log_dir}. """""". - Error trace: . ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz"" --outfile_base ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant"". I0626 19:01:30.369722 139699125458752 genomics_reader.py:222] Reading ../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:3291,integrability,api,api,3291,"run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", line 93, in main. vcf_stats.create_vcf_report(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats.py"", line 392, in create_vcf_report. vcf_stats_vis.create_visual_report(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 543, in create_visual_report. _save_html(basename, all_charts). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 532, in _save_html. html_string = _altair_chart_to_html(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 513, in _altair_chart_to_html. altair_chart.save(. File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 476, in save. result = save(**kwds). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/save.py"", line 79, in save. spec = chart.to_dict(). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:3516,integrability,api,api,3516,"ats_report.py"", line 93, in main. vcf_stats.create_vcf_report(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats.py"", line 392, in create_vcf_report. vcf_stats_vis.create_visual_report(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 543, in create_visual_report. _save_html(basename, all_charts). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 532, in _save_html. html_string = _altair_chart_to_html(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 513, in _altair_chart_to_html. altair_chart.save(. File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 476, in save. result = save(**kwds). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/save.py"", line 79, in save. spec = chart.to_dict(). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:3664,integrability,schema,schemapi,3664,"ts.py"", line 392, in create_vcf_report. vcf_stats_vis.create_visual_report(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 543, in create_visual_report. _save_html(basename, all_charts). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 532, in _save_html. html_string = _altair_chart_to_html(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 513, in _altair_chart_to_html. altair_chart.save(. File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 476, in save. result = save(**kwds). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/save.py"", line 79, in save. spec = chart.to_dict(). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:3777,integrability,schema,schemapi,3777,"unfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 543, in create_visual_report. _save_html(basename, all_charts). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 532, in _save_html. html_string = _altair_chart_to_html(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 513, in _altair_chart_to_html. altair_chart.save(. File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 476, in save. result = save(**kwds). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/save.py"", line 79, in save. spec = chart.to_dict(). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/loca",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:3880,integrability,schema,schemapi,3880,"html(basename, all_charts). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 532, in _save_html. html_string = _altair_chart_to_html(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 513, in _altair_chart_to_html. altair_chart.save(. File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 476, in save. result = save(**kwds). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/save.py"", line 79, in save. spec = chart.to_dict(). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:4010,integrability,schema,schemapi,4010," 532, in _save_html. html_string = _altair_chart_to_html(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 513, in _altair_chart_to_html. altair_chart.save(. File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 476, in save. result = save(**kwds). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/save.py"", line 79, in save. spec = chart.to_dict(). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, valida",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:4156,integrability,schema,schemapi,4156,"s_vis.py"", line 513, in _altair_chart_to_html. altair_chart.save(. File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 476, in save. result = save(**kwds). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/save.py"", line 79, in save. spec = chart.to_dict(). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, val",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:4305,integrability,schema,schemapi,4305," in save. result = save(**kwds). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/save.py"", line 79, in save. spec = chart.to_dict(). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(valida",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:4460,integrability,api,api,4460,"/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, dat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:4608,integrability,schema,schemapi,4608,"/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/py",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:4721,integrability,schema,schemapi,4721,"/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/u",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:4824,integrability,schema,schemapi,4824,"/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:4954,integrability,schema,schemapi,4954,"/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. return curried.pipe(data, limit_rows(max_rows=max_rows), to_values). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:5100,integrability,schema,schemapi,5100,"/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. return curried.pipe(data, limit_rows(max_rows=max_rows), to_values). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._par",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:5249,integrability,schema,schemapi,5249,"/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. return curried.pipe(data, limit_rows(max_rows=max_rows), to_values). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/data.py"", line 149, in to_values. data = sanitize_dataframe(data). F",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:5404,integrability,api,api,5404,"/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. return curried.pipe(data, limit_rows(max_rows=max_rows), to_values). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/data.py"", line 149, in to_values. data = sanitize_dataframe(data). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/core.py"", line 283, in sanitize_dataframe. for col_name, dtype in df.dtypes.iteritems():. File """,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:2109,interoperability,platform,platform,2109,"t \. --model_type=WGS \. --ref={input.reference_fasta} \. --reads={input.reads} \. --output_vcf={output.vcf} \. --output_gvcf={output.vcf} \. --make_examples_extra_args --channels=insert_size \. --intermediate_results_dir {params.inter_dir} \. --num_shards=6 \. --logging_dir={params.log_dir}. """""". - Error trace: . ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz"" --outfile_base ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant"". I0626 19:01:30.369722 139699125458752 genomics_reader.py:222] Reading ../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", line 103, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", line 93, in main. vcf_stats.create_vcf_report(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats.py"", line 392, in create_vcf_report. vcf_stats_vis.create_visual_report(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 543, in create_visual_report. _save_html(basename, all_charts). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 532, in _save_html. html_string = _altair_chart_to_html(. File ""/tmp/Bazel.runfiles_xq721o6r/runfi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:3291,interoperability,api,api,3291,"run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", line 93, in main. vcf_stats.create_vcf_report(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats.py"", line 392, in create_vcf_report. vcf_stats_vis.create_visual_report(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 543, in create_visual_report. _save_html(basename, all_charts). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 532, in _save_html. html_string = _altair_chart_to_html(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 513, in _altair_chart_to_html. altair_chart.save(. File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 476, in save. result = save(**kwds). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/save.py"", line 79, in save. spec = chart.to_dict(). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:3516,interoperability,api,api,3516,"ats_report.py"", line 93, in main. vcf_stats.create_vcf_report(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats.py"", line 392, in create_vcf_report. vcf_stats_vis.create_visual_report(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 543, in create_visual_report. _save_html(basename, all_charts). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 532, in _save_html. html_string = _altair_chart_to_html(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 513, in _altair_chart_to_html. altair_chart.save(. File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 476, in save. result = save(**kwds). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/save.py"", line 79, in save. spec = chart.to_dict(). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:4460,interoperability,api,api,4460,"/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, dat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:5404,interoperability,api,api,5404,"/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. return curried.pipe(data, limit_rows(max_rows=max_rows), to_values). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/data.py"", line 149, in to_values. data = sanitize_dataframe(data). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/core.py"", line 283, in sanitize_dataframe. for col_name, dtype in df.dtypes.iteritems():. File """,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:212,modifiability,version,version,212,"AttributeError issue ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): singularity image built form Docker Hub. - Type of data: bacteria whole genome. **Steps to reproduce:**. - Command:. smakemake pipeline. rule run_deepvariant:. output:. vcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.vcf.gz"",. gvcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.g.vcf.gz"". input:. reference_fasta = ""/project/databases/bacteroides_genome/reference_genomic.fna"",. reads = rules.sam2bam.output.sorted_bam. params:. inter_dir = ""../../results/deepVariant/{dataset}/{sample}/intermediate"",. log_dir = ""../../results/deepVariant/{dataset}/{sample}/log"",. work_dir = ""/project/"",. deepvariant = ""/project/software/deepVariant.sif"". shell:. """""". module load singularity/3.7.0. singularity exec -B {params.work_dir} {params.deepvariant} /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref={input.reference_fasta} \. --reads={input.reads} \. --output_vcf={output.vcf} \. --output_gvcf={output.vcf} \. --make_examples_extra_args --channels=insert_size \. --intermediate_results_dir {params.inter_dir} \. --num_shards=6 \. --logging_dir={params.log_dir}. """""". - Error trace: . ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz"" --outfile_base ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant"". I0626 19:01:30.369722 139699125458752 genomics_reader.py:222] Reading ../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:820,modifiability,interm,intermediate,820,"AttributeError issue ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): singularity image built form Docker Hub. - Type of data: bacteria whole genome. **Steps to reproduce:**. - Command:. smakemake pipeline. rule run_deepvariant:. output:. vcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.vcf.gz"",. gvcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.g.vcf.gz"". input:. reference_fasta = ""/project/databases/bacteroides_genome/reference_genomic.fna"",. reads = rules.sam2bam.output.sorted_bam. params:. inter_dir = ""../../results/deepVariant/{dataset}/{sample}/intermediate"",. log_dir = ""../../results/deepVariant/{dataset}/{sample}/log"",. work_dir = ""/project/"",. deepvariant = ""/project/software/deepVariant.sif"". shell:. """""". module load singularity/3.7.0. singularity exec -B {params.work_dir} {params.deepvariant} /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref={input.reference_fasta} \. --reads={input.reads} \. --output_vcf={output.vcf} \. --output_gvcf={output.vcf} \. --make_examples_extra_args --channels=insert_size \. --intermediate_results_dir {params.inter_dir} \. --num_shards=6 \. --logging_dir={params.log_dir}. """""". - Error trace: . ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz"" --outfile_base ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant"". I0626 19:01:30.369722 139699125458752 genomics_reader.py:222] Reading ../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:988,modifiability,modul,module,988,"AttributeError issue ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): singularity image built form Docker Hub. - Type of data: bacteria whole genome. **Steps to reproduce:**. - Command:. smakemake pipeline. rule run_deepvariant:. output:. vcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.vcf.gz"",. gvcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.g.vcf.gz"". input:. reference_fasta = ""/project/databases/bacteroides_genome/reference_genomic.fna"",. reads = rules.sam2bam.output.sorted_bam. params:. inter_dir = ""../../results/deepVariant/{dataset}/{sample}/intermediate"",. log_dir = ""../../results/deepVariant/{dataset}/{sample}/log"",. work_dir = ""/project/"",. deepvariant = ""/project/software/deepVariant.sif"". shell:. """""". module load singularity/3.7.0. singularity exec -B {params.work_dir} {params.deepvariant} /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref={input.reference_fasta} \. --reads={input.reads} \. --output_vcf={output.vcf} \. --output_gvcf={output.vcf} \. --make_examples_extra_args --channels=insert_size \. --intermediate_results_dir {params.inter_dir} \. --num_shards=6 \. --logging_dir={params.log_dir}. """""". - Error trace: . ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz"" --outfile_base ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant"". I0626 19:01:30.369722 139699125458752 genomics_reader.py:222] Reading ../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:2013,modifiability,modul,module,2013,"0. singularity exec -B {params.work_dir} {params.deepvariant} /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref={input.reference_fasta} \. --reads={input.reads} \. --output_vcf={output.vcf} \. --output_gvcf={output.vcf} \. --make_examples_extra_args --channels=insert_size \. --intermediate_results_dir {params.inter_dir} \. --num_shards=6 \. --logging_dir={params.log_dir}. """""". - Error trace: . ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz"" --outfile_base ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant"". I0626 19:01:30.369722 139699125458752 genomics_reader.py:222] Reading ../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", line 103, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", line 93, in main. vcf_stats.create_vcf_report(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats.py"", line 392, in create_vcf_report. vcf_stats_vis.create_visual_report(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 543, in create_visual_report. _save_html(basename, all_charts). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:2082,modifiability,pac,packages,2082,"pvariant/bin/run_deepvariant \. --model_type=WGS \. --ref={input.reference_fasta} \. --reads={input.reads} \. --output_vcf={output.vcf} \. --output_gvcf={output.vcf} \. --make_examples_extra_args --channels=insert_size \. --intermediate_results_dir {params.inter_dir} \. --num_shards=6 \. --logging_dir={params.log_dir}. """""". - Error trace: . ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz"" --outfile_base ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant"". I0626 19:01:30.369722 139699125458752 genomics_reader.py:222] Reading ../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", line 103, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", line 93, in main. vcf_stats.create_vcf_report(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats.py"", line 392, in create_vcf_report. vcf_stats_vis.create_visual_report(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 543, in create_visual_report. _save_html(basename, all_charts). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 532, in _save_html. html_string = _altair_chart_to_html(. File ""/tmp/Ba",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:3263,modifiability,pac,packages,3263,"bsl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", line 93, in main. vcf_stats.create_vcf_report(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats.py"", line 392, in create_vcf_report. vcf_stats_vis.create_visual_report(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 543, in create_visual_report. _save_html(basename, all_charts). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 532, in _save_html. html_string = _altair_chart_to_html(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 513, in _altair_chart_to_html. altair_chart.save(. File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 476, in save. result = save(**kwds). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/save.py"", line 79, in save. spec = chart.to_dict(). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:3378,modifiability,pac,packages,3378,"py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", line 93, in main. vcf_stats.create_vcf_report(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats.py"", line 392, in create_vcf_report. vcf_stats_vis.create_visual_report(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 543, in create_visual_report. _save_html(basename, all_charts). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 532, in _save_html. html_string = _altair_chart_to_html(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 513, in _altair_chart_to_html. altair_chart.save(. File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 476, in save. result = save(**kwds). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/save.py"", line 79, in save. spec = chart.to_dict(). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, cont",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:3488,modifiability,pac,packages,3488,"variant/deepvariant/vcf_stats_report.py"", line 93, in main. vcf_stats.create_vcf_report(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats.py"", line 392, in create_vcf_report. vcf_stats_vis.create_visual_report(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 543, in create_visual_report. _save_html(basename, all_charts). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 532, in _save_html. html_string = _altair_chart_to_html(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 513, in _altair_chart_to_html. altair_chart.save(. File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 476, in save. result = save(**kwds). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/save.py"", line 79, in save. spec = chart.to_dict(). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:3642,modifiability,pac,packages,3642,"nt/deepvariant/vcf_stats.py"", line 392, in create_vcf_report. vcf_stats_vis.create_visual_report(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 543, in create_visual_report. _save_html(basename, all_charts). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 532, in _save_html. html_string = _altair_chart_to_html(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 513, in _altair_chart_to_html. altair_chart.save(. File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 476, in save. result = save(**kwds). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/save.py"", line 79, in save. spec = chart.to_dict(). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:3755,modifiability,pac,packages,3755,"el.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 543, in create_visual_report. _save_html(basename, all_charts). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 532, in _save_html. html_string = _altair_chart_to_html(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 513, in _altair_chart_to_html. altair_chart.save(. File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 476, in save. result = save(**kwds). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/save.py"", line 79, in save. spec = chart.to_dict(). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. ret",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:3858,modifiability,pac,packages,3858,"_visual_report. _save_html(basename, all_charts). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 532, in _save_html. html_string = _altair_chart_to_html(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 513, in _altair_chart_to_html. altair_chart.save(. File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 476, in save. result = save(**kwds). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/save.py"", line 79, in save. spec = chart.to_dict(). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:3988,modifiability,pac,packages,3988,"cf_stats_vis.py"", line 532, in _save_html. html_string = _altair_chart_to_html(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 513, in _altair_chart_to_html. altair_chart.save(. File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 476, in save. result = save(**kwds). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/save.py"", line 79, in save. spec = chart.to_dict(). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. ret",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:4134,modifiability,pac,packages,4134,"t/deepvariant/vcf_stats_vis.py"", line 513, in _altair_chart_to_html. altair_chart.save(. File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 476, in save. result = save(**kwds). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/save.py"", line 79, in save. spec = chart.to_dict(). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:4283,modifiability,pac,packages,4283,"/v4/api.py"", line 476, in save. result = save(**kwds). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/save.py"", line 79, in save. spec = chart.to_dict(). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. ret",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:4432,modifiability,pac,packages,4432,"hart.to_dict(). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_da",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:4586,modifiability,pac,packages,4586,"rgs, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). F",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:4699,modifiability,pac,packages,4699,"ult = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*arg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:4802,modifiability,pac,packages,4802,"dict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in defaul",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:4932,modifiability,pac,packages,4932,"date, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. return curried.pipe(data, limit_rows(max_rows=max_rows), to_values). File ""/usr/local/lib/python3.8/dist-packa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:5078,modifiability,pac,packages,5078," for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. return curried.pipe(data, limit_rows(max_rows=max_rows), to_values). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __ca",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:5227,modifiability,pac,packages,5227," for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. return curried.pipe(data, limit_rows(max_rows=max_rows), to_values). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/data.py"", line 149, in to_values. data = sanit",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:5376,modifiability,pac,packages,5376,"ntext=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. return curried.pipe(data, limit_rows(max_rows=max_rows), to_values). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/data.py"", line 149, in to_values. data = sanitize_dataframe(data). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/core.py"", line 283, in sanitize_dataframe. for col_name, dtype in df.d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:5521,modifiability,pac,packages,5521,"o_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. return curried.pipe(data, limit_rows(max_rows=max_rows), to_values). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/data.py"", line 149, in to_values. data = sanitize_dataframe(data). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/core.py"", line 283, in sanitize_dataframe. for col_name, dtype in df.dtypes.iteritems():. File ""/home/hangyin_umass_edu/.local/lib/python3.8/site-packages/pandas/core/generic.py"", line 5989, in __getattr__. return o",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:5625,modifiability,pac,packages,5625,"line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. return curried.pipe(data, limit_rows(max_rows=max_rows), to_values). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/data.py"", line 149, in to_values. data = sanitize_dataframe(data). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/core.py"", line 283, in sanitize_dataframe. for col_name, dtype in df.dtypes.iteritems():. File ""/home/hangyin_umass_edu/.local/lib/python3.8/site-packages/pandas/core/generic.py"", line 5989, in __getattr__. return object.__getattribute__(self, name). AttributeError: 'Series' object has no attribute 'iteritems'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:5753,modifiability,pac,packages,5753,"line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. return curried.pipe(data, limit_rows(max_rows=max_rows), to_values). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/data.py"", line 149, in to_values. data = sanitize_dataframe(data). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/core.py"", line 283, in sanitize_dataframe. for col_name, dtype in df.dtypes.iteritems():. File ""/home/hangyin_umass_edu/.local/lib/python3.8/site-packages/pandas/core/generic.py"", line 5989, in __getattr__. return object.__getattribute__(self, name). AttributeError: 'Series' object has no attribute 'iteritems'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:5931,modifiability,pac,packages,5931,"line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. return curried.pipe(data, limit_rows(max_rows=max_rows), to_values). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/data.py"", line 149, in to_values. data = sanitize_dataframe(data). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/core.py"", line 283, in sanitize_dataframe. for col_name, dtype in df.dtypes.iteritems():. File ""/home/hangyin_umass_edu/.local/lib/python3.8/site-packages/pandas/core/generic.py"", line 5989, in __getattr__. return object.__getattribute__(self, name). AttributeError: 'Series' object has no attribute 'iteritems'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:6035,modifiability,pac,packages,6035,"line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. return curried.pipe(data, limit_rows(max_rows=max_rows), to_values). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/data.py"", line 149, in to_values. data = sanitize_dataframe(data). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/core.py"", line 283, in sanitize_dataframe. for col_name, dtype in df.dtypes.iteritems():. File ""/home/hangyin_umass_edu/.local/lib/python3.8/site-packages/pandas/core/generic.py"", line 5989, in __getattr__. return object.__getattribute__(self, name). AttributeError: 'Series' object has no attribute 'iteritems'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:6163,modifiability,pac,packages,6163,"line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. return curried.pipe(data, limit_rows(max_rows=max_rows), to_values). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/data.py"", line 149, in to_values. data = sanitize_dataframe(data). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/core.py"", line 283, in sanitize_dataframe. for col_name, dtype in df.dtypes.iteritems():. File ""/home/hangyin_umass_edu/.local/lib/python3.8/site-packages/pandas/core/generic.py"", line 5989, in __getattr__. return object.__getattribute__(self, name). AttributeError: 'Series' object has no attribute 'iteritems'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:6288,modifiability,pac,packages,6288,"line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. return curried.pipe(data, limit_rows(max_rows=max_rows), to_values). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/data.py"", line 149, in to_values. data = sanitize_dataframe(data). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/core.py"", line 283, in sanitize_dataframe. for col_name, dtype in df.dtypes.iteritems():. File ""/home/hangyin_umass_edu/.local/lib/python3.8/site-packages/pandas/core/generic.py"", line 5989, in __getattr__. return object.__getattribute__(self, name). AttributeError: 'Series' object has no attribute 'iteritems'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:6456,modifiability,pac,packages,6456,"line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. return curried.pipe(data, limit_rows(max_rows=max_rows), to_values). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/data.py"", line 149, in to_values. data = sanitize_dataframe(data). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/core.py"", line 283, in sanitize_dataframe. for col_name, dtype in df.dtypes.iteritems():. File ""/home/hangyin_umass_edu/.local/lib/python3.8/site-packages/pandas/core/generic.py"", line 5989, in __getattr__. return object.__getattribute__(self, name). AttributeError: 'Series' object has no attribute 'iteritems'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:995,performance,load,load,995,"AttributeError issue ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): singularity image built form Docker Hub. - Type of data: bacteria whole genome. **Steps to reproduce:**. - Command:. smakemake pipeline. rule run_deepvariant:. output:. vcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.vcf.gz"",. gvcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.g.vcf.gz"". input:. reference_fasta = ""/project/databases/bacteroides_genome/reference_genomic.fna"",. reads = rules.sam2bam.output.sorted_bam. params:. inter_dir = ""../../results/deepVariant/{dataset}/{sample}/intermediate"",. log_dir = ""../../results/deepVariant/{dataset}/{sample}/log"",. work_dir = ""/project/"",. deepvariant = ""/project/software/deepVariant.sif"". shell:. """""". module load singularity/3.7.0. singularity exec -B {params.work_dir} {params.deepvariant} /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref={input.reference_fasta} \. --reads={input.reads} \. --output_vcf={output.vcf} \. --output_gvcf={output.vcf} \. --make_examples_extra_args --channels=insert_size \. --intermediate_results_dir {params.inter_dir} \. --num_shards=6 \. --logging_dir={params.log_dir}. """""". - Error trace: . ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz"" --outfile_base ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant"". I0626 19:01:30.369722 139699125458752 genomics_reader.py:222] Reading ../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:1414,performance,Error,Error,1414,"e. rule run_deepvariant:. output:. vcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.vcf.gz"",. gvcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.g.vcf.gz"". input:. reference_fasta = ""/project/databases/bacteroides_genome/reference_genomic.fna"",. reads = rules.sam2bam.output.sorted_bam. params:. inter_dir = ""../../results/deepVariant/{dataset}/{sample}/intermediate"",. log_dir = ""../../results/deepVariant/{dataset}/{sample}/log"",. work_dir = ""/project/"",. deepvariant = ""/project/software/deepVariant.sif"". shell:. """""". module load singularity/3.7.0. singularity exec -B {params.work_dir} {params.deepvariant} /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref={input.reference_fasta} \. --reads={input.reads} \. --output_vcf={output.vcf} \. --output_gvcf={output.vcf} \. --make_examples_extra_args --channels=insert_size \. --intermediate_results_dir {params.inter_dir} \. --num_shards=6 \. --logging_dir={params.log_dir}. """""". - Error trace: . ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz"" --outfile_base ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant"". I0626 19:01:30.369722 139699125458752 genomics_reader.py:222] Reading ../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", line 103, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.ex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:1462,performance,time,time,1462,"sults/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.vcf.gz"",. gvcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.g.vcf.gz"". input:. reference_fasta = ""/project/databases/bacteroides_genome/reference_genomic.fna"",. reads = rules.sam2bam.output.sorted_bam. params:. inter_dir = ""../../results/deepVariant/{dataset}/{sample}/intermediate"",. log_dir = ""../../results/deepVariant/{dataset}/{sample}/log"",. work_dir = ""/project/"",. deepvariant = ""/project/software/deepVariant.sif"". shell:. """""". module load singularity/3.7.0. singularity exec -B {params.work_dir} {params.deepvariant} /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref={input.reference_fasta} \. --reads={input.reads} \. --output_vcf={output.vcf} \. --output_gvcf={output.vcf} \. --make_examples_extra_args --channels=insert_size \. --intermediate_results_dir {params.inter_dir} \. --num_shards=6 \. --logging_dir={params.log_dir}. """""". - Error trace: . ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz"" --outfile_base ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant"". I0626 19:01:30.369722 139699125458752 genomics_reader.py:222] Reading ../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", line 103, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xq721",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:622,safety,input,input,622,"AttributeError issue ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): singularity image built form Docker Hub. - Type of data: bacteria whole genome. **Steps to reproduce:**. - Command:. smakemake pipeline. rule run_deepvariant:. output:. vcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.vcf.gz"",. gvcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.g.vcf.gz"". input:. reference_fasta = ""/project/databases/bacteroides_genome/reference_genomic.fna"",. reads = rules.sam2bam.output.sorted_bam. params:. inter_dir = ""../../results/deepVariant/{dataset}/{sample}/intermediate"",. log_dir = ""../../results/deepVariant/{dataset}/{sample}/log"",. work_dir = ""/project/"",. deepvariant = ""/project/software/deepVariant.sif"". shell:. """""". module load singularity/3.7.0. singularity exec -B {params.work_dir} {params.deepvariant} /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref={input.reference_fasta} \. --reads={input.reads} \. --output_vcf={output.vcf} \. --output_gvcf={output.vcf} \. --make_examples_extra_args --channels=insert_size \. --intermediate_results_dir {params.inter_dir} \. --num_shards=6 \. --logging_dir={params.log_dir}. """""". - Error trace: . ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz"" --outfile_base ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant"". I0626 19:01:30.369722 139699125458752 genomics_reader.py:222] Reading ../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:892,safety,log,log,892,"AttributeError issue ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): singularity image built form Docker Hub. - Type of data: bacteria whole genome. **Steps to reproduce:**. - Command:. smakemake pipeline. rule run_deepvariant:. output:. vcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.vcf.gz"",. gvcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.g.vcf.gz"". input:. reference_fasta = ""/project/databases/bacteroides_genome/reference_genomic.fna"",. reads = rules.sam2bam.output.sorted_bam. params:. inter_dir = ""../../results/deepVariant/{dataset}/{sample}/intermediate"",. log_dir = ""../../results/deepVariant/{dataset}/{sample}/log"",. work_dir = ""/project/"",. deepvariant = ""/project/software/deepVariant.sif"". shell:. """""". module load singularity/3.7.0. singularity exec -B {params.work_dir} {params.deepvariant} /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref={input.reference_fasta} \. --reads={input.reads} \. --output_vcf={output.vcf} \. --output_gvcf={output.vcf} \. --make_examples_extra_args --channels=insert_size \. --intermediate_results_dir {params.inter_dir} \. --num_shards=6 \. --logging_dir={params.log_dir}. """""". - Error trace: . ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz"" --outfile_base ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant"". I0626 19:01:30.369722 139699125458752 genomics_reader.py:222] Reading ../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:988,safety,modul,module,988,"AttributeError issue ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): singularity image built form Docker Hub. - Type of data: bacteria whole genome. **Steps to reproduce:**. - Command:. smakemake pipeline. rule run_deepvariant:. output:. vcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.vcf.gz"",. gvcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.g.vcf.gz"". input:. reference_fasta = ""/project/databases/bacteroides_genome/reference_genomic.fna"",. reads = rules.sam2bam.output.sorted_bam. params:. inter_dir = ""../../results/deepVariant/{dataset}/{sample}/intermediate"",. log_dir = ""../../results/deepVariant/{dataset}/{sample}/log"",. work_dir = ""/project/"",. deepvariant = ""/project/software/deepVariant.sif"". shell:. """""". module load singularity/3.7.0. singularity exec -B {params.work_dir} {params.deepvariant} /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref={input.reference_fasta} \. --reads={input.reads} \. --output_vcf={output.vcf} \. --output_gvcf={output.vcf} \. --make_examples_extra_args --channels=insert_size \. --intermediate_results_dir {params.inter_dir} \. --num_shards=6 \. --logging_dir={params.log_dir}. """""". - Error trace: . ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz"" --outfile_base ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant"". I0626 19:01:30.369722 139699125458752 genomics_reader.py:222] Reading ../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:1145,safety,input,input,1145,"*Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): singularity image built form Docker Hub. - Type of data: bacteria whole genome. **Steps to reproduce:**. - Command:. smakemake pipeline. rule run_deepvariant:. output:. vcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.vcf.gz"",. gvcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.g.vcf.gz"". input:. reference_fasta = ""/project/databases/bacteroides_genome/reference_genomic.fna"",. reads = rules.sam2bam.output.sorted_bam. params:. inter_dir = ""../../results/deepVariant/{dataset}/{sample}/intermediate"",. log_dir = ""../../results/deepVariant/{dataset}/{sample}/log"",. work_dir = ""/project/"",. deepvariant = ""/project/software/deepVariant.sif"". shell:. """""". module load singularity/3.7.0. singularity exec -B {params.work_dir} {params.deepvariant} /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref={input.reference_fasta} \. --reads={input.reads} \. --output_vcf={output.vcf} \. --output_gvcf={output.vcf} \. --make_examples_extra_args --channels=insert_size \. --intermediate_results_dir {params.inter_dir} \. --num_shards=6 \. --logging_dir={params.log_dir}. """""". - Error trace: . ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz"" --outfile_base ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant"". I0626 19:01:30.369722 139699125458752 genomics_reader.py:222] Reading ../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", line 103, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:1180,safety,input,input,1180,"u 20.04.6 LTS. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): singularity image built form Docker Hub. - Type of data: bacteria whole genome. **Steps to reproduce:**. - Command:. smakemake pipeline. rule run_deepvariant:. output:. vcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.vcf.gz"",. gvcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.g.vcf.gz"". input:. reference_fasta = ""/project/databases/bacteroides_genome/reference_genomic.fna"",. reads = rules.sam2bam.output.sorted_bam. params:. inter_dir = ""../../results/deepVariant/{dataset}/{sample}/intermediate"",. log_dir = ""../../results/deepVariant/{dataset}/{sample}/log"",. work_dir = ""/project/"",. deepvariant = ""/project/software/deepVariant.sif"". shell:. """""". module load singularity/3.7.0. singularity exec -B {params.work_dir} {params.deepvariant} /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref={input.reference_fasta} \. --reads={input.reads} \. --output_vcf={output.vcf} \. --output_gvcf={output.vcf} \. --make_examples_extra_args --channels=insert_size \. --intermediate_results_dir {params.inter_dir} \. --num_shards=6 \. --logging_dir={params.log_dir}. """""". - Error trace: . ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz"" --outfile_base ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant"". I0626 19:01:30.369722 139699125458752 genomics_reader.py:222] Reading ../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", line 103, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:1414,safety,Error,Error,1414,"e. rule run_deepvariant:. output:. vcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.vcf.gz"",. gvcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.g.vcf.gz"". input:. reference_fasta = ""/project/databases/bacteroides_genome/reference_genomic.fna"",. reads = rules.sam2bam.output.sorted_bam. params:. inter_dir = ""../../results/deepVariant/{dataset}/{sample}/intermediate"",. log_dir = ""../../results/deepVariant/{dataset}/{sample}/log"",. work_dir = ""/project/"",. deepvariant = ""/project/software/deepVariant.sif"". shell:. """""". module load singularity/3.7.0. singularity exec -B {params.work_dir} {params.deepvariant} /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref={input.reference_fasta} \. --reads={input.reads} \. --output_vcf={output.vcf} \. --output_gvcf={output.vcf} \. --make_examples_extra_args --channels=insert_size \. --intermediate_results_dir {params.inter_dir} \. --num_shards=6 \. --logging_dir={params.log_dir}. """""". - Error trace: . ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz"" --outfile_base ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant"". I0626 19:01:30.369722 139699125458752 genomics_reader.py:222] Reading ../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", line 103, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.ex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:2013,safety,modul,module,2013,"0. singularity exec -B {params.work_dir} {params.deepvariant} /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref={input.reference_fasta} \. --reads={input.reads} \. --output_vcf={output.vcf} \. --output_gvcf={output.vcf} \. --make_examples_extra_args --channels=insert_size \. --intermediate_results_dir {params.inter_dir} \. --num_shards=6 \. --logging_dir={params.log_dir}. """""". - Error trace: . ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz"" --outfile_base ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant"". I0626 19:01:30.369722 139699125458752 genomics_reader.py:222] Reading ../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", line 103, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", line 93, in main. vcf_stats.create_vcf_report(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats.py"", line 392, in create_vcf_report. vcf_stats_vis.create_visual_report(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 543, in create_visual_report. _save_html(basename, all_charts). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:3932,safety,valid,validate,3932,"s_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 532, in _save_html. html_string = _altair_chart_to_html(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 513, in _altair_chart_to_html. altair_chart.save(. File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 476, in save. result = save(**kwds). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/save.py"", line 79, in save. spec = chart.to_dict(). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-pack",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:4064,safety,valid,validate,4064,"ml(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 513, in _altair_chart_to_html. altair_chart.save(. File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 476, in save. result = save(**kwds). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/save.py"", line 79, in save. spec = chart.to_dict(). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/pytho",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:4213,safety,valid,validate,4213,"rt.save(. File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 476, in save. result = save(**kwds). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/save.py"", line 79, in save. spec = chart.to_dict(). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/pytho",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:4359,safety,valid,validate,4359,"python3.8/dist-packages/altair/utils/save.py"", line 79, in save. spec = chart.to_dict(). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/py",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:4368,safety,valid,validate,4368,"/dist-packages/altair/utils/save.py"", line 79, in save. spec = chart.to_dict(). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:4876,safety,valid,validate,4876,"schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. return curried.pipe(data, limit_rows(max_rows=max_rows",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:5008,safety,valid,validate,5008,"hemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. return curried.pipe(data, limit_rows(max_rows=max_rows), to_values). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/lo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:5157,safety,valid,validate,5157,"api.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. return curried.pipe(data, limit_rows(max_rows=max_rows), to_values). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dis",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:5303,safety,valid,validate,5303,"hemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. return curried.pipe(data, limit_rows(max_rows=max_rows), to_values). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/data.py"", line 149, in to_values. data = sanitize_dataframe(data). File ""/usr/local/lib/python3.8/dist-packages/altair/uti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:5312,safety,valid,validate,5312,""", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. return curried.pipe(data, limit_rows(max_rows=max_rows), to_values). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/data.py"", line 149, in to_values. data = sanitize_dataframe(data). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/core.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:892,security,log,log,892,"AttributeError issue ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): singularity image built form Docker Hub. - Type of data: bacteria whole genome. **Steps to reproduce:**. - Command:. smakemake pipeline. rule run_deepvariant:. output:. vcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.vcf.gz"",. gvcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.g.vcf.gz"". input:. reference_fasta = ""/project/databases/bacteroides_genome/reference_genomic.fna"",. reads = rules.sam2bam.output.sorted_bam. params:. inter_dir = ""../../results/deepVariant/{dataset}/{sample}/intermediate"",. log_dir = ""../../results/deepVariant/{dataset}/{sample}/log"",. work_dir = ""/project/"",. deepvariant = ""/project/software/deepVariant.sif"". shell:. """""". module load singularity/3.7.0. singularity exec -B {params.work_dir} {params.deepvariant} /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref={input.reference_fasta} \. --reads={input.reads} \. --output_vcf={output.vcf} \. --output_gvcf={output.vcf} \. --make_examples_extra_args --channels=insert_size \. --intermediate_results_dir {params.inter_dir} \. --num_shards=6 \. --logging_dir={params.log_dir}. """""". - Error trace: . ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz"" --outfile_base ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant"". I0626 19:01:30.369722 139699125458752 genomics_reader.py:222] Reading ../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:3932,security,validat,validate,3932,"s_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 532, in _save_html. html_string = _altair_chart_to_html(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 513, in _altair_chart_to_html. altair_chart.save(. File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 476, in save. result = save(**kwds). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/save.py"", line 79, in save. spec = chart.to_dict(). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-pack",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:4064,security,validat,validate,4064,"ml(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 513, in _altair_chart_to_html. altair_chart.save(. File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 476, in save. result = save(**kwds). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/save.py"", line 79, in save. spec = chart.to_dict(). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/pytho",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:4213,security,validat,validate,4213,"rt.save(. File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 476, in save. result = save(**kwds). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/save.py"", line 79, in save. spec = chart.to_dict(). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/pytho",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:4359,security,validat,validate,4359,"python3.8/dist-packages/altair/utils/save.py"", line 79, in save. spec = chart.to_dict(). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/py",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:4368,security,validat,validate,4368,"/dist-packages/altair/utils/save.py"", line 79, in save. spec = chart.to_dict(). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:4876,security,validat,validate,4876,"schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. return curried.pipe(data, limit_rows(max_rows=max_rows",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:5008,security,validat,validate,5008,"hemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. return curried.pipe(data, limit_rows(max_rows=max_rows), to_values). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/lo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:5157,security,validat,validate,5157,"api.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. return curried.pipe(data, limit_rows(max_rows=max_rows), to_values). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dis",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:5303,security,validat,validate,5303,"hemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. return curried.pipe(data, limit_rows(max_rows=max_rows), to_values). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/data.py"", line 149, in to_values. data = sanitize_dataframe(data). File ""/usr/local/lib/python3.8/dist-packages/altair/uti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:5312,security,validat,validate,5312,""", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. return curried.pipe(data, limit_rows(max_rows=max_rows), to_values). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/data.py"", line 149, in to_values. data = sanitize_dataframe(data). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/core.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:892,testability,log,log,892,"AttributeError issue ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): singularity image built form Docker Hub. - Type of data: bacteria whole genome. **Steps to reproduce:**. - Command:. smakemake pipeline. rule run_deepvariant:. output:. vcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.vcf.gz"",. gvcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.g.vcf.gz"". input:. reference_fasta = ""/project/databases/bacteroides_genome/reference_genomic.fna"",. reads = rules.sam2bam.output.sorted_bam. params:. inter_dir = ""../../results/deepVariant/{dataset}/{sample}/intermediate"",. log_dir = ""../../results/deepVariant/{dataset}/{sample}/log"",. work_dir = ""/project/"",. deepvariant = ""/project/software/deepVariant.sif"". shell:. """""". module load singularity/3.7.0. singularity exec -B {params.work_dir} {params.deepvariant} /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref={input.reference_fasta} \. --reads={input.reads} \. --output_vcf={output.vcf} \. --output_gvcf={output.vcf} \. --make_examples_extra_args --channels=insert_size \. --intermediate_results_dir {params.inter_dir} \. --num_shards=6 \. --logging_dir={params.log_dir}. """""". - Error trace: . ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz"" --outfile_base ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant"". I0626 19:01:30.369722 139699125458752 genomics_reader.py:222] Reading ../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:1420,testability,trace,trace,1420,"e run_deepvariant:. output:. vcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.vcf.gz"",. gvcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.g.vcf.gz"". input:. reference_fasta = ""/project/databases/bacteroides_genome/reference_genomic.fna"",. reads = rules.sam2bam.output.sorted_bam. params:. inter_dir = ""../../results/deepVariant/{dataset}/{sample}/intermediate"",. log_dir = ""../../results/deepVariant/{dataset}/{sample}/log"",. work_dir = ""/project/"",. deepvariant = ""/project/software/deepVariant.sif"". shell:. """""". module load singularity/3.7.0. singularity exec -B {params.work_dir} {params.deepvariant} /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref={input.reference_fasta} \. --reads={input.reads} \. --output_vcf={output.vcf} \. --output_gvcf={output.vcf} \. --make_examples_extra_args --channels=insert_size \. --intermediate_results_dir {params.inter_dir} \. --num_shards=6 \. --logging_dir={params.log_dir}. """""". - Error trace: . ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz"" --outfile_base ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant"". I0626 19:01:30.369722 139699125458752 genomics_reader.py:222] Reading ../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", line 103, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(mai",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:1862,testability,Trace,Traceback,1862,"riant/{dataset}/{sample}/log"",. work_dir = ""/project/"",. deepvariant = ""/project/software/deepVariant.sif"". shell:. """""". module load singularity/3.7.0. singularity exec -B {params.work_dir} {params.deepvariant} /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref={input.reference_fasta} \. --reads={input.reads} \. --output_vcf={output.vcf} \. --output_gvcf={output.vcf} \. --make_examples_extra_args --channels=insert_size \. --intermediate_results_dir {params.inter_dir} \. --num_shards=6 \. --logging_dir={params.log_dir}. """""". - Error trace: . ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz"" --outfile_base ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant"". I0626 19:01:30.369722 139699125458752 genomics_reader.py:222] Reading ../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", line 103, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", line 93, in main. vcf_stats.create_vcf_report(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats.py"", line 392, in create_vcf_report. vcf_stats_vis.create_visual_report(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 543, in create_visu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:3942,testability,context,context,3942,"/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 532, in _save_html. html_string = _altair_chart_to_html(. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 513, in _altair_chart_to_html. altair_chart.save(. File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 476, in save. result = save(**kwds). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/save.py"", line 79, in save. spec = chart.to_dict(). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altai",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:4074,testability,context,context,4074,"""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_vis.py"", line 513, in _altair_chart_to_html. altair_chart.save(. File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 476, in save. result = save(**kwds). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/save.py"", line 79, in save. spec = chart.to_dict(). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:4223,testability,context,context,4223,"File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 476, in save. result = save(**kwds). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/save.py"", line 79, in save. spec = chart.to_dict(). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:4378,testability,context,context,4378,"ages/altair/utils/save.py"", line 79, in save. spec = chart.to_dict(). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packag",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:4386,testability,context,context,4386,"air/utils/save.py"", line 79, in save. spec = chart.to_dict(). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altai",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:4886,testability,context,context,4886,"y"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. return curried.pipe(data, limit_rows(max_rows=max_rows), to_valu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:5018,testability,context,context,5018,", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. return curried.pipe(data, limit_rows(max_rows=max_rows), to_values). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/py",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:5167,testability,context,context,5167,"ine 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. return curried.pipe(data, limit_rows(max_rows=max_rows), to_values). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:5322,testability,context,context,5322,", in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. return curried.pipe(data, limit_rows(max_rows=max_rows), to_values). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/data.py"", line 149, in to_values. data = sanitize_dataframe(data). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/core.py"", line 2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:5330,testability,context,context,5330,"dict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 373, in to_dict. dct = super(TopLevelMixin, copy).to_dict(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. return curried.pipe(data, limit_rows(max_rows=max_rows), to_values). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/data.py"", line 149, in to_values. data = sanitize_dataframe(data). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/core.py"", line 283, in s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:390,usability,Command,Command,390,"AttributeError issue ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): singularity image built form Docker Hub. - Type of data: bacteria whole genome. **Steps to reproduce:**. - Command:. smakemake pipeline. rule run_deepvariant:. output:. vcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.vcf.gz"",. gvcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.g.vcf.gz"". input:. reference_fasta = ""/project/databases/bacteroides_genome/reference_genomic.fna"",. reads = rules.sam2bam.output.sorted_bam. params:. inter_dir = ""../../results/deepVariant/{dataset}/{sample}/intermediate"",. log_dir = ""../../results/deepVariant/{dataset}/{sample}/log"",. work_dir = ""/project/"",. deepvariant = ""/project/software/deepVariant.sif"". shell:. """""". module load singularity/3.7.0. singularity exec -B {params.work_dir} {params.deepvariant} /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref={input.reference_fasta} \. --reads={input.reads} \. --output_vcf={output.vcf} \. --output_gvcf={output.vcf} \. --make_examples_extra_args --channels=insert_size \. --intermediate_results_dir {params.inter_dir} \. --num_shards=6 \. --logging_dir={params.log_dir}. """""". - Error trace: . ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz"" --outfile_base ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant"". I0626 19:01:30.369722 139699125458752 genomics_reader.py:222] Reading ../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:622,usability,input,input,622,"AttributeError issue ; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. **Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): singularity image built form Docker Hub. - Type of data: bacteria whole genome. **Steps to reproduce:**. - Command:. smakemake pipeline. rule run_deepvariant:. output:. vcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.vcf.gz"",. gvcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.g.vcf.gz"". input:. reference_fasta = ""/project/databases/bacteroides_genome/reference_genomic.fna"",. reads = rules.sam2bam.output.sorted_bam. params:. inter_dir = ""../../results/deepVariant/{dataset}/{sample}/intermediate"",. log_dir = ""../../results/deepVariant/{dataset}/{sample}/log"",. work_dir = ""/project/"",. deepvariant = ""/project/software/deepVariant.sif"". shell:. """""". module load singularity/3.7.0. singularity exec -B {params.work_dir} {params.deepvariant} /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref={input.reference_fasta} \. --reads={input.reads} \. --output_vcf={output.vcf} \. --output_gvcf={output.vcf} \. --make_examples_extra_args --channels=insert_size \. --intermediate_results_dir {params.inter_dir} \. --num_shards=6 \. --logging_dir={params.log_dir}. """""". - Error trace: . ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz"" --outfile_base ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant"". I0626 19:01:30.369722 139699125458752 genomics_reader.py:222] Reading ../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:1145,usability,input,input,1145,"*Setup**. - Operating system: Ubuntu 20.04.6 LTS. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): singularity image built form Docker Hub. - Type of data: bacteria whole genome. **Steps to reproduce:**. - Command:. smakemake pipeline. rule run_deepvariant:. output:. vcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.vcf.gz"",. gvcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.g.vcf.gz"". input:. reference_fasta = ""/project/databases/bacteroides_genome/reference_genomic.fna"",. reads = rules.sam2bam.output.sorted_bam. params:. inter_dir = ""../../results/deepVariant/{dataset}/{sample}/intermediate"",. log_dir = ""../../results/deepVariant/{dataset}/{sample}/log"",. work_dir = ""/project/"",. deepvariant = ""/project/software/deepVariant.sif"". shell:. """""". module load singularity/3.7.0. singularity exec -B {params.work_dir} {params.deepvariant} /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref={input.reference_fasta} \. --reads={input.reads} \. --output_vcf={output.vcf} \. --output_gvcf={output.vcf} \. --make_examples_extra_args --channels=insert_size \. --intermediate_results_dir {params.inter_dir} \. --num_shards=6 \. --logging_dir={params.log_dir}. """""". - Error trace: . ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz"" --outfile_base ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant"". I0626 19:01:30.369722 139699125458752 genomics_reader.py:222] Reading ../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", line 103, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:1180,usability,input,input,1180,"u 20.04.6 LTS. - DeepVariant version: 1.6. - Installation method (Docker, built from source, etc.): singularity image built form Docker Hub. - Type of data: bacteria whole genome. **Steps to reproduce:**. - Command:. smakemake pipeline. rule run_deepvariant:. output:. vcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.vcf.gz"",. gvcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.g.vcf.gz"". input:. reference_fasta = ""/project/databases/bacteroides_genome/reference_genomic.fna"",. reads = rules.sam2bam.output.sorted_bam. params:. inter_dir = ""../../results/deepVariant/{dataset}/{sample}/intermediate"",. log_dir = ""../../results/deepVariant/{dataset}/{sample}/log"",. work_dir = ""/project/"",. deepvariant = ""/project/software/deepVariant.sif"". shell:. """""". module load singularity/3.7.0. singularity exec -B {params.work_dir} {params.deepvariant} /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref={input.reference_fasta} \. --reads={input.reads} \. --output_vcf={output.vcf} \. --output_gvcf={output.vcf} \. --make_examples_extra_args --channels=insert_size \. --intermediate_results_dir {params.inter_dir} \. --num_shards=6 \. --logging_dir={params.log_dir}. """""". - Error trace: . ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz"" --outfile_base ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant"". I0626 19:01:30.369722 139699125458752 genomics_reader.py:222] Reading ../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", line 103, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:1414,usability,Error,Error,1414,"e. rule run_deepvariant:. output:. vcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.vcf.gz"",. gvcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.g.vcf.gz"". input:. reference_fasta = ""/project/databases/bacteroides_genome/reference_genomic.fna"",. reads = rules.sam2bam.output.sorted_bam. params:. inter_dir = ""../../results/deepVariant/{dataset}/{sample}/intermediate"",. log_dir = ""../../results/deepVariant/{dataset}/{sample}/log"",. work_dir = ""/project/"",. deepvariant = ""/project/software/deepVariant.sif"". shell:. """""". module load singularity/3.7.0. singularity exec -B {params.work_dir} {params.deepvariant} /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref={input.reference_fasta} \. --reads={input.reads} \. --output_vcf={output.vcf} \. --output_gvcf={output.vcf} \. --make_examples_extra_args --channels=insert_size \. --intermediate_results_dir {params.inter_dir} \. --num_shards=6 \. --logging_dir={params.log_dir}. """""". - Error trace: . ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz"" --outfile_base ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant"". I0626 19:01:30.369722 139699125458752 genomics_reader.py:222] Reading ../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", line 103, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.ex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:1447,usability,command,command,1447," vcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.vcf.gz"",. gvcf = ""../results/deepVariant/{dataset}/{sample}/vcf/{sample}.deepVariant.g.vcf.gz"". input:. reference_fasta = ""/project/databases/bacteroides_genome/reference_genomic.fna"",. reads = rules.sam2bam.output.sorted_bam. params:. inter_dir = ""../../results/deepVariant/{dataset}/{sample}/intermediate"",. log_dir = ""../../results/deepVariant/{dataset}/{sample}/log"",. work_dir = ""/project/"",. deepvariant = ""/project/software/deepVariant.sif"". shell:. """""". module load singularity/3.7.0. singularity exec -B {params.work_dir} {params.deepvariant} /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref={input.reference_fasta} \. --reads={input.reads} \. --output_vcf={output.vcf} \. --output_gvcf={output.vcf} \. --make_examples_extra_args --channels=insert_size \. --intermediate_results_dir {params.inter_dir} \. --num_shards=6 \. --logging_dir={params.log_dir}. """""". - Error trace: . ***** Running the command:*****. time /opt/deepvariant/bin/vcf_stats_report --input_vcf ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz"" --outfile_base ""../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant"". I0626 19:01:30.369722 139699125458752 genomics_reader.py:222] Reading ../results/deepVariant/KO_PV/<sample_name>/vcf/<sample_name>.deepVariant.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/com_google_deepvariant/deepvariant/vcf_stats_report.py"", line 103, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 36, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xq721o6r/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:5530,usability,tool,toolz,5530,"args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. return curried.pipe(data, limit_rows(max_rows=max_rows), to_values). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/data.py"", line 149, in to_values. data = sanitize_dataframe(data). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/core.py"", line 283, in sanitize_dataframe. for col_name, dtype in df.dtypes.iteritems():. File ""/home/hangyin_umass_edu/.local/lib/python3.8/site-packages/pandas/core/generic.py"", line 5989, in __getattr__. return object.__",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:5634,usability,tool,toolz,5634,"line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. return curried.pipe(data, limit_rows(max_rows=max_rows), to_values). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/data.py"", line 149, in to_values. data = sanitize_dataframe(data). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/core.py"", line 283, in sanitize_dataframe. for col_name, dtype in df.dtypes.iteritems():. File ""/home/hangyin_umass_edu/.local/lib/python3.8/site-packages/pandas/core/generic.py"", line 5989, in __getattr__. return object.__getattribute__(self, name). AttributeError: 'Series' object has no attribute 'iteritems'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:5940,usability,tool,toolz,5940,"line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. return curried.pipe(data, limit_rows(max_rows=max_rows), to_values). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/data.py"", line 149, in to_values. data = sanitize_dataframe(data). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/core.py"", line 283, in sanitize_dataframe. for col_name, dtype in df.dtypes.iteritems():. File ""/home/hangyin_umass_edu/.local/lib/python3.8/site-packages/pandas/core/generic.py"", line 5989, in __getattr__. return object.__getattribute__(self, name). AttributeError: 'Series' object has no attribute 'iteritems'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/839:6044,usability,tool,toolz,6044,"line 325, in to_dict. result = _todict(. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 60, in _todict. return {. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 61, in <dictcomp>. k: _todict(v, validate, context). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in _todict. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 58, in <listcomp>. return [_todict(v, validate, context) for v in obj]. File ""/usr/local/lib/python3.8/dist-packages/altair/utils/schemapi.py"", line 56, in _todict. return obj.to_dict(validate=validate, context=context). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/v4/api.py"", line 84, in _prepare_data. data = _pipe(data, data_transformers.get()). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/vegalite/data.py"", line 19, in default_data_transformer. return curried.pipe(data, limit_rows(max_rows=max_rows), to_values). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 628, in pipe. data = func(data). File ""/usr/local/lib/python3.8/dist-packages/toolz/functoolz.py"", line 304, in __call__. return self._partial(*args, **kwargs). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/data.py"", line 149, in to_values. data = sanitize_dataframe(data). File ""/usr/local/lib/python3.8/dist-packages/altair/utils/core.py"", line 283, in sanitize_dataframe. for col_name, dtype in df.dtypes.iteritems():. File ""/home/hangyin_umass_edu/.local/lib/python3.8/site-packages/pandas/core/generic.py"", line 5989, in __getattr__. return object.__getattribute__(self, name). AttributeError: 'Series' object has no attribute 'iteritems'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/839
https://github.com/google/deepvariant/issues/840:111,availability,checkpoint,checkpoints,111,"Follow up to issue 797; Hello, . Previously I had an issue where the parameters I was using were not producing checkpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:963,availability,cluster,cluster,963,"Follow up to issue 797; Hello, . Previously I had an issue where the parameters I was using were not producing checkpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1194,availability,cluster,cluster,1194," of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:2132,availability,error,error,2132,"that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/miniconda3/bin. export APPTAINER_CACHEDIR=$TMPDIR . export APPTAINER_TMPDIR=$TMPDIR. condapath=/project/ag100pest/sheina.sim/condaenvs. softwarepath=/project/ag100pest/sheina.sim/software. slurmpath=/project/ag100pest/sheina.sim/slurm_scripts. module load apptainer. apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/train \. --config=/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/dv_config.py:base \. --config.train_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/training_set_channelsize_F1F1shuffle.pbtxt"" \. --config.tune_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_full",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:2188,availability,error,error,2188,"my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/miniconda3/bin. export APPTAINER_CACHEDIR=$TMPDIR . export APPTAINER_TMPDIR=$TMPDIR. condapath=/project/ag100pest/sheina.sim/condaenvs. softwarepath=/project/ag100pest/sheina.sim/software. slurmpath=/project/ag100pest/sheina.sim/slurm_scripts. module load apptainer. apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/train \. --config=/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/dv_config.py:base \. --config.train_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/training_set_channelsize_F1F1shuffle.pbtxt"" \. --config.tune_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/validation_set_channelsize_F1F2shuffled.pbtx",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:3264,availability,checkpoint,checkpoints,3264,"las . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/miniconda3/bin. export APPTAINER_CACHEDIR=$TMPDIR . export APPTAINER_TMPDIR=$TMPDIR. condapath=/project/ag100pest/sheina.sim/condaenvs. softwarepath=/project/ag100pest/sheina.sim/software. slurmpath=/project/ag100pest/sheina.sim/slurm_scripts. module load apptainer. apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/train \. --config=/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/dv_config.py:base \. --config.train_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/training_set_channelsize_F1F1shuffle.pbtxt"" \. --config.tune_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/validation_set_channelsize_F1F2shuffled.pbtxt"" \. --config.init_checkpoint=gs://deepvariant/models/DeepVariant/1.6.1/checkpoints/wgs/deepvariant.wgs.ckpt \. --config.num_epochs=10 \. --config.learning_rate=0.02 \. --config.num_validation_examples=0 \. --experiment_dir=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/fullindividualmodel"" \. --strategy=mirrored \. --config.batch_size=32`.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:963,deployability,cluster,cluster,963,"Follow up to issue 797; Hello, . Previously I had an issue where the parameters I was using were not producing checkpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1000,deployability,resourc,resources,1000,"w up to issue 797; Hello, . Previously I had an issue where the parameters I was using were not producing checkpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mai",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1024,deployability,log,log,1024,"llo, . Previously I had an issue where the parameters I was using were not producing checkpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1038,deployability,log,log,1038,"sly I had an issue where the parameters I was using were not producing checkpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1194,deployability,cluster,cluster,1194," of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1202,deployability,resourc,resources,1202,"work and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j repl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1269,deployability,resourc,resource,1269,"ns anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:2012,deployability,FAIL,FAIL,2012,"produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/miniconda3/bin. export APPTAINER_CACHEDIR=$TMPDIR . export APPTAINER_TMPDIR=$TMPDIR. condapath=/project/ag100pest/sheina.sim/condaenvs. softwarepath=/project/ag100pest/sheina.sim/software. slurmpath=/project/ag100pest/sheina.sim/slurm_scripts. module load apptainer. apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/train \. --config=/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/dv_config.py:base \. --config.train_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/training_set_channelsize_F1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:2260,deployability,MODUL,MODULES,2260,"with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/miniconda3/bin. export APPTAINER_CACHEDIR=$TMPDIR . export APPTAINER_TMPDIR=$TMPDIR. condapath=/project/ag100pest/sheina.sim/condaenvs. softwarepath=/project/ag100pest/sheina.sim/software. slurmpath=/project/ag100pest/sheina.sim/slurm_scripts. module load apptainer. apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/train \. --config=/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/dv_config.py:base \. --config.train_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/training_set_channelsize_F1F1shuffle.pbtxt"" \. --config.tune_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/validation_set_channelsize_F1F2shuffled.pbtxt"" \. --config.init_checkpoint=gs://deepvariant/models/DeepVariant/1.6.1/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:2697,deployability,modul,module,2697,"las . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/miniconda3/bin. export APPTAINER_CACHEDIR=$TMPDIR . export APPTAINER_TMPDIR=$TMPDIR. condapath=/project/ag100pest/sheina.sim/condaenvs. softwarepath=/project/ag100pest/sheina.sim/software. slurmpath=/project/ag100pest/sheina.sim/slurm_scripts. module load apptainer. apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/train \. --config=/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/dv_config.py:base \. --config.train_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/training_set_channelsize_F1F1shuffle.pbtxt"" \. --config.tune_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/validation_set_channelsize_F1F2shuffled.pbtxt"" \. --config.init_checkpoint=gs://deepvariant/models/DeepVariant/1.6.1/checkpoints/wgs/deepvariant.wgs.ckpt \. --config.num_epochs=10 \. --config.learning_rate=0.02 \. --config.num_validation_examples=0 \. --experiment_dir=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/fullindividualmodel"" \. --strategy=mirrored \. --config.batch_size=32`.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:130,energy efficiency,model,model,130,"Follow up to issue 797; Hello, . Previously I had an issue where the parameters I was using were not producing checkpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:323,energy efficiency,model,model,323,"Follow up to issue 797; Hello, . Previously I had an issue where the parameters I was using were not producing checkpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:503,energy efficiency,model,model,503,"Follow up to issue 797; Hello, . Previously I had an issue where the parameters I was using were not producing checkpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:869,energy efficiency,model,models,869,"Follow up to issue 797; Hello, . Previously I had an issue where the parameters I was using were not producing checkpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1000,energy efficiency,resourc,resources,1000,"w up to issue 797; Hello, . Previously I had an issue where the parameters I was using were not producing checkpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mai",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1202,energy efficiency,resourc,resources,1202,"work and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j repl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1269,energy efficiency,resourc,resource,1269,"ns anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1278,energy efficiency,alloc,allocation,1278,"e on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, A",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1694,energy efficiency,gpu,gpus-per-node,1694," sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/miniconda3/bin. export APPTAINER_CACHEDIR=$TMPDIR . export APPTAINER_TMPDIR=$TMPDIR. condapath=/project/ag100pest/sheina.sim/condaenvs. softwarepath=/project/ag100pest/sheina.sim/software. slurmpath=/project/ag100pest/sheina.sim/slurm_scripts. modu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1725,energy efficiency,core,core,1725," described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/miniconda3/bin. export APPTAINER_CACHEDIR=$TMPDIR . export APPTAINER_TMPDIR=$TMPDIR. condapath=/project/ag100pest/sheina.sim/condaenvs. softwarepath=/project/ag100pest/sheina.sim/software. slurmpath=/project/ag100pest/sheina.sim/slurm_scripts. module load apptainer. apptain",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1758,energy efficiency,core,core,1758,"github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/miniconda3/bin. export APPTAINER_CACHEDIR=$TMPDIR . export APPTAINER_TMPDIR=$TMPDIR. condapath=/project/ag100pest/sheina.sim/condaenvs. softwarepath=/project/ag100pest/sheina.sim/software. slurmpath=/project/ag100pest/sheina.sim/slurm_scripts. module load apptainer. apptainer exec deepvariant_1.6.0.sif /op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1784,energy efficiency,gpu,gpu-,1784,"s/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/miniconda3/bin. export APPTAINER_CACHEDIR=$TMPDIR . export APPTAINER_TMPDIR=$TMPDIR. condapath=/project/ag100pest/sheina.sim/condaenvs. softwarepath=/project/ag100pest/sheina.sim/software. slurmpath=/project/ag100pest/sheina.sim/slurm_scripts. module load apptainer. apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/train \.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:2255,energy efficiency,LOAD,LOAD,2255," issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/miniconda3/bin. export APPTAINER_CACHEDIR=$TMPDIR . export APPTAINER_TMPDIR=$TMPDIR. condapath=/project/ag100pest/sheina.sim/condaenvs. softwarepath=/project/ag100pest/sheina.sim/software. slurmpath=/project/ag100pest/sheina.sim/slurm_scripts. module load apptainer. apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/train \. --config=/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/dv_config.py:base \. --config.train_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/training_set_channelsize_F1F1shuffle.pbtxt"" \. --config.tune_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/validation_set_channelsize_F1F2shuffled.pbtxt"" \. --config.init_checkpoint=gs://deepvariant/models/DeepVariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:2704,energy efficiency,load,load,2704,"las . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/miniconda3/bin. export APPTAINER_CACHEDIR=$TMPDIR . export APPTAINER_TMPDIR=$TMPDIR. condapath=/project/ag100pest/sheina.sim/condaenvs. softwarepath=/project/ag100pest/sheina.sim/software. slurmpath=/project/ag100pest/sheina.sim/slurm_scripts. module load apptainer. apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/train \. --config=/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/dv_config.py:base \. --config.train_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/training_set_channelsize_F1F1shuffle.pbtxt"" \. --config.tune_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/validation_set_channelsize_F1F2shuffled.pbtxt"" \. --config.init_checkpoint=gs://deepvariant/models/DeepVariant/1.6.1/checkpoints/wgs/deepvariant.wgs.ckpt \. --config.num_epochs=10 \. --config.learning_rate=0.02 \. --config.num_validation_examples=0 \. --experiment_dir=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/fullindividualmodel"" \. --strategy=mirrored \. --config.batch_size=32`.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:3239,energy efficiency,model,models,3239,"las . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/miniconda3/bin. export APPTAINER_CACHEDIR=$TMPDIR . export APPTAINER_TMPDIR=$TMPDIR. condapath=/project/ag100pest/sheina.sim/condaenvs. softwarepath=/project/ag100pest/sheina.sim/software. slurmpath=/project/ag100pest/sheina.sim/slurm_scripts. module load apptainer. apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/train \. --config=/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/dv_config.py:base \. --config.train_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/training_set_channelsize_F1F1shuffle.pbtxt"" \. --config.tune_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/validation_set_channelsize_F1F2shuffled.pbtxt"" \. --config.init_checkpoint=gs://deepvariant/models/DeepVariant/1.6.1/checkpoints/wgs/deepvariant.wgs.ckpt \. --config.num_epochs=10 \. --config.learning_rate=0.02 \. --config.num_validation_examples=0 \. --experiment_dir=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/fullindividualmodel"" \. --strategy=mirrored \. --config.batch_size=32`.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:3501,energy efficiency,model,modeltrainout,3501,"las . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/miniconda3/bin. export APPTAINER_CACHEDIR=$TMPDIR . export APPTAINER_TMPDIR=$TMPDIR. condapath=/project/ag100pest/sheina.sim/condaenvs. softwarepath=/project/ag100pest/sheina.sim/software. slurmpath=/project/ag100pest/sheina.sim/slurm_scripts. module load apptainer. apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/train \. --config=/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/dv_config.py:base \. --config.train_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/training_set_channelsize_F1F1shuffle.pbtxt"" \. --config.tune_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/validation_set_channelsize_F1F2shuffled.pbtxt"" \. --config.init_checkpoint=gs://deepvariant/models/DeepVariant/1.6.1/checkpoints/wgs/deepvariant.wgs.ckpt \. --config.num_epochs=10 \. --config.learning_rate=0.02 \. --config.num_validation_examples=0 \. --experiment_dir=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/fullindividualmodel"" \. --strategy=mirrored \. --config.batch_size=32`.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:189,integrability,compon,component,189,"Follow up to issue 797; Hello, . Previously I had an issue where the parameters I was using were not producing checkpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:932,integrability,sub,submit,932,"Follow up to issue 797; Hello, . Previously I had an issue where the parameters I was using were not producing checkpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1376,integrability,sub,submitting,1376,"mewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-cento",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:189,interoperability,compon,component,189,"Follow up to issue 797; Hello, . Previously I had an issue where the parameters I was using were not producing checkpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:848,interoperability,specif,specific-deepvariant-models,848,"Follow up to issue 797; Hello, . Previously I had an issue where the parameters I was using were not producing checkpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1795,interoperability,standard,standard,1795,"improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/miniconda3/bin. export APPTAINER_CACHEDIR=$TMPDIR . export APPTAINER_TMPDIR=$TMPDIR. condapath=/project/ag100pest/sheina.sim/condaenvs. softwarepath=/project/ag100pest/sheina.sim/software. slurmpath=/project/ag100pest/sheina.sim/slurm_scripts. module load apptainer. apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/train \. --config=/90",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:2076,interoperability,standard,standard,2076,"e code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/miniconda3/bin. export APPTAINER_CACHEDIR=$TMPDIR . export APPTAINER_TMPDIR=$TMPDIR. condapath=/project/ag100pest/sheina.sim/condaenvs. softwarepath=/project/ag100pest/sheina.sim/software. slurmpath=/project/ag100pest/sheina.sim/slurm_scripts. module load apptainer. apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/train \. --config=/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/dv_config.py:base \. --config.train_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/training_set_channelsize_F1F1shuffle.pbtxt"" \. --config.tune_dataset_pbtxt=""/90daydata/pbarc/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:2179,interoperability,standard,standard,2179," asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/miniconda3/bin. export APPTAINER_CACHEDIR=$TMPDIR . export APPTAINER_TMPDIR=$TMPDIR. condapath=/project/ag100pest/sheina.sim/condaenvs. softwarepath=/project/ag100pest/sheina.sim/software. slurmpath=/project/ag100pest/sheina.sim/slurm_scripts. module load apptainer. apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/train \. --config=/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/dv_config.py:base \. --config.train_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/training_set_channelsize_F1F1shuffle.pbtxt"" \. --config.tune_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/validation_set_channelsize_F1F2shuff",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:69,modifiability,paramet,parameters,69,"Follow up to issue 797; Hello, . Previously I had an issue where the parameters I was using were not producing checkpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:172,modifiability,paramet,parameters,172,"Follow up to issue 797; Hello, . Previously I had an issue where the parameters I was using were not producing checkpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:189,modifiability,compon,component,189,"Follow up to issue 797; Hello, . Previously I had an issue where the parameters I was using were not producing checkpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:338,modifiability,paramet,parameters,338,"Follow up to issue 797; Hello, . Previously I had an issue where the parameters I was using were not producing checkpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:419,modifiability,paramet,parameter,419,"Follow up to issue 797; Hello, . Previously I had an issue where the parameters I was using were not producing checkpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:2260,modifiability,MODUL,MODULES,2260,"with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/miniconda3/bin. export APPTAINER_CACHEDIR=$TMPDIR . export APPTAINER_TMPDIR=$TMPDIR. condapath=/project/ag100pest/sheina.sim/condaenvs. softwarepath=/project/ag100pest/sheina.sim/software. slurmpath=/project/ag100pest/sheina.sim/slurm_scripts. module load apptainer. apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/train \. --config=/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/dv_config.py:base \. --config.train_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/training_set_channelsize_F1F1shuffle.pbtxt"" \. --config.tune_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/validation_set_channelsize_F1F2shuffled.pbtxt"" \. --config.init_checkpoint=gs://deepvariant/models/DeepVariant/1.6.1/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:2697,modifiability,modul,module,2697,"las . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/miniconda3/bin. export APPTAINER_CACHEDIR=$TMPDIR . export APPTAINER_TMPDIR=$TMPDIR. condapath=/project/ag100pest/sheina.sim/condaenvs. softwarepath=/project/ag100pest/sheina.sim/software. slurmpath=/project/ag100pest/sheina.sim/slurm_scripts. module load apptainer. apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/train \. --config=/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/dv_config.py:base \. --config.train_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/training_set_channelsize_F1F1shuffle.pbtxt"" \. --config.tune_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/validation_set_channelsize_F1F2shuffled.pbtxt"" \. --config.init_checkpoint=gs://deepvariant/models/DeepVariant/1.6.1/checkpoints/wgs/deepvariant.wgs.ckpt \. --config.num_epochs=10 \. --config.learning_rate=0.02 \. --config.num_validation_examples=0 \. --experiment_dir=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/fullindividualmodel"" \. --strategy=mirrored \. --config.batch_size=32`.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1000,performance,resourc,resources,1000,"w up to issue 797; Hello, . Previously I had an issue where the parameters I was using were not producing checkpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mai",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1202,performance,resourc,resources,1202,"work and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j repl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1269,performance,resourc,resource,1269,"ns anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1602,performance,time,time,1602," validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/miniconda3/bin. export APPTAINER_CACHEDIR=$TMPDIR . export APPTAINER_TMPDIR=$TMPDIR. condapath=/project/ag100pest/sheina.sim/condaenvs. softwarepath=/p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1694,performance,gpu,gpus-per-node,1694," sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/miniconda3/bin. export APPTAINER_CACHEDIR=$TMPDIR . export APPTAINER_TMPDIR=$TMPDIR. condapath=/project/ag100pest/sheina.sim/condaenvs. softwarepath=/project/ag100pest/sheina.sim/software. slurmpath=/project/ag100pest/sheina.sim/slurm_scripts. modu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1784,performance,gpu,gpu-,1784,"s/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/miniconda3/bin. export APPTAINER_CACHEDIR=$TMPDIR . export APPTAINER_TMPDIR=$TMPDIR. condapath=/project/ag100pest/sheina.sim/condaenvs. softwarepath=/project/ag100pest/sheina.sim/software. slurmpath=/project/ag100pest/sheina.sim/slurm_scripts. module load apptainer. apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/train \.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:2132,performance,error,error,2132,"that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/miniconda3/bin. export APPTAINER_CACHEDIR=$TMPDIR . export APPTAINER_TMPDIR=$TMPDIR. condapath=/project/ag100pest/sheina.sim/condaenvs. softwarepath=/project/ag100pest/sheina.sim/software. slurmpath=/project/ag100pest/sheina.sim/slurm_scripts. module load apptainer. apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/train \. --config=/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/dv_config.py:base \. --config.train_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/training_set_channelsize_F1F1shuffle.pbtxt"" \. --config.tune_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_full",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:2188,performance,error,error,2188,"my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/miniconda3/bin. export APPTAINER_CACHEDIR=$TMPDIR . export APPTAINER_TMPDIR=$TMPDIR. condapath=/project/ag100pest/sheina.sim/condaenvs. softwarepath=/project/ag100pest/sheina.sim/software. slurmpath=/project/ag100pest/sheina.sim/slurm_scripts. module load apptainer. apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/train \. --config=/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/dv_config.py:base \. --config.train_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/training_set_channelsize_F1F1shuffle.pbtxt"" \. --config.tune_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/validation_set_channelsize_F1F2shuffled.pbtx",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:2255,performance,LOAD,LOAD,2255," issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/miniconda3/bin. export APPTAINER_CACHEDIR=$TMPDIR . export APPTAINER_TMPDIR=$TMPDIR. condapath=/project/ag100pest/sheina.sim/condaenvs. softwarepath=/project/ag100pest/sheina.sim/software. slurmpath=/project/ag100pest/sheina.sim/slurm_scripts. module load apptainer. apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/train \. --config=/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/dv_config.py:base \. --config.train_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/training_set_channelsize_F1F1shuffle.pbtxt"" \. --config.tune_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/validation_set_channelsize_F1F2shuffled.pbtxt"" \. --config.init_checkpoint=gs://deepvariant/models/DeepVariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:2704,performance,load,load,2704,"las . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/miniconda3/bin. export APPTAINER_CACHEDIR=$TMPDIR . export APPTAINER_TMPDIR=$TMPDIR. condapath=/project/ag100pest/sheina.sim/condaenvs. softwarepath=/project/ag100pest/sheina.sim/software. slurmpath=/project/ag100pest/sheina.sim/slurm_scripts. module load apptainer. apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/train \. --config=/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/dv_config.py:base \. --config.train_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/training_set_channelsize_F1F1shuffle.pbtxt"" \. --config.tune_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/validation_set_channelsize_F1F2shuffled.pbtxt"" \. --config.init_checkpoint=gs://deepvariant/models/DeepVariant/1.6.1/checkpoints/wgs/deepvariant.wgs.ckpt \. --config.num_epochs=10 \. --config.learning_rate=0.02 \. --config.num_validation_examples=0 \. --experiment_dir=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/fullindividualmodel"" \. --strategy=mirrored \. --config.batch_size=32`.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:111,reliability,checkpoint,checkpoints,111,"Follow up to issue 797; Hello, . Previously I had an issue where the parameters I was using were not producing checkpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:2012,reliability,FAIL,FAIL,2012,"produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/miniconda3/bin. export APPTAINER_CACHEDIR=$TMPDIR . export APPTAINER_TMPDIR=$TMPDIR. condapath=/project/ag100pest/sheina.sim/condaenvs. softwarepath=/project/ag100pest/sheina.sim/software. slurmpath=/project/ag100pest/sheina.sim/slurm_scripts. module load apptainer. apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/train \. --config=/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/dv_config.py:base \. --config.train_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/training_set_channelsize_F1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:3264,reliability,checkpoint,checkpoints,3264,"las . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/miniconda3/bin. export APPTAINER_CACHEDIR=$TMPDIR . export APPTAINER_TMPDIR=$TMPDIR. condapath=/project/ag100pest/sheina.sim/condaenvs. softwarepath=/project/ag100pest/sheina.sim/software. slurmpath=/project/ag100pest/sheina.sim/slurm_scripts. module load apptainer. apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/train \. --config=/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/dv_config.py:base \. --config.train_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/training_set_channelsize_F1F1shuffle.pbtxt"" \. --config.tune_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/validation_set_channelsize_F1F2shuffled.pbtxt"" \. --config.init_checkpoint=gs://deepvariant/models/DeepVariant/1.6.1/checkpoints/wgs/deepvariant.wgs.ckpt \. --config.num_epochs=10 \. --config.learning_rate=0.02 \. --config.num_validation_examples=0 \. --experiment_dir=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/fullindividualmodel"" \. --strategy=mirrored \. --config.batch_size=32`.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:605,safety,valid,validation,605,"Follow up to issue 797; Hello, . Previously I had an issue where the parameters I was using were not producing checkpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:691,safety,valid,validation,691,"Follow up to issue 797; Hello, . Previously I had an issue where the parameters I was using were not producing checkpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1000,safety,resourc,resources,1000,"w up to issue 797; Hello, . Previously I had an issue where the parameters I was using were not producing checkpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mai",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1024,safety,log,log,1024,"llo, . Previously I had an issue where the parameters I was using were not producing checkpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1038,safety,log,log,1038,"sly I had an issue where the parameters I was using were not producing checkpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1202,safety,resourc,resources,1202,"work and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j repl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1269,safety,resourc,resource,1269,"ns anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1479,safety,compl,completely,1479,"pting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/miniconda3/bin. export APPTAINE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:2132,safety,error,error,2132,"that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/miniconda3/bin. export APPTAINER_CACHEDIR=$TMPDIR . export APPTAINER_TMPDIR=$TMPDIR. condapath=/project/ag100pest/sheina.sim/condaenvs. softwarepath=/project/ag100pest/sheina.sim/software. slurmpath=/project/ag100pest/sheina.sim/slurm_scripts. module load apptainer. apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/train \. --config=/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/dv_config.py:base \. --config.train_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/training_set_channelsize_F1F1shuffle.pbtxt"" \. --config.tune_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_full",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:2188,safety,error,error,2188,"my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/miniconda3/bin. export APPTAINER_CACHEDIR=$TMPDIR . export APPTAINER_TMPDIR=$TMPDIR. condapath=/project/ag100pest/sheina.sim/condaenvs. softwarepath=/project/ag100pest/sheina.sim/software. slurmpath=/project/ag100pest/sheina.sim/slurm_scripts. module load apptainer. apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/train \. --config=/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/dv_config.py:base \. --config.train_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/training_set_channelsize_F1F1shuffle.pbtxt"" \. --config.tune_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/validation_set_channelsize_F1F2shuffled.pbtx",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:2260,safety,MODUL,MODULES,2260,"with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/miniconda3/bin. export APPTAINER_CACHEDIR=$TMPDIR . export APPTAINER_TMPDIR=$TMPDIR. condapath=/project/ag100pest/sheina.sim/condaenvs. softwarepath=/project/ag100pest/sheina.sim/software. slurmpath=/project/ag100pest/sheina.sim/slurm_scripts. module load apptainer. apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/train \. --config=/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/dv_config.py:base \. --config.train_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/training_set_channelsize_F1F1shuffle.pbtxt"" \. --config.tune_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/validation_set_channelsize_F1F2shuffled.pbtxt"" \. --config.init_checkpoint=gs://deepvariant/models/DeepVariant/1.6.1/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:2697,safety,modul,module,2697,"las . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/miniconda3/bin. export APPTAINER_CACHEDIR=$TMPDIR . export APPTAINER_TMPDIR=$TMPDIR. condapath=/project/ag100pest/sheina.sim/condaenvs. softwarepath=/project/ag100pest/sheina.sim/software. slurmpath=/project/ag100pest/sheina.sim/slurm_scripts. module load apptainer. apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/train \. --config=/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/dv_config.py:base \. --config.train_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/training_set_channelsize_F1F1shuffle.pbtxt"" \. --config.tune_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/validation_set_channelsize_F1F2shuffled.pbtxt"" \. --config.init_checkpoint=gs://deepvariant/models/DeepVariant/1.6.1/checkpoints/wgs/deepvariant.wgs.ckpt \. --config.num_epochs=10 \. --config.learning_rate=0.02 \. --config.num_validation_examples=0 \. --experiment_dir=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/fullindividualmodel"" \. --strategy=mirrored \. --config.batch_size=32`.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:130,security,model,model,130,"Follow up to issue 797; Hello, . Previously I had an issue where the parameters I was using were not producing checkpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:323,security,model,model,323,"Follow up to issue 797; Hello, . Previously I had an issue where the parameters I was using were not producing checkpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:503,security,model,model,503,"Follow up to issue 797; Hello, . Previously I had an issue where the parameters I was using were not producing checkpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:605,security,validat,validation,605,"Follow up to issue 797; Hello, . Previously I had an issue where the parameters I was using were not producing checkpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:691,security,validat,validation,691,"Follow up to issue 797; Hello, . Previously I had an issue where the parameters I was using were not producing checkpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:869,security,model,models,869,"Follow up to issue 797; Hello, . Previously I had an issue where the parameters I was using were not producing checkpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1024,security,log,log,1024,"llo, . Previously I had an issue where the parameters I was using were not producing checkpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1038,security,log,log,1038,"sly I had an issue where the parameters I was using were not producing checkpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1479,security,compl,completely,1479,"pting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/miniconda3/bin. export APPTAINE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:3239,security,model,models,3239,"las . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/miniconda3/bin. export APPTAINER_CACHEDIR=$TMPDIR . export APPTAINER_TMPDIR=$TMPDIR. condapath=/project/ag100pest/sheina.sim/condaenvs. softwarepath=/project/ag100pest/sheina.sim/software. slurmpath=/project/ag100pest/sheina.sim/slurm_scripts. module load apptainer. apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/train \. --config=/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/dv_config.py:base \. --config.train_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/training_set_channelsize_F1F1shuffle.pbtxt"" \. --config.tune_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/validation_set_channelsize_F1F2shuffled.pbtxt"" \. --config.init_checkpoint=gs://deepvariant/models/DeepVariant/1.6.1/checkpoints/wgs/deepvariant.wgs.ckpt \. --config.num_epochs=10 \. --config.learning_rate=0.02 \. --config.num_validation_examples=0 \. --experiment_dir=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/fullindividualmodel"" \. --strategy=mirrored \. --config.batch_size=32`.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:3501,security,model,modeltrainout,3501,"las . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/miniconda3/bin. export APPTAINER_CACHEDIR=$TMPDIR . export APPTAINER_TMPDIR=$TMPDIR. condapath=/project/ag100pest/sheina.sim/condaenvs. softwarepath=/project/ag100pest/sheina.sim/software. slurmpath=/project/ag100pest/sheina.sim/slurm_scripts. module load apptainer. apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/train \. --config=/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/dv_config.py:base \. --config.train_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/training_set_channelsize_F1F1shuffle.pbtxt"" \. --config.tune_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/validation_set_channelsize_F1F2shuffled.pbtxt"" \. --config.init_checkpoint=gs://deepvariant/models/DeepVariant/1.6.1/checkpoints/wgs/deepvariant.wgs.ckpt \. --config.num_epochs=10 \. --config.learning_rate=0.02 \. --config.num_validation_examples=0 \. --experiment_dir=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/fullindividualmodel"" \. --strategy=mirrored \. --config.batch_size=32`.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1000,testability,resourc,resources,1000,"w up to issue 797; Hello, . Previously I had an issue where the parameters I was using were not producing checkpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mai",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1024,testability,log,log,1024,"llo, . Previously I had an issue where the parameters I was using were not producing checkpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1038,testability,log,log,1038,"sly I had an issue where the parameters I was using were not producing checkpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1202,testability,resourc,resources,1202,"work and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j repl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1269,testability,resourc,resource,1269,"ns anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1095,usability,indicat,indicating,1095," producing checkpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1109,usability,progress,progress,1109,"eckpoints in the model training step. I know that choosing parameters has a component of guesswork and iteration, and I was wondering if there are recommendations anywhere on how to choose a starting point for model training parameters, or if there are descriptions somewhere of what changing a particular parameter is likely to do. In the run described below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1456,usability,command,commands,1456,"cribed below, I am attempting to train the model on an individual using a second individual for the training data and a third individual for the validation data, but my goal is to use multiple individuals for both the training and validation sets, akin to the project described [here](https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/). . Secondly, I've been having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/minicon",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:1896,usability,user,user,1896,"en having an issue lately where I submit scripts to my computing cluster, and though they are granted resources and produce a log file, the log file is empty after several days of the code running indicating no progress has been made or that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/miniconda3/bin. export APPTAINER_CACHEDIR=$TMPDIR . export APPTAINER_TMPDIR=$TMPDIR. condapath=/project/ag100pest/sheina.sim/condaenvs. softwarepath=/project/ag100pest/sheina.sim/software. slurmpath=/project/ag100pest/sheina.sim/slurm_scripts. module load apptainer. apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/train \. --config=/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/dv_config.py:base \. --config.train_dataset_pb",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:2132,usability,error,error,2132,"that the program has even initialized. I am also asking my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/miniconda3/bin. export APPTAINER_CACHEDIR=$TMPDIR . export APPTAINER_TMPDIR=$TMPDIR. condapath=/project/ag100pest/sheina.sim/condaenvs. softwarepath=/project/ag100pest/sheina.sim/software. slurmpath=/project/ag100pest/sheina.sim/slurm_scripts. module load apptainer. apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/train \. --config=/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/dv_config.py:base \. --config.train_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/training_set_channelsize_F1F1shuffle.pbtxt"" \. --config.tune_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_full",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/840:2188,usability,error,error,2188,"my cluster resources about this, as I suspect it is more likely an issue with resource allocation, but I would also very much appreciate if someone could take a glance at the code I am submitting to make sure there are no obvious causes for this in the deepvariant commands that I'm just completely missing. . Thank you very much! . Best, . Haley. Here is the code: . `#!/bin/bash. #SBATCH -p atlas . #SBATCH --time=5-48:00:00 # walltime limit (HH:MM:SS). #SBATCH --nodes=1 # number of nodes. #SBATCH --gpus-per-node=1 # 20 processor core(s) per node X 2 threads per core. #SBATCH --partition=gpu-a100 # standard node(s). #SBATCH --ntasks=1. #SBATCH --job-name=""deepvariant_modeltraining"". #SBATCH --mail-user=haley.arnold@usda.gov # email address. #SBATCH --mail-type=BEGIN. #SBATCH --mail-type=END. #SBATCH --mail-type=FAIL. #SBATCH --output=""deepvariant_modeltrain-%j-%N.out"" # job standard output file (%j replaced by job id). #SBATCH --error=""deepvariant_modeltrain-%j-%N.err"" # job standard error file (%j replaced by job id). #SBATCH --account=ag100pest. # LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE. export PATH=$PATH:/project/ag100pest/sratoolkit/sratoolkit.2.10.9-centos_linux64/bin. export PATH=$PATH:/project/ag100pest/sheina.sim/software/miniconda3/bin. export APPTAINER_CACHEDIR=$TMPDIR . export APPTAINER_TMPDIR=$TMPDIR. condapath=/project/ag100pest/sheina.sim/condaenvs. softwarepath=/project/ag100pest/sheina.sim/software. slurmpath=/project/ag100pest/sheina.sim/slurm_scripts. module load apptainer. apptainer exec deepvariant_1.6.0.sif /opt/deepvariant/bin/train \. --config=/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/dv_config.py:base \. --config.train_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/training_set_channelsize_F1F1shuffle.pbtxt"" \. --config.tune_dataset_pbtxt=""/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/validation_set_channelsize_F1F2shuffled.pbtx",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/840
https://github.com/google/deepvariant/issues/841:866,availability,error,error,866,"How to train deepvariant v1.6.1 on tpu?; I managed to start training on a GPU, but it took too much time. Now, I am attempting to train DeepVariant on a TPU v3-8 VM. However, the most recent tutorial I found is for version 0.9, and I am unsure how to proceed with version 1.6.1. The command I used is the following: . ```. docker run \. -v ${HOME}:${HOME} \. google/deepvariant:1.6.1 \. train \. --config=${HOME}/dv_config.py:base \. --config.train_dataset_pbtxt=""${SHUFFLE_DIR}/training_set.dataset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""${SHUFFLE_DIR}/validation_set.dataset_config.pbtxt"" \. --config.num_epochs=10 \. --config.learning_rate=0.001 \. --config.num_validation_examples=0 \. --experiment_dir=${TRAINING_DIR} \. --strategy=tpu \. --config.batch_size=1024. ```. However, I am not an expert with TPUs, and this is entirely new to me. Below is the error I encountered. Do you have any suggestions or can you direct me to an updated tutorial to follow? ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:1178,availability,mainten,maintenance,1178,"recent tutorial I found is for version 0.9, and I am unsure how to proceed with version 1.6.1. The command I used is the following: . ```. docker run \. -v ${HOME}:${HOME} \. google/deepvariant:1.6.1 \. train \. --config=${HOME}/dv_config.py:base \. --config.train_dataset_pbtxt=""${SHUFFLE_DIR}/training_set.dataset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""${SHUFFLE_DIR}/validation_set.dataset_config.pbtxt"" \. --config.num_epochs=10 \. --config.learning_rate=0.001 \. --config.num_validation_examples=0 \. --experiment_dir=${TRAINING_DIR} \. --strategy=tpu \. --config.batch_size=1024. ```. However, I am not an expert with TPUs, and this is entirely new to me. Below is the error I encountered. Do you have any suggestions or can you direct me to an updated tutorial to follow? ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 139683296487232 tpu_strategy_util.py:81] Initializing the TPU system: local. 2024-06-27 21:18:43.848149: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:1262,availability,down,downstream,1262,"sion 1.6.1. The command I used is the following: . ```. docker run \. -v ${HOME}:${HOME} \. google/deepvariant:1.6.1 \. train \. --config=${HOME}/dv_config.py:base \. --config.train_dataset_pbtxt=""${SHUFFLE_DIR}/training_set.dataset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""${SHUFFLE_DIR}/validation_set.dataset_config.pbtxt"" \. --config.num_epochs=10 \. --config.learning_rate=0.001 \. --config.num_validation_examples=0 \. --experiment_dir=${TRAINING_DIR} \. --strategy=tpu \. --config.batch_size=1024. ```. However, I am not an expert with TPUs, and this is entirely new to me. Below is the error I encountered. Do you have any suggestions or can you direct me to an updated tutorial to follow? ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 139683296487232 tpu_strategy_util.py:81] Initializing the TPU system: local. 2024-06-27 21:18:43.848149: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:2305,availability,operat,operations,2305,"ther repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 139683296487232 tpu_strategy_util.py:81] Initializing the TPU system: local. 2024-06-27 21:18:43.848149: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-06-27 21:18:43.855816: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: . Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 110, in initialize_tpu_system. output = _tpu_init_fn(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py"", line 134, in __call__. return concrete_function._call_flat(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 1745, in _call_flat. return self._build_call_outputs(self._inference_function.call(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 378, in call. outputs = execute.execute(. File ""/usr/loc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:2359,availability,operat,operations,2359,"ras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 139683296487232 tpu_strategy_util.py:81] Initializing the TPU system: local. 2024-06-27 21:18:43.848149: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-06-27 21:18:43.855816: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: . Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 110, in initialize_tpu_system. output = _tpu_init_fn(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py"", line 134, in __call__. return concrete_function._call_flat(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 1745, in _call_flat. return self._build_call_outputs(self._inference_function.call(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 378, in call. outputs = execute.execute(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:4857,availability,error,errors,4857,"cute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 109, in train. tf.tpu.experimental.initialize_tpu_system(resolver). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 113, in initialize_tpu_system. raise errors.NotFoundError(. tensorflow.python.framework.errors_impl.NotFoundError: TPUs not found in the cluster. Failed in initialization: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:4957,availability,cluster,cluster,4957,"cute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 109, in train. tf.tpu.experimental.initialize_tpu_system(resolver). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 113, in initialize_tpu_system. raise errors.NotFoundError(. tensorflow.python.framework.errors_impl.NotFoundError: TPUs not found in the cluster. Failed in initialization: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:43,deployability,manag,managed,43,"How to train deepvariant v1.6.1 on tpu?; I managed to start training on a GPU, but it took too much time. Now, I am attempting to train DeepVariant on a TPU v3-8 VM. However, the most recent tutorial I found is for version 0.9, and I am unsure how to proceed with version 1.6.1. The command I used is the following: . ```. docker run \. -v ${HOME}:${HOME} \. google/deepvariant:1.6.1 \. train \. --config=${HOME}/dv_config.py:base \. --config.train_dataset_pbtxt=""${SHUFFLE_DIR}/training_set.dataset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""${SHUFFLE_DIR}/validation_set.dataset_config.pbtxt"" \. --config.num_epochs=10 \. --config.learning_rate=0.001 \. --config.num_validation_examples=0 \. --experiment_dir=${TRAINING_DIR} \. --strategy=tpu \. --config.batch_size=1024. ```. However, I am not an expert with TPUs, and this is entirely new to me. Below is the error I encountered. Do you have any suggestions or can you direct me to an updated tutorial to follow? ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:215,deployability,version,version,215,"How to train deepvariant v1.6.1 on tpu?; I managed to start training on a GPU, but it took too much time. Now, I am attempting to train DeepVariant on a TPU v3-8 VM. However, the most recent tutorial I found is for version 0.9, and I am unsure how to proceed with version 1.6.1. The command I used is the following: . ```. docker run \. -v ${HOME}:${HOME} \. google/deepvariant:1.6.1 \. train \. --config=${HOME}/dv_config.py:base \. --config.train_dataset_pbtxt=""${SHUFFLE_DIR}/training_set.dataset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""${SHUFFLE_DIR}/validation_set.dataset_config.pbtxt"" \. --config.num_epochs=10 \. --config.learning_rate=0.001 \. --config.num_validation_examples=0 \. --experiment_dir=${TRAINING_DIR} \. --strategy=tpu \. --config.batch_size=1024. ```. However, I am not an expert with TPUs, and this is entirely new to me. Below is the error I encountered. Do you have any suggestions or can you direct me to an updated tutorial to follow? ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:264,deployability,version,version,264,"How to train deepvariant v1.6.1 on tpu?; I managed to start training on a GPU, but it took too much time. Now, I am attempting to train DeepVariant on a TPU v3-8 VM. However, the most recent tutorial I found is for version 0.9, and I am unsure how to proceed with version 1.6.1. The command I used is the following: . ```. docker run \. -v ${HOME}:${HOME} \. google/deepvariant:1.6.1 \. train \. --config=${HOME}/dv_config.py:base \. --config.train_dataset_pbtxt=""${SHUFFLE_DIR}/training_set.dataset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""${SHUFFLE_DIR}/validation_set.dataset_config.pbtxt"" \. --config.num_epochs=10 \. --config.learning_rate=0.001 \. --config.num_validation_examples=0 \. --experiment_dir=${TRAINING_DIR} \. --strategy=tpu \. --config.batch_size=1024. ```. However, I am not an expert with TPUs, and this is entirely new to me. Below is the error I encountered. Do you have any suggestions or can you direct me to an updated tutorial to follow? ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:942,deployability,updat,updated,942,"How to train deepvariant v1.6.1 on tpu?; I managed to start training on a GPU, but it took too much time. Now, I am attempting to train DeepVariant on a TPU v3-8 VM. However, the most recent tutorial I found is for version 0.9, and I am unsure how to proceed with version 1.6.1. The command I used is the following: . ```. docker run \. -v ${HOME}:${HOME} \. google/deepvariant:1.6.1 \. train \. --config=${HOME}/dv_config.py:base \. --config.train_dataset_pbtxt=""${SHUFFLE_DIR}/training_set.dataset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""${SHUFFLE_DIR}/validation_set.dataset_config.pbtxt"" \. --config.num_epochs=10 \. --config.learning_rate=0.001 \. --config.num_validation_examples=0 \. --experiment_dir=${TRAINING_DIR} \. --strategy=tpu \. --config.batch_size=1024. ```. However, I am not an expert with TPUs, and this is entirely new to me. Below is the error I encountered. Do you have any suggestions or can you direct me to an updated tutorial to follow? ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:1194,deployability,releas,release,1194,"l I found is for version 0.9, and I am unsure how to proceed with version 1.6.1. The command I used is the following: . ```. docker run \. -v ${HOME}:${HOME} \. google/deepvariant:1.6.1 \. train \. --config=${HOME}/dv_config.py:base \. --config.train_dataset_pbtxt=""${SHUFFLE_DIR}/training_set.dataset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""${SHUFFLE_DIR}/validation_set.dataset_config.pbtxt"" \. --config.num_epochs=10 \. --config.learning_rate=0.001 \. --config.num_validation_examples=0 \. --experiment_dir=${TRAINING_DIR} \. --strategy=tpu \. --config.batch_size=1024. ```. However, I am not an expert with TPUs, and this is entirely new to me. Below is the error I encountered. Do you have any suggestions or can you direct me to an updated tutorial to follow? ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 139683296487232 tpu_strategy_util.py:81] Initializing the TPU system: local. 2024-06-27 21:18:43.848149: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:1291,deployability,depend,dependencies,1291," is the following: . ```. docker run \. -v ${HOME}:${HOME} \. google/deepvariant:1.6.1 \. train \. --config=${HOME}/dv_config.py:base \. --config.train_dataset_pbtxt=""${SHUFFLE_DIR}/training_set.dataset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""${SHUFFLE_DIR}/validation_set.dataset_config.pbtxt"" \. --config.num_epochs=10 \. --config.learning_rate=0.001 \. --config.num_validation_examples=0 \. --experiment_dir=${TRAINING_DIR} \. --strategy=tpu \. --config.batch_size=1024. ```. However, I am not an expert with TPUs, and this is entirely new to me. Below is the error I encountered. Do you have any suggestions or can you direct me to an updated tutorial to follow? ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 139683296487232 tpu_strategy_util.py:81] Initializing the TPU system: local. 2024-06-27 21:18:43.848149: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:4189,deployability,modul,module,4189,"hon/eager/polymorphic_function/monomorphic_function.py"", line 378, in call. outputs = execute.execute(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py"", line 52, in quick_execute. tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 109, in train. tf.tpu.experimental.initialize_tpu_system(resolver). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 113, in initialize_tpu_system. raise errors.NotFoundError(. tensorflow.python.framework.errors_impl.NotFoundError: TPUs not found in the cluster. Failed in initialization: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:4957,deployability,cluster,cluster,4957,"cute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 109, in train. tf.tpu.experimental.initialize_tpu_system(resolver). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 113, in initialize_tpu_system. raise errors.NotFoundError(. tensorflow.python.framework.errors_impl.NotFoundError: TPUs not found in the cluster. Failed in initialization: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:4966,deployability,Fail,Failed,4966,"cute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 109, in train. tf.tpu.experimental.initialize_tpu_system(resolver). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 113, in initialize_tpu_system. raise errors.NotFoundError(. tensorflow.python.framework.errors_impl.NotFoundError: TPUs not found in the cluster. Failed in initialization: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:43,energy efficiency,manag,managed,43,"How to train deepvariant v1.6.1 on tpu?; I managed to start training on a GPU, but it took too much time. Now, I am attempting to train DeepVariant on a TPU v3-8 VM. However, the most recent tutorial I found is for version 0.9, and I am unsure how to proceed with version 1.6.1. The command I used is the following: . ```. docker run \. -v ${HOME}:${HOME} \. google/deepvariant:1.6.1 \. train \. --config=${HOME}/dv_config.py:base \. --config.train_dataset_pbtxt=""${SHUFFLE_DIR}/training_set.dataset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""${SHUFFLE_DIR}/validation_set.dataset_config.pbtxt"" \. --config.num_epochs=10 \. --config.learning_rate=0.001 \. --config.num_validation_examples=0 \. --experiment_dir=${TRAINING_DIR} \. --strategy=tpu \. --config.batch_size=1024. ```. However, I am not an expert with TPUs, and this is entirely new to me. Below is the error I encountered. Do you have any suggestions or can you direct me to an updated tutorial to follow? ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:74,energy efficiency,GPU,GPU,74,"How to train deepvariant v1.6.1 on tpu?; I managed to start training on a GPU, but it took too much time. Now, I am attempting to train DeepVariant on a TPU v3-8 VM. However, the most recent tutorial I found is for version 0.9, and I am unsure how to proceed with version 1.6.1. The command I used is the following: . ```. docker run \. -v ${HOME}:${HOME} \. google/deepvariant:1.6.1 \. train \. --config=${HOME}/dv_config.py:base \. --config.train_dataset_pbtxt=""${SHUFFLE_DIR}/training_set.dataset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""${SHUFFLE_DIR}/validation_set.dataset_config.pbtxt"" \. --config.num_epochs=10 \. --config.learning_rate=0.001 \. --config.num_validation_examples=0 \. --experiment_dir=${TRAINING_DIR} \. --strategy=tpu \. --config.batch_size=1024. ```. However, I am not an expert with TPUs, and this is entirely new to me. Below is the error I encountered. Do you have any suggestions or can you direct me to an updated tutorial to follow? ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:2118,energy efficiency,core,core,2118,"d introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 139683296487232 tpu_strategy_util.py:81] Initializing the TPU system: local. 2024-06-27 21:18:43.848149: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-06-27 21:18:43.855816: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: . Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 110, in initialize_tpu_system. output = _tpu_init_fn(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py"", line 134, in __call__. return concrete_function._call_flat(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 1745, in _call_flat. return self._build_call_outputs(self._inference_fun",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:2184,energy efficiency,optim,optimized,2184," and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 139683296487232 tpu_strategy_util.py:81] Initializing the TPU system: local. 2024-06-27 21:18:43.848149: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-06-27 21:18:43.855816: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: . Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 110, in initialize_tpu_system. output = _tpu_init_fn(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py"", line 134, in __call__. return concrete_function._call_flat(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 1745, in _call_flat. return self._build_call_outputs(self._inference_function.call(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:2264,energy efficiency,CPU,CPU,2264,"stream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 139683296487232 tpu_strategy_util.py:81] Initializing the TPU system: local. 2024-06-27 21:18:43.848149: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-06-27 21:18:43.855816: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: . Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 110, in initialize_tpu_system. output = _tpu_init_fn(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py"", line 134, in __call__. return concrete_function._call_flat(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 1745, in _call_flat. return self._build_call_outputs(self._inference_function.call(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 378, in call",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:2468,energy efficiency,core,core,2468,"7 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 139683296487232 tpu_strategy_util.py:81] Initializing the TPU system: local. 2024-06-27 21:18:43.848149: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-06-27 21:18:43.855816: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: . Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 110, in initialize_tpu_system. output = _tpu_init_fn(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py"", line 134, in __call__. return concrete_function._call_flat(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 1745, in _call_flat. return self._build_call_outputs(self._inference_function.call(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 378, in call. outputs = execute.execute(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py"", line 52, in quick_execute. tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:3867,energy efficiency,CPU,CPU,3867,"e 134, in __call__. return concrete_function._call_flat(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 1745, in _call_flat. return self._build_call_outputs(self._inference_function.call(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 378, in call. outputs = execute.execute(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py"", line 52, in quick_execute. tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 109, in train. tf.tpu.experimental.initialize_tpu_system(resolver). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 113, in initialize_tpu_system. raise errors.NotFo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:5320,energy efficiency,CPU,CPU,5320,"cute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 109, in train. tf.tpu.experimental.initialize_tpu_system(resolver). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 113, in initialize_tpu_system. raise errors.NotFoundError(. tensorflow.python.framework.errors_impl.NotFoundError: TPUs not found in the cluster. Failed in initialization: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:215,integrability,version,version,215,"How to train deepvariant v1.6.1 on tpu?; I managed to start training on a GPU, but it took too much time. Now, I am attempting to train DeepVariant on a TPU v3-8 VM. However, the most recent tutorial I found is for version 0.9, and I am unsure how to proceed with version 1.6.1. The command I used is the following: . ```. docker run \. -v ${HOME}:${HOME} \. google/deepvariant:1.6.1 \. train \. --config=${HOME}/dv_config.py:base \. --config.train_dataset_pbtxt=""${SHUFFLE_DIR}/training_set.dataset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""${SHUFFLE_DIR}/validation_set.dataset_config.pbtxt"" \. --config.num_epochs=10 \. --config.learning_rate=0.001 \. --config.num_validation_examples=0 \. --experiment_dir=${TRAINING_DIR} \. --strategy=tpu \. --config.batch_size=1024. ```. However, I am not an expert with TPUs, and this is entirely new to me. Below is the error I encountered. Do you have any suggestions or can you direct me to an updated tutorial to follow? ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:264,integrability,version,version,264,"How to train deepvariant v1.6.1 on tpu?; I managed to start training on a GPU, but it took too much time. Now, I am attempting to train DeepVariant on a TPU v3-8 VM. However, the most recent tutorial I found is for version 0.9, and I am unsure how to proceed with version 1.6.1. The command I used is the following: . ```. docker run \. -v ${HOME}:${HOME} \. google/deepvariant:1.6.1 \. train \. --config=${HOME}/dv_config.py:base \. --config.train_dataset_pbtxt=""${SHUFFLE_DIR}/training_set.dataset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""${SHUFFLE_DIR}/validation_set.dataset_config.pbtxt"" \. --config.num_epochs=10 \. --config.learning_rate=0.001 \. --config.num_validation_examples=0 \. --experiment_dir=${TRAINING_DIR} \. --strategy=tpu \. --config.batch_size=1024. ```. However, I am not an expert with TPUs, and this is entirely new to me. Below is the error I encountered. Do you have any suggestions or can you direct me to an updated tutorial to follow? ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:1291,integrability,depend,dependencies,1291," is the following: . ```. docker run \. -v ${HOME}:${HOME} \. google/deepvariant:1.6.1 \. train \. --config=${HOME}/dv_config.py:base \. --config.train_dataset_pbtxt=""${SHUFFLE_DIR}/training_set.dataset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""${SHUFFLE_DIR}/validation_set.dataset_config.pbtxt"" \. --config.num_epochs=10 \. --config.learning_rate=0.001 \. --config.num_validation_examples=0 \. --experiment_dir=${TRAINING_DIR} \. --strategy=tpu \. --config.batch_size=1024. ```. However, I am not an expert with TPUs, and this is entirely new to me. Below is the error I encountered. Do you have any suggestions or can you direct me to an updated tutorial to follow? ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 139683296487232 tpu_strategy_util.py:81] Initializing the TPU system: local. 2024-06-27 21:18:43.848149: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:1315,integrability,repositor,repositories,1315,". docker run \. -v ${HOME}:${HOME} \. google/deepvariant:1.6.1 \. train \. --config=${HOME}/dv_config.py:base \. --config.train_dataset_pbtxt=""${SHUFFLE_DIR}/training_set.dataset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""${SHUFFLE_DIR}/validation_set.dataset_config.pbtxt"" \. --config.num_epochs=10 \. --config.learning_rate=0.001 \. --config.num_validation_examples=0 \. --experiment_dir=${TRAINING_DIR} \. --strategy=tpu \. --config.batch_size=1024. ```. However, I am not an expert with TPUs, and this is entirely new to me. Below is the error I encountered. Do you have any suggestions or can you direct me to an updated tutorial to follow? ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 139683296487232 tpu_strategy_util.py:81] Initializing the TPU system: local. 2024-06-27 21:18:43.848149: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:1768,integrability,buffer,buffers,1768,"024. ```. However, I am not an expert with TPUs, and this is entirely new to me. Below is the error I encountered. Do you have any suggestions or can you direct me to an updated tutorial to follow? ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 139683296487232 tpu_strategy_util.py:81] Initializing the TPU system: local. 2024-06-27 21:18:43.848149: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-06-27 21:18:43.855816: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: . Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 110, in initialize_tpu_system. output = _tpu_init_fn(). File ""/usr/local/l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:1886,integrability,buffer,buffers,1886,"you have any suggestions or can you direct me to an updated tutorial to follow? ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 139683296487232 tpu_strategy_util.py:81] Initializing the TPU system: local. 2024-06-27 21:18:43.848149: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-06-27 21:18:43.855816: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: . Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 110, in initialize_tpu_system. output = _tpu_init_fn(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py"", line 134, in __call__. r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:3581,integrability,Configur,ConfigureDistributedTPU,3581,"l last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 110, in initialize_tpu_system. output = _tpu_init_fn(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py"", line 134, in __call__. return concrete_function._call_flat(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 1745, in _call_flat. return self._build_call_outputs(self._inference_function.call(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 378, in call. outputs = execute.execute(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py"", line 52, in quick_execute. tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ol6r0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:3621,integrability,Configur,ConfigureDistributedTPU,3621,"/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 110, in initialize_tpu_system. output = _tpu_init_fn(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py"", line 134, in __call__. return concrete_function._call_flat(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 1745, in _call_flat. return self._build_call_outputs(self._inference_function.call(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 378, in call. outputs = execute.execute(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py"", line 52, in quick_execute. tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:3921,integrability,Configur,ConfigureDistributedTPU,3921,"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 1745, in _call_flat. return self._build_call_outputs(self._inference_function.call(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 378, in call. outputs = execute.execute(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py"", line 52, in quick_execute. tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 109, in train. tf.tpu.experimental.initialize_tpu_system(resolver). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 113, in initialize_tpu_system. raise errors.NotFoundError(. tensorflow.python.framework.errors_impl.NotFoundError",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:5034,integrability,Configur,ConfigureDistributedTPU,5034,"cute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 109, in train. tf.tpu.experimental.initialize_tpu_system(resolver). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 113, in initialize_tpu_system. raise errors.NotFoundError(. tensorflow.python.framework.errors_impl.NotFoundError: TPUs not found in the cluster. Failed in initialization: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:5074,integrability,Configur,ConfigureDistributedTPU,5074,"cute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 109, in train. tf.tpu.experimental.initialize_tpu_system(resolver). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 113, in initialize_tpu_system. raise errors.NotFoundError(. tensorflow.python.framework.errors_impl.NotFoundError: TPUs not found in the cluster. Failed in initialization: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:5374,integrability,Configur,ConfigureDistributedTPU,5374,"cute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 109, in train. tf.tpu.experimental.initialize_tpu_system(resolver). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 113, in initialize_tpu_system. raise errors.NotFoundError(. tensorflow.python.framework.errors_impl.NotFoundError: TPUs not found in the cluster. Failed in initialization: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:1315,interoperability,repositor,repositories,1315,". docker run \. -v ${HOME}:${HOME} \. google/deepvariant:1.6.1 \. train \. --config=${HOME}/dv_config.py:base \. --config.train_dataset_pbtxt=""${SHUFFLE_DIR}/training_set.dataset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""${SHUFFLE_DIR}/validation_set.dataset_config.pbtxt"" \. --config.num_epochs=10 \. --config.learning_rate=0.001 \. --config.num_validation_examples=0 \. --experiment_dir=${TRAINING_DIR} \. --strategy=tpu \. --config.batch_size=1024. ```. However, I am not an expert with TPUs, and this is entirely new to me. Below is the error I encountered. Do you have any suggestions or can you direct me to an updated tutorial to follow? ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 139683296487232 tpu_strategy_util.py:81] Initializing the TPU system: local. 2024-06-27 21:18:43.848149: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:2123,interoperability,platform,platform,2123,"duction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 139683296487232 tpu_strategy_util.py:81] Initializing the TPU system: local. 2024-06-27 21:18:43.848149: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-06-27 21:18:43.855816: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: . Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 110, in initialize_tpu_system. output = _tpu_init_fn(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py"", line 134, in __call__. return concrete_function._call_flat(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 1745, in _call_flat. return self._build_call_outputs(self._inference_function.c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:215,modifiability,version,version,215,"How to train deepvariant v1.6.1 on tpu?; I managed to start training on a GPU, but it took too much time. Now, I am attempting to train DeepVariant on a TPU v3-8 VM. However, the most recent tutorial I found is for version 0.9, and I am unsure how to proceed with version 1.6.1. The command I used is the following: . ```. docker run \. -v ${HOME}:${HOME} \. google/deepvariant:1.6.1 \. train \. --config=${HOME}/dv_config.py:base \. --config.train_dataset_pbtxt=""${SHUFFLE_DIR}/training_set.dataset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""${SHUFFLE_DIR}/validation_set.dataset_config.pbtxt"" \. --config.num_epochs=10 \. --config.learning_rate=0.001 \. --config.num_validation_examples=0 \. --experiment_dir=${TRAINING_DIR} \. --strategy=tpu \. --config.batch_size=1024. ```. However, I am not an expert with TPUs, and this is entirely new to me. Below is the error I encountered. Do you have any suggestions or can you direct me to an updated tutorial to follow? ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:264,modifiability,version,version,264,"How to train deepvariant v1.6.1 on tpu?; I managed to start training on a GPU, but it took too much time. Now, I am attempting to train DeepVariant on a TPU v3-8 VM. However, the most recent tutorial I found is for version 0.9, and I am unsure how to proceed with version 1.6.1. The command I used is the following: . ```. docker run \. -v ${HOME}:${HOME} \. google/deepvariant:1.6.1 \. train \. --config=${HOME}/dv_config.py:base \. --config.train_dataset_pbtxt=""${SHUFFLE_DIR}/training_set.dataset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""${SHUFFLE_DIR}/validation_set.dataset_config.pbtxt"" \. --config.num_epochs=10 \. --config.learning_rate=0.001 \. --config.num_validation_examples=0 \. --experiment_dir=${TRAINING_DIR} \. --strategy=tpu \. --config.batch_size=1024. ```. However, I am not an expert with TPUs, and this is entirely new to me. Below is the error I encountered. Do you have any suggestions or can you direct me to an updated tutorial to follow? ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:1005,modifiability,pac,packages,1005,"ain deepvariant v1.6.1 on tpu?; I managed to start training on a GPU, but it took too much time. Now, I am attempting to train DeepVariant on a TPU v3-8 VM. However, the most recent tutorial I found is for version 0.9, and I am unsure how to proceed with version 1.6.1. The command I used is the following: . ```. docker run \. -v ${HOME}:${HOME} \. google/deepvariant:1.6.1 \. train \. --config=${HOME}/dv_config.py:base \. --config.train_dataset_pbtxt=""${SHUFFLE_DIR}/training_set.dataset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""${SHUFFLE_DIR}/validation_set.dataset_config.pbtxt"" \. --config.num_epochs=10 \. --config.learning_rate=0.001 \. --config.num_validation_examples=0 \. --experiment_dir=${TRAINING_DIR} \. --strategy=tpu \. --config.batch_size=1024. ```. However, I am not an expert with TPUs, and this is entirely new to me. Below is the error I encountered. Do you have any suggestions or can you direct me to an updated tutorial to follow? ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 139683296",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:1291,modifiability,depend,dependencies,1291," is the following: . ```. docker run \. -v ${HOME}:${HOME} \. google/deepvariant:1.6.1 \. train \. --config=${HOME}/dv_config.py:base \. --config.train_dataset_pbtxt=""${SHUFFLE_DIR}/training_set.dataset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""${SHUFFLE_DIR}/validation_set.dataset_config.pbtxt"" \. --config.num_epochs=10 \. --config.learning_rate=0.001 \. --config.num_validation_examples=0 \. --experiment_dir=${TRAINING_DIR} \. --strategy=tpu \. --config.batch_size=1024. ```. However, I am not an expert with TPUs, and this is entirely new to me. Below is the error I encountered. Do you have any suggestions or can you direct me to an updated tutorial to follow? ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 139683296487232 tpu_strategy_util.py:81] Initializing the TPU system: local. 2024-06-27 21:18:43.848149: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:2639,modifiability,pac,packages,2639,"21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 139683296487232 tpu_strategy_util.py:81] Initializing the TPU system: local. 2024-06-27 21:18:43.848149: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-06-27 21:18:43.855816: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: . Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 110, in initialize_tpu_system. output = _tpu_init_fn(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py"", line 134, in __call__. return concrete_function._call_flat(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 1745, in _call_flat. return self._build_call_outputs(self._inference_function.call(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 378, in call. outputs = execute.execute(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py"", line 52, in quick_execute. tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTP",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:2790,modifiability,pac,packages,2790,"g tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 139683296487232 tpu_strategy_util.py:81] Initializing the TPU system: local. 2024-06-27 21:18:43.848149: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-06-27 21:18:43.855816: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: . Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 110, in initialize_tpu_system. output = _tpu_init_fn(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py"", line 134, in __call__. return concrete_function._call_flat(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 1745, in _call_flat. return self._build_call_outputs(self._inference_function.call(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 378, in call. outputs = execute.execute(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py"", line 52, in quick_execute. tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_wh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:2963,modifiability,pac,packages,2963,"em: local. I0627 21:18:43.846984 139683296487232 tpu_strategy_util.py:81] Initializing the TPU system: local. 2024-06-27 21:18:43.848149: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-06-27 21:18:43.855816: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: . Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 110, in initialize_tpu_system. output = _tpu_init_fn(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py"", line 134, in __call__. return concrete_function._call_flat(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 1745, in _call_flat. return self._build_call_outputs(self._inference_function.call(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 378, in call. outputs = execute.execute(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py"", line 52, in quick_execute. tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:3169,modifiability,pac,packages,3169," binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-06-27 21:18:43.855816: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: . Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 110, in initialize_tpu_system. output = _tpu_init_fn(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py"", line 134, in __call__. return concrete_function._call_flat(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 1745, in _call_flat. return self._build_call_outputs(self._inference_function.call(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 378, in call. outputs = execute.execute(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py"", line 52, in quick_execute. tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:3332,modifiability,pac,packages,3332,"o enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-06-27 21:18:43.855816: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: . Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 110, in initialize_tpu_system. output = _tpu_init_fn(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py"", line 134, in __call__. return concrete_function._call_flat(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 1745, in _call_flat. return self._build_call_outputs(self._inference_function.call(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 378, in call. outputs = execute.execute(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py"", line 52, in quick_execute. tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:3581,modifiability,Configur,ConfigureDistributedTPU,3581,"l last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 110, in initialize_tpu_system. output = _tpu_init_fn(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py"", line 134, in __call__. return concrete_function._call_flat(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 1745, in _call_flat. return self._build_call_outputs(self._inference_function.call(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 378, in call. outputs = execute.execute(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py"", line 52, in quick_execute. tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ol6r0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:3621,modifiability,Configur,ConfigureDistributedTPU,3621,"/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 110, in initialize_tpu_system. output = _tpu_init_fn(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py"", line 134, in __call__. return concrete_function._call_flat(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 1745, in _call_flat. return self._build_call_outputs(self._inference_function.call(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 378, in call. outputs = execute.execute(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py"", line 52, in quick_execute. tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:3921,modifiability,Configur,ConfigureDistributedTPU,3921,"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 1745, in _call_flat. return self._build_call_outputs(self._inference_function.call(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 378, in call. outputs = execute.execute(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py"", line 52, in quick_execute. tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 109, in train. tf.tpu.experimental.initialize_tpu_system(resolver). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 113, in initialize_tpu_system. raise errors.NotFoundError(. tensorflow.python.framework.errors_impl.NotFoundError",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:4189,modifiability,modul,module,4189,"hon/eager/polymorphic_function/monomorphic_function.py"", line 378, in call. outputs = execute.execute(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py"", line 52, in quick_execute. tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 109, in train. tf.tpu.experimental.initialize_tpu_system(resolver). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 113, in initialize_tpu_system. raise errors.NotFoundError(. tensorflow.python.framework.errors_impl.NotFoundError: TPUs not found in the cluster. Failed in initialization: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:4761,modifiability,pac,packages,4761,"cute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 109, in train. tf.tpu.experimental.initialize_tpu_system(resolver). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 113, in initialize_tpu_system. raise errors.NotFoundError(. tensorflow.python.framework.errors_impl.NotFoundError: TPUs not found in the cluster. Failed in initialization: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:5034,modifiability,Configur,ConfigureDistributedTPU,5034,"cute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 109, in train. tf.tpu.experimental.initialize_tpu_system(resolver). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 113, in initialize_tpu_system. raise errors.NotFoundError(. tensorflow.python.framework.errors_impl.NotFoundError: TPUs not found in the cluster. Failed in initialization: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:5074,modifiability,Configur,ConfigureDistributedTPU,5074,"cute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 109, in train. tf.tpu.experimental.initialize_tpu_system(resolver). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 113, in initialize_tpu_system. raise errors.NotFoundError(. tensorflow.python.framework.errors_impl.NotFoundError: TPUs not found in the cluster. Failed in initialization: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:5374,modifiability,Configur,ConfigureDistributedTPU,5374,"cute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 109, in train. tf.tpu.experimental.initialize_tpu_system(resolver). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 113, in initialize_tpu_system. raise errors.NotFoundError(. tensorflow.python.framework.errors_impl.NotFoundError: TPUs not found in the cluster. Failed in initialization: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:74,performance,GPU,GPU,74,"How to train deepvariant v1.6.1 on tpu?; I managed to start training on a GPU, but it took too much time. Now, I am attempting to train DeepVariant on a TPU v3-8 VM. However, the most recent tutorial I found is for version 0.9, and I am unsure how to proceed with version 1.6.1. The command I used is the following: . ```. docker run \. -v ${HOME}:${HOME} \. google/deepvariant:1.6.1 \. train \. --config=${HOME}/dv_config.py:base \. --config.train_dataset_pbtxt=""${SHUFFLE_DIR}/training_set.dataset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""${SHUFFLE_DIR}/validation_set.dataset_config.pbtxt"" \. --config.num_epochs=10 \. --config.learning_rate=0.001 \. --config.num_validation_examples=0 \. --experiment_dir=${TRAINING_DIR} \. --strategy=tpu \. --config.batch_size=1024. ```. However, I am not an expert with TPUs, and this is entirely new to me. Below is the error I encountered. Do you have any suggestions or can you direct me to an updated tutorial to follow? ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:100,performance,time,time,100,"How to train deepvariant v1.6.1 on tpu?; I managed to start training on a GPU, but it took too much time. Now, I am attempting to train DeepVariant on a TPU v3-8 VM. However, the most recent tutorial I found is for version 0.9, and I am unsure how to proceed with version 1.6.1. The command I used is the following: . ```. docker run \. -v ${HOME}:${HOME} \. google/deepvariant:1.6.1 \. train \. --config=${HOME}/dv_config.py:base \. --config.train_dataset_pbtxt=""${SHUFFLE_DIR}/training_set.dataset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""${SHUFFLE_DIR}/validation_set.dataset_config.pbtxt"" \. --config.num_epochs=10 \. --config.learning_rate=0.001 \. --config.num_validation_examples=0 \. --experiment_dir=${TRAINING_DIR} \. --strategy=tpu \. --config.batch_size=1024. ```. However, I am not an expert with TPUs, and this is entirely new to me. Below is the error I encountered. Do you have any suggestions or can you direct me to an updated tutorial to follow? ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:866,performance,error,error,866,"How to train deepvariant v1.6.1 on tpu?; I managed to start training on a GPU, but it took too much time. Now, I am attempting to train DeepVariant on a TPU v3-8 VM. However, the most recent tutorial I found is for version 0.9, and I am unsure how to proceed with version 1.6.1. The command I used is the following: . ```. docker run \. -v ${HOME}:${HOME} \. google/deepvariant:1.6.1 \. train \. --config=${HOME}/dv_config.py:base \. --config.train_dataset_pbtxt=""${SHUFFLE_DIR}/training_set.dataset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""${SHUFFLE_DIR}/validation_set.dataset_config.pbtxt"" \. --config.num_epochs=10 \. --config.learning_rate=0.001 \. --config.num_validation_examples=0 \. --experiment_dir=${TRAINING_DIR} \. --strategy=tpu \. --config.batch_size=1024. ```. However, I am not an expert with TPUs, and this is entirely new to me. Below is the error I encountered. Do you have any suggestions or can you direct me to an updated tutorial to follow? ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:2184,performance,optimiz,optimized,2184," and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 139683296487232 tpu_strategy_util.py:81] Initializing the TPU system: local. 2024-06-27 21:18:43.848149: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-06-27 21:18:43.855816: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: . Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 110, in initialize_tpu_system. output = _tpu_init_fn(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py"", line 134, in __call__. return concrete_function._call_flat(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 1745, in _call_flat. return self._build_call_outputs(self._inference_function.call(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:2218,performance,Network,Network,2218," end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 139683296487232 tpu_strategy_util.py:81] Initializing the TPU system: local. 2024-06-27 21:18:43.848149: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-06-27 21:18:43.855816: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: . Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 110, in initialize_tpu_system. output = _tpu_init_fn(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py"", line 134, in __call__. return concrete_function._call_flat(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 1745, in _call_flat. return self._build_call_outputs(self._inference_function.call(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:2264,performance,CPU,CPU,2264,"stream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 139683296487232 tpu_strategy_util.py:81] Initializing the TPU system: local. 2024-06-27 21:18:43.848149: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-06-27 21:18:43.855816: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: . Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 110, in initialize_tpu_system. output = _tpu_init_fn(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py"", line 134, in __call__. return concrete_function._call_flat(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 1745, in _call_flat. return self._build_call_outputs(self._inference_function.call(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 378, in call",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:2284,performance,perform,performance-critical,2284,"endencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 139683296487232 tpu_strategy_util.py:81] Initializing the TPU system: local. 2024-06-27 21:18:43.848149: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-06-27 21:18:43.855816: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: . Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 110, in initialize_tpu_system. output = _tpu_init_fn(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py"", line 134, in __call__. return concrete_function._call_flat(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 1745, in _call_flat. return self._build_call_outputs(self._inference_function.call(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 378, in call. outputs = execute.execute(",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:3867,performance,CPU,CPU,3867,"e 134, in __call__. return concrete_function._call_flat(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 1745, in _call_flat. return self._build_call_outputs(self._inference_function.call(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 378, in call. outputs = execute.execute(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py"", line 52, in quick_execute. tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 109, in train. tf.tpu.experimental.initialize_tpu_system(resolver). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 113, in initialize_tpu_system. raise errors.NotFo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:4857,performance,error,errors,4857,"cute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 109, in train. tf.tpu.experimental.initialize_tpu_system(resolver). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 113, in initialize_tpu_system. raise errors.NotFoundError(. tensorflow.python.framework.errors_impl.NotFoundError: TPUs not found in the cluster. Failed in initialization: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:5320,performance,CPU,CPU,5320,"cute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 109, in train. tf.tpu.experimental.initialize_tpu_system(resolver). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 113, in initialize_tpu_system. raise errors.NotFoundError(. tensorflow.python.framework.errors_impl.NotFoundError: TPUs not found in the cluster. Failed in initialization: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:1178,reliability,mainten,maintenance,1178,"recent tutorial I found is for version 0.9, and I am unsure how to proceed with version 1.6.1. The command I used is the following: . ```. docker run \. -v ${HOME}:${HOME} \. google/deepvariant:1.6.1 \. train \. --config=${HOME}/dv_config.py:base \. --config.train_dataset_pbtxt=""${SHUFFLE_DIR}/training_set.dataset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""${SHUFFLE_DIR}/validation_set.dataset_config.pbtxt"" \. --config.num_epochs=10 \. --config.learning_rate=0.001 \. --config.num_validation_examples=0 \. --experiment_dir=${TRAINING_DIR} \. --strategy=tpu \. --config.batch_size=1024. ```. However, I am not an expert with TPUs, and this is entirely new to me. Below is the error I encountered. Do you have any suggestions or can you direct me to an updated tutorial to follow? ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 139683296487232 tpu_strategy_util.py:81] Initializing the TPU system: local. 2024-06-27 21:18:43.848149: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:4966,reliability,Fail,Failed,4966,"cute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 109, in train. tf.tpu.experimental.initialize_tpu_system(resolver). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 113, in initialize_tpu_system. raise errors.NotFoundError(. tensorflow.python.framework.errors_impl.NotFoundError: TPUs not found in the cluster. Failed in initialization: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:43,safety,manag,managed,43,"How to train deepvariant v1.6.1 on tpu?; I managed to start training on a GPU, but it took too much time. Now, I am attempting to train DeepVariant on a TPU v3-8 VM. However, the most recent tutorial I found is for version 0.9, and I am unsure how to proceed with version 1.6.1. The command I used is the following: . ```. docker run \. -v ${HOME}:${HOME} \. google/deepvariant:1.6.1 \. train \. --config=${HOME}/dv_config.py:base \. --config.train_dataset_pbtxt=""${SHUFFLE_DIR}/training_set.dataset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""${SHUFFLE_DIR}/validation_set.dataset_config.pbtxt"" \. --config.num_epochs=10 \. --config.learning_rate=0.001 \. --config.num_validation_examples=0 \. --experiment_dir=${TRAINING_DIR} \. --strategy=tpu \. --config.batch_size=1024. ```. However, I am not an expert with TPUs, and this is entirely new to me. Below is the error I encountered. Do you have any suggestions or can you direct me to an updated tutorial to follow? ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:866,safety,error,error,866,"How to train deepvariant v1.6.1 on tpu?; I managed to start training on a GPU, but it took too much time. Now, I am attempting to train DeepVariant on a TPU v3-8 VM. However, the most recent tutorial I found is for version 0.9, and I am unsure how to proceed with version 1.6.1. The command I used is the following: . ```. docker run \. -v ${HOME}:${HOME} \. google/deepvariant:1.6.1 \. train \. --config=${HOME}/dv_config.py:base \. --config.train_dataset_pbtxt=""${SHUFFLE_DIR}/training_set.dataset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""${SHUFFLE_DIR}/validation_set.dataset_config.pbtxt"" \. --config.num_epochs=10 \. --config.learning_rate=0.001 \. --config.num_validation_examples=0 \. --experiment_dir=${TRAINING_DIR} \. --strategy=tpu \. --config.batch_size=1024. ```. However, I am not an expert with TPUs, and this is entirely new to me. Below is the error I encountered. Do you have any suggestions or can you direct me to an updated tutorial to follow? ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:942,safety,updat,updated,942,"How to train deepvariant v1.6.1 on tpu?; I managed to start training on a GPU, but it took too much time. Now, I am attempting to train DeepVariant on a TPU v3-8 VM. However, the most recent tutorial I found is for version 0.9, and I am unsure how to proceed with version 1.6.1. The command I used is the following: . ```. docker run \. -v ${HOME}:${HOME} \. google/deepvariant:1.6.1 \. train \. --config=${HOME}/dv_config.py:base \. --config.train_dataset_pbtxt=""${SHUFFLE_DIR}/training_set.dataset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""${SHUFFLE_DIR}/validation_set.dataset_config.pbtxt"" \. --config.num_epochs=10 \. --config.learning_rate=0.001 \. --config.num_validation_examples=0 \. --experiment_dir=${TRAINING_DIR} \. --strategy=tpu \. --config.batch_size=1024. ```. However, I am not an expert with TPUs, and this is entirely new to me. Below is the error I encountered. Do you have any suggestions or can you direct me to an updated tutorial to follow? ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:1291,safety,depend,dependencies,1291," is the following: . ```. docker run \. -v ${HOME}:${HOME} \. google/deepvariant:1.6.1 \. train \. --config=${HOME}/dv_config.py:base \. --config.train_dataset_pbtxt=""${SHUFFLE_DIR}/training_set.dataset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""${SHUFFLE_DIR}/validation_set.dataset_config.pbtxt"" \. --config.num_epochs=10 \. --config.learning_rate=0.001 \. --config.num_validation_examples=0 \. --experiment_dir=${TRAINING_DIR} \. --strategy=tpu \. --config.batch_size=1024. ```. However, I am not an expert with TPUs, and this is entirely new to me. Below is the error I encountered. Do you have any suggestions or can you direct me to an updated tutorial to follow? ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 139683296487232 tpu_strategy_util.py:81] Initializing the TPU system: local. 2024-06-27 21:18:43.848149: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:4009,safety,except,exception,4009,"on/monomorphic_function.py"", line 1745, in _call_flat. return self._build_call_outputs(self._inference_function.call(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 378, in call. outputs = execute.execute(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py"", line 52, in quick_execute. tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 109, in train. tf.tpu.experimental.initialize_tpu_system(resolver). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 113, in initialize_tpu_system. raise errors.NotFoundError(. tensorflow.python.framework.errors_impl.NotFoundError: TPUs not found in the cluster. Failed in initialization: No OpKernel was regist",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:4028,safety,except,exception,4028,"tion.py"", line 1745, in _call_flat. return self._build_call_outputs(self._inference_function.call(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 378, in call. outputs = execute.execute(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py"", line 52, in quick_execute. tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 109, in train. tf.tpu.experimental.initialize_tpu_system(resolver). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 113, in initialize_tpu_system. raise errors.NotFoundError(. tensorflow.python.framework.errors_impl.NotFoundError: TPUs not found in the cluster. Failed in initialization: No OpKernel was registered to support Op ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:4189,safety,modul,module,4189,"hon/eager/polymorphic_function/monomorphic_function.py"", line 378, in call. outputs = execute.execute(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py"", line 52, in quick_execute. tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 109, in train. tf.tpu.experimental.initialize_tpu_system(resolver). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 113, in initialize_tpu_system. raise errors.NotFoundError(. tensorflow.python.framework.errors_impl.NotFoundError: TPUs not found in the cluster. Failed in initialization: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:4857,safety,error,errors,4857,"cute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 109, in train. tf.tpu.experimental.initialize_tpu_system(resolver). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 113, in initialize_tpu_system. raise errors.NotFoundError(. tensorflow.python.framework.errors_impl.NotFoundError: TPUs not found in the cluster. Failed in initialization: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:942,security,updat,updated,942,"How to train deepvariant v1.6.1 on tpu?; I managed to start training on a GPU, but it took too much time. Now, I am attempting to train DeepVariant on a TPU v3-8 VM. However, the most recent tutorial I found is for version 0.9, and I am unsure how to proceed with version 1.6.1. The command I used is the following: . ```. docker run \. -v ${HOME}:${HOME} \. google/deepvariant:1.6.1 \. train \. --config=${HOME}/dv_config.py:base \. --config.train_dataset_pbtxt=""${SHUFFLE_DIR}/training_set.dataset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""${SHUFFLE_DIR}/validation_set.dataset_config.pbtxt"" \. --config.num_epochs=10 \. --config.learning_rate=0.001 \. --config.num_validation_examples=0 \. --experiment_dir=${TRAINING_DIR} \. --strategy=tpu \. --config.batch_size=1024. ```. However, I am not an expert with TPUs, and this is entirely new to me. Below is the error I encountered. Do you have any suggestions or can you direct me to an updated tutorial to follow? ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:1255,security,modif,modify,1255," with version 1.6.1. The command I used is the following: . ```. docker run \. -v ${HOME}:${HOME} \. google/deepvariant:1.6.1 \. train \. --config=${HOME}/dv_config.py:base \. --config.train_dataset_pbtxt=""${SHUFFLE_DIR}/training_set.dataset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""${SHUFFLE_DIR}/validation_set.dataset_config.pbtxt"" \. --config.num_epochs=10 \. --config.learning_rate=0.001 \. --config.num_validation_examples=0 \. --experiment_dir=${TRAINING_DIR} \. --strategy=tpu \. --config.batch_size=1024. ```. However, I am not an expert with TPUs, and this is entirely new to me. Below is the error I encountered. Do you have any suggestions or can you direct me to an updated tutorial to follow? ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 139683296487232 tpu_strategy_util.py:81] Initializing the TPU system: local. 2024-06-27 21:18:43.848149: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the foll",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:2218,security,Network,Network,2218," end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 139683296487232 tpu_strategy_util.py:81] Initializing the TPU system: local. 2024-06-27 21:18:43.848149: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-06-27 21:18:43.855816: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: . Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 110, in initialize_tpu_system. output = _tpu_init_fn(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py"", line 134, in __call__. return concrete_function._call_flat(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 1745, in _call_flat. return self._build_call_outputs(self._inference_function.call(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:3581,security,Configur,ConfigureDistributedTPU,3581,"l last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 110, in initialize_tpu_system. output = _tpu_init_fn(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py"", line 134, in __call__. return concrete_function._call_flat(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 1745, in _call_flat. return self._build_call_outputs(self._inference_function.call(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 378, in call. outputs = execute.execute(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py"", line 52, in quick_execute. tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ol6r0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:3621,security,Configur,ConfigureDistributedTPU,3621,"/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 110, in initialize_tpu_system. output = _tpu_init_fn(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py"", line 134, in __call__. return concrete_function._call_flat(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 1745, in _call_flat. return self._build_call_outputs(self._inference_function.call(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 378, in call. outputs = execute.execute(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py"", line 52, in quick_execute. tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:3921,security,Configur,ConfigureDistributedTPU,3921,"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 1745, in _call_flat. return self._build_call_outputs(self._inference_function.call(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 378, in call. outputs = execute.execute(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py"", line 52, in quick_execute. tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 109, in train. tf.tpu.experimental.initialize_tpu_system(resolver). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 113, in initialize_tpu_system. raise errors.NotFoundError(. tensorflow.python.framework.errors_impl.NotFoundError",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:5034,security,Configur,ConfigureDistributedTPU,5034,"cute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 109, in train. tf.tpu.experimental.initialize_tpu_system(resolver). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 113, in initialize_tpu_system. raise errors.NotFoundError(. tensorflow.python.framework.errors_impl.NotFoundError: TPUs not found in the cluster. Failed in initialization: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:5074,security,Configur,ConfigureDistributedTPU,5074,"cute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 109, in train. tf.tpu.experimental.initialize_tpu_system(resolver). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 113, in initialize_tpu_system. raise errors.NotFoundError(. tensorflow.python.framework.errors_impl.NotFoundError: TPUs not found in the cluster. Failed in initialization: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:5374,security,Configur,ConfigureDistributedTPU,5374,"cute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 109, in train. tf.tpu.experimental.initialize_tpu_system(resolver). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 113, in initialize_tpu_system. raise errors.NotFoundError(. tensorflow.python.framework.errors_impl.NotFoundError: TPUs not found in the cluster. Failed in initialization: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:1215,testability,plan,planned,1215,"ion 0.9, and I am unsure how to proceed with version 1.6.1. The command I used is the following: . ```. docker run \. -v ${HOME}:${HOME} \. google/deepvariant:1.6.1 \. train \. --config=${HOME}/dv_config.py:base \. --config.train_dataset_pbtxt=""${SHUFFLE_DIR}/training_set.dataset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""${SHUFFLE_DIR}/validation_set.dataset_config.pbtxt"" \. --config.num_epochs=10 \. --config.learning_rate=0.001 \. --config.num_validation_examples=0 \. --experiment_dir=${TRAINING_DIR} \. --strategy=tpu \. --config.batch_size=1024. ```. However, I am not an expert with TPUs, and this is entirely new to me. Below is the error I encountered. Do you have any suggestions or can you direct me to an updated tutorial to follow? ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 139683296487232 tpu_strategy_util.py:81] Initializing the TPU system: local. 2024-06-27 21:18:43.848149: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural N",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:1291,testability,depend,dependencies,1291," is the following: . ```. docker run \. -v ${HOME}:${HOME} \. google/deepvariant:1.6.1 \. train \. --config=${HOME}/dv_config.py:base \. --config.train_dataset_pbtxt=""${SHUFFLE_DIR}/training_set.dataset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""${SHUFFLE_DIR}/validation_set.dataset_config.pbtxt"" \. --config.num_epochs=10 \. --config.learning_rate=0.001 \. --config.num_validation_examples=0 \. --experiment_dir=${TRAINING_DIR} \. --strategy=tpu \. --config.batch_size=1024. ```. However, I am not an expert with TPUs, and this is entirely new to me. Below is the error I encountered. Do you have any suggestions or can you direct me to an updated tutorial to follow? ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 139683296487232 tpu_strategy_util.py:81] Initializing the TPU system: local. 2024-06-27 21:18:43.848149: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:2567,testability,Trace,Traceback,2567," 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 139683296487232 tpu_strategy_util.py:81] Initializing the TPU system: local. 2024-06-27 21:18:43.848149: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-06-27 21:18:43.855816: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: . Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 110, in initialize_tpu_system. output = _tpu_init_fn(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py"", line 134, in __call__. return concrete_function._call_flat(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 1745, in _call_flat. return self._build_call_outputs(self._inference_function.call(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 378, in call. outputs = execute.execute(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py"", line 52, in quick_execute. tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to sup",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:4049,testability,Trace,Traceback,4049,"in _call_flat. return self._build_call_outputs(self._inference_function.call(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 378, in call. outputs = execute.execute(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py"", line 52, in quick_execute. tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 109, in train. tf.tpu.experimental.initialize_tpu_system(resolver). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 113, in initialize_tpu_system. raise errors.NotFoundError(. tensorflow.python.framework.errors_impl.NotFoundError: TPUs not found in the cluster. Failed in initialization: No OpKernel was registered to support Op 'ConfigureDistributed",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:283,usability,command,command,283,"How to train deepvariant v1.6.1 on tpu?; I managed to start training on a GPU, but it took too much time. Now, I am attempting to train DeepVariant on a TPU v3-8 VM. However, the most recent tutorial I found is for version 0.9, and I am unsure how to proceed with version 1.6.1. The command I used is the following: . ```. docker run \. -v ${HOME}:${HOME} \. google/deepvariant:1.6.1 \. train \. --config=${HOME}/dv_config.py:base \. --config.train_dataset_pbtxt=""${SHUFFLE_DIR}/training_set.dataset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""${SHUFFLE_DIR}/validation_set.dataset_config.pbtxt"" \. --config.num_epochs=10 \. --config.learning_rate=0.001 \. --config.num_validation_examples=0 \. --experiment_dir=${TRAINING_DIR} \. --strategy=tpu \. --config.batch_size=1024. ```. However, I am not an expert with TPUs, and this is entirely new to me. Below is the error I encountered. Do you have any suggestions or can you direct me to an updated tutorial to follow? ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:866,usability,error,error,866,"How to train deepvariant v1.6.1 on tpu?; I managed to start training on a GPU, but it took too much time. Now, I am attempting to train DeepVariant on a TPU v3-8 VM. However, the most recent tutorial I found is for version 0.9, and I am unsure how to proceed with version 1.6.1. The command I used is the following: . ```. docker run \. -v ${HOME}:${HOME} \. google/deepvariant:1.6.1 \. train \. --config=${HOME}/dv_config.py:base \. --config.train_dataset_pbtxt=""${SHUFFLE_DIR}/training_set.dataset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""${SHUFFLE_DIR}/validation_set.dataset_config.pbtxt"" \. --config.num_epochs=10 \. --config.learning_rate=0.001 \. --config.num_validation_examples=0 \. --experiment_dir=${TRAINING_DIR} \. --strategy=tpu \. --config.batch_size=1024. ```. However, I am not an expert with TPUs, and this is entirely new to me. Below is the error I encountered. Do you have any suggestions or can you direct me to an updated tutorial to follow? ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:1057,usability,User,UserWarning,1057,"ining on a GPU, but it took too much time. Now, I am attempting to train DeepVariant on a TPU v3-8 VM. However, the most recent tutorial I found is for version 0.9, and I am unsure how to proceed with version 1.6.1. The command I used is the following: . ```. docker run \. -v ${HOME}:${HOME} \. google/deepvariant:1.6.1 \. train \. --config=${HOME}/dv_config.py:base \. --config.train_dataset_pbtxt=""${SHUFFLE_DIR}/training_set.dataset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""${SHUFFLE_DIR}/validation_set.dataset_config.pbtxt"" \. --config.num_epochs=10 \. --config.learning_rate=0.001 \. --config.num_validation_examples=0 \. --experiment_dir=${TRAINING_DIR} \. --strategy=tpu \. --config.batch_size=1024. ```. However, I am not an expert with TPUs, and this is entirely new to me. Below is the error I encountered. Do you have any suggestions or can you direct me to an updated tutorial to follow? ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 139683296487232 tpu_strategy_util.py:81] Initializing the TPU s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:1170,usability,minim,minimal,1170," the most recent tutorial I found is for version 0.9, and I am unsure how to proceed with version 1.6.1. The command I used is the following: . ```. docker run \. -v ${HOME}:${HOME} \. google/deepvariant:1.6.1 \. train \. --config=${HOME}/dv_config.py:base \. --config.train_dataset_pbtxt=""${SHUFFLE_DIR}/training_set.dataset_config.pbtxt"" \. --config.tune_dataset_pbtxt=""${SHUFFLE_DIR}/validation_set.dataset_config.pbtxt"" \. --config.num_epochs=10 \. --config.learning_rate=0.001 \. --config.num_validation_examples=0 \. --experiment_dir=${TRAINING_DIR} \. --strategy=tpu \. --config.batch_size=1024. ```. However, I am not an expert with TPUs, and this is entirely new to me. Below is the error I encountered. Do you have any suggestions or can you direct me to an updated tutorial to follow? ```. /usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: . TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 139683296487232 tpu_strategy_util.py:81] Initializing the TPU system: local. 2024-06-27 21:18:43.848149: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:2284,usability,perform,performance-critical,2284,"endencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). . For more information see: https://github.com/tensorflow/addons/issues/2807 . warnings.warn(. I0627 21:18:43.707066 139683296487232 train.py:92] Running with debug=False. I0627 21:18:43.707488 139683296487232 train.py:100] Use TPU at local. I0627 21:18:43.707705 139683296487232 train.py:103] experiment_dir: /home/gambardella/training_chk. INFO:tensorflow:Deallocate tpu buffers before initializing tpu system. I0627 21:18:43.707828 139683296487232 tpu_strategy_util.py:57] Deallocate tpu buffers before initializing tpu system. INFO:tensorflow:Initializing the TPU system: local. I0627 21:18:43.846984 139683296487232 tpu_strategy_util.py:81] Initializing the TPU system: local. 2024-06-27 21:18:43.848149: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-06-27 21:18:43.855816: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: . Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 110, in initialize_tpu_system. output = _tpu_init_fn(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py"", line 134, in __call__. return concrete_function._call_flat(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 1745, in _call_flat. return self._build_call_outputs(self._inference_function.call(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 378, in call. outputs = execute.execute(",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:3569,usability,support,support,3569,"ack (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 110, in initialize_tpu_system. output = _tpu_init_fn(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py"", line 134, in __call__. return concrete_function._call_flat(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 1745, in _call_flat. return self._build_call_outputs(self._inference_function.call(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py"", line 378, in call. outputs = execute.execute(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py"", line 52, in quick_execute. tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:4857,usability,error,errors,4857,"cute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 109, in train. tf.tpu.experimental.initialize_tpu_system(resolver). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 113, in initialize_tpu_system. raise errors.NotFoundError(. tensorflow.python.framework.errors_impl.NotFoundError: TPUs not found in the cluster. Failed in initialization: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/841:5022,usability,support,support,5022,"cute(ctx._handle, device_name, op_name,. tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 532, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 518, in main. train(FLAGS.config). File ""/tmp/Bazel.runfiles_ol6r0lcv/runfiles/com_google_deepvariant/deepvariant/train.py"", line 109, in train. tf.tpu.experimental.initialize_tpu_system(resolver). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/tpu_strategy_util.py"", line 113, in initialize_tpu_system. raise errors.NotFoundError(. tensorflow.python.framework.errors_impl.NotFoundError: TPUs not found in the cluster. Failed in initialization: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [compilation_failure_closes_chips=false, tpu_cancellation_closes_chips=2, tpu_embedding_config="""", embedding_config="""", enable_whole_mesh_compilations=false, is_global_init=false]. Registered devices: [CPU]. Registered kernels:. <no registered kernels>. [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/841
https://github.com/google/deepvariant/issues/842:97,availability,down,downloading,97,"data resources path; Sorry to bother, but could you please provide me with the original path for downloading the data in the exome case study? I am interested in exploring some related data. Thank you very much. . Here's the code related to the data in case study:. ```. HTTPDIR=https://storage.googleapis.com/deepvariant/exome-case-study-testdata. curl ${HTTPDIR}/HG003.novaseq.wes_idt.100x.dedup.bam > input/HG003.novaseq.wes_idt.100x.dedup.bam. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/842
https://github.com/google/deepvariant/issues/842:5,deployability,resourc,resources,5,"data resources path; Sorry to bother, but could you please provide me with the original path for downloading the data in the exome case study? I am interested in exploring some related data. Thank you very much. . Here's the code related to the data in case study:. ```. HTTPDIR=https://storage.googleapis.com/deepvariant/exome-case-study-testdata. curl ${HTTPDIR}/HG003.novaseq.wes_idt.100x.dedup.bam > input/HG003.novaseq.wes_idt.100x.dedup.bam. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/842
https://github.com/google/deepvariant/issues/842:5,energy efficiency,resourc,resources,5,"data resources path; Sorry to bother, but could you please provide me with the original path for downloading the data in the exome case study? I am interested in exploring some related data. Thank you very much. . Here's the code related to the data in case study:. ```. HTTPDIR=https://storage.googleapis.com/deepvariant/exome-case-study-testdata. curl ${HTTPDIR}/HG003.novaseq.wes_idt.100x.dedup.bam > input/HG003.novaseq.wes_idt.100x.dedup.bam. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/842
https://github.com/google/deepvariant/issues/842:5,performance,resourc,resources,5,"data resources path; Sorry to bother, but could you please provide me with the original path for downloading the data in the exome case study? I am interested in exploring some related data. Thank you very much. . Here's the code related to the data in case study:. ```. HTTPDIR=https://storage.googleapis.com/deepvariant/exome-case-study-testdata. curl ${HTTPDIR}/HG003.novaseq.wes_idt.100x.dedup.bam > input/HG003.novaseq.wes_idt.100x.dedup.bam. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/842
https://github.com/google/deepvariant/issues/842:5,safety,resourc,resources,5,"data resources path; Sorry to bother, but could you please provide me with the original path for downloading the data in the exome case study? I am interested in exploring some related data. Thank you very much. . Here's the code related to the data in case study:. ```. HTTPDIR=https://storage.googleapis.com/deepvariant/exome-case-study-testdata. curl ${HTTPDIR}/HG003.novaseq.wes_idt.100x.dedup.bam > input/HG003.novaseq.wes_idt.100x.dedup.bam. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/842
https://github.com/google/deepvariant/issues/842:339,safety,test,testdata,339,"data resources path; Sorry to bother, but could you please provide me with the original path for downloading the data in the exome case study? I am interested in exploring some related data. Thank you very much. . Here's the code related to the data in case study:. ```. HTTPDIR=https://storage.googleapis.com/deepvariant/exome-case-study-testdata. curl ${HTTPDIR}/HG003.novaseq.wes_idt.100x.dedup.bam > input/HG003.novaseq.wes_idt.100x.dedup.bam. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/842
https://github.com/google/deepvariant/issues/842:404,safety,input,input,404,"data resources path; Sorry to bother, but could you please provide me with the original path for downloading the data in the exome case study? I am interested in exploring some related data. Thank you very much. . Here's the code related to the data in case study:. ```. HTTPDIR=https://storage.googleapis.com/deepvariant/exome-case-study-testdata. curl ${HTTPDIR}/HG003.novaseq.wes_idt.100x.dedup.bam > input/HG003.novaseq.wes_idt.100x.dedup.bam. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/842
https://github.com/google/deepvariant/issues/842:5,testability,resourc,resources,5,"data resources path; Sorry to bother, but could you please provide me with the original path for downloading the data in the exome case study? I am interested in exploring some related data. Thank you very much. . Here's the code related to the data in case study:. ```. HTTPDIR=https://storage.googleapis.com/deepvariant/exome-case-study-testdata. curl ${HTTPDIR}/HG003.novaseq.wes_idt.100x.dedup.bam > input/HG003.novaseq.wes_idt.100x.dedup.bam. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/842
https://github.com/google/deepvariant/issues/842:339,testability,test,testdata,339,"data resources path; Sorry to bother, but could you please provide me with the original path for downloading the data in the exome case study? I am interested in exploring some related data. Thank you very much. . Here's the code related to the data in case study:. ```. HTTPDIR=https://storage.googleapis.com/deepvariant/exome-case-study-testdata. curl ${HTTPDIR}/HG003.novaseq.wes_idt.100x.dedup.bam > input/HG003.novaseq.wes_idt.100x.dedup.bam. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/842
https://github.com/google/deepvariant/issues/842:404,usability,input,input,404,"data resources path; Sorry to bother, but could you please provide me with the original path for downloading the data in the exome case study? I am interested in exploring some related data. Thank you very much. . Here's the code related to the data in case study:. ```. HTTPDIR=https://storage.googleapis.com/deepvariant/exome-case-study-testdata. curl ${HTTPDIR}/HG003.novaseq.wes_idt.100x.dedup.bam > input/HG003.novaseq.wes_idt.100x.dedup.bam. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/842
https://github.com/google/deepvariant/issues/843:27,energy efficiency,Frequenc,Frequency,27,"DeepVariant Variant Allele Frequency; Hello，. Thanks for this fast and useful germline calling tool. When I used DeepVariant 1.6.0 for single sample WES germline calling, I found that some real germline mutations with VAF (variant allele frequency) values less than 0.3 to 0.4 could not be called. IGV view figures of these variants are below. May I ask if DeepVariant considers VAF parameters during runtime or sets threshold filtering for VAF parameters? We look forward to your reply. . Our Codes(All variables have been defined):. `singularity run \. -B ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"" \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/testinput/human_g1k_v37_modified.fasta \. --reads=/input/${i}.sorted.markdup.BQSR.bam \. --regions /input/testinput/use_agilent_region_padding_100.bed \. --output_vcf=/output/${i}.vcf.gz \. --output_gvcf=/output/${i}.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir/${i} \. --num_shards=10. `. IGV figures:. ![EP90t_R](https://github.com/google/deepvariant/assets/174405155/6e9263f9-ff9e-4495-b51d-54127dbfc837). ![EP40b](https://github.com/google/deepvariant/assets/174405155/0b8f1fec-b5d9-4bb5-be97-6431c38135b0).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/843
https://github.com/google/deepvariant/issues/843:238,energy efficiency,frequenc,frequency,238,"DeepVariant Variant Allele Frequency; Hello，. Thanks for this fast and useful germline calling tool. When I used DeepVariant 1.6.0 for single sample WES germline calling, I found that some real germline mutations with VAF (variant allele frequency) values less than 0.3 to 0.4 could not be called. IGV view figures of these variants are below. May I ask if DeepVariant considers VAF parameters during runtime or sets threshold filtering for VAF parameters? We look forward to your reply. . Our Codes(All variables have been defined):. `singularity run \. -B ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"" \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/testinput/human_g1k_v37_modified.fasta \. --reads=/input/${i}.sorted.markdup.BQSR.bam \. --regions /input/testinput/use_agilent_region_padding_100.bed \. --output_vcf=/output/${i}.vcf.gz \. --output_gvcf=/output/${i}.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir/${i} \. --num_shards=10. `. IGV figures:. ![EP90t_R](https://github.com/google/deepvariant/assets/174405155/6e9263f9-ff9e-4495-b51d-54127dbfc837). ![EP40b](https://github.com/google/deepvariant/assets/174405155/0b8f1fec-b5d9-4bb5-be97-6431c38135b0).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/843
https://github.com/google/deepvariant/issues/843:427,integrability,filter,filtering,427,"DeepVariant Variant Allele Frequency; Hello，. Thanks for this fast and useful germline calling tool. When I used DeepVariant 1.6.0 for single sample WES germline calling, I found that some real germline mutations with VAF (variant allele frequency) values less than 0.3 to 0.4 could not be called. IGV view figures of these variants are below. May I ask if DeepVariant considers VAF parameters during runtime or sets threshold filtering for VAF parameters? We look forward to your reply. . Our Codes(All variables have been defined):. `singularity run \. -B ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"" \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/testinput/human_g1k_v37_modified.fasta \. --reads=/input/${i}.sorted.markdup.BQSR.bam \. --regions /input/testinput/use_agilent_region_padding_100.bed \. --output_vcf=/output/${i}.vcf.gz \. --output_gvcf=/output/${i}.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir/${i} \. --num_shards=10. `. IGV figures:. ![EP90t_R](https://github.com/google/deepvariant/assets/174405155/6e9263f9-ff9e-4495-b51d-54127dbfc837). ![EP40b](https://github.com/google/deepvariant/assets/174405155/0b8f1fec-b5d9-4bb5-be97-6431c38135b0).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/843
https://github.com/google/deepvariant/issues/843:383,modifiability,paramet,parameters,383,"DeepVariant Variant Allele Frequency; Hello，. Thanks for this fast and useful germline calling tool. When I used DeepVariant 1.6.0 for single sample WES germline calling, I found that some real germline mutations with VAF (variant allele frequency) values less than 0.3 to 0.4 could not be called. IGV view figures of these variants are below. May I ask if DeepVariant considers VAF parameters during runtime or sets threshold filtering for VAF parameters? We look forward to your reply. . Our Codes(All variables have been defined):. `singularity run \. -B ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"" \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/testinput/human_g1k_v37_modified.fasta \. --reads=/input/${i}.sorted.markdup.BQSR.bam \. --regions /input/testinput/use_agilent_region_padding_100.bed \. --output_vcf=/output/${i}.vcf.gz \. --output_gvcf=/output/${i}.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir/${i} \. --num_shards=10. `. IGV figures:. ![EP90t_R](https://github.com/google/deepvariant/assets/174405155/6e9263f9-ff9e-4495-b51d-54127dbfc837). ![EP40b](https://github.com/google/deepvariant/assets/174405155/0b8f1fec-b5d9-4bb5-be97-6431c38135b0).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/843
https://github.com/google/deepvariant/issues/843:445,modifiability,paramet,parameters,445,"DeepVariant Variant Allele Frequency; Hello，. Thanks for this fast and useful germline calling tool. When I used DeepVariant 1.6.0 for single sample WES germline calling, I found that some real germline mutations with VAF (variant allele frequency) values less than 0.3 to 0.4 could not be called. IGV view figures of these variants are below. May I ask if DeepVariant considers VAF parameters during runtime or sets threshold filtering for VAF parameters? We look forward to your reply. . Our Codes(All variables have been defined):. `singularity run \. -B ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"" \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/testinput/human_g1k_v37_modified.fasta \. --reads=/input/${i}.sorted.markdup.BQSR.bam \. --regions /input/testinput/use_agilent_region_padding_100.bed \. --output_vcf=/output/${i}.vcf.gz \. --output_gvcf=/output/${i}.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir/${i} \. --num_shards=10. `. IGV figures:. ![EP90t_R](https://github.com/google/deepvariant/assets/174405155/6e9263f9-ff9e-4495-b51d-54127dbfc837). ![EP40b](https://github.com/google/deepvariant/assets/174405155/0b8f1fec-b5d9-4bb5-be97-6431c38135b0).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/843
https://github.com/google/deepvariant/issues/843:504,modifiability,variab,variables,504,"DeepVariant Variant Allele Frequency; Hello，. Thanks for this fast and useful germline calling tool. When I used DeepVariant 1.6.0 for single sample WES germline calling, I found that some real germline mutations with VAF (variant allele frequency) values less than 0.3 to 0.4 could not be called. IGV view figures of these variants are below. May I ask if DeepVariant considers VAF parameters during runtime or sets threshold filtering for VAF parameters? We look forward to your reply. . Our Codes(All variables have been defined):. `singularity run \. -B ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"" \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/testinput/human_g1k_v37_modified.fasta \. --reads=/input/${i}.sorted.markdup.BQSR.bam \. --regions /input/testinput/use_agilent_region_padding_100.bed \. --output_vcf=/output/${i}.vcf.gz \. --output_gvcf=/output/${i}.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir/${i} \. --num_shards=10. `. IGV figures:. ![EP90t_R](https://github.com/google/deepvariant/assets/174405155/6e9263f9-ff9e-4495-b51d-54127dbfc837). ![EP40b](https://github.com/google/deepvariant/assets/174405155/0b8f1fec-b5d9-4bb5-be97-6431c38135b0).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/843
https://github.com/google/deepvariant/issues/843:575,safety,input,input,575,"DeepVariant Variant Allele Frequency; Hello，. Thanks for this fast and useful germline calling tool. When I used DeepVariant 1.6.0 for single sample WES germline calling, I found that some real germline mutations with VAF (variant allele frequency) values less than 0.3 to 0.4 could not be called. IGV view figures of these variants are below. May I ask if DeepVariant considers VAF parameters during runtime or sets threshold filtering for VAF parameters? We look forward to your reply. . Our Codes(All variables have been defined):. `singularity run \. -B ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"" \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/testinput/human_g1k_v37_modified.fasta \. --reads=/input/${i}.sorted.markdup.BQSR.bam \. --regions /input/testinput/use_agilent_region_padding_100.bed \. --output_vcf=/output/${i}.vcf.gz \. --output_gvcf=/output/${i}.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir/${i} \. --num_shards=10. `. IGV figures:. ![EP90t_R](https://github.com/google/deepvariant/assets/174405155/6e9263f9-ff9e-4495-b51d-54127dbfc837). ![EP40b](https://github.com/google/deepvariant/assets/174405155/0b8f1fec-b5d9-4bb5-be97-6431c38135b0).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/843
https://github.com/google/deepvariant/issues/843:703,safety,input,input,703,"DeepVariant Variant Allele Frequency; Hello，. Thanks for this fast and useful germline calling tool. When I used DeepVariant 1.6.0 for single sample WES germline calling, I found that some real germline mutations with VAF (variant allele frequency) values less than 0.3 to 0.4 could not be called. IGV view figures of these variants are below. May I ask if DeepVariant considers VAF parameters during runtime or sets threshold filtering for VAF parameters? We look forward to your reply. . Our Codes(All variables have been defined):. `singularity run \. -B ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"" \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/testinput/human_g1k_v37_modified.fasta \. --reads=/input/${i}.sorted.markdup.BQSR.bam \. --regions /input/testinput/use_agilent_region_padding_100.bed \. --output_vcf=/output/${i}.vcf.gz \. --output_gvcf=/output/${i}.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir/${i} \. --num_shards=10. `. IGV figures:. ![EP90t_R](https://github.com/google/deepvariant/assets/174405155/6e9263f9-ff9e-4495-b51d-54127dbfc837). ![EP40b](https://github.com/google/deepvariant/assets/174405155/0b8f1fec-b5d9-4bb5-be97-6431c38135b0).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/843
https://github.com/google/deepvariant/issues/843:709,safety,test,testinput,709,"DeepVariant Variant Allele Frequency; Hello，. Thanks for this fast and useful germline calling tool. When I used DeepVariant 1.6.0 for single sample WES germline calling, I found that some real germline mutations with VAF (variant allele frequency) values less than 0.3 to 0.4 could not be called. IGV view figures of these variants are below. May I ask if DeepVariant considers VAF parameters during runtime or sets threshold filtering for VAF parameters? We look forward to your reply. . Our Codes(All variables have been defined):. `singularity run \. -B ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"" \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/testinput/human_g1k_v37_modified.fasta \. --reads=/input/${i}.sorted.markdup.BQSR.bam \. --regions /input/testinput/use_agilent_region_padding_100.bed \. --output_vcf=/output/${i}.vcf.gz \. --output_gvcf=/output/${i}.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir/${i} \. --num_shards=10. `. IGV figures:. ![EP90t_R](https://github.com/google/deepvariant/assets/174405155/6e9263f9-ff9e-4495-b51d-54127dbfc837). ![EP40b](https://github.com/google/deepvariant/assets/174405155/0b8f1fec-b5d9-4bb5-be97-6431c38135b0).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/843
https://github.com/google/deepvariant/issues/843:760,safety,input,input,760,"DeepVariant Variant Allele Frequency; Hello，. Thanks for this fast and useful germline calling tool. When I used DeepVariant 1.6.0 for single sample WES germline calling, I found that some real germline mutations with VAF (variant allele frequency) values less than 0.3 to 0.4 could not be called. IGV view figures of these variants are below. May I ask if DeepVariant considers VAF parameters during runtime or sets threshold filtering for VAF parameters? We look forward to your reply. . Our Codes(All variables have been defined):. `singularity run \. -B ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"" \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/testinput/human_g1k_v37_modified.fasta \. --reads=/input/${i}.sorted.markdup.BQSR.bam \. --regions /input/testinput/use_agilent_region_padding_100.bed \. --output_vcf=/output/${i}.vcf.gz \. --output_gvcf=/output/${i}.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir/${i} \. --num_shards=10. `. IGV figures:. ![EP90t_R](https://github.com/google/deepvariant/assets/174405155/6e9263f9-ff9e-4495-b51d-54127dbfc837). ![EP40b](https://github.com/google/deepvariant/assets/174405155/0b8f1fec-b5d9-4bb5-be97-6431c38135b0).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/843
https://github.com/google/deepvariant/issues/843:809,safety,input,input,809,"DeepVariant Variant Allele Frequency; Hello，. Thanks for this fast and useful germline calling tool. When I used DeepVariant 1.6.0 for single sample WES germline calling, I found that some real germline mutations with VAF (variant allele frequency) values less than 0.3 to 0.4 could not be called. IGV view figures of these variants are below. May I ask if DeepVariant considers VAF parameters during runtime or sets threshold filtering for VAF parameters? We look forward to your reply. . Our Codes(All variables have been defined):. `singularity run \. -B ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"" \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/testinput/human_g1k_v37_modified.fasta \. --reads=/input/${i}.sorted.markdup.BQSR.bam \. --regions /input/testinput/use_agilent_region_padding_100.bed \. --output_vcf=/output/${i}.vcf.gz \. --output_gvcf=/output/${i}.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir/${i} \. --num_shards=10. `. IGV figures:. ![EP90t_R](https://github.com/google/deepvariant/assets/174405155/6e9263f9-ff9e-4495-b51d-54127dbfc837). ![EP40b](https://github.com/google/deepvariant/assets/174405155/0b8f1fec-b5d9-4bb5-be97-6431c38135b0).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/843
https://github.com/google/deepvariant/issues/843:815,safety,test,testinput,815,"DeepVariant Variant Allele Frequency; Hello，. Thanks for this fast and useful germline calling tool. When I used DeepVariant 1.6.0 for single sample WES germline calling, I found that some real germline mutations with VAF (variant allele frequency) values less than 0.3 to 0.4 could not be called. IGV view figures of these variants are below. May I ask if DeepVariant considers VAF parameters during runtime or sets threshold filtering for VAF parameters? We look forward to your reply. . Our Codes(All variables have been defined):. `singularity run \. -B ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"" \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/testinput/human_g1k_v37_modified.fasta \. --reads=/input/${i}.sorted.markdup.BQSR.bam \. --regions /input/testinput/use_agilent_region_padding_100.bed \. --output_vcf=/output/${i}.vcf.gz \. --output_gvcf=/output/${i}.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir/${i} \. --num_shards=10. `. IGV figures:. ![EP90t_R](https://github.com/google/deepvariant/assets/174405155/6e9263f9-ff9e-4495-b51d-54127dbfc837). ![EP40b](https://github.com/google/deepvariant/assets/174405155/0b8f1fec-b5d9-4bb5-be97-6431c38135b0).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/843
https://github.com/google/deepvariant/issues/843:709,testability,test,testinput,709,"DeepVariant Variant Allele Frequency; Hello，. Thanks for this fast and useful germline calling tool. When I used DeepVariant 1.6.0 for single sample WES germline calling, I found that some real germline mutations with VAF (variant allele frequency) values less than 0.3 to 0.4 could not be called. IGV view figures of these variants are below. May I ask if DeepVariant considers VAF parameters during runtime or sets threshold filtering for VAF parameters? We look forward to your reply. . Our Codes(All variables have been defined):. `singularity run \. -B ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"" \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/testinput/human_g1k_v37_modified.fasta \. --reads=/input/${i}.sorted.markdup.BQSR.bam \. --regions /input/testinput/use_agilent_region_padding_100.bed \. --output_vcf=/output/${i}.vcf.gz \. --output_gvcf=/output/${i}.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir/${i} \. --num_shards=10. `. IGV figures:. ![EP90t_R](https://github.com/google/deepvariant/assets/174405155/6e9263f9-ff9e-4495-b51d-54127dbfc837). ![EP40b](https://github.com/google/deepvariant/assets/174405155/0b8f1fec-b5d9-4bb5-be97-6431c38135b0).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/843
https://github.com/google/deepvariant/issues/843:815,testability,test,testinput,815,"DeepVariant Variant Allele Frequency; Hello，. Thanks for this fast and useful germline calling tool. When I used DeepVariant 1.6.0 for single sample WES germline calling, I found that some real germline mutations with VAF (variant allele frequency) values less than 0.3 to 0.4 could not be called. IGV view figures of these variants are below. May I ask if DeepVariant considers VAF parameters during runtime or sets threshold filtering for VAF parameters? We look forward to your reply. . Our Codes(All variables have been defined):. `singularity run \. -B ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"" \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/testinput/human_g1k_v37_modified.fasta \. --reads=/input/${i}.sorted.markdup.BQSR.bam \. --regions /input/testinput/use_agilent_region_padding_100.bed \. --output_vcf=/output/${i}.vcf.gz \. --output_gvcf=/output/${i}.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir/${i} \. --num_shards=10. `. IGV figures:. ![EP90t_R](https://github.com/google/deepvariant/assets/174405155/6e9263f9-ff9e-4495-b51d-54127dbfc837). ![EP40b](https://github.com/google/deepvariant/assets/174405155/0b8f1fec-b5d9-4bb5-be97-6431c38135b0).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/843
https://github.com/google/deepvariant/issues/843:95,usability,tool,tool,95,"DeepVariant Variant Allele Frequency; Hello，. Thanks for this fast and useful germline calling tool. When I used DeepVariant 1.6.0 for single sample WES germline calling, I found that some real germline mutations with VAF (variant allele frequency) values less than 0.3 to 0.4 could not be called. IGV view figures of these variants are below. May I ask if DeepVariant considers VAF parameters during runtime or sets threshold filtering for VAF parameters? We look forward to your reply. . Our Codes(All variables have been defined):. `singularity run \. -B ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"" \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/testinput/human_g1k_v37_modified.fasta \. --reads=/input/${i}.sorted.markdup.BQSR.bam \. --regions /input/testinput/use_agilent_region_padding_100.bed \. --output_vcf=/output/${i}.vcf.gz \. --output_gvcf=/output/${i}.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir/${i} \. --num_shards=10. `. IGV figures:. ![EP90t_R](https://github.com/google/deepvariant/assets/174405155/6e9263f9-ff9e-4495-b51d-54127dbfc837). ![EP40b](https://github.com/google/deepvariant/assets/174405155/0b8f1fec-b5d9-4bb5-be97-6431c38135b0).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/843
https://github.com/google/deepvariant/issues/843:575,usability,input,input,575,"DeepVariant Variant Allele Frequency; Hello，. Thanks for this fast and useful germline calling tool. When I used DeepVariant 1.6.0 for single sample WES germline calling, I found that some real germline mutations with VAF (variant allele frequency) values less than 0.3 to 0.4 could not be called. IGV view figures of these variants are below. May I ask if DeepVariant considers VAF parameters during runtime or sets threshold filtering for VAF parameters? We look forward to your reply. . Our Codes(All variables have been defined):. `singularity run \. -B ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"" \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/testinput/human_g1k_v37_modified.fasta \. --reads=/input/${i}.sorted.markdup.BQSR.bam \. --regions /input/testinput/use_agilent_region_padding_100.bed \. --output_vcf=/output/${i}.vcf.gz \. --output_gvcf=/output/${i}.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir/${i} \. --num_shards=10. `. IGV figures:. ![EP90t_R](https://github.com/google/deepvariant/assets/174405155/6e9263f9-ff9e-4495-b51d-54127dbfc837). ![EP40b](https://github.com/google/deepvariant/assets/174405155/0b8f1fec-b5d9-4bb5-be97-6431c38135b0).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/843
https://github.com/google/deepvariant/issues/843:703,usability,input,input,703,"DeepVariant Variant Allele Frequency; Hello，. Thanks for this fast and useful germline calling tool. When I used DeepVariant 1.6.0 for single sample WES germline calling, I found that some real germline mutations with VAF (variant allele frequency) values less than 0.3 to 0.4 could not be called. IGV view figures of these variants are below. May I ask if DeepVariant considers VAF parameters during runtime or sets threshold filtering for VAF parameters? We look forward to your reply. . Our Codes(All variables have been defined):. `singularity run \. -B ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"" \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/testinput/human_g1k_v37_modified.fasta \. --reads=/input/${i}.sorted.markdup.BQSR.bam \. --regions /input/testinput/use_agilent_region_padding_100.bed \. --output_vcf=/output/${i}.vcf.gz \. --output_gvcf=/output/${i}.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir/${i} \. --num_shards=10. `. IGV figures:. ![EP90t_R](https://github.com/google/deepvariant/assets/174405155/6e9263f9-ff9e-4495-b51d-54127dbfc837). ![EP40b](https://github.com/google/deepvariant/assets/174405155/0b8f1fec-b5d9-4bb5-be97-6431c38135b0).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/843
https://github.com/google/deepvariant/issues/843:760,usability,input,input,760,"DeepVariant Variant Allele Frequency; Hello，. Thanks for this fast and useful germline calling tool. When I used DeepVariant 1.6.0 for single sample WES germline calling, I found that some real germline mutations with VAF (variant allele frequency) values less than 0.3 to 0.4 could not be called. IGV view figures of these variants are below. May I ask if DeepVariant considers VAF parameters during runtime or sets threshold filtering for VAF parameters? We look forward to your reply. . Our Codes(All variables have been defined):. `singularity run \. -B ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"" \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/testinput/human_g1k_v37_modified.fasta \. --reads=/input/${i}.sorted.markdup.BQSR.bam \. --regions /input/testinput/use_agilent_region_padding_100.bed \. --output_vcf=/output/${i}.vcf.gz \. --output_gvcf=/output/${i}.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir/${i} \. --num_shards=10. `. IGV figures:. ![EP90t_R](https://github.com/google/deepvariant/assets/174405155/6e9263f9-ff9e-4495-b51d-54127dbfc837). ![EP40b](https://github.com/google/deepvariant/assets/174405155/0b8f1fec-b5d9-4bb5-be97-6431c38135b0).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/843
https://github.com/google/deepvariant/issues/843:809,usability,input,input,809,"DeepVariant Variant Allele Frequency; Hello，. Thanks for this fast and useful germline calling tool. When I used DeepVariant 1.6.0 for single sample WES germline calling, I found that some real germline mutations with VAF (variant allele frequency) values less than 0.3 to 0.4 could not be called. IGV view figures of these variants are below. May I ask if DeepVariant considers VAF parameters during runtime or sets threshold filtering for VAF parameters? We look forward to your reply. . Our Codes(All variables have been defined):. `singularity run \. -B ""${INPUT_DIR}"":""/input"",""${OUTPUT_DIR}"":""/output"" \. deepvariant_1.6.0.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=/input/testinput/human_g1k_v37_modified.fasta \. --reads=/input/${i}.sorted.markdup.BQSR.bam \. --regions /input/testinput/use_agilent_region_padding_100.bed \. --output_vcf=/output/${i}.vcf.gz \. --output_gvcf=/output/${i}.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir/${i} \. --num_shards=10. `. IGV figures:. ![EP90t_R](https://github.com/google/deepvariant/assets/174405155/6e9263f9-ff9e-4495-b51d-54127dbfc837). ![EP40b](https://github.com/google/deepvariant/assets/174405155/0b8f1fec-b5d9-4bb5-be97-6431c38135b0).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/843
https://github.com/google/deepvariant/issues/844:561,availability,Operat,Operating,561,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:977,availability,Error,Error,977,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:1419,availability,avail,available,1419,"er images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:1726,availability,operat,operations,1726,"strument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:1840,availability,operat,operations,1840,"to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:1986,availability,operat,operations,1986,"if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are perio",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:2017,availability,sli,slightly,2017,"on 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:2086,availability,error,errors,2086,"ON & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:4781,availability,down,download-archive,4781,"r/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. L40S card is CUDA CC = 8.9. supported since CUDA >= 11.8 currently 12.4 and 12.5. https://developer.nvidia.com/cuda-11-8-0-download-archive - installed, still doesn't work with containerized 11.3.1. tensorRT is used. https://docs.nvidia.com/deeplearning/tensorrt/support-matrix/index.html . currently 10.1 ; version 8 in CUDA 11.8. python >= 3.8. lspci | grep -i nvidia. 0a:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). ae:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). nvidia-container-cli is installed (supersedes nvidia-docker - https://github.com/NVIDIA/nvidia-docker )",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:408,deployability,build,build,408,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:604,deployability,version,version,604,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:637,deployability,Instal,Installation,637,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:1016,deployability,Version,Version,1016,".5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see sli",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:1032,deployability,Contain,Container,1032,"/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different n",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:1132,deployability,contain,container,1132,"ave you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:1206,deployability,Contain,Container,1206,"/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:1250,deployability,contain,container,1250,"*. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:1369,deployability,contain,container-license,1369,"UDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:1437,deployability,contain,container,1437,"A >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or dire",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:1458,deployability,CONTAIN,CONTAINER-LICENSE,1458,".8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:2762,deployability,instal,installed,2762,"12_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:3026,deployability,Version,Version,3026,"erent numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:3137,deployability,fail,failed,3137," off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/co",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:3313,deployability,fail,failed,3313," load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:3472,deployability,log,log,3472,"al/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please te",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:3590,deployability,fail,failed,3590,"38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:4075,deployability,version,version,4075,"low/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. L40S card is CUDA CC = 8.9. supported since CUDA >= 11.8 currently 12.4 and 12.5. https://developer.nvidia.com/cuda-11-8-0-download-archive - installed, still doesn't work with containerized 11.3.1. tensorRT is used. https://docs.nvidia.com/deeplearning/tensorrt/support-matrix/index.html . currently 10.1 ; version 8 in CUDA 11.8. python >= 3.8. lspci | grep -i nvidia. 0a:00.0 3D controller: NVIDIA Corporation AD102GL ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:4213,deployability,version,version,4213," 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. L40S card is CUDA CC = 8.9. supported since CUDA >= 11.8 currently 12.4 and 12.5. https://developer.nvidia.com/cuda-11-8-0-download-archive - installed, still doesn't work with containerized 11.3.1. tensorRT is used. https://docs.nvidia.com/deeplearning/tensorrt/support-matrix/index.html . currently 10.1 ; version 8 in CUDA 11.8. python >= 3.8. lspci | grep -i nvidia. 0a:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). ae:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). nvidia-container-cli is installed (supersedes nvidia-d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:4342,deployability,version,version,4342,"r/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. L40S card is CUDA CC = 8.9. supported since CUDA >= 11.8 currently 12.4 and 12.5. https://developer.nvidia.com/cuda-11-8-0-download-archive - installed, still doesn't work with containerized 11.3.1. tensorRT is used. https://docs.nvidia.com/deeplearning/tensorrt/support-matrix/index.html . currently 10.1 ; version 8 in CUDA 11.8. python >= 3.8. lspci | grep -i nvidia. 0a:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). ae:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). nvidia-container-cli is installed (supersedes nvidia-docker - https://github.com/NVIDIA/nvidia-docker )",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:4800,deployability,instal,installed,4800,"r/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. L40S card is CUDA CC = 8.9. supported since CUDA >= 11.8 currently 12.4 and 12.5. https://developer.nvidia.com/cuda-11-8-0-download-archive - installed, still doesn't work with containerized 11.3.1. tensorRT is used. https://docs.nvidia.com/deeplearning/tensorrt/support-matrix/index.html . currently 10.1 ; version 8 in CUDA 11.8. python >= 3.8. lspci | grep -i nvidia. 0a:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). ae:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). nvidia-container-cli is installed (supersedes nvidia-docker - https://github.com/NVIDIA/nvidia-docker )",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:4835,deployability,contain,containerized,4835,"r/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. L40S card is CUDA CC = 8.9. supported since CUDA >= 11.8 currently 12.4 and 12.5. https://developer.nvidia.com/cuda-11-8-0-download-archive - installed, still doesn't work with containerized 11.3.1. tensorRT is used. https://docs.nvidia.com/deeplearning/tensorrt/support-matrix/index.html . currently 10.1 ; version 8 in CUDA 11.8. python >= 3.8. lspci | grep -i nvidia. 0a:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). ae:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). nvidia-container-cli is installed (supersedes nvidia-docker - https://github.com/NVIDIA/nvidia-docker )",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:4966,deployability,version,version,4966,"r/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. L40S card is CUDA CC = 8.9. supported since CUDA >= 11.8 currently 12.4 and 12.5. https://developer.nvidia.com/cuda-11-8-0-download-archive - installed, still doesn't work with containerized 11.3.1. tensorRT is used. https://docs.nvidia.com/deeplearning/tensorrt/support-matrix/index.html . currently 10.1 ; version 8 in CUDA 11.8. python >= 3.8. lspci | grep -i nvidia. 0a:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). ae:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). nvidia-container-cli is installed (supersedes nvidia-docker - https://github.com/NVIDIA/nvidia-docker )",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:5170,deployability,contain,container-cli,5170,"r/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. L40S card is CUDA CC = 8.9. supported since CUDA >= 11.8 currently 12.4 and 12.5. https://developer.nvidia.com/cuda-11-8-0-download-archive - installed, still doesn't work with containerized 11.3.1. tensorRT is used. https://docs.nvidia.com/deeplearning/tensorrt/support-matrix/index.html . currently 10.1 ; version 8 in CUDA 11.8. python >= 3.8. lspci | grep -i nvidia. 0a:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). ae:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). nvidia-container-cli is installed (supersedes nvidia-docker - https://github.com/NVIDIA/nvidia-docker )",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:5187,deployability,instal,installed,5187,"r/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. L40S card is CUDA CC = 8.9. supported since CUDA >= 11.8 currently 12.4 and 12.5. https://developer.nvidia.com/cuda-11-8-0-download-archive - installed, still doesn't work with containerized 11.3.1. tensorRT is used. https://docs.nvidia.com/deeplearning/tensorrt/support-matrix/index.html . currently 10.1 ; version 8 in CUDA 11.8. python >= 3.8. lspci | grep -i nvidia. 0a:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). ae:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). nvidia-container-cli is installed (supersedes nvidia-docker - https://github.com/NVIDIA/nvidia-docker )",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:25,energy efficiency,gpu,gpu,25,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:56,energy efficiency,gpu,gpu,56,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:81,energy efficiency,CPU,CPU-only,81,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:283,energy efficiency,gpu,gpu,283,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:312,energy efficiency,gpu,gpu,312,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:337,energy efficiency,CPU,CPU-only,337,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:619,energy efficiency,gpu,gpu,619,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:630,energy efficiency,gpu,gpu,630,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:886,energy efficiency,gpu,gpus,886,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:918,energy efficiency,gpu,gpu,918,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:938,energy efficiency,gpu,gpus,938,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:970,energy efficiency,gpu,gpu,970,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:1539,energy efficiency,core,core,1539," 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:1605,energy efficiency,optim,optimized,1605,"n: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warnin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:1685,energy efficiency,CPU,CPU,1685,"c.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:1949,energy efficiency,core,core,1949,"/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provide",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:2317,energy efficiency,load,load,2317,"s://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:2684,energy efficiency,GPU,GPU,2684,"PU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:3429,energy efficiency,CPU,CPUs,3429,"ile or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:4715,energy efficiency,current,currently,4715,"r/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. L40S card is CUDA CC = 8.9. supported since CUDA >= 11.8 currently 12.4 and 12.5. https://developer.nvidia.com/cuda-11-8-0-download-archive - installed, still doesn't work with containerized 11.3.1. tensorRT is used. https://docs.nvidia.com/deeplearning/tensorrt/support-matrix/index.html . currently 10.1 ; version 8 in CUDA 11.8. python >= 3.8. lspci | grep -i nvidia. 0a:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). ae:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). nvidia-container-cli is installed (supersedes nvidia-docker - https://github.com/NVIDIA/nvidia-docker )",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:4949,energy efficiency,current,currently,4949,"r/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. L40S card is CUDA CC = 8.9. supported since CUDA >= 11.8 currently 12.4 and 12.5. https://developer.nvidia.com/cuda-11-8-0-download-archive - installed, still doesn't work with containerized 11.3.1. tensorRT is used. https://docs.nvidia.com/deeplearning/tensorrt/support-matrix/index.html . currently 10.1 ; version 8 in CUDA 11.8. python >= 3.8. lspci | grep -i nvidia. 0a:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). ae:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). nvidia-container-cli is installed (supersedes nvidia-docker - https://github.com/NVIDIA/nvidia-docker )",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:604,integrability,version,version,604,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:1016,integrability,Version,Version,1016,".5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see sli",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:2973,integrability,messag,messages,2973,"N custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:3026,integrability,Version,Version,3026,"erent numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:4075,integrability,version,version,4075,"low/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. L40S card is CUDA CC = 8.9. supported since CUDA >= 11.8 currently 12.4 and 12.5. https://developer.nvidia.com/cuda-11-8-0-download-archive - installed, still doesn't work with containerized 11.3.1. tensorRT is used. https://docs.nvidia.com/deeplearning/tensorrt/support-matrix/index.html . currently 10.1 ; version 8 in CUDA 11.8. python >= 3.8. lspci | grep -i nvidia. 0a:00.0 3D controller: NVIDIA Corporation AD102GL ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:4213,integrability,version,version,4213," 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. L40S card is CUDA CC = 8.9. supported since CUDA >= 11.8 currently 12.4 and 12.5. https://developer.nvidia.com/cuda-11-8-0-download-archive - installed, still doesn't work with containerized 11.3.1. tensorRT is used. https://docs.nvidia.com/deeplearning/tensorrt/support-matrix/index.html . currently 10.1 ; version 8 in CUDA 11.8. python >= 3.8. lspci | grep -i nvidia. 0a:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). ae:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). nvidia-container-cli is installed (supersedes nvidia-d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:4342,integrability,version,version,4342,"r/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. L40S card is CUDA CC = 8.9. supported since CUDA >= 11.8 currently 12.4 and 12.5. https://developer.nvidia.com/cuda-11-8-0-download-archive - installed, still doesn't work with containerized 11.3.1. tensorRT is used. https://docs.nvidia.com/deeplearning/tensorrt/support-matrix/index.html . currently 10.1 ; version 8 in CUDA 11.8. python >= 3.8. lspci | grep -i nvidia. 0a:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). ae:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). nvidia-container-cli is installed (supersedes nvidia-docker - https://github.com/NVIDIA/nvidia-docker )",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:4966,integrability,version,version,4966,"r/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. L40S card is CUDA CC = 8.9. supported since CUDA >= 11.8 currently 12.4 and 12.5. https://developer.nvidia.com/cuda-11-8-0-download-archive - installed, still doesn't work with containerized 11.3.1. tensorRT is used. https://docs.nvidia.com/deeplearning/tensorrt/support-matrix/index.html . currently 10.1 ; version 8 in CUDA 11.8. python >= 3.8. lspci | grep -i nvidia. 0a:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). ae:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). nvidia-container-cli is installed (supersedes nvidia-docker - https://github.com/NVIDIA/nvidia-docker )",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:1544,interoperability,platform,platform,1544,"**Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tenso",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:2272,interoperability,platform,platform,2272,"terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stre",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:2402,interoperability,share,shared,2402,"cense is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and pro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:2973,interoperability,messag,messages,2973,"N custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:396,modifiability,maintain,maintainers,396,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:604,modifiability,version,version,604,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:810,modifiability,Pac,Pacbio,810,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:1016,modifiability,Version,Version,1016,".5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see sli",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:2166,modifiability,variab,variable,2166,"overned by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:3026,modifiability,Version,Version,3026,"erent numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:4075,modifiability,version,version,4075,"low/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. L40S card is CUDA CC = 8.9. supported since CUDA >= 11.8 currently 12.4 and 12.5. https://developer.nvidia.com/cuda-11-8-0-download-archive - installed, still doesn't work with containerized 11.3.1. tensorRT is used. https://docs.nvidia.com/deeplearning/tensorrt/support-matrix/index.html . currently 10.1 ; version 8 in CUDA 11.8. python >= 3.8. lspci | grep -i nvidia. 0a:00.0 3D controller: NVIDIA Corporation AD102GL ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:4213,modifiability,version,version,4213," 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. L40S card is CUDA CC = 8.9. supported since CUDA >= 11.8 currently 12.4 and 12.5. https://developer.nvidia.com/cuda-11-8-0-download-archive - installed, still doesn't work with containerized 11.3.1. tensorRT is used. https://docs.nvidia.com/deeplearning/tensorrt/support-matrix/index.html . currently 10.1 ; version 8 in CUDA 11.8. python >= 3.8. lspci | grep -i nvidia. 0a:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). ae:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). nvidia-container-cli is installed (supersedes nvidia-d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:4342,modifiability,version,version,4342,"r/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. L40S card is CUDA CC = 8.9. supported since CUDA >= 11.8 currently 12.4 and 12.5. https://developer.nvidia.com/cuda-11-8-0-download-archive - installed, still doesn't work with containerized 11.3.1. tensorRT is used. https://docs.nvidia.com/deeplearning/tensorrt/support-matrix/index.html . currently 10.1 ; version 8 in CUDA 11.8. python >= 3.8. lspci | grep -i nvidia. 0a:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). ae:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). nvidia-container-cli is installed (supersedes nvidia-docker - https://github.com/NVIDIA/nvidia-docker )",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:4966,modifiability,version,version,4966,"r/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. L40S card is CUDA CC = 8.9. supported since CUDA >= 11.8 currently 12.4 and 12.5. https://developer.nvidia.com/cuda-11-8-0-download-archive - installed, still doesn't work with containerized 11.3.1. tensorRT is used. https://docs.nvidia.com/deeplearning/tensorrt/support-matrix/index.html . currently 10.1 ; version 8 in CUDA 11.8. python >= 3.8. lspci | grep -i nvidia. 0a:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). ae:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). nvidia-container-cli is installed (supersedes nvidia-docker - https://github.com/NVIDIA/nvidia-docker )",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:25,performance,gpu,gpu,25,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:56,performance,gpu,gpu,56,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:81,performance,CPU,CPU-only,81,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:283,performance,gpu,gpu,283,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:312,performance,gpu,gpu,312,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:337,performance,CPU,CPU-only,337,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:619,performance,gpu,gpu,619,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:630,performance,gpu,gpu,630,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:886,performance,gpu,gpus,886,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:918,performance,gpu,gpu,918,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:938,performance,gpu,gpus,938,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:970,performance,gpu,gpu,970,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:977,performance,Error,Error,977,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:1156,performance,content,contents,1156,"? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the enviro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:1605,performance,optimiz,optimized,1605,"n: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warnin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:1639,performance,Network,Network,1639,"lation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT li",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:1685,performance,CPU,CPU,1685,"c.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:1705,performance,perform,performance-critical,1705,": (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:2086,performance,error,errors,2086,"ON & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:2317,performance,load,load,2317,"s://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:2684,performance,GPU,GPU,2684,"PU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:3416,performance,perform,performed,3416," No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:3429,performance,CPU,CPUs,3429,"ile or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:3487,performance,time,times,3487,"sr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please test with https://",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:1419,reliability,availab,available,1419,"er images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:2017,reliability,sli,slightly,2017,"on 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:3137,reliability,fail,failed,3137," off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/co",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:3313,reliability,fail,failed,3313," load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:3590,reliability,fail,failed,3590,"38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:3787,reliability,diagno,diagnostic,3787," steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. L40S card is CUDA CC = 8.9. supported since CUDA >= 11.8 currently 12.4 and 12.5. https://developer.nvidia.com/cuda-11-8-0-download-ar",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:4415,reliability,Doe,Does,4415,"r/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. L40S card is CUDA CC = 8.9. supported since CUDA >= 11.8 currently 12.4 and 12.5. https://developer.nvidia.com/cuda-11-8-0-download-archive - installed, still doesn't work with containerized 11.3.1. tensorRT is used. https://docs.nvidia.com/deeplearning/tensorrt/support-matrix/index.html . currently 10.1 ; version 8 in CUDA 11.8. python >= 3.8. lspci | grep -i nvidia. 0a:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). ae:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). nvidia-container-cli is installed (supersedes nvidia-docker - https://github.com/NVIDIA/nvidia-docker )",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:4817,reliability,doe,doesn,4817,"r/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. L40S card is CUDA CC = 8.9. supported since CUDA >= 11.8 currently 12.4 and 12.5. https://developer.nvidia.com/cuda-11-8-0-download-archive - installed, still doesn't work with containerized 11.3.1. tensorRT is used. https://docs.nvidia.com/deeplearning/tensorrt/support-matrix/index.html . currently 10.1 ; version 8 in CUDA 11.8. python >= 3.8. lspci | grep -i nvidia. 0a:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). ae:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). nvidia-container-cli is installed (supersedes nvidia-docker - https://github.com/NVIDIA/nvidia-docker )",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:396,safety,maintain,maintainers,396,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:977,safety,Error,Error,977,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:1419,safety,avail,available,1419,"er images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:2086,safety,error,errors,2086,"ON & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:2810,safety,input,input,2810,"A. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:3208,safety,detect,detected,3208," 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:3384,safety,detect,detected,3384,": cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:3472,safety,log,log,3472,"al/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please te",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:3661,safety,detect,detected,3661,"like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. L40S ca",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:4436,safety,test,test,4436,"r/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. L40S card is CUDA CC = 8.9. supported since CUDA >= 11.8 currently 12.4 and 12.5. https://developer.nvidia.com/cuda-11-8-0-download-archive - installed, still doesn't work with containerized 11.3.1. tensorRT is used. https://docs.nvidia.com/deeplearning/tensorrt/support-matrix/index.html . currently 10.1 ; version 8 in CUDA 11.8. python >= 3.8. lspci | grep -i nvidia. 0a:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). ae:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). nvidia-container-cli is installed (supersedes nvidia-docker - https://github.com/NVIDIA/nvidia-docker )",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:4472,safety,test,test,4472,"r/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. L40S card is CUDA CC = 8.9. supported since CUDA >= 11.8 currently 12.4 and 12.5. https://developer.nvidia.com/cuda-11-8-0-download-archive - installed, still doesn't work with containerized 11.3.1. tensorRT is used. https://docs.nvidia.com/deeplearning/tensorrt/support-matrix/index.html . currently 10.1 ; version 8 in CUDA 11.8. python >= 3.8. lspci | grep -i nvidia. 0a:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). ae:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). nvidia-container-cli is installed (supersedes nvidia-docker - https://github.com/NVIDIA/nvidia-docker )",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:1169,security,govern,governed,1169,"hub.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variabl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:1419,security,availab,available,1419,"er images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:1639,security,Network,Network,1639,"lation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT li",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:3208,security,detect,detected,3208," 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:3384,security,detect,detected,3384,": cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:3472,security,log,log,3472,"al/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please te",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:3661,security,detect,detected,3661,"like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. L40S ca",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:5040,security,control,controller,5040,"r/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. L40S card is CUDA CC = 8.9. supported since CUDA >= 11.8 currently 12.4 and 12.5. https://developer.nvidia.com/cuda-11-8-0-download-archive - installed, still doesn't work with containerized 11.3.1. tensorRT is used. https://docs.nvidia.com/deeplearning/tensorrt/support-matrix/index.html . currently 10.1 ; version 8 in CUDA 11.8. python >= 3.8. lspci | grep -i nvidia. 0a:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). ae:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). nvidia-container-cli is installed (supersedes nvidia-docker - https://github.com/NVIDIA/nvidia-docker )",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:5107,security,control,controller,5107,"r/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. L40S card is CUDA CC = 8.9. supported since CUDA >= 11.8 currently 12.4 and 12.5. https://developer.nvidia.com/cuda-11-8-0-download-archive - installed, still doesn't work with containerized 11.3.1. tensorRT is used. https://docs.nvidia.com/deeplearning/tensorrt/support-matrix/index.html . currently 10.1 ; version 8 in CUDA 11.8. python >= 3.8. lspci | grep -i nvidia. 0a:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). ae:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). nvidia-container-cli is installed (supersedes nvidia-docker - https://github.com/NVIDIA/nvidia-docker )",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:729,testability,instrument,instrument,729,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:983,testability,trace,trace,983,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:3472,testability,log,log,3472,"al/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please te",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:3787,testability,diagno,diagnostic,3787," steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. L40S card is CUDA CC = 8.9. supported since CUDA >= 11.8 currently 12.4 and 12.5. https://developer.nvidia.com/cuda-11-8-0-download-ar",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:4436,testability,test,test,4436,"r/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. L40S card is CUDA CC = 8.9. supported since CUDA >= 11.8 currently 12.4 and 12.5. https://developer.nvidia.com/cuda-11-8-0-download-archive - installed, still doesn't work with containerized 11.3.1. tensorRT is used. https://docs.nvidia.com/deeplearning/tensorrt/support-matrix/index.html . currently 10.1 ; version 8 in CUDA 11.8. python >= 3.8. lspci | grep -i nvidia. 0a:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). ae:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). nvidia-container-cli is installed (supersedes nvidia-docker - https://github.com/NVIDIA/nvidia-docker )",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:4472,testability,test,test,4472,"r/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. L40S card is CUDA CC = 8.9. supported since CUDA >= 11.8 currently 12.4 and 12.5. https://developer.nvidia.com/cuda-11-8-0-download-archive - installed, still doesn't work with containerized 11.3.1. tensorRT is used. https://docs.nvidia.com/deeplearning/tensorrt/support-matrix/index.html . currently 10.1 ; version 8 in CUDA 11.8. python >= 3.8. lspci | grep -i nvidia. 0a:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). ae:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). nvidia-container-cli is installed (supersedes nvidia-docker - https://github.com/NVIDIA/nvidia-docker )",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:4646,testability,context,context,4646,"r/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. L40S card is CUDA CC = 8.9. supported since CUDA >= 11.8 currently 12.4 and 12.5. https://developer.nvidia.com/cuda-11-8-0-download-archive - installed, still doesn't work with containerized 11.3.1. tensorRT is used. https://docs.nvidia.com/deeplearning/tensorrt/support-matrix/index.html . currently 10.1 ; version 8 in CUDA 11.8. python >= 3.8. lspci | grep -i nvidia. 0a:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). ae:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). nvidia-container-cli is installed (supersedes nvidia-docker - https://github.com/NVIDIA/nvidia-docker )",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:5040,testability,control,controller,5040,"r/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. L40S card is CUDA CC = 8.9. supported since CUDA >= 11.8 currently 12.4 and 12.5. https://developer.nvidia.com/cuda-11-8-0-download-archive - installed, still doesn't work with containerized 11.3.1. tensorRT is used. https://docs.nvidia.com/deeplearning/tensorrt/support-matrix/index.html . currently 10.1 ; version 8 in CUDA 11.8. python >= 3.8. lspci | grep -i nvidia. 0a:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). ae:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). nvidia-container-cli is installed (supersedes nvidia-docker - https://github.com/NVIDIA/nvidia-docker )",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:5107,testability,control,controller,5107,"r/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. L40S card is CUDA CC = 8.9. supported since CUDA >= 11.8 currently 12.4 and 12.5. https://developer.nvidia.com/cuda-11-8-0-download-archive - installed, still doesn't work with containerized 11.3.1. tensorRT is used. https://docs.nvidia.com/deeplearning/tensorrt/support-matrix/index.html . currently 10.1 ; version 8 in CUDA 11.8. python >= 3.8. lspci | grep -i nvidia. 0a:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). ae:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). nvidia-container-cli is installed (supersedes nvidia-docker - https://github.com/NVIDIA/nvidia-docker )",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:864,usability,Command,Command,864,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:977,usability,Error,Error,977,"google/deepvariant:1.5.0-gpu | google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:1197,usability,Learn,Learning,1197,"lob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. google/deepvariant:1.5.0-gpu google/deepvariant:1.6.1-gpu docker images run as CPU-only because they are using ancient CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:1360,usability,learn,learning-container-license,1360,"ent CUDA 11.3.1. Could maintainers build newer docker images with CUDA >=12.4 or at least >=11.8 to be able to use modern cards such as H100 and L40S (CUDA CC = 8.9 and 9.0). **Setup**. - Operating system: RHEL 8.10. - DeepVariant version: 1.5.0-gpu, 1.6.1-gpu. - Installation method (Docker, built from source, etc.): docker . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:1705,usability,perform,performance-critical,1705,": (sequencing instrument, reference genome, anything special that is unlike the case studies?) Pacbio Revel fresh data. . **Steps to reproduce:**. - Command: docker run --gpus 1 google/deepvariant:1.5.0-gpu or docker run --gpus 1 google/deepvariant:1.6.1-gpu. - Error trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:1979,usability,custom,custom,1979," trace: (if applicable). ... CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:2086,usability,error,errors,2086,"ON & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-03 17:21:57.549571: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:2810,usability,input,input,2810,"A. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2024-07-03 17:21:57.644332: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 2024-07-03 17:21:58.247052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libcublas.so.12: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:3416,usability,perform,performed,3416," No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64. 2024-07-03 17:21:58.247080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. Runs all 3 steps to go from input DNA reads to output VCF/gVCF files. (... then -- the list of all options follows). If run on a proper BAM file with all options provided, all TF-TRT warning messages are periodically repeated as well as . CUDA Version 11.3.1. 2024-07-02 22:47:07.493311: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-02 22:47:12.386498: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:4686,usability,support,supported,4686,"r/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. L40S card is CUDA CC = 8.9. supported since CUDA >= 11.8 currently 12.4 and 12.5. https://developer.nvidia.com/cuda-11-8-0-download-archive - installed, still doesn't work with containerized 11.3.1. tensorRT is used. https://docs.nvidia.com/deeplearning/tensorrt/support-matrix/index.html . currently 10.1 ; version 8 in CUDA 11.8. python >= 3.8. lspci | grep -i nvidia. 0a:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). ae:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). nvidia-container-cli is installed (supersedes nvidia-docker - https://github.com/NVIDIA/nvidia-docker )",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/844:4921,usability,support,support-matrix,4921,"r/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. ... and processing is performed on CPUs. . Also, these details are put in the log hudreds of times:. 2024-07-03 18:27:31.862526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected. 2024-07-03 18:27:31.862557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 8308a7bb3067. 2024-07-03 18:27:31.862563: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 8308a7bb3067. 2024-07-03 18:27:31.862607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 555.42.6. 2024-07-03 18:27:31.862621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 555.42.6. 2024-07-03 18:27:31.862626: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 555.42.6. (then repeated with every call). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. L40S card is CUDA CC = 8.9. supported since CUDA >= 11.8 currently 12.4 and 12.5. https://developer.nvidia.com/cuda-11-8-0-download-archive - installed, still doesn't work with containerized 11.3.1. tensorRT is used. https://docs.nvidia.com/deeplearning/tensorrt/support-matrix/index.html . currently 10.1 ; version 8 in CUDA 11.8. python >= 3.8. lspci | grep -i nvidia. 0a:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). ae:00.0 3D controller: NVIDIA Corporation AD102GL [L40S] (rev a1). nvidia-container-cli is installed (supersedes nvidia-docker - https://github.com/NVIDIA/nvidia-docker )",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/844
https://github.com/google/deepvariant/issues/845:59,availability,restor,restored,59,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:255,availability,error,error,255,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:383,availability,checkpoint,checkpoint,383,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:394,availability,checkpoint,checkpoint,394,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:468,availability,checkpoint,checkpoint,468,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:479,availability,checkpoint,checkpoint,479,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:574,availability,Restor,Restoring,574,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:612,availability,checkpoint,checkpoint,612,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:646,availability,restor,restore,646,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:752,availability,restor,restore,752,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:849,availability,checkpoint,checkpoints,849,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:982,availability,checkpoint,checkpoint,982,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1128,availability,checkpoint,checkpoint,1128,"ant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(ma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1139,availability,checkpoint,checkpoint,1139,"el on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1213,availability,checkpoint,checkpoint,1213," but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvar",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1224,availability,checkpoint,checkpoint,1224,"del keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_v",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1319,availability,Restor,Restoring,1319,"m /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1357,availability,checkpoint,checkpoint,1357,"es/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_v",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1391,availability,restor,restore,1391,"heckpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_va",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1497,availability,restor,restore,1497,"ted and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1594,availability,checkpoint,checkpoints,1594,"train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) fr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1727,availability,checkpoint,checkpoint,1727,"e. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. ra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:2672,availability,checkpoint,checkpoint,2672,"ame one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 7, 32) dtype=float32, numpy=. . My knowledge in deep learning models is not the best, so if you could please tell me how to overcome this error, as the RNA model seems to have very promising results for RNA variant calling and i want to use it. **Setup**. - Operating system: Ubuntu 20.0. - DeepVariant version: Latest version 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: GIAB benchmark data used in the deepvariant-rnaseq-case-study.md but not restricted to chr20. **Steps to reproduce:**. - Command: . docker run -v ""$(pwd):$(pwd)"" -w $(pwd) google/deepvariant:latest run_deepvariant --model_type=WES --customized_model=model/model.ckpt --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta --reads=STAR/Mapping/marked_split.bam --output_vcf=STAR/Mapping/deepvar",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:2683,availability,checkpoint,checkpoint,2683,"s message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 7, 32) dtype=float32, numpy=. . My knowledge in deep learning models is not the best, so if you could please tell me how to overcome this error, as the RNA model seems to have very promising results for RNA variant calling and i want to use it. **Setup**. - Operating system: Ubuntu 20.0. - DeepVariant version: Latest version 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: GIAB benchmark data used in the deepvariant-rnaseq-case-study.md but not restricted to chr20. **Steps to reproduce:**. - Command: . docker run -v ""$(pwd):$(pwd)"" -w $(pwd) google/deepvariant:latest run_deepvariant --model_type=WES --customized_model=model/model.ckpt --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta --reads=STAR/Mapping/marked_split.bam --output_vcf=STAR/Mapping/deepvariant.rna.vc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:2812,availability,restor,restored,2812,"m) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 7, 32) dtype=float32, numpy=. . My knowledge in deep learning models is not the best, so if you could please tell me how to overcome this error, as the RNA model seems to have very promising results for RNA variant calling and i want to use it. **Setup**. - Operating system: Ubuntu 20.0. - DeepVariant version: Latest version 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: GIAB benchmark data used in the deepvariant-rnaseq-case-study.md but not restricted to chr20. **Steps to reproduce:**. - Command: . docker run -v ""$(pwd):$(pwd)"" -w $(pwd) google/deepvariant:latest run_deepvariant --model_type=WES --customized_model=model/model.ckpt --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta --reads=STAR/Mapping/marked_split.bam --output_vcf=STAR/Mapping/deepvariant.rna.vcf --num_shards=$(nproc)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:3006,availability,error,error,3006,"m) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 7, 32) dtype=float32, numpy=. . My knowledge in deep learning models is not the best, so if you could please tell me how to overcome this error, as the RNA model seems to have very promising results for RNA variant calling and i want to use it. **Setup**. - Operating system: Ubuntu 20.0. - DeepVariant version: Latest version 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: GIAB benchmark data used in the deepvariant-rnaseq-case-study.md but not restricted to chr20. **Steps to reproduce:**. - Command: . docker run -v ""$(pwd):$(pwd)"" -w $(pwd) google/deepvariant:latest run_deepvariant --model_type=WES --customized_model=model/model.ckpt --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta --reads=STAR/Mapping/marked_split.bam --output_vcf=STAR/Mapping/deepvariant.rna.vcf --num_shards=$(nproc)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:3126,availability,Operat,Operating,3126,"m) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 7, 32) dtype=float32, numpy=. . My knowledge in deep learning models is not the best, so if you could please tell me how to overcome this error, as the RNA model seems to have very promising results for RNA variant calling and i want to use it. **Setup**. - Operating system: Ubuntu 20.0. - DeepVariant version: Latest version 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: GIAB benchmark data used in the deepvariant-rnaseq-case-study.md but not restricted to chr20. **Steps to reproduce:**. - Command: . docker run -v ""$(pwd):$(pwd)"" -w $(pwd) google/deepvariant:latest run_deepvariant --model_type=WES --customized_model=model/model.ckpt --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta --reads=STAR/Mapping/marked_split.bam --output_vcf=STAR/Mapping/deepvariant.rna.vcf --num_shards=$(nproc)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:537,deployability,version,version,537,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:563,deployability,updat,updating,563,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:654,deployability,API,API,654,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:811,deployability,build,building,811,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1282,deployability,version,version,1282,"riants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tm",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1308,deployability,updat,updating,1308,"nsorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1399,deployability,API,API,1399,"int.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1556,deployability,build,building,1556,"or updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1901,deployability,modul,module,1901,"he object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 7, 32) dtype=float32, numpy=. . My k",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:3171,deployability,version,version,3171,"m) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 7, 32) dtype=float32, numpy=. . My knowledge in deep learning models is not the best, so if you could please tell me how to overcome this error, as the RNA model seems to have very promising results for RNA variant calling and i want to use it. **Setup**. - Operating system: Ubuntu 20.0. - DeepVariant version: Latest version 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: GIAB benchmark data used in the deepvariant-rnaseq-case-study.md but not restricted to chr20. **Steps to reproduce:**. - Command: . docker run -v ""$(pwd):$(pwd)"" -w $(pwd) google/deepvariant:latest run_deepvariant --model_type=WES --customized_model=model/model.ckpt --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta --reads=STAR/Mapping/marked_split.bam --output_vcf=STAR/Mapping/deepvariant.rna.vcf --num_shards=$(nproc)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:3187,deployability,version,version,3187,"m) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 7, 32) dtype=float32, numpy=. . My knowledge in deep learning models is not the best, so if you could please tell me how to overcome this error, as the RNA model seems to have very promising results for RNA variant calling and i want to use it. **Setup**. - Operating system: Ubuntu 20.0. - DeepVariant version: Latest version 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: GIAB benchmark data used in the deepvariant-rnaseq-case-study.md but not restricted to chr20. **Steps to reproduce:**. - Command: . docker run -v ""$(pwd):$(pwd)"" -w $(pwd) google/deepvariant:latest run_deepvariant --model_type=WES --customized_model=model/model.ckpt --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta --reads=STAR/Mapping/marked_split.bam --output_vcf=STAR/Mapping/deepvariant.rna.vcf --num_shards=$(nproc)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:3204,deployability,Instal,Installation,3204,"m) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 7, 32) dtype=float32, numpy=. . My knowledge in deep learning models is not the best, so if you could please tell me how to overcome this error, as the RNA model seems to have very promising results for RNA variant calling and i want to use it. **Setup**. - Operating system: Ubuntu 20.0. - DeepVariant version: Latest version 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: GIAB benchmark data used in the deepvariant-rnaseq-case-study.md but not restricted to chr20. **Steps to reproduce:**. - Command: . docker run -v ""$(pwd):$(pwd)"" -w $(pwd) google/deepvariant:latest run_deepvariant --model_type=WES --customized_model=model/model.ckpt --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta --reads=STAR/Mapping/marked_split.bam --output_vcf=STAR/Mapping/deepvariant.rna.vcf --num_shards=$(nproc)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:141,energy efficiency,model,model,141,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:227,energy efficiency,model,model,227,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:2403,energy efficiency,model,model,2403,"is mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 7, 32) dtype=float32, numpy=. . My knowledge in deep learning models is not the best, so if you could please tell me how to overcome this error, as the RNA model seems to have very promising results for RNA variant calling and i want to use it. **Setup**. - Operating system: Ubuntu 20.0. - DeepVariant version: Latest version 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: GIAB benchmark data used in the deepvariant-rnaseq-case-study.md but not restricted to chr20. **Steps to reproduce:**. - Co",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:2930,energy efficiency,model,models,2930,"m) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 7, 32) dtype=float32, numpy=. . My knowledge in deep learning models is not the best, so if you could please tell me how to overcome this error, as the RNA model seems to have very promising results for RNA variant calling and i want to use it. **Setup**. - Operating system: Ubuntu 20.0. - DeepVariant version: Latest version 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: GIAB benchmark data used in the deepvariant-rnaseq-case-study.md but not restricted to chr20. **Steps to reproduce:**. - Command: . docker run -v ""$(pwd):$(pwd)"" -w $(pwd) google/deepvariant:latest run_deepvariant --model_type=WES --customized_model=model/model.ckpt --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta --reads=STAR/Mapping/marked_split.bam --output_vcf=STAR/Mapping/deepvariant.rna.vcf --num_shards=$(nproc)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:3024,energy efficiency,model,model,3024,"m) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 7, 32) dtype=float32, numpy=. . My knowledge in deep learning models is not the best, so if you could please tell me how to overcome this error, as the RNA model seems to have very promising results for RNA variant calling and i want to use it. **Setup**. - Operating system: Ubuntu 20.0. - DeepVariant version: Latest version 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: GIAB benchmark data used in the deepvariant-rnaseq-case-study.md but not restricted to chr20. **Steps to reproduce:**. - Command: . docker run -v ""$(pwd):$(pwd)"" -w $(pwd) google/deepvariant:latest run_deepvariant --model_type=WES --customized_model=model/model.ckpt --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta --reads=STAR/Mapping/marked_split.bam --output_vcf=STAR/Mapping/deepvariant.rna.vcf --num_shards=$(nproc)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:3533,energy efficiency,model,model,3533,"m) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 7, 32) dtype=float32, numpy=. . My knowledge in deep learning models is not the best, so if you could please tell me how to overcome this error, as the RNA model seems to have very promising results for RNA variant calling and i want to use it. **Setup**. - Operating system: Ubuntu 20.0. - DeepVariant version: Latest version 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: GIAB benchmark data used in the deepvariant-rnaseq-case-study.md but not restricted to chr20. **Steps to reproduce:**. - Command: . docker run -v ""$(pwd):$(pwd)"" -w $(pwd) google/deepvariant:latest run_deepvariant --model_type=WES --customized_model=model/model.ckpt --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta --reads=STAR/Mapping/marked_split.bam --output_vcf=STAR/Mapping/deepvariant.rna.vcf --num_shards=$(nproc)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:3539,energy efficiency,model,model,3539,"m) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 7, 32) dtype=float32, numpy=. . My knowledge in deep learning models is not the best, so if you could please tell me how to overcome this error, as the RNA model seems to have very promising results for RNA variant calling and i want to use it. **Setup**. - Operating system: Ubuntu 20.0. - DeepVariant version: Latest version 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: GIAB benchmark data used in the deepvariant-rnaseq-case-study.md but not restricted to chr20. **Steps to reproduce:**. - Command: . docker run -v ""$(pwd):$(pwd)"" -w $(pwd) google/deepvariant:latest run_deepvariant --model_type=WES --customized_model=model/model.ckpt --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta --reads=STAR/Mapping/marked_split.bam --output_vcf=STAR/Mapping/deepvariant.rna.vcf --num_shards=$(nproc)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:537,integrability,version,version,537,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:654,integrability,API,API,654,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:945,integrability,messag,message,945,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1282,integrability,version,version,1282,"riants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tm",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1399,integrability,API,API,1399,"int.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1690,integrability,messag,message,1690,"h variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:3171,integrability,version,version,3171,"m) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 7, 32) dtype=float32, numpy=. . My knowledge in deep learning models is not the best, so if you could please tell me how to overcome this error, as the RNA model seems to have very promising results for RNA variant calling and i want to use it. **Setup**. - Operating system: Ubuntu 20.0. - DeepVariant version: Latest version 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: GIAB benchmark data used in the deepvariant-rnaseq-case-study.md but not restricted to chr20. **Steps to reproduce:**. - Command: . docker run -v ""$(pwd):$(pwd)"" -w $(pwd) google/deepvariant:latest run_deepvariant --model_type=WES --customized_model=model/model.ckpt --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta --reads=STAR/Mapping/marked_split.bam --output_vcf=STAR/Mapping/deepvariant.rna.vcf --num_shards=$(nproc)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:3187,integrability,version,version,3187,"m) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 7, 32) dtype=float32, numpy=. . My knowledge in deep learning models is not the best, so if you could please tell me how to overcome this error, as the RNA model seems to have very promising results for RNA variant calling and i want to use it. **Setup**. - Operating system: Ubuntu 20.0. - DeepVariant version: Latest version 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: GIAB benchmark data used in the deepvariant-rnaseq-case-study.md but not restricted to chr20. **Steps to reproduce:**. - Command: . docker run -v ""$(pwd):$(pwd)"" -w $(pwd) google/deepvariant:latest run_deepvariant --model_type=WES --customized_model=model/model.ckpt --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta --reads=STAR/Mapping/marked_split.bam --output_vcf=STAR/Mapping/deepvariant.rna.vcf --num_shards=$(nproc)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:654,interoperability,API,API,654,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:881,interoperability,format,format,881,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:945,interoperability,messag,message,945,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1399,interoperability,API,API,1399,"int.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1626,interoperability,format,format,1626,"the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1690,interoperability,messag,message,1690,"h variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:356,modifiability,pac,packages,356,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:537,modifiability,version,version,537,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:696,modifiability,variab,variables,696,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1101,modifiability,pac,packages,1101,"m trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 25",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1282,modifiability,version,version,1282,"riants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tm",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1441,modifiability,variab,variables,1441,"rom tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1901,modifiability,modul,module,1901,"he object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 7, 32) dtype=float32, numpy=. . My k",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:2493,modifiability,pac,packages,2493,"restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 7, 32) dtype=float32, numpy=. . My knowledge in deep learning models is not the best, so if you could please tell me how to overcome this error, as the RNA model seems to have very promising results for RNA variant calling and i want to use it. **Setup**. - Operating system: Ubuntu 20.0. - DeepVariant version: Latest version 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: GIAB benchmark data used in the deepvariant-rnaseq-case-study.md but not restricted to chr20. **Steps to reproduce:**. - Command: . docker run -v ""$(pwd):$(pwd)"" -w $(pwd) google/deepvariant:latest run_deepvariant ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:2645,modifiability,pac,packages,2645,"he object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 7, 32) dtype=float32, numpy=. . My knowledge in deep learning models is not the best, so if you could please tell me how to overcome this error, as the RNA model seems to have very promising results for RNA variant calling and i want to use it. **Setup**. - Operating system: Ubuntu 20.0. - DeepVariant version: Latest version 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: GIAB benchmark data used in the deepvariant-rnaseq-case-study.md but not restricted to chr20. **Steps to reproduce:**. - Command: . docker run -v ""$(pwd):$(pwd)"" -w $(pwd) google/deepvariant:latest run_deepvariant --model_type=WES --customized_model=model/model.ckpt --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta --reads=STAR/Mapping/marked_split.bam --out",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:2828,modifiability,Variab,Variable,2828,"m) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 7, 32) dtype=float32, numpy=. . My knowledge in deep learning models is not the best, so if you could please tell me how to overcome this error, as the RNA model seems to have very promising results for RNA variant calling and i want to use it. **Setup**. - Operating system: Ubuntu 20.0. - DeepVariant version: Latest version 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: GIAB benchmark data used in the deepvariant-rnaseq-case-study.md but not restricted to chr20. **Steps to reproduce:**. - Command: . docker run -v ""$(pwd):$(pwd)"" -w $(pwd) google/deepvariant:latest run_deepvariant --model_type=WES --customized_model=model/model.ckpt --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta --reads=STAR/Mapping/marked_split.bam --output_vcf=STAR/Mapping/deepvariant.rna.vcf --num_shards=$(nproc)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:3171,modifiability,version,version,3171,"m) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 7, 32) dtype=float32, numpy=. . My knowledge in deep learning models is not the best, so if you could please tell me how to overcome this error, as the RNA model seems to have very promising results for RNA variant calling and i want to use it. **Setup**. - Operating system: Ubuntu 20.0. - DeepVariant version: Latest version 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: GIAB benchmark data used in the deepvariant-rnaseq-case-study.md but not restricted to chr20. **Steps to reproduce:**. - Command: . docker run -v ""$(pwd):$(pwd)"" -w $(pwd) google/deepvariant:latest run_deepvariant --model_type=WES --customized_model=model/model.ckpt --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta --reads=STAR/Mapping/marked_split.bam --output_vcf=STAR/Mapping/deepvariant.rna.vcf --num_shards=$(nproc)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:3187,modifiability,version,version,3187,"m) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 7, 32) dtype=float32, numpy=. . My knowledge in deep learning models is not the best, so if you could please tell me how to overcome this error, as the RNA model seems to have very promising results for RNA variant calling and i want to use it. **Setup**. - Operating system: Ubuntu 20.0. - DeepVariant version: Latest version 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: GIAB benchmark data used in the deepvariant-rnaseq-case-study.md but not restricted to chr20. **Steps to reproduce:**. - Command: . docker run -v ""$(pwd):$(pwd)"" -w $(pwd) google/deepvariant:latest run_deepvariant --model_type=WES --customized_model=model/model.ckpt --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta --reads=STAR/Mapping/marked_split.bam --output_vcf=STAR/Mapping/deepvariant.rna.vcf --num_shards=$(nproc)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:255,performance,error,error,255,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:782,performance,time,time,782,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1527,performance,time,time,1527," future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:3006,performance,error,error,3006,"m) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 7, 32) dtype=float32, numpy=. . My knowledge in deep learning models is not the best, so if you could please tell me how to overcome this error, as the RNA model seems to have very promising results for RNA variant calling and i want to use it. **Setup**. - Operating system: Ubuntu 20.0. - DeepVariant version: Latest version 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: GIAB benchmark data used in the deepvariant-rnaseq-case-study.md but not restricted to chr20. **Steps to reproduce:**. - Command: . docker run -v ""$(pwd):$(pwd)"" -w $(pwd) google/deepvariant:latest run_deepvariant --model_type=WES --customized_model=model/model.ckpt --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta --reads=STAR/Mapping/marked_split.bam --output_vcf=STAR/Mapping/deepvariant.rna.vcf --num_shards=$(nproc)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:59,reliability,restor,restored,59,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:383,reliability,checkpoint,checkpoint,383,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:394,reliability,checkpoint,checkpoint,394,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:468,reliability,checkpoint,checkpoint,468,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:479,reliability,checkpoint,checkpoint,479,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:574,reliability,Restor,Restoring,574,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:612,reliability,checkpoint,checkpoint,612,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:646,reliability,restor,restore,646,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:752,reliability,restor,restore,752,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:849,reliability,checkpoint,checkpoints,849,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:982,reliability,checkpoint,checkpoint,982,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1128,reliability,checkpoint,checkpoint,1128,"ant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(ma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1139,reliability,checkpoint,checkpoint,1139,"el on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1213,reliability,checkpoint,checkpoint,1213," but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvar",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1224,reliability,checkpoint,checkpoint,1224,"del keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_v",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1319,reliability,Restor,Restoring,1319,"m /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1357,reliability,checkpoint,checkpoint,1357,"es/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_v",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1391,reliability,restor,restore,1391,"heckpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_va",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1497,reliability,restor,restore,1497,"ted and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1594,reliability,checkpoint,checkpoints,1594,"train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) fr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1727,reliability,checkpoint,checkpoint,1727,"e. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. ra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:2672,reliability,checkpoint,checkpoint,2672,"ame one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 7, 32) dtype=float32, numpy=. . My knowledge in deep learning models is not the best, so if you could please tell me how to overcome this error, as the RNA model seems to have very promising results for RNA variant calling and i want to use it. **Setup**. - Operating system: Ubuntu 20.0. - DeepVariant version: Latest version 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: GIAB benchmark data used in the deepvariant-rnaseq-case-study.md but not restricted to chr20. **Steps to reproduce:**. - Command: . docker run -v ""$(pwd):$(pwd)"" -w $(pwd) google/deepvariant:latest run_deepvariant --model_type=WES --customized_model=model/model.ckpt --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta --reads=STAR/Mapping/marked_split.bam --output_vcf=STAR/Mapping/deepvar",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:2683,reliability,checkpoint,checkpoint,2683,"s message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 7, 32) dtype=float32, numpy=. . My knowledge in deep learning models is not the best, so if you could please tell me how to overcome this error, as the RNA model seems to have very promising results for RNA variant calling and i want to use it. **Setup**. - Operating system: Ubuntu 20.0. - DeepVariant version: Latest version 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: GIAB benchmark data used in the deepvariant-rnaseq-case-study.md but not restricted to chr20. **Steps to reproduce:**. - Command: . docker run -v ""$(pwd):$(pwd)"" -w $(pwd) google/deepvariant:latest run_deepvariant --model_type=WES --customized_model=model/model.ckpt --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta --reads=STAR/Mapping/marked_split.bam --output_vcf=STAR/Mapping/deepvariant.rna.vc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:2812,reliability,restor,restored,2812,"m) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 7, 32) dtype=float32, numpy=. . My knowledge in deep learning models is not the best, so if you could please tell me how to overcome this error, as the RNA model seems to have very promising results for RNA variant calling and i want to use it. **Setup**. - Operating system: Ubuntu 20.0. - DeepVariant version: Latest version 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: GIAB benchmark data used in the deepvariant-rnaseq-case-study.md but not restricted to chr20. **Steps to reproduce:**. - Command: . docker run -v ""$(pwd):$(pwd)"" -w $(pwd) google/deepvariant:latest run_deepvariant --model_type=WES --customized_model=model/model.ckpt --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta --reads=STAR/Mapping/marked_split.bam --output_vcf=STAR/Mapping/deepvariant.rna.vcf --num_shards=$(nproc)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:255,safety,error,error,255,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:563,safety,updat,updating,563,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1308,safety,updat,updating,1308,"nsorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1901,safety,modul,module,1901,"he object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 7, 32) dtype=float32, numpy=. . My k",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:3006,safety,error,error,3006,"m) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 7, 32) dtype=float32, numpy=. . My knowledge in deep learning models is not the best, so if you could please tell me how to overcome this error, as the RNA model seems to have very promising results for RNA variant calling and i want to use it. **Setup**. - Operating system: Ubuntu 20.0. - DeepVariant version: Latest version 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: GIAB benchmark data used in the deepvariant-rnaseq-case-study.md but not restricted to chr20. **Steps to reproduce:**. - Command: . docker run -v ""$(pwd):$(pwd)"" -w $(pwd) google/deepvariant:latest run_deepvariant --model_type=WES --customized_model=model/model.ckpt --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta --reads=STAR/Mapping/marked_split.bam --output_vcf=STAR/Mapping/deepvariant.rna.vcf --num_shards=$(nproc)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:141,security,model,model,141,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:227,security,model,model,227,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:563,security,updat,updating,563,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1308,security,updat,updating,1308,"nsorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:2403,security,model,model,2403,"is mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 7, 32) dtype=float32, numpy=. . My knowledge in deep learning models is not the best, so if you could please tell me how to overcome this error, as the RNA model seems to have very promising results for RNA variant calling and i want to use it. **Setup**. - Operating system: Ubuntu 20.0. - DeepVariant version: Latest version 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: GIAB benchmark data used in the deepvariant-rnaseq-case-study.md but not restricted to chr20. **Steps to reproduce:**. - Co",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:2930,security,model,models,2930,"m) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 7, 32) dtype=float32, numpy=. . My knowledge in deep learning models is not the best, so if you could please tell me how to overcome this error, as the RNA model seems to have very promising results for RNA variant calling and i want to use it. **Setup**. - Operating system: Ubuntu 20.0. - DeepVariant version: Latest version 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: GIAB benchmark data used in the deepvariant-rnaseq-case-study.md but not restricted to chr20. **Steps to reproduce:**. - Command: . docker run -v ""$(pwd):$(pwd)"" -w $(pwd) google/deepvariant:latest run_deepvariant --model_type=WES --customized_model=model/model.ckpt --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta --reads=STAR/Mapping/marked_split.bam --output_vcf=STAR/Mapping/deepvariant.rna.vcf --num_shards=$(nproc)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:3024,security,model,model,3024,"m) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 7, 32) dtype=float32, numpy=. . My knowledge in deep learning models is not the best, so if you could please tell me how to overcome this error, as the RNA model seems to have very promising results for RNA variant calling and i want to use it. **Setup**. - Operating system: Ubuntu 20.0. - DeepVariant version: Latest version 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: GIAB benchmark data used in the deepvariant-rnaseq-case-study.md but not restricted to chr20. **Steps to reproduce:**. - Command: . docker run -v ""$(pwd):$(pwd)"" -w $(pwd) google/deepvariant:latest run_deepvariant --model_type=WES --customized_model=model/model.ckpt --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta --reads=STAR/Mapping/marked_split.bam --output_vcf=STAR/Mapping/deepvariant.rna.vcf --num_shards=$(nproc)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:3533,security,model,model,3533,"m) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 7, 32) dtype=float32, numpy=. . My knowledge in deep learning models is not the best, so if you could please tell me how to overcome this error, as the RNA model seems to have very promising results for RNA variant calling and i want to use it. **Setup**. - Operating system: Ubuntu 20.0. - DeepVariant version: Latest version 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: GIAB benchmark data used in the deepvariant-rnaseq-case-study.md but not restricted to chr20. **Steps to reproduce:**. - Command: . docker run -v ""$(pwd):$(pwd)"" -w $(pwd) google/deepvariant:latest run_deepvariant --model_type=WES --customized_model=model/model.ckpt --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta --reads=STAR/Mapping/marked_split.bam --output_vcf=STAR/Mapping/deepvariant.rna.vcf --num_shards=$(nproc)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:3539,security,model,model,3539,"m) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 7, 32) dtype=float32, numpy=. . My knowledge in deep learning models is not the best, so if you could please tell me how to overcome this error, as the RNA model seems to have very promising results for RNA variant calling and i want to use it. **Setup**. - Operating system: Ubuntu 20.0. - DeepVariant version: Latest version 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: GIAB benchmark data used in the deepvariant-rnaseq-case-study.md but not restricted to chr20. **Steps to reproduce:**. - Command: . docker run -v ""$(pwd):$(pwd)"" -w $(pwd) google/deepvariant:latest run_deepvariant --model_type=WES --customized_model=model/model.ckpt --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta --reads=STAR/Mapping/marked_split.bam --output_vcf=STAR/Mapping/deepvariant.rna.vcf --num_shards=$(nproc)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:0,testability,Assert,AssertionError,0,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1753,testability,Trace,Traceback,1753,"e ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. Asser",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:2736,testability,Assert,AssertionError,2736,"m) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 7, 32) dtype=float32, numpy=. . My knowledge in deep learning models is not the best, so if you could please tell me how to overcome this error, as the RNA model seems to have very promising results for RNA variant calling and i want to use it. **Setup**. - Operating system: Ubuntu 20.0. - DeepVariant version: Latest version 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: GIAB benchmark data used in the deepvariant-rnaseq-case-study.md but not restricted to chr20. **Steps to reproduce:**. - Command: . docker run -v ""$(pwd):$(pwd)"" -w $(pwd) google/deepvariant:latest run_deepvariant --model_type=WES --customized_model=model/model.ckpt --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta --reads=STAR/Mapping/marked_split.bam --output_vcf=STAR/Mapping/deepvariant.rna.vcf --num_shards=$(nproc)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:2753,testability,Assert,AssertionError,2753,"m) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 7, 32) dtype=float32, numpy=. . My knowledge in deep learning models is not the best, so if you could please tell me how to overcome this error, as the RNA model seems to have very promising results for RNA variant calling and i want to use it. **Setup**. - Operating system: Ubuntu 20.0. - DeepVariant version: Latest version 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: GIAB benchmark data used in the deepvariant-rnaseq-case-study.md but not restricted to chr20. **Steps to reproduce:**. - Command: . docker run -v ""$(pwd):$(pwd)"" -w $(pwd) google/deepvariant:latest run_deepvariant --model_type=WES --customized_model=model/model.ckpt --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta --reads=STAR/Mapping/marked_split.bam --output_vcf=STAR/Mapping/deepvariant.rna.vcf --num_shards=$(nproc)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:255,usability,error,error,255,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:821,usability,Prefer,Prefer,821,"AssertionError: Some objects had attributes which were not restored:; **Describe the issue:**. Hello, I am trying to run the deepvariant RNA model on HG005 data locally (not restricted to chr20 like the Github example) but the model keeps generating this error while running the call_variants.py step. WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:1566,usability,Prefer,Prefer,1566,"ng:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. W0626 13:39:06.145823 140632388314944 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py:1473: NameBasedSaverStatus.__init__ (from tensorflow.python.checkpoint.checkpoint) is deprecated and will be removed in a future version. Instructions for updating:. Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:2921,usability,learn,learning,2921,"m) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 7, 32) dtype=float32, numpy=. . My knowledge in deep learning models is not the best, so if you could please tell me how to overcome this error, as the RNA model seems to have very promising results for RNA variant calling and i want to use it. **Setup**. - Operating system: Ubuntu 20.0. - DeepVariant version: Latest version 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: GIAB benchmark data used in the deepvariant-rnaseq-case-study.md but not restricted to chr20. **Steps to reproduce:**. - Command: . docker run -v ""$(pwd):$(pwd)"" -w $(pwd) google/deepvariant:latest run_deepvariant --model_type=WES --customized_model=model/model.ckpt --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta --reads=STAR/Mapping/marked_split.bam --output_vcf=STAR/Mapping/deepvariant.rna.vcf --num_shards=$(nproc)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:3006,usability,error,error,3006,"m) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 7, 32) dtype=float32, numpy=. . My knowledge in deep learning models is not the best, so if you could please tell me how to overcome this error, as the RNA model seems to have very promising results for RNA variant calling and i want to use it. **Setup**. - Operating system: Ubuntu 20.0. - DeepVariant version: Latest version 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: GIAB benchmark data used in the deepvariant-rnaseq-case-study.md but not restricted to chr20. **Steps to reproduce:**. - Command: . docker run -v ""$(pwd):$(pwd)"" -w $(pwd) google/deepvariant:latest run_deepvariant --model_type=WES --customized_model=model/model.ckpt --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta --reads=STAR/Mapping/marked_split.bam --output_vcf=STAR/Mapping/deepvariant.rna.vcf --num_shards=$(nproc)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/845:3404,usability,Command,Command,3404,"m) and use that checkpoint in the future. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 633, in <module>. app.run(main). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 618, in main. call_variants(. File ""/tmp/Bazel.runfiles__zgkztyv/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 558, in call_variants. model.load_weights(checkpoint_path).expect_partial(). File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 70, in error_handler. raise e.with_traceback(filtered_tb) from None. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/checkpoint/checkpoint.py"", line 1047, in assert_consumed. raise AssertionError(. AssertionError: Some objects had attributes which were not restored: . <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 7, 32) dtype=float32, numpy=. . My knowledge in deep learning models is not the best, so if you could please tell me how to overcome this error, as the RNA model seems to have very promising results for RNA variant calling and i want to use it. **Setup**. - Operating system: Ubuntu 20.0. - DeepVariant version: Latest version 1.6.1. - Installation method (Docker, built from source, etc.): Docker. - Type of data: GIAB benchmark data used in the deepvariant-rnaseq-case-study.md but not restricted to chr20. **Steps to reproduce:**. - Command: . docker run -v ""$(pwd):$(pwd)"" -w $(pwd) google/deepvariant:latest run_deepvariant --model_type=WES --customized_model=model/model.ckpt --ref=GCA_000001405.15_GRCh38_no_alt_analysis_set.fasta --reads=STAR/Mapping/marked_split.bam --output_vcf=STAR/Mapping/deepvariant.rna.vcf --num_shards=$(nproc)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/845
https://github.com/google/deepvariant/issues/846:291,integrability,Filter,Filter,291,"I have a question about how deepvariant create the vcf files?; Hello, I wonder how do you create the vcf file? . 1. For example, how do deepvariant produce the value of QUAL of each variant? 2. I see you use p_error while calculating the GQ? What's the p_error and how you get it ? 3. I see Filter filed has value : PASS, RefCall and so on. How did it decided? 4. And I have no idea about what's meaning of PL? A vcf item:. `chr20 61098 . C T 48.9 PASS . GT:GQ:DP:AD:VAF:PL 0/1:49:34:17,17:0.5:48,0,66`. Thank you!!!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/846
https://github.com/google/deepvariant/issues/847:455,availability,Operat,Operating,455,"Deepvariant run too long and fails on giraffe output; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I mapped the WGS data to pangenome graph with `vg giraffe`. When calling variant with deepvariant, it takes a very long time on `make_exmaples` and find a huge number of examples (~50X more than my previous data aligned to GRCh38). And finally, deepvariant fails. **Setup**. - Operating system: CentOS 7. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: PCR-free WGS data from 1000 Genomes, CHM13-based pangenome graph. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B $inpath \. -B $outpath \. -B ${TMPDIR}:${TMPDIR} \. -B $(dirname $ref) \. ~/container/deepvariant.1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$ref \. --reads=${inpath}/${sample}.cram \. --output_vcf=${outpath}/${sample}.vcf.gz \. --output_gvcf=${outpath}/${sample}.g.vcf.gz \. --num_shards=${threads} \. --intermediate_results_dir ${TMPDIR} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"". ```. - Error trace: (if applicable). ```. I0706 12:06:34.396180 140036894541632 make_examples_core.py:301] Task 16/40: 20600183 candidates (20662757 examples) [6.77s elapsed]. I0706 12:06:34.020470 140496845215552 make_examples_core.py:301] Task 39/40: 20480581 candidates (20541819 examples) [9.70s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Reference/Human_genome/CHM13/chm13v2.0.fa --reads HG00438.hap48.cram --examples tmp/tmp_HG00438.hap48/make_examples.tfrecord@40.gz --channels insert_size --gvcf tmp/tmp_HG00438.hap48/gvcf.tfrecord@40.gz --keep_legacy_allele_counter_behavior --min_mapping_quality 1 --normalize_reads --task 24. real 1500m24.832s. user 1478m47.340s. sys 6m51.817",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/847
https://github.com/google/deepvariant/issues/847:1269,availability,Error,Error,1269,"ant, it takes a very long time on `make_exmaples` and find a huge number of examples (~50X more than my previous data aligned to GRCh38). And finally, deepvariant fails. **Setup**. - Operating system: CentOS 7. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: PCR-free WGS data from 1000 Genomes, CHM13-based pangenome graph. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B $inpath \. -B $outpath \. -B ${TMPDIR}:${TMPDIR} \. -B $(dirname $ref) \. ~/container/deepvariant.1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$ref \. --reads=${inpath}/${sample}.cram \. --output_vcf=${outpath}/${sample}.vcf.gz \. --output_gvcf=${outpath}/${sample}.g.vcf.gz \. --num_shards=${threads} \. --intermediate_results_dir ${TMPDIR} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"". ```. - Error trace: (if applicable). ```. I0706 12:06:34.396180 140036894541632 make_examples_core.py:301] Task 16/40: 20600183 candidates (20662757 examples) [6.77s elapsed]. I0706 12:06:34.020470 140496845215552 make_examples_core.py:301] Task 39/40: 20480581 candidates (20541819 examples) [9.70s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Reference/Human_genome/CHM13/chm13v2.0.fa --reads HG00438.hap48.cram --examples tmp/tmp_HG00438.hap48/make_examples.tfrecord@40.gz --channels insert_size --gvcf tmp/tmp_HG00438.hap48/gvcf.tfrecord@40.gz --keep_legacy_allele_counter_behavior --min_mapping_quality 1 --normalize_reads --task 24. real 1500m24.832s. user 1478m47.340s. sys 6m51.817s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Deepvariant previously work well with data align",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/847
https://github.com/google/deepvariant/issues/847:29,deployability,fail,fails,29,"Deepvariant run too long and fails on giraffe output; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I mapped the WGS data to pangenome graph with `vg giraffe`. When calling variant with deepvariant, it takes a very long time on `make_exmaples` and find a huge number of examples (~50X more than my previous data aligned to GRCh38). And finally, deepvariant fails. **Setup**. - Operating system: CentOS 7. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: PCR-free WGS data from 1000 Genomes, CHM13-based pangenome graph. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B $inpath \. -B $outpath \. -B ${TMPDIR}:${TMPDIR} \. -B $(dirname $ref) \. ~/container/deepvariant.1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$ref \. --reads=${inpath}/${sample}.cram \. --output_vcf=${outpath}/${sample}.vcf.gz \. --output_gvcf=${outpath}/${sample}.g.vcf.gz \. --num_shards=${threads} \. --intermediate_results_dir ${TMPDIR} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"". ```. - Error trace: (if applicable). ```. I0706 12:06:34.396180 140036894541632 make_examples_core.py:301] Task 16/40: 20600183 candidates (20662757 examples) [6.77s elapsed]. I0706 12:06:34.020470 140496845215552 make_examples_core.py:301] Task 39/40: 20480581 candidates (20541819 examples) [9.70s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Reference/Human_genome/CHM13/chm13v2.0.fa --reads HG00438.hap48.cram --examples tmp/tmp_HG00438.hap48/make_examples.tfrecord@40.gz --channels insert_size --gvcf tmp/tmp_HG00438.hap48/gvcf.tfrecord@40.gz --keep_legacy_allele_counter_behavior --min_mapping_quality 1 --normalize_reads --task 24. real 1500m24.832s. user 1478m47.340s. sys 6m51.817",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/847
https://github.com/google/deepvariant/issues/847:435,deployability,fail,fails,435,"Deepvariant run too long and fails on giraffe output; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I mapped the WGS data to pangenome graph with `vg giraffe`. When calling variant with deepvariant, it takes a very long time on `make_exmaples` and find a huge number of examples (~50X more than my previous data aligned to GRCh38). And finally, deepvariant fails. **Setup**. - Operating system: CentOS 7. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: PCR-free WGS data from 1000 Genomes, CHM13-based pangenome graph. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B $inpath \. -B $outpath \. -B ${TMPDIR}:${TMPDIR} \. -B $(dirname $ref) \. ~/container/deepvariant.1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$ref \. --reads=${inpath}/${sample}.cram \. --output_vcf=${outpath}/${sample}.vcf.gz \. --output_gvcf=${outpath}/${sample}.g.vcf.gz \. --num_shards=${threads} \. --intermediate_results_dir ${TMPDIR} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"". ```. - Error trace: (if applicable). ```. I0706 12:06:34.396180 140036894541632 make_examples_core.py:301] Task 16/40: 20600183 candidates (20662757 examples) [6.77s elapsed]. I0706 12:06:34.020470 140496845215552 make_examples_core.py:301] Task 39/40: 20480581 candidates (20541819 examples) [9.70s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Reference/Human_genome/CHM13/chm13v2.0.fa --reads HG00438.hap48.cram --examples tmp/tmp_HG00438.hap48/make_examples.tfrecord@40.gz --channels insert_size --gvcf tmp/tmp_HG00438.hap48/gvcf.tfrecord@40.gz --keep_legacy_allele_counter_behavior --min_mapping_quality 1 --normalize_reads --task 24. real 1500m24.832s. user 1478m47.340s. sys 6m51.817",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/847
https://github.com/google/deepvariant/issues/847:497,deployability,version,version,497,"Deepvariant run too long and fails on giraffe output; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I mapped the WGS data to pangenome graph with `vg giraffe`. When calling variant with deepvariant, it takes a very long time on `make_exmaples` and find a huge number of examples (~50X more than my previous data aligned to GRCh38). And finally, deepvariant fails. **Setup**. - Operating system: CentOS 7. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: PCR-free WGS data from 1000 Genomes, CHM13-based pangenome graph. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B $inpath \. -B $outpath \. -B ${TMPDIR}:${TMPDIR} \. -B $(dirname $ref) \. ~/container/deepvariant.1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$ref \. --reads=${inpath}/${sample}.cram \. --output_vcf=${outpath}/${sample}.vcf.gz \. --output_gvcf=${outpath}/${sample}.g.vcf.gz \. --num_shards=${threads} \. --intermediate_results_dir ${TMPDIR} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"". ```. - Error trace: (if applicable). ```. I0706 12:06:34.396180 140036894541632 make_examples_core.py:301] Task 16/40: 20600183 candidates (20662757 examples) [6.77s elapsed]. I0706 12:06:34.020470 140496845215552 make_examples_core.py:301] Task 39/40: 20480581 candidates (20541819 examples) [9.70s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Reference/Human_genome/CHM13/chm13v2.0.fa --reads HG00438.hap48.cram --examples tmp/tmp_HG00438.hap48/make_examples.tfrecord@40.gz --channels insert_size --gvcf tmp/tmp_HG00438.hap48/gvcf.tfrecord@40.gz --keep_legacy_allele_counter_behavior --min_mapping_quality 1 --normalize_reads --task 24. real 1500m24.832s. user 1478m47.340s. sys 6m51.817",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/847
https://github.com/google/deepvariant/issues/847:515,deployability,Instal,Installation,515,"Deepvariant run too long and fails on giraffe output; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I mapped the WGS data to pangenome graph with `vg giraffe`. When calling variant with deepvariant, it takes a very long time on `make_exmaples` and find a huge number of examples (~50X more than my previous data aligned to GRCh38). And finally, deepvariant fails. **Setup**. - Operating system: CentOS 7. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: PCR-free WGS data from 1000 Genomes, CHM13-based pangenome graph. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B $inpath \. -B $outpath \. -B ${TMPDIR}:${TMPDIR} \. -B $(dirname $ref) \. ~/container/deepvariant.1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$ref \. --reads=${inpath}/${sample}.cram \. --output_vcf=${outpath}/${sample}.vcf.gz \. --output_gvcf=${outpath}/${sample}.g.vcf.gz \. --num_shards=${threads} \. --intermediate_results_dir ${TMPDIR} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"". ```. - Error trace: (if applicable). ```. I0706 12:06:34.396180 140036894541632 make_examples_core.py:301] Task 16/40: 20600183 candidates (20662757 examples) [6.77s elapsed]. I0706 12:06:34.020470 140496845215552 make_examples_core.py:301] Task 39/40: 20480581 candidates (20541819 examples) [9.70s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Reference/Human_genome/CHM13/chm13v2.0.fa --reads HG00438.hap48.cram --examples tmp/tmp_HG00438.hap48/make_examples.tfrecord@40.gz --channels insert_size --gvcf tmp/tmp_HG00438.hap48/gvcf.tfrecord@40.gz --keep_legacy_allele_counter_behavior --min_mapping_quality 1 --normalize_reads --task 24. real 1500m24.832s. user 1478m47.340s. sys 6m51.817",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/847
https://github.com/google/deepvariant/issues/847:845,deployability,contain,container,845,"Deepvariant run too long and fails on giraffe output; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I mapped the WGS data to pangenome graph with `vg giraffe`. When calling variant with deepvariant, it takes a very long time on `make_exmaples` and find a huge number of examples (~50X more than my previous data aligned to GRCh38). And finally, deepvariant fails. **Setup**. - Operating system: CentOS 7. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: PCR-free WGS data from 1000 Genomes, CHM13-based pangenome graph. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B $inpath \. -B $outpath \. -B ${TMPDIR}:${TMPDIR} \. -B $(dirname $ref) \. ~/container/deepvariant.1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$ref \. --reads=${inpath}/${sample}.cram \. --output_vcf=${outpath}/${sample}.vcf.gz \. --output_gvcf=${outpath}/${sample}.g.vcf.gz \. --num_shards=${threads} \. --intermediate_results_dir ${TMPDIR} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"". ```. - Error trace: (if applicable). ```. I0706 12:06:34.396180 140036894541632 make_examples_core.py:301] Task 16/40: 20600183 candidates (20662757 examples) [6.77s elapsed]. I0706 12:06:34.020470 140496845215552 make_examples_core.py:301] Task 39/40: 20480581 candidates (20541819 examples) [9.70s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Reference/Human_genome/CHM13/chm13v2.0.fa --reads HG00438.hap48.cram --examples tmp/tmp_HG00438.hap48/make_examples.tfrecord@40.gz --channels insert_size --gvcf tmp/tmp_HG00438.hap48/gvcf.tfrecord@40.gz --keep_legacy_allele_counter_behavior --min_mapping_quality 1 --normalize_reads --task 24. real 1500m24.832s. user 1478m47.340s. sys 6m51.817",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/847
https://github.com/google/deepvariant/issues/847:1591,deployability,fail,failed,1591,"ata: PCR-free WGS data from 1000 Genomes, CHM13-based pangenome graph. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B $inpath \. -B $outpath \. -B ${TMPDIR}:${TMPDIR} \. -B $(dirname $ref) \. ~/container/deepvariant.1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$ref \. --reads=${inpath}/${sample}.cram \. --output_vcf=${outpath}/${sample}.vcf.gz \. --output_gvcf=${outpath}/${sample}.g.vcf.gz \. --num_shards=${threads} \. --intermediate_results_dir ${TMPDIR} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"". ```. - Error trace: (if applicable). ```. I0706 12:06:34.396180 140036894541632 make_examples_core.py:301] Task 16/40: 20600183 candidates (20662757 examples) [6.77s elapsed]. I0706 12:06:34.020470 140496845215552 make_examples_core.py:301] Task 39/40: 20480581 candidates (20541819 examples) [9.70s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Reference/Human_genome/CHM13/chm13v2.0.fa --reads HG00438.hap48.cram --examples tmp/tmp_HG00438.hap48/make_examples.tfrecord@40.gz --channels insert_size --gvcf tmp/tmp_HG00438.hap48/gvcf.tfrecord@40.gz --keep_legacy_allele_counter_behavior --min_mapping_quality 1 --normalize_reads --task 24. real 1500m24.832s. user 1478m47.340s. sys 6m51.817s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Deepvariant previously work well with data aligned to linear reference genome. So, I think it could be some issue with pangenome-aligned data. I can share the cram (e.g., chr22) if you would like to test. **Any additional context:**. Code I used to align to a haplotype sampled pangenome graph:. ```. # vg giraffe to align reads to graph. rg=""ID:1\tLB:lib_${sample}\tSM:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/847
https://github.com/google/deepvariant/issues/847:497,integrability,version,version,497,"Deepvariant run too long and fails on giraffe output; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I mapped the WGS data to pangenome graph with `vg giraffe`. When calling variant with deepvariant, it takes a very long time on `make_exmaples` and find a huge number of examples (~50X more than my previous data aligned to GRCh38). And finally, deepvariant fails. **Setup**. - Operating system: CentOS 7. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: PCR-free WGS data from 1000 Genomes, CHM13-based pangenome graph. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B $inpath \. -B $outpath \. -B ${TMPDIR}:${TMPDIR} \. -B $(dirname $ref) \. ~/container/deepvariant.1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$ref \. --reads=${inpath}/${sample}.cram \. --output_vcf=${outpath}/${sample}.vcf.gz \. --output_gvcf=${outpath}/${sample}.g.vcf.gz \. --num_shards=${threads} \. --intermediate_results_dir ${TMPDIR} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"". ```. - Error trace: (if applicable). ```. I0706 12:06:34.396180 140036894541632 make_examples_core.py:301] Task 16/40: 20600183 candidates (20662757 examples) [6.77s elapsed]. I0706 12:06:34.020470 140496845215552 make_examples_core.py:301] Task 39/40: 20480581 candidates (20541819 examples) [9.70s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Reference/Human_genome/CHM13/chm13v2.0.fa --reads HG00438.hap48.cram --examples tmp/tmp_HG00438.hap48/make_examples.tfrecord@40.gz --channels insert_size --gvcf tmp/tmp_HG00438.hap48/gvcf.tfrecord@40.gz --keep_legacy_allele_counter_behavior --min_mapping_quality 1 --normalize_reads --task 24. real 1500m24.832s. user 1478m47.340s. sys 6m51.817",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/847
https://github.com/google/deepvariant/issues/847:2373,interoperability,share,share,2373,"/40: 20600183 candidates (20662757 examples) [6.77s elapsed]. I0706 12:06:34.020470 140496845215552 make_examples_core.py:301] Task 39/40: 20480581 candidates (20541819 examples) [9.70s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Reference/Human_genome/CHM13/chm13v2.0.fa --reads HG00438.hap48.cram --examples tmp/tmp_HG00438.hap48/make_examples.tfrecord@40.gz --channels insert_size --gvcf tmp/tmp_HG00438.hap48/gvcf.tfrecord@40.gz --keep_legacy_allele_counter_behavior --min_mapping_quality 1 --normalize_reads --task 24. real 1500m24.832s. user 1478m47.340s. sys 6m51.817s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Deepvariant previously work well with data aligned to linear reference genome. So, I think it could be some issue with pangenome-aligned data. I can share the cram (e.g., chr22) if you would like to test. **Any additional context:**. Code I used to align to a haplotype sampled pangenome graph:. ```. # vg giraffe to align reads to graph. rg=""ID:1\tLB:lib_${sample}\tSM:${sample}\tPL:illumina\tPU:lib_${sample}.1"". time \. vg giraffe \. --progress \. --read-group $rg \. --sample ${sample} \. --output-format gam \. -f ${fqpath}/${sample%.hap*}_1_paired.fq.gz \. -f ${fqpath}/${sample%.hap*}_2_paired.fq.gz \. -Z ${gbzpath}/${sample}.gbz \. -t $threads > ${outpath}/${sample}.gam. # vg surject to convert gam to bam. time \. vg surject \. -F $path_list \. -x ${gbzpath}/${sample}.gbz \. -t $(($threads - 10)) \. --sam-output \. --read-group '1' \. --sample ${sample} \. --prune-low-cplx \. --interleaved \. --max-frag-len 3000 \. ${outpath}/${sample}.gam | \. sed 's/CHM13#0#//g' - | \. samtools view -hb - | \. samtools reheader ${outpath}/${sample}.tmp.header.sam - | \. samtools sort --write-index -@ 10 -m 4G -O CRAM --reference $ref -T ${outpath}/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/847
https://github.com/google/deepvariant/issues/847:2726,interoperability,format,format,2726,"7s elapsed]. I0706 12:06:34.020470 140496845215552 make_examples_core.py:301] Task 39/40: 20480581 candidates (20541819 examples) [9.70s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Reference/Human_genome/CHM13/chm13v2.0.fa --reads HG00438.hap48.cram --examples tmp/tmp_HG00438.hap48/make_examples.tfrecord@40.gz --channels insert_size --gvcf tmp/tmp_HG00438.hap48/gvcf.tfrecord@40.gz --keep_legacy_allele_counter_behavior --min_mapping_quality 1 --normalize_reads --task 24. real 1500m24.832s. user 1478m47.340s. sys 6m51.817s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Deepvariant previously work well with data aligned to linear reference genome. So, I think it could be some issue with pangenome-aligned data. I can share the cram (e.g., chr22) if you would like to test. **Any additional context:**. Code I used to align to a haplotype sampled pangenome graph:. ```. # vg giraffe to align reads to graph. rg=""ID:1\tLB:lib_${sample}\tSM:${sample}\tPL:illumina\tPU:lib_${sample}.1"". time \. vg giraffe \. --progress \. --read-group $rg \. --sample ${sample} \. --output-format gam \. -f ${fqpath}/${sample%.hap*}_1_paired.fq.gz \. -f ${fqpath}/${sample%.hap*}_2_paired.fq.gz \. -Z ${gbzpath}/${sample}.gbz \. -t $threads > ${outpath}/${sample}.gam. # vg surject to convert gam to bam. time \. vg surject \. -F $path_list \. -x ${gbzpath}/${sample}.gbz \. -t $(($threads - 10)) \. --sam-output \. --read-group '1' \. --sample ${sample} \. --prune-low-cplx \. --interleaved \. --max-frag-len 3000 \. ${outpath}/${sample}.gam | \. sed 's/CHM13#0#//g' - | \. samtools view -hb - | \. samtools reheader ${outpath}/${sample}.tmp.header.sam - | \. samtools sort --write-index -@ 10 -m 4G -O CRAM --reference $ref -T ${outpath}/${sample}.cram -o ${outpath}/${sample}.cram. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/847
https://github.com/google/deepvariant/issues/847:497,modifiability,version,version,497,"Deepvariant run too long and fails on giraffe output; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I mapped the WGS data to pangenome graph with `vg giraffe`. When calling variant with deepvariant, it takes a very long time on `make_exmaples` and find a huge number of examples (~50X more than my previous data aligned to GRCh38). And finally, deepvariant fails. **Setup**. - Operating system: CentOS 7. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: PCR-free WGS data from 1000 Genomes, CHM13-based pangenome graph. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B $inpath \. -B $outpath \. -B ${TMPDIR}:${TMPDIR} \. -B $(dirname $ref) \. ~/container/deepvariant.1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$ref \. --reads=${inpath}/${sample}.cram \. --output_vcf=${outpath}/${sample}.vcf.gz \. --output_gvcf=${outpath}/${sample}.g.vcf.gz \. --num_shards=${threads} \. --intermediate_results_dir ${TMPDIR} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"". ```. - Error trace: (if applicable). ```. I0706 12:06:34.396180 140036894541632 make_examples_core.py:301] Task 16/40: 20600183 candidates (20662757 examples) [6.77s elapsed]. I0706 12:06:34.020470 140496845215552 make_examples_core.py:301] Task 39/40: 20480581 candidates (20541819 examples) [9.70s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Reference/Human_genome/CHM13/chm13v2.0.fa --reads HG00438.hap48.cram --examples tmp/tmp_HG00438.hap48/make_examples.tfrecord@40.gz --channels insert_size --gvcf tmp/tmp_HG00438.hap48/gvcf.tfrecord@40.gz --keep_legacy_allele_counter_behavior --min_mapping_quality 1 --normalize_reads --task 24. real 1500m24.832s. user 1478m47.340s. sys 6m51.817",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/847
https://github.com/google/deepvariant/issues/847:298,performance,time,time,298,"Deepvariant run too long and fails on giraffe output; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I mapped the WGS data to pangenome graph with `vg giraffe`. When calling variant with deepvariant, it takes a very long time on `make_exmaples` and find a huge number of examples (~50X more than my previous data aligned to GRCh38). And finally, deepvariant fails. **Setup**. - Operating system: CentOS 7. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: PCR-free WGS data from 1000 Genomes, CHM13-based pangenome graph. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B $inpath \. -B $outpath \. -B ${TMPDIR}:${TMPDIR} \. -B $(dirname $ref) \. ~/container/deepvariant.1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$ref \. --reads=${inpath}/${sample}.cram \. --output_vcf=${outpath}/${sample}.vcf.gz \. --output_gvcf=${outpath}/${sample}.g.vcf.gz \. --num_shards=${threads} \. --intermediate_results_dir ${TMPDIR} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"". ```. - Error trace: (if applicable). ```. I0706 12:06:34.396180 140036894541632 make_examples_core.py:301] Task 16/40: 20600183 candidates (20662757 examples) [6.77s elapsed]. I0706 12:06:34.020470 140496845215552 make_examples_core.py:301] Task 39/40: 20480581 candidates (20541819 examples) [9.70s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Reference/Human_genome/CHM13/chm13v2.0.fa --reads HG00438.hap48.cram --examples tmp/tmp_HG00438.hap48/make_examples.tfrecord@40.gz --channels insert_size --gvcf tmp/tmp_HG00438.hap48/gvcf.tfrecord@40.gz --keep_legacy_allele_counter_behavior --min_mapping_quality 1 --normalize_reads --task 24. real 1500m24.832s. user 1478m47.340s. sys 6m51.817",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/847
https://github.com/google/deepvariant/issues/847:1269,performance,Error,Error,1269,"ant, it takes a very long time on `make_exmaples` and find a huge number of examples (~50X more than my previous data aligned to GRCh38). And finally, deepvariant fails. **Setup**. - Operating system: CentOS 7. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: PCR-free WGS data from 1000 Genomes, CHM13-based pangenome graph. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B $inpath \. -B $outpath \. -B ${TMPDIR}:${TMPDIR} \. -B $(dirname $ref) \. ~/container/deepvariant.1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$ref \. --reads=${inpath}/${sample}.cram \. --output_vcf=${outpath}/${sample}.vcf.gz \. --output_gvcf=${outpath}/${sample}.g.vcf.gz \. --num_shards=${threads} \. --intermediate_results_dir ${TMPDIR} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"". ```. - Error trace: (if applicable). ```. I0706 12:06:34.396180 140036894541632 make_examples_core.py:301] Task 16/40: 20600183 candidates (20662757 examples) [6.77s elapsed]. I0706 12:06:34.020470 140496845215552 make_examples_core.py:301] Task 39/40: 20480581 candidates (20541819 examples) [9.70s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Reference/Human_genome/CHM13/chm13v2.0.fa --reads HG00438.hap48.cram --examples tmp/tmp_HG00438.hap48/make_examples.tfrecord@40.gz --channels insert_size --gvcf tmp/tmp_HG00438.hap48/gvcf.tfrecord@40.gz --keep_legacy_allele_counter_behavior --min_mapping_quality 1 --normalize_reads --task 24. real 1500m24.832s. user 1478m47.340s. sys 6m51.817s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Deepvariant previously work well with data align",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/847
https://github.com/google/deepvariant/issues/847:1572,performance,parallel,parallel,1572,"arity. - Type of data: PCR-free WGS data from 1000 Genomes, CHM13-based pangenome graph. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B $inpath \. -B $outpath \. -B ${TMPDIR}:${TMPDIR} \. -B $(dirname $ref) \. ~/container/deepvariant.1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$ref \. --reads=${inpath}/${sample}.cram \. --output_vcf=${outpath}/${sample}.vcf.gz \. --output_gvcf=${outpath}/${sample}.g.vcf.gz \. --num_shards=${threads} \. --intermediate_results_dir ${TMPDIR} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"". ```. - Error trace: (if applicable). ```. I0706 12:06:34.396180 140036894541632 make_examples_core.py:301] Task 16/40: 20600183 candidates (20662757 examples) [6.77s elapsed]. I0706 12:06:34.020470 140496845215552 make_examples_core.py:301] Task 39/40: 20480581 candidates (20541819 examples) [9.70s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Reference/Human_genome/CHM13/chm13v2.0.fa --reads HG00438.hap48.cram --examples tmp/tmp_HG00438.hap48/make_examples.tfrecord@40.gz --channels insert_size --gvcf tmp/tmp_HG00438.hap48/gvcf.tfrecord@40.gz --keep_legacy_allele_counter_behavior --min_mapping_quality 1 --normalize_reads --task 24. real 1500m24.832s. user 1478m47.340s. sys 6m51.817s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Deepvariant previously work well with data aligned to linear reference genome. So, I think it could be some issue with pangenome-aligned data. I can share the cram (e.g., chr22) if you would like to test. **Any additional context:**. Code I used to align to a haplotype sampled pangenome graph:. ```. # vg giraffe to align reads to graph. rg=""ID:1\tLB:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/847
https://github.com/google/deepvariant/issues/847:2639,performance,time,time,2639,"7s elapsed]. I0706 12:06:34.020470 140496845215552 make_examples_core.py:301] Task 39/40: 20480581 candidates (20541819 examples) [9.70s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Reference/Human_genome/CHM13/chm13v2.0.fa --reads HG00438.hap48.cram --examples tmp/tmp_HG00438.hap48/make_examples.tfrecord@40.gz --channels insert_size --gvcf tmp/tmp_HG00438.hap48/gvcf.tfrecord@40.gz --keep_legacy_allele_counter_behavior --min_mapping_quality 1 --normalize_reads --task 24. real 1500m24.832s. user 1478m47.340s. sys 6m51.817s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Deepvariant previously work well with data aligned to linear reference genome. So, I think it could be some issue with pangenome-aligned data. I can share the cram (e.g., chr22) if you would like to test. **Any additional context:**. Code I used to align to a haplotype sampled pangenome graph:. ```. # vg giraffe to align reads to graph. rg=""ID:1\tLB:lib_${sample}\tSM:${sample}\tPL:illumina\tPU:lib_${sample}.1"". time \. vg giraffe \. --progress \. --read-group $rg \. --sample ${sample} \. --output-format gam \. -f ${fqpath}/${sample%.hap*}_1_paired.fq.gz \. -f ${fqpath}/${sample%.hap*}_2_paired.fq.gz \. -Z ${gbzpath}/${sample}.gbz \. -t $threads > ${outpath}/${sample}.gam. # vg surject to convert gam to bam. time \. vg surject \. -F $path_list \. -x ${gbzpath}/${sample}.gbz \. -t $(($threads - 10)) \. --sam-output \. --read-group '1' \. --sample ${sample} \. --prune-low-cplx \. --interleaved \. --max-frag-len 3000 \. ${outpath}/${sample}.gam | \. sed 's/CHM13#0#//g' - | \. samtools view -hb - | \. samtools reheader ${outpath}/${sample}.tmp.header.sam - | \. samtools sort --write-index -@ 10 -m 4G -O CRAM --reference $ref -T ${outpath}/${sample}.cram -o ${outpath}/${sample}.cram. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/847
https://github.com/google/deepvariant/issues/847:2941,performance,time,time,2941,"7s elapsed]. I0706 12:06:34.020470 140496845215552 make_examples_core.py:301] Task 39/40: 20480581 candidates (20541819 examples) [9.70s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Reference/Human_genome/CHM13/chm13v2.0.fa --reads HG00438.hap48.cram --examples tmp/tmp_HG00438.hap48/make_examples.tfrecord@40.gz --channels insert_size --gvcf tmp/tmp_HG00438.hap48/gvcf.tfrecord@40.gz --keep_legacy_allele_counter_behavior --min_mapping_quality 1 --normalize_reads --task 24. real 1500m24.832s. user 1478m47.340s. sys 6m51.817s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Deepvariant previously work well with data aligned to linear reference genome. So, I think it could be some issue with pangenome-aligned data. I can share the cram (e.g., chr22) if you would like to test. **Any additional context:**. Code I used to align to a haplotype sampled pangenome graph:. ```. # vg giraffe to align reads to graph. rg=""ID:1\tLB:lib_${sample}\tSM:${sample}\tPL:illumina\tPU:lib_${sample}.1"". time \. vg giraffe \. --progress \. --read-group $rg \. --sample ${sample} \. --output-format gam \. -f ${fqpath}/${sample%.hap*}_1_paired.fq.gz \. -f ${fqpath}/${sample%.hap*}_2_paired.fq.gz \. -Z ${gbzpath}/${sample}.gbz \. -t $threads > ${outpath}/${sample}.gam. # vg surject to convert gam to bam. time \. vg surject \. -F $path_list \. -x ${gbzpath}/${sample}.gbz \. -t $(($threads - 10)) \. --sam-output \. --read-group '1' \. --sample ${sample} \. --prune-low-cplx \. --interleaved \. --max-frag-len 3000 \. ${outpath}/${sample}.gam | \. sed 's/CHM13#0#//g' - | \. samtools view -hb - | \. samtools reheader ${outpath}/${sample}.tmp.header.sam - | \. samtools sort --write-index -@ 10 -m 4G -O CRAM --reference $ref -T ${outpath}/${sample}.cram -o ${outpath}/${sample}.cram. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/847
https://github.com/google/deepvariant/issues/847:29,reliability,fail,fails,29,"Deepvariant run too long and fails on giraffe output; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I mapped the WGS data to pangenome graph with `vg giraffe`. When calling variant with deepvariant, it takes a very long time on `make_exmaples` and find a huge number of examples (~50X more than my previous data aligned to GRCh38). And finally, deepvariant fails. **Setup**. - Operating system: CentOS 7. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: PCR-free WGS data from 1000 Genomes, CHM13-based pangenome graph. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B $inpath \. -B $outpath \. -B ${TMPDIR}:${TMPDIR} \. -B $(dirname $ref) \. ~/container/deepvariant.1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$ref \. --reads=${inpath}/${sample}.cram \. --output_vcf=${outpath}/${sample}.vcf.gz \. --output_gvcf=${outpath}/${sample}.g.vcf.gz \. --num_shards=${threads} \. --intermediate_results_dir ${TMPDIR} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"". ```. - Error trace: (if applicable). ```. I0706 12:06:34.396180 140036894541632 make_examples_core.py:301] Task 16/40: 20600183 candidates (20662757 examples) [6.77s elapsed]. I0706 12:06:34.020470 140496845215552 make_examples_core.py:301] Task 39/40: 20480581 candidates (20541819 examples) [9.70s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Reference/Human_genome/CHM13/chm13v2.0.fa --reads HG00438.hap48.cram --examples tmp/tmp_HG00438.hap48/make_examples.tfrecord@40.gz --channels insert_size --gvcf tmp/tmp_HG00438.hap48/gvcf.tfrecord@40.gz --keep_legacy_allele_counter_behavior --min_mapping_quality 1 --normalize_reads --task 24. real 1500m24.832s. user 1478m47.340s. sys 6m51.817",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/847
https://github.com/google/deepvariant/issues/847:435,reliability,fail,fails,435,"Deepvariant run too long and fails on giraffe output; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I mapped the WGS data to pangenome graph with `vg giraffe`. When calling variant with deepvariant, it takes a very long time on `make_exmaples` and find a huge number of examples (~50X more than my previous data aligned to GRCh38). And finally, deepvariant fails. **Setup**. - Operating system: CentOS 7. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: PCR-free WGS data from 1000 Genomes, CHM13-based pangenome graph. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B $inpath \. -B $outpath \. -B ${TMPDIR}:${TMPDIR} \. -B $(dirname $ref) \. ~/container/deepvariant.1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$ref \. --reads=${inpath}/${sample}.cram \. --output_vcf=${outpath}/${sample}.vcf.gz \. --output_gvcf=${outpath}/${sample}.g.vcf.gz \. --num_shards=${threads} \. --intermediate_results_dir ${TMPDIR} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"". ```. - Error trace: (if applicable). ```. I0706 12:06:34.396180 140036894541632 make_examples_core.py:301] Task 16/40: 20600183 candidates (20662757 examples) [6.77s elapsed]. I0706 12:06:34.020470 140496845215552 make_examples_core.py:301] Task 39/40: 20480581 candidates (20541819 examples) [9.70s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Reference/Human_genome/CHM13/chm13v2.0.fa --reads HG00438.hap48.cram --examples tmp/tmp_HG00438.hap48/make_examples.tfrecord@40.gz --channels insert_size --gvcf tmp/tmp_HG00438.hap48/gvcf.tfrecord@40.gz --keep_legacy_allele_counter_behavior --min_mapping_quality 1 --normalize_reads --task 24. real 1500m24.832s. user 1478m47.340s. sys 6m51.817",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/847
https://github.com/google/deepvariant/issues/847:1591,reliability,fail,failed,1591,"ata: PCR-free WGS data from 1000 Genomes, CHM13-based pangenome graph. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B $inpath \. -B $outpath \. -B ${TMPDIR}:${TMPDIR} \. -B $(dirname $ref) \. ~/container/deepvariant.1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$ref \. --reads=${inpath}/${sample}.cram \. --output_vcf=${outpath}/${sample}.vcf.gz \. --output_gvcf=${outpath}/${sample}.g.vcf.gz \. --num_shards=${threads} \. --intermediate_results_dir ${TMPDIR} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"". ```. - Error trace: (if applicable). ```. I0706 12:06:34.396180 140036894541632 make_examples_core.py:301] Task 16/40: 20600183 candidates (20662757 examples) [6.77s elapsed]. I0706 12:06:34.020470 140496845215552 make_examples_core.py:301] Task 39/40: 20480581 candidates (20541819 examples) [9.70s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Reference/Human_genome/CHM13/chm13v2.0.fa --reads HG00438.hap48.cram --examples tmp/tmp_HG00438.hap48/make_examples.tfrecord@40.gz --channels insert_size --gvcf tmp/tmp_HG00438.hap48/gvcf.tfrecord@40.gz --keep_legacy_allele_counter_behavior --min_mapping_quality 1 --normalize_reads --task 24. real 1500m24.832s. user 1478m47.340s. sys 6m51.817s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Deepvariant previously work well with data aligned to linear reference genome. So, I think it could be some issue with pangenome-aligned data. I can share the cram (e.g., chr22) if you would like to test. **Any additional context:**. Code I used to align to a haplotype sampled pangenome graph:. ```. # vg giraffe to align reads to graph. rg=""ID:1\tLB:lib_${sample}\tSM:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/847
https://github.com/google/deepvariant/issues/847:2010,reliability,Doe,Does,2010,"}/${sample}.vcf.gz \. --output_gvcf=${outpath}/${sample}.g.vcf.gz \. --num_shards=${threads} \. --intermediate_results_dir ${TMPDIR} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"". ```. - Error trace: (if applicable). ```. I0706 12:06:34.396180 140036894541632 make_examples_core.py:301] Task 16/40: 20600183 candidates (20662757 examples) [6.77s elapsed]. I0706 12:06:34.020470 140496845215552 make_examples_core.py:301] Task 39/40: 20480581 candidates (20541819 examples) [9.70s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Reference/Human_genome/CHM13/chm13v2.0.fa --reads HG00438.hap48.cram --examples tmp/tmp_HG00438.hap48/make_examples.tfrecord@40.gz --channels insert_size --gvcf tmp/tmp_HG00438.hap48/gvcf.tfrecord@40.gz --keep_legacy_allele_counter_behavior --min_mapping_quality 1 --normalize_reads --task 24. real 1500m24.832s. user 1478m47.340s. sys 6m51.817s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Deepvariant previously work well with data aligned to linear reference genome. So, I think it could be some issue with pangenome-aligned data. I can share the cram (e.g., chr22) if you would like to test. **Any additional context:**. Code I used to align to a haplotype sampled pangenome graph:. ```. # vg giraffe to align reads to graph. rg=""ID:1\tLB:lib_${sample}\tSM:${sample}\tPL:illumina\tPU:lib_${sample}.1"". time \. vg giraffe \. --progress \. --read-group $rg \. --sample ${sample} \. --output-format gam \. -f ${fqpath}/${sample%.hap*}_1_paired.fq.gz \. -f ${fqpath}/${sample%.hap*}_2_paired.fq.gz \. -Z ${gbzpath}/${sample}.gbz \. -t $threads > ${outpath}/${sample}.gam. # vg surject to convert gam to bam. time \. vg surject \. -F $path_list \. -x ${gbzpath}/${sample}.gbz \. -",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/847
https://github.com/google/deepvariant/issues/847:1269,safety,Error,Error,1269,"ant, it takes a very long time on `make_exmaples` and find a huge number of examples (~50X more than my previous data aligned to GRCh38). And finally, deepvariant fails. **Setup**. - Operating system: CentOS 7. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: PCR-free WGS data from 1000 Genomes, CHM13-based pangenome graph. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B $inpath \. -B $outpath \. -B ${TMPDIR}:${TMPDIR} \. -B $(dirname $ref) \. ~/container/deepvariant.1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$ref \. --reads=${inpath}/${sample}.cram \. --output_vcf=${outpath}/${sample}.vcf.gz \. --output_gvcf=${outpath}/${sample}.g.vcf.gz \. --num_shards=${threads} \. --intermediate_results_dir ${TMPDIR} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"". ```. - Error trace: (if applicable). ```. I0706 12:06:34.396180 140036894541632 make_examples_core.py:301] Task 16/40: 20600183 candidates (20662757 examples) [6.77s elapsed]. I0706 12:06:34.020470 140496845215552 make_examples_core.py:301] Task 39/40: 20480581 candidates (20541819 examples) [9.70s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Reference/Human_genome/CHM13/chm13v2.0.fa --reads HG00438.hap48.cram --examples tmp/tmp_HG00438.hap48/make_examples.tfrecord@40.gz --channels insert_size --gvcf tmp/tmp_HG00438.hap48/gvcf.tfrecord@40.gz --keep_legacy_allele_counter_behavior --min_mapping_quality 1 --normalize_reads --task 24. real 1500m24.832s. user 1478m47.340s. sys 6m51.817s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Deepvariant previously work well with data align",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/847
https://github.com/google/deepvariant/issues/847:2031,safety,test,test,2031," --output_gvcf=${outpath}/${sample}.g.vcf.gz \. --num_shards=${threads} \. --intermediate_results_dir ${TMPDIR} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"". ```. - Error trace: (if applicable). ```. I0706 12:06:34.396180 140036894541632 make_examples_core.py:301] Task 16/40: 20600183 candidates (20662757 examples) [6.77s elapsed]. I0706 12:06:34.020470 140496845215552 make_examples_core.py:301] Task 39/40: 20480581 candidates (20541819 examples) [9.70s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Reference/Human_genome/CHM13/chm13v2.0.fa --reads HG00438.hap48.cram --examples tmp/tmp_HG00438.hap48/make_examples.tfrecord@40.gz --channels insert_size --gvcf tmp/tmp_HG00438.hap48/gvcf.tfrecord@40.gz --keep_legacy_allele_counter_behavior --min_mapping_quality 1 --normalize_reads --task 24. real 1500m24.832s. user 1478m47.340s. sys 6m51.817s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Deepvariant previously work well with data aligned to linear reference genome. So, I think it could be some issue with pangenome-aligned data. I can share the cram (e.g., chr22) if you would like to test. **Any additional context:**. Code I used to align to a haplotype sampled pangenome graph:. ```. # vg giraffe to align reads to graph. rg=""ID:1\tLB:lib_${sample}\tSM:${sample}\tPL:illumina\tPU:lib_${sample}.1"". time \. vg giraffe \. --progress \. --read-group $rg \. --sample ${sample} \. --output-format gam \. -f ${fqpath}/${sample%.hap*}_1_paired.fq.gz \. -f ${fqpath}/${sample%.hap*}_2_paired.fq.gz \. -Z ${gbzpath}/${sample}.gbz \. -t $threads > ${outpath}/${sample}.gam. # vg surject to convert gam to bam. time \. vg surject \. -F $path_list \. -x ${gbzpath}/${sample}.gbz \. -t $(($threads - 10)) ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/847
https://github.com/google/deepvariant/issues/847:2067,safety,test,test,2067,"g.vcf.gz \. --num_shards=${threads} \. --intermediate_results_dir ${TMPDIR} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"". ```. - Error trace: (if applicable). ```. I0706 12:06:34.396180 140036894541632 make_examples_core.py:301] Task 16/40: 20600183 candidates (20662757 examples) [6.77s elapsed]. I0706 12:06:34.020470 140496845215552 make_examples_core.py:301] Task 39/40: 20480581 candidates (20541819 examples) [9.70s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Reference/Human_genome/CHM13/chm13v2.0.fa --reads HG00438.hap48.cram --examples tmp/tmp_HG00438.hap48/make_examples.tfrecord@40.gz --channels insert_size --gvcf tmp/tmp_HG00438.hap48/gvcf.tfrecord@40.gz --keep_legacy_allele_counter_behavior --min_mapping_quality 1 --normalize_reads --task 24. real 1500m24.832s. user 1478m47.340s. sys 6m51.817s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Deepvariant previously work well with data aligned to linear reference genome. So, I think it could be some issue with pangenome-aligned data. I can share the cram (e.g., chr22) if you would like to test. **Any additional context:**. Code I used to align to a haplotype sampled pangenome graph:. ```. # vg giraffe to align reads to graph. rg=""ID:1\tLB:lib_${sample}\tSM:${sample}\tPL:illumina\tPU:lib_${sample}.1"". time \. vg giraffe \. --progress \. --read-group $rg \. --sample ${sample} \. --output-format gam \. -f ${fqpath}/${sample%.hap*}_1_paired.fq.gz \. -f ${fqpath}/${sample%.hap*}_2_paired.fq.gz \. -Z ${gbzpath}/${sample}.gbz \. -t $threads > ${outpath}/${sample}.gam. # vg surject to convert gam to bam. time \. vg surject \. -F $path_list \. -x ${gbzpath}/${sample}.gbz \. -t $(($threads - 10)) \. --sam-output \. --read-group '1' ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/847
https://github.com/google/deepvariant/issues/847:2423,safety,test,test,2423,"7s elapsed]. I0706 12:06:34.020470 140496845215552 make_examples_core.py:301] Task 39/40: 20480581 candidates (20541819 examples) [9.70s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Reference/Human_genome/CHM13/chm13v2.0.fa --reads HG00438.hap48.cram --examples tmp/tmp_HG00438.hap48/make_examples.tfrecord@40.gz --channels insert_size --gvcf tmp/tmp_HG00438.hap48/gvcf.tfrecord@40.gz --keep_legacy_allele_counter_behavior --min_mapping_quality 1 --normalize_reads --task 24. real 1500m24.832s. user 1478m47.340s. sys 6m51.817s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Deepvariant previously work well with data aligned to linear reference genome. So, I think it could be some issue with pangenome-aligned data. I can share the cram (e.g., chr22) if you would like to test. **Any additional context:**. Code I used to align to a haplotype sampled pangenome graph:. ```. # vg giraffe to align reads to graph. rg=""ID:1\tLB:lib_${sample}\tSM:${sample}\tPL:illumina\tPU:lib_${sample}.1"". time \. vg giraffe \. --progress \. --read-group $rg \. --sample ${sample} \. --output-format gam \. -f ${fqpath}/${sample%.hap*}_1_paired.fq.gz \. -f ${fqpath}/${sample%.hap*}_2_paired.fq.gz \. -Z ${gbzpath}/${sample}.gbz \. -t $threads > ${outpath}/${sample}.gam. # vg surject to convert gam to bam. time \. vg surject \. -F $path_list \. -x ${gbzpath}/${sample}.gbz \. -t $(($threads - 10)) \. --sam-output \. --read-group '1' \. --sample ${sample} \. --prune-low-cplx \. --interleaved \. --max-frag-len 3000 \. ${outpath}/${sample}.gam | \. sed 's/CHM13#0#//g' - | \. samtools view -hb - | \. samtools reheader ${outpath}/${sample}.tmp.header.sam - | \. samtools sort --write-index -@ 10 -m 4G -O CRAM --reference $ref -T ${outpath}/${sample}.cram -o ${outpath}/${sample}.cram. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/847
https://github.com/google/deepvariant/issues/847:1275,testability,trace,trace,1275,"t takes a very long time on `make_exmaples` and find a huge number of examples (~50X more than my previous data aligned to GRCh38). And finally, deepvariant fails. **Setup**. - Operating system: CentOS 7. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: PCR-free WGS data from 1000 Genomes, CHM13-based pangenome graph. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B $inpath \. -B $outpath \. -B ${TMPDIR}:${TMPDIR} \. -B $(dirname $ref) \. ~/container/deepvariant.1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$ref \. --reads=${inpath}/${sample}.cram \. --output_vcf=${outpath}/${sample}.vcf.gz \. --output_gvcf=${outpath}/${sample}.g.vcf.gz \. --num_shards=${threads} \. --intermediate_results_dir ${TMPDIR} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"". ```. - Error trace: (if applicable). ```. I0706 12:06:34.396180 140036894541632 make_examples_core.py:301] Task 16/40: 20600183 candidates (20662757 examples) [6.77s elapsed]. I0706 12:06:34.020470 140496845215552 make_examples_core.py:301] Task 39/40: 20480581 candidates (20541819 examples) [9.70s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Reference/Human_genome/CHM13/chm13v2.0.fa --reads HG00438.hap48.cram --examples tmp/tmp_HG00438.hap48/make_examples.tfrecord@40.gz --channels insert_size --gvcf tmp/tmp_HG00438.hap48/gvcf.tfrecord@40.gz --keep_legacy_allele_counter_behavior --min_mapping_quality 1 --normalize_reads --task 24. real 1500m24.832s. user 1478m47.340s. sys 6m51.817s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Deepvariant previously work well with data aligned to ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/847
https://github.com/google/deepvariant/issues/847:2031,testability,test,test,2031," --output_gvcf=${outpath}/${sample}.g.vcf.gz \. --num_shards=${threads} \. --intermediate_results_dir ${TMPDIR} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"". ```. - Error trace: (if applicable). ```. I0706 12:06:34.396180 140036894541632 make_examples_core.py:301] Task 16/40: 20600183 candidates (20662757 examples) [6.77s elapsed]. I0706 12:06:34.020470 140496845215552 make_examples_core.py:301] Task 39/40: 20480581 candidates (20541819 examples) [9.70s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Reference/Human_genome/CHM13/chm13v2.0.fa --reads HG00438.hap48.cram --examples tmp/tmp_HG00438.hap48/make_examples.tfrecord@40.gz --channels insert_size --gvcf tmp/tmp_HG00438.hap48/gvcf.tfrecord@40.gz --keep_legacy_allele_counter_behavior --min_mapping_quality 1 --normalize_reads --task 24. real 1500m24.832s. user 1478m47.340s. sys 6m51.817s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Deepvariant previously work well with data aligned to linear reference genome. So, I think it could be some issue with pangenome-aligned data. I can share the cram (e.g., chr22) if you would like to test. **Any additional context:**. Code I used to align to a haplotype sampled pangenome graph:. ```. # vg giraffe to align reads to graph. rg=""ID:1\tLB:lib_${sample}\tSM:${sample}\tPL:illumina\tPU:lib_${sample}.1"". time \. vg giraffe \. --progress \. --read-group $rg \. --sample ${sample} \. --output-format gam \. -f ${fqpath}/${sample%.hap*}_1_paired.fq.gz \. -f ${fqpath}/${sample%.hap*}_2_paired.fq.gz \. -Z ${gbzpath}/${sample}.gbz \. -t $threads > ${outpath}/${sample}.gam. # vg surject to convert gam to bam. time \. vg surject \. -F $path_list \. -x ${gbzpath}/${sample}.gbz \. -t $(($threads - 10)) ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/847
https://github.com/google/deepvariant/issues/847:2067,testability,test,test,2067,"g.vcf.gz \. --num_shards=${threads} \. --intermediate_results_dir ${TMPDIR} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"". ```. - Error trace: (if applicable). ```. I0706 12:06:34.396180 140036894541632 make_examples_core.py:301] Task 16/40: 20600183 candidates (20662757 examples) [6.77s elapsed]. I0706 12:06:34.020470 140496845215552 make_examples_core.py:301] Task 39/40: 20480581 candidates (20541819 examples) [9.70s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Reference/Human_genome/CHM13/chm13v2.0.fa --reads HG00438.hap48.cram --examples tmp/tmp_HG00438.hap48/make_examples.tfrecord@40.gz --channels insert_size --gvcf tmp/tmp_HG00438.hap48/gvcf.tfrecord@40.gz --keep_legacy_allele_counter_behavior --min_mapping_quality 1 --normalize_reads --task 24. real 1500m24.832s. user 1478m47.340s. sys 6m51.817s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Deepvariant previously work well with data aligned to linear reference genome. So, I think it could be some issue with pangenome-aligned data. I can share the cram (e.g., chr22) if you would like to test. **Any additional context:**. Code I used to align to a haplotype sampled pangenome graph:. ```. # vg giraffe to align reads to graph. rg=""ID:1\tLB:lib_${sample}\tSM:${sample}\tPL:illumina\tPU:lib_${sample}.1"". time \. vg giraffe \. --progress \. --read-group $rg \. --sample ${sample} \. --output-format gam \. -f ${fqpath}/${sample%.hap*}_1_paired.fq.gz \. -f ${fqpath}/${sample%.hap*}_2_paired.fq.gz \. -Z ${gbzpath}/${sample}.gbz \. -t $threads > ${outpath}/${sample}.gam. # vg surject to convert gam to bam. time \. vg surject \. -F $path_list \. -x ${gbzpath}/${sample}.gbz \. -t $(($threads - 10)) \. --sam-output \. --read-group '1' ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/847
https://github.com/google/deepvariant/issues/847:2423,testability,test,test,2423,"7s elapsed]. I0706 12:06:34.020470 140496845215552 make_examples_core.py:301] Task 39/40: 20480581 candidates (20541819 examples) [9.70s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Reference/Human_genome/CHM13/chm13v2.0.fa --reads HG00438.hap48.cram --examples tmp/tmp_HG00438.hap48/make_examples.tfrecord@40.gz --channels insert_size --gvcf tmp/tmp_HG00438.hap48/gvcf.tfrecord@40.gz --keep_legacy_allele_counter_behavior --min_mapping_quality 1 --normalize_reads --task 24. real 1500m24.832s. user 1478m47.340s. sys 6m51.817s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Deepvariant previously work well with data aligned to linear reference genome. So, I think it could be some issue with pangenome-aligned data. I can share the cram (e.g., chr22) if you would like to test. **Any additional context:**. Code I used to align to a haplotype sampled pangenome graph:. ```. # vg giraffe to align reads to graph. rg=""ID:1\tLB:lib_${sample}\tSM:${sample}\tPL:illumina\tPU:lib_${sample}.1"". time \. vg giraffe \. --progress \. --read-group $rg \. --sample ${sample} \. --output-format gam \. -f ${fqpath}/${sample%.hap*}_1_paired.fq.gz \. -f ${fqpath}/${sample%.hap*}_2_paired.fq.gz \. -Z ${gbzpath}/${sample}.gbz \. -t $threads > ${outpath}/${sample}.gam. # vg surject to convert gam to bam. time \. vg surject \. -F $path_list \. -x ${gbzpath}/${sample}.gbz \. -t $(($threads - 10)) \. --sam-output \. --read-group '1' \. --sample ${sample} \. --prune-low-cplx \. --interleaved \. --max-frag-len 3000 \. ${outpath}/${sample}.gam | \. sed 's/CHM13#0#//g' - | \. samtools view -hb - | \. samtools reheader ${outpath}/${sample}.tmp.header.sam - | \. samtools sort --write-index -@ 10 -m 4G -O CRAM --reference $ref -T ${outpath}/${sample}.cram -o ${outpath}/${sample}.cram. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/847
https://github.com/google/deepvariant/issues/847:2446,testability,context,context,2446,"7s elapsed]. I0706 12:06:34.020470 140496845215552 make_examples_core.py:301] Task 39/40: 20480581 candidates (20541819 examples) [9.70s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Reference/Human_genome/CHM13/chm13v2.0.fa --reads HG00438.hap48.cram --examples tmp/tmp_HG00438.hap48/make_examples.tfrecord@40.gz --channels insert_size --gvcf tmp/tmp_HG00438.hap48/gvcf.tfrecord@40.gz --keep_legacy_allele_counter_behavior --min_mapping_quality 1 --normalize_reads --task 24. real 1500m24.832s. user 1478m47.340s. sys 6m51.817s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Deepvariant previously work well with data aligned to linear reference genome. So, I think it could be some issue with pangenome-aligned data. I can share the cram (e.g., chr22) if you would like to test. **Any additional context:**. Code I used to align to a haplotype sampled pangenome graph:. ```. # vg giraffe to align reads to graph. rg=""ID:1\tLB:lib_${sample}\tSM:${sample}\tPL:illumina\tPU:lib_${sample}.1"". time \. vg giraffe \. --progress \. --read-group $rg \. --sample ${sample} \. --output-format gam \. -f ${fqpath}/${sample%.hap*}_1_paired.fq.gz \. -f ${fqpath}/${sample%.hap*}_2_paired.fq.gz \. -Z ${gbzpath}/${sample}.gbz \. -t $threads > ${outpath}/${sample}.gam. # vg surject to convert gam to bam. time \. vg surject \. -F $path_list \. -x ${gbzpath}/${sample}.gbz \. -t $(($threads - 10)) \. --sam-output \. --read-group '1' \. --sample ${sample} \. --prune-low-cplx \. --interleaved \. --max-frag-len 3000 \. ${outpath}/${sample}.gam | \. sed 's/CHM13#0#//g' - | \. samtools view -hb - | \. samtools reheader ${outpath}/${sample}.tmp.header.sam - | \. samtools sort --write-index -@ 10 -m 4G -O CRAM --reference $ref -T ${outpath}/${sample}.cram -o ${outpath}/${sample}.cram. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/847
https://github.com/google/deepvariant/issues/847:692,usability,Command,Command,692,"Deepvariant run too long and fails on giraffe output; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I mapped the WGS data to pangenome graph with `vg giraffe`. When calling variant with deepvariant, it takes a very long time on `make_exmaples` and find a huge number of examples (~50X more than my previous data aligned to GRCh38). And finally, deepvariant fails. **Setup**. - Operating system: CentOS 7. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: PCR-free WGS data from 1000 Genomes, CHM13-based pangenome graph. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B $inpath \. -B $outpath \. -B ${TMPDIR}:${TMPDIR} \. -B $(dirname $ref) \. ~/container/deepvariant.1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$ref \. --reads=${inpath}/${sample}.cram \. --output_vcf=${outpath}/${sample}.vcf.gz \. --output_gvcf=${outpath}/${sample}.g.vcf.gz \. --num_shards=${threads} \. --intermediate_results_dir ${TMPDIR} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"". ```. - Error trace: (if applicable). ```. I0706 12:06:34.396180 140036894541632 make_examples_core.py:301] Task 16/40: 20600183 candidates (20662757 examples) [6.77s elapsed]. I0706 12:06:34.020470 140496845215552 make_examples_core.py:301] Task 39/40: 20480581 candidates (20541819 examples) [9.70s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Reference/Human_genome/CHM13/chm13v2.0.fa --reads HG00438.hap48.cram --examples tmp/tmp_HG00438.hap48/make_examples.tfrecord@40.gz --channels insert_size --gvcf tmp/tmp_HG00438.hap48/gvcf.tfrecord@40.gz --keep_legacy_allele_counter_behavior --min_mapping_quality 1 --normalize_reads --task 24. real 1500m24.832s. user 1478m47.340s. sys 6m51.817",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/847
https://github.com/google/deepvariant/issues/847:1269,usability,Error,Error,1269,"ant, it takes a very long time on `make_exmaples` and find a huge number of examples (~50X more than my previous data aligned to GRCh38). And finally, deepvariant fails. **Setup**. - Operating system: CentOS 7. - DeepVariant version: 1.6.1. - Installation method (Docker, built from source, etc.): Singularity. - Type of data: PCR-free WGS data from 1000 Genomes, CHM13-based pangenome graph. **Steps to reproduce:**. - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/ \. -B $inpath \. -B $outpath \. -B ${TMPDIR}:${TMPDIR} \. -B $(dirname $ref) \. ~/container/deepvariant.1.6.1.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$ref \. --reads=${inpath}/${sample}.cram \. --output_vcf=${outpath}/${sample}.vcf.gz \. --output_gvcf=${outpath}/${sample}.g.vcf.gz \. --num_shards=${threads} \. --intermediate_results_dir ${TMPDIR} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"". ```. - Error trace: (if applicable). ```. I0706 12:06:34.396180 140036894541632 make_examples_core.py:301] Task 16/40: 20600183 candidates (20662757 examples) [6.77s elapsed]. I0706 12:06:34.020470 140496845215552 make_examples_core.py:301] Task 39/40: 20480581 candidates (20541819 examples) [9.70s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Reference/Human_genome/CHM13/chm13v2.0.fa --reads HG00438.hap48.cram --examples tmp/tmp_HG00438.hap48/make_examples.tfrecord@40.gz --channels insert_size --gvcf tmp/tmp_HG00438.hap48/gvcf.tfrecord@40.gz --keep_legacy_allele_counter_behavior --min_mapping_quality 1 --normalize_reads --task 24. real 1500m24.832s. user 1478m47.340s. sys 6m51.817s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Deepvariant previously work well with data align",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/847
https://github.com/google/deepvariant/issues/847:1969,usability,user,user,1969,"/${sample}.cram \. --output_vcf=${outpath}/${sample}.vcf.gz \. --output_gvcf=${outpath}/${sample}.g.vcf.gz \. --num_shards=${threads} \. --intermediate_results_dir ${TMPDIR} \. --make_examples_extra_args=""min_mapping_quality=1,keep_legacy_allele_counter_behavior=true,normalize_reads=true"". ```. - Error trace: (if applicable). ```. I0706 12:06:34.396180 140036894541632 make_examples_core.py:301] Task 16/40: 20600183 candidates (20662757 examples) [6.77s elapsed]. I0706 12:06:34.020470 140496845215552 make_examples_core.py:301] Task 39/40: 20480581 candidates (20541819 examples) [9.70s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Reference/Human_genome/CHM13/chm13v2.0.fa --reads HG00438.hap48.cram --examples tmp/tmp_HG00438.hap48/make_examples.tfrecord@40.gz --channels insert_size --gvcf tmp/tmp_HG00438.hap48/gvcf.tfrecord@40.gz --keep_legacy_allele_counter_behavior --min_mapping_quality 1 --normalize_reads --task 24. real 1500m24.832s. user 1478m47.340s. sys 6m51.817s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Deepvariant previously work well with data aligned to linear reference genome. So, I think it could be some issue with pangenome-aligned data. I can share the cram (e.g., chr22) if you would like to test. **Any additional context:**. Code I used to align to a haplotype sampled pangenome graph:. ```. # vg giraffe to align reads to graph. rg=""ID:1\tLB:lib_${sample}\tSM:${sample}\tPL:illumina\tPU:lib_${sample}.1"". time \. vg giraffe \. --progress \. --read-group $rg \. --sample ${sample} \. --output-format gam \. -f ${fqpath}/${sample%.hap*}_1_paired.fq.gz \. -f ${fqpath}/${sample%.hap*}_2_paired.fq.gz \. -Z ${gbzpath}/${sample}.gbz \. -t $threads > ${outpath}/${sample}.gam. # vg surject to convert gam to bam. time \. vg surject \. -F $path",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/847
https://github.com/google/deepvariant/issues/847:2663,usability,progress,progress,2663,"7s elapsed]. I0706 12:06:34.020470 140496845215552 make_examples_core.py:301] Task 39/40: 20480581 candidates (20541819 examples) [9.70s elapsed]. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Reference/Human_genome/CHM13/chm13v2.0.fa --reads HG00438.hap48.cram --examples tmp/tmp_HG00438.hap48/make_examples.tfrecord@40.gz --channels insert_size --gvcf tmp/tmp_HG00438.hap48/gvcf.tfrecord@40.gz --keep_legacy_allele_counter_behavior --min_mapping_quality 1 --normalize_reads --task 24. real 1500m24.832s. user 1478m47.340s. sys 6m51.817s. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Deepvariant previously work well with data aligned to linear reference genome. So, I think it could be some issue with pangenome-aligned data. I can share the cram (e.g., chr22) if you would like to test. **Any additional context:**. Code I used to align to a haplotype sampled pangenome graph:. ```. # vg giraffe to align reads to graph. rg=""ID:1\tLB:lib_${sample}\tSM:${sample}\tPL:illumina\tPU:lib_${sample}.1"". time \. vg giraffe \. --progress \. --read-group $rg \. --sample ${sample} \. --output-format gam \. -f ${fqpath}/${sample%.hap*}_1_paired.fq.gz \. -f ${fqpath}/${sample%.hap*}_2_paired.fq.gz \. -Z ${gbzpath}/${sample}.gbz \. -t $threads > ${outpath}/${sample}.gam. # vg surject to convert gam to bam. time \. vg surject \. -F $path_list \. -x ${gbzpath}/${sample}.gbz \. -t $(($threads - 10)) \. --sam-output \. --read-group '1' \. --sample ${sample} \. --prune-low-cplx \. --interleaved \. --max-frag-len 3000 \. ${outpath}/${sample}.gam | \. sed 's/CHM13#0#//g' - | \. samtools view -hb - | \. samtools reheader ${outpath}/${sample}.tmp.header.sam - | \. samtools sort --write-index -@ 10 -m 4G -O CRAM --reference $ref -T ${outpath}/${sample}.cram -o ${outpath}/${sample}.cram. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/847
https://github.com/google/deepvariant/issues/848:713,deployability,log,logs,713,"Why all the GT of the PASS variant site is 1/1? use deepsomatic; Hi,. Why all the GT of the PASS variant site is 1/1? use deepsomatic. chr1	91748	.	C	T	10	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:10:61:48,13:0.213115:9,19,0. The command:. BIN_VERSION=""1.6.1"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepsomatic:""${BIN_VERSION}"" \. run_deepsomatic \. --model_type=PACBIO \. --ref=/input/chm13v2.0.fa \. --reads_normal=/input/hifi_normal.bam \. --reads_tumor=/input/hifi_tumor.bam \. --output_vcf=/output/somatic_output_vcf.gz \. --output_gvcf=/output/somatic_output_g.vcf.gz \. --sample_name_tumor=""tumor"" \. --sample_name_normal=""normal"" \. --num_shards=48 \. --logging_dir=/output/logs \. --intermediate_results_dir=/output/intermediate_results_dir. Best wishes.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/848
https://github.com/google/deepvariant/issues/848:394,modifiability,PAC,PACBIO,394,"Why all the GT of the PASS variant site is 1/1? use deepsomatic; Hi,. Why all the GT of the PASS variant site is 1/1? use deepsomatic. chr1	91748	.	C	T	10	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:10:61:48,13:0.213115:9,19,0. The command:. BIN_VERSION=""1.6.1"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepsomatic:""${BIN_VERSION}"" \. run_deepsomatic \. --model_type=PACBIO \. --ref=/input/chm13v2.0.fa \. --reads_normal=/input/hifi_normal.bam \. --reads_tumor=/input/hifi_tumor.bam \. --output_vcf=/output/somatic_output_vcf.gz \. --output_gvcf=/output/somatic_output_g.vcf.gz \. --sample_name_tumor=""tumor"" \. --sample_name_normal=""normal"" \. --num_shards=48 \. --logging_dir=/output/logs \. --intermediate_results_dir=/output/intermediate_results_dir. Best wishes.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/848
https://github.com/google/deepvariant/issues/848:283,safety,input,input,283,"Why all the GT of the PASS variant site is 1/1? use deepsomatic; Hi,. Why all the GT of the PASS variant site is 1/1? use deepsomatic. chr1	91748	.	C	T	10	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:10:61:48,13:0.213115:9,19,0. The command:. BIN_VERSION=""1.6.1"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepsomatic:""${BIN_VERSION}"" \. run_deepsomatic \. --model_type=PACBIO \. --ref=/input/chm13v2.0.fa \. --reads_normal=/input/hifi_normal.bam \. --reads_tumor=/input/hifi_tumor.bam \. --output_vcf=/output/somatic_output_vcf.gz \. --output_gvcf=/output/somatic_output_g.vcf.gz \. --sample_name_tumor=""tumor"" \. --sample_name_normal=""normal"" \. --num_shards=48 \. --logging_dir=/output/logs \. --intermediate_results_dir=/output/intermediate_results_dir. Best wishes.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/848
https://github.com/google/deepvariant/issues/848:411,safety,input,input,411,"Why all the GT of the PASS variant site is 1/1? use deepsomatic; Hi,. Why all the GT of the PASS variant site is 1/1? use deepsomatic. chr1	91748	.	C	T	10	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:10:61:48,13:0.213115:9,19,0. The command:. BIN_VERSION=""1.6.1"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepsomatic:""${BIN_VERSION}"" \. run_deepsomatic \. --model_type=PACBIO \. --ref=/input/chm13v2.0.fa \. --reads_normal=/input/hifi_normal.bam \. --reads_tumor=/input/hifi_tumor.bam \. --output_vcf=/output/somatic_output_vcf.gz \. --output_gvcf=/output/somatic_output_g.vcf.gz \. --sample_name_tumor=""tumor"" \. --sample_name_normal=""normal"" \. --num_shards=48 \. --logging_dir=/output/logs \. --intermediate_results_dir=/output/intermediate_results_dir. Best wishes.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/848
https://github.com/google/deepvariant/issues/848:449,safety,input,input,449,"Why all the GT of the PASS variant site is 1/1? use deepsomatic; Hi,. Why all the GT of the PASS variant site is 1/1? use deepsomatic. chr1	91748	.	C	T	10	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:10:61:48,13:0.213115:9,19,0. The command:. BIN_VERSION=""1.6.1"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepsomatic:""${BIN_VERSION}"" \. run_deepsomatic \. --model_type=PACBIO \. --ref=/input/chm13v2.0.fa \. --reads_normal=/input/hifi_normal.bam \. --reads_tumor=/input/hifi_tumor.bam \. --output_vcf=/output/somatic_output_vcf.gz \. --output_gvcf=/output/somatic_output_g.vcf.gz \. --sample_name_tumor=""tumor"" \. --sample_name_normal=""normal"" \. --num_shards=48 \. --logging_dir=/output/logs \. --intermediate_results_dir=/output/intermediate_results_dir. Best wishes.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/848
https://github.com/google/deepvariant/issues/848:489,safety,input,input,489,"Why all the GT of the PASS variant site is 1/1? use deepsomatic; Hi,. Why all the GT of the PASS variant site is 1/1? use deepsomatic. chr1	91748	.	C	T	10	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:10:61:48,13:0.213115:9,19,0. The command:. BIN_VERSION=""1.6.1"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepsomatic:""${BIN_VERSION}"" \. run_deepsomatic \. --model_type=PACBIO \. --ref=/input/chm13v2.0.fa \. --reads_normal=/input/hifi_normal.bam \. --reads_tumor=/input/hifi_tumor.bam \. --output_vcf=/output/somatic_output_vcf.gz \. --output_gvcf=/output/somatic_output_g.vcf.gz \. --sample_name_tumor=""tumor"" \. --sample_name_normal=""normal"" \. --num_shards=48 \. --logging_dir=/output/logs \. --intermediate_results_dir=/output/intermediate_results_dir. Best wishes.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/848
https://github.com/google/deepvariant/issues/848:713,safety,log,logs,713,"Why all the GT of the PASS variant site is 1/1? use deepsomatic; Hi,. Why all the GT of the PASS variant site is 1/1? use deepsomatic. chr1	91748	.	C	T	10	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:10:61:48,13:0.213115:9,19,0. The command:. BIN_VERSION=""1.6.1"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepsomatic:""${BIN_VERSION}"" \. run_deepsomatic \. --model_type=PACBIO \. --ref=/input/chm13v2.0.fa \. --reads_normal=/input/hifi_normal.bam \. --reads_tumor=/input/hifi_tumor.bam \. --output_vcf=/output/somatic_output_vcf.gz \. --output_gvcf=/output/somatic_output_g.vcf.gz \. --sample_name_tumor=""tumor"" \. --sample_name_normal=""normal"" \. --num_shards=48 \. --logging_dir=/output/logs \. --intermediate_results_dir=/output/intermediate_results_dir. Best wishes.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/848
https://github.com/google/deepvariant/issues/848:713,security,log,logs,713,"Why all the GT of the PASS variant site is 1/1? use deepsomatic; Hi,. Why all the GT of the PASS variant site is 1/1? use deepsomatic. chr1	91748	.	C	T	10	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:10:61:48,13:0.213115:9,19,0. The command:. BIN_VERSION=""1.6.1"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepsomatic:""${BIN_VERSION}"" \. run_deepsomatic \. --model_type=PACBIO \. --ref=/input/chm13v2.0.fa \. --reads_normal=/input/hifi_normal.bam \. --reads_tumor=/input/hifi_tumor.bam \. --output_vcf=/output/somatic_output_vcf.gz \. --output_gvcf=/output/somatic_output_g.vcf.gz \. --sample_name_tumor=""tumor"" \. --sample_name_normal=""normal"" \. --num_shards=48 \. --logging_dir=/output/logs \. --intermediate_results_dir=/output/intermediate_results_dir. Best wishes.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/848
https://github.com/google/deepvariant/issues/848:713,testability,log,logs,713,"Why all the GT of the PASS variant site is 1/1? use deepsomatic; Hi,. Why all the GT of the PASS variant site is 1/1? use deepsomatic. chr1	91748	.	C	T	10	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:10:61:48,13:0.213115:9,19,0. The command:. BIN_VERSION=""1.6.1"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepsomatic:""${BIN_VERSION}"" \. run_deepsomatic \. --model_type=PACBIO \. --ref=/input/chm13v2.0.fa \. --reads_normal=/input/hifi_normal.bam \. --reads_tumor=/input/hifi_tumor.bam \. --output_vcf=/output/somatic_output_vcf.gz \. --output_gvcf=/output/somatic_output_g.vcf.gz \. --sample_name_tumor=""tumor"" \. --sample_name_normal=""normal"" \. --num_shards=48 \. --logging_dir=/output/logs \. --intermediate_results_dir=/output/intermediate_results_dir. Best wishes.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/848
https://github.com/google/deepvariant/issues/848:218,usability,command,command,218,"Why all the GT of the PASS variant site is 1/1? use deepsomatic; Hi,. Why all the GT of the PASS variant site is 1/1? use deepsomatic. chr1	91748	.	C	T	10	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:10:61:48,13:0.213115:9,19,0. The command:. BIN_VERSION=""1.6.1"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepsomatic:""${BIN_VERSION}"" \. run_deepsomatic \. --model_type=PACBIO \. --ref=/input/chm13v2.0.fa \. --reads_normal=/input/hifi_normal.bam \. --reads_tumor=/input/hifi_tumor.bam \. --output_vcf=/output/somatic_output_vcf.gz \. --output_gvcf=/output/somatic_output_g.vcf.gz \. --sample_name_tumor=""tumor"" \. --sample_name_normal=""normal"" \. --num_shards=48 \. --logging_dir=/output/logs \. --intermediate_results_dir=/output/intermediate_results_dir. Best wishes.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/848
https://github.com/google/deepvariant/issues/848:283,usability,input,input,283,"Why all the GT of the PASS variant site is 1/1? use deepsomatic; Hi,. Why all the GT of the PASS variant site is 1/1? use deepsomatic. chr1	91748	.	C	T	10	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:10:61:48,13:0.213115:9,19,0. The command:. BIN_VERSION=""1.6.1"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepsomatic:""${BIN_VERSION}"" \. run_deepsomatic \. --model_type=PACBIO \. --ref=/input/chm13v2.0.fa \. --reads_normal=/input/hifi_normal.bam \. --reads_tumor=/input/hifi_tumor.bam \. --output_vcf=/output/somatic_output_vcf.gz \. --output_gvcf=/output/somatic_output_g.vcf.gz \. --sample_name_tumor=""tumor"" \. --sample_name_normal=""normal"" \. --num_shards=48 \. --logging_dir=/output/logs \. --intermediate_results_dir=/output/intermediate_results_dir. Best wishes.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/848
https://github.com/google/deepvariant/issues/848:411,usability,input,input,411,"Why all the GT of the PASS variant site is 1/1? use deepsomatic; Hi,. Why all the GT of the PASS variant site is 1/1? use deepsomatic. chr1	91748	.	C	T	10	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:10:61:48,13:0.213115:9,19,0. The command:. BIN_VERSION=""1.6.1"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepsomatic:""${BIN_VERSION}"" \. run_deepsomatic \. --model_type=PACBIO \. --ref=/input/chm13v2.0.fa \. --reads_normal=/input/hifi_normal.bam \. --reads_tumor=/input/hifi_tumor.bam \. --output_vcf=/output/somatic_output_vcf.gz \. --output_gvcf=/output/somatic_output_g.vcf.gz \. --sample_name_tumor=""tumor"" \. --sample_name_normal=""normal"" \. --num_shards=48 \. --logging_dir=/output/logs \. --intermediate_results_dir=/output/intermediate_results_dir. Best wishes.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/848
https://github.com/google/deepvariant/issues/848:449,usability,input,input,449,"Why all the GT of the PASS variant site is 1/1? use deepsomatic; Hi,. Why all the GT of the PASS variant site is 1/1? use deepsomatic. chr1	91748	.	C	T	10	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:10:61:48,13:0.213115:9,19,0. The command:. BIN_VERSION=""1.6.1"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepsomatic:""${BIN_VERSION}"" \. run_deepsomatic \. --model_type=PACBIO \. --ref=/input/chm13v2.0.fa \. --reads_normal=/input/hifi_normal.bam \. --reads_tumor=/input/hifi_tumor.bam \. --output_vcf=/output/somatic_output_vcf.gz \. --output_gvcf=/output/somatic_output_g.vcf.gz \. --sample_name_tumor=""tumor"" \. --sample_name_normal=""normal"" \. --num_shards=48 \. --logging_dir=/output/logs \. --intermediate_results_dir=/output/intermediate_results_dir. Best wishes.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/848
https://github.com/google/deepvariant/issues/848:489,usability,input,input,489,"Why all the GT of the PASS variant site is 1/1? use deepsomatic; Hi,. Why all the GT of the PASS variant site is 1/1? use deepsomatic. chr1	91748	.	C	T	10	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:10:61:48,13:0.213115:9,19,0. The command:. BIN_VERSION=""1.6.1"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepsomatic:""${BIN_VERSION}"" \. run_deepsomatic \. --model_type=PACBIO \. --ref=/input/chm13v2.0.fa \. --reads_normal=/input/hifi_normal.bam \. --reads_tumor=/input/hifi_tumor.bam \. --output_vcf=/output/somatic_output_vcf.gz \. --output_gvcf=/output/somatic_output_g.vcf.gz \. --sample_name_tumor=""tumor"" \. --sample_name_normal=""normal"" \. --num_shards=48 \. --logging_dir=/output/logs \. --intermediate_results_dir=/output/intermediate_results_dir. Best wishes.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/848
https://github.com/google/deepvariant/issues/849:383,availability,error,error,383,"Postprocess_variants.py ValueError: ptrue must be between zero and one: nan; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I have processed around 30 samples albeit having some issues with GPU, possibly due to nvidia driver / cuda version. However, recently postprocess has started stalling with the same error. Any help troubleshooting this would be greatly appreciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 202",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:463,availability,Operat,Operating,463,"Postprocess_variants.py ValueError: ptrue must be between zero and one: nan; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I have processed around 30 samples albeit having some issues with GPU, possibly due to nvidia driver / cuda version. However, recently postprocess has started stalling with the same error. Any help troubleshooting this would be greatly appreciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 202",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1439,availability,Error,Error,1439,"ciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1918,availability,avail,available,1918,"ir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. I0710 12:09:25.874185 139944337696576 postprocess_variants.py:1313] CVO sorting took 2.0161957065264384 minutes. I0710 12:09:25.874843 139944337696576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0710 12:09:25.874915 139944337696576 postprocess_variants.py:1318] Using 19 CPUs for parallelization of variant transformation. I0710 12:09:45.096508 139944337696576 postprocess_variants.py:1211] Using sample nam",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:2225,availability,operat,operations,2225,"ecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. I0710 12:09:25.874185 139944337696576 postprocess_variants.py:1313] CVO sorting took 2.0161957065264384 minutes. I0710 12:09:25.874843 139944337696576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0710 12:09:25.874915 139944337696576 postprocess_variants.py:1318] Using 19 CPUs for parallelization of variant transformation. I0710 12:09:45.096508 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. multiprocessing.pool.RemoteTraceback:. """""". Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 125, in worker. result = (True, func(*args, **kwds)). File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 48, in map",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:2279,availability,operat,operations,2279,"cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. I0710 12:09:25.874185 139944337696576 postprocess_variants.py:1313] CVO sorting took 2.0161957065264384 minutes. I0710 12:09:25.874843 139944337696576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0710 12:09:25.874915 139944337696576 postprocess_variants.py:1318] Using 19 CPUs for parallelization of variant transformation. I0710 12:09:45.096508 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. multiprocessing.pool.RemoteTraceback:. """""". Traceback (most recent call last):. File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 125, in worker. result = (True, func(*args, **kwds)). File ""/usr/lib/python3.8/multiprocessing/pool.py"", line 48, in mapstar. return list(map(*args)). File ""/tmp/Bazel.runfil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:309,deployability,version,version,309,"Postprocess_variants.py ValueError: ptrue must be between zero and one: nan; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I have processed around 30 samples albeit having some issues with GPU, possibly due to nvidia driver / cuda version. However, recently postprocess has started stalling with the same error. Any help troubleshooting this would be greatly appreciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 202",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:514,deployability,VERSION,VERSION,514,"Postprocess_variants.py ValueError: ptrue must be between zero and one: nan; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I have processed around 30 samples albeit having some issues with GPU, possibly due to nvidia driver / cuda version. However, recently postprocess has started stalling with the same error. Any help troubleshooting this would be greatly appreciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 202",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:548,deployability,version,version,548,"Postprocess_variants.py ValueError: ptrue must be between zero and one: nan; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I have processed around 30 samples albeit having some issues with GPU, possibly due to nvidia driver / cuda version. However, recently postprocess has started stalling with the same error. Any help troubleshooting this would be greatly appreciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 202",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:582,deployability,Instal,Installation,582,"Postprocess_variants.py ValueError: ptrue must be between zero and one: nan; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I have processed around 30 samples albeit having some issues with GPU, possibly due to nvidia driver / cuda version. However, recently postprocess has started stalling with the same error. Any help troubleshooting this would be greatly appreciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 202",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:937,deployability,contain,containers,937,"Postprocess_variants.py ValueError: ptrue must be between zero and one: nan; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md**:. Yes. **Describe the issue:**. I have processed around 30 samples albeit having some issues with GPU, possibly due to nvidia driver / cuda version. However, recently postprocess has started stalling with the same error. Any help troubleshooting this would be greatly appreciated! **Setup**. - Operating system: . NAME=Red Hat Enterprise Linux. VERSION=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 202",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1515,deployability,Version,Version,1515,"ON=9.4 (Plow). - DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. I0710 12:09:25.874185 139944337696576",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1531,deployability,Contain,Container,1531,"DeepVariant version: deepvariant:1.6.1-gpu. - Installation method (Docker, built from source, etc.): Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. I0710 12:09:25.874185 139944337696576 postprocess_vari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1631,deployability,contain,container,1631," Docker (via podman). - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. I0710 12:09:25.874185 139944337696576 postprocess_variants.py:1313] CVO sorting took 2.0161957065264384 minutes. I0710 12:09:25.874843 139944337696576 pos",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1705,deployability,Contain,Container,1705,"nome, anything special that is unlike the case studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. I0710 12:09:25.874185 139944337696576 postprocess_variants.py:1313] CVO sorting took 2.0161957065264384 minutes. I0710 12:09:25.874843 139944337696576 postprocess_variants.py:1316] Transforming call_variants_output to variants. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1749,deployability,contain,container,1749,"se studies?) Illumina WGS, GCA_000001405.15_GRCh38_no_alt_analysis_set. **Steps to reproduce:**. - Command: . `podman run -it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. I0710 12:09:25.874185 139944337696576 postprocess_variants.py:1313] CVO sorting took 2.0161957065264384 minutes. I0710 12:09:25.874843 139944337696576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0710 12:09:25.874915 139944337696576 postpr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1868,deployability,contain,container-license,1868,"it --rm --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. I0710 12:09:25.874185 139944337696576 postprocess_variants.py:1313] CVO sorting took 2.0161957065264384 minutes. I0710 12:09:25.874843 139944337696576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0710 12:09:25.874915 139944337696576 postprocess_variants.py:1318] Using 19 CPUs for parallelization of variant transformation. I0710 12:09:45.096508 139944337696576 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1936,deployability,contain,container,1936,"ainers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. I0710 12:09:25.874185 139944337696576 postprocess_variants.py:1313] CVO sorting took 2.0161957065264384 minutes. I0710 12:09:25.874843 139944337696576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0710 12:09:25.874915 139944337696576 postprocess_variants.py:1318] Using 19 CPUs for parallelization of variant transformation. I0710 12:09:45.096508 139944337696576 postprocess_variants.py:1211] Using sample name from call_varian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1957,deployability,CONTAIN,CONTAINER-LICENSE,1957,"s 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/postprocess_variants --ref ""/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz"" --infile ""/data/variants/sample1.intermediate/call_variants_output.tfrecord.gz"" --outfile ""/data/variants/sample1.vcf.gz"" --cpus ""19"" --gvcf_outfile ""/data/variants/sample1.g.vcf.gz"" --nonvariant_site_tfrecord_path ""/data/variants/sample1.intermediate/gvcf.tfrecord@19.gz"". `. - Error trace: (if applicable). ```. ==========. == CUDA ==. ==========. CUDA Version 11.3.1. Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved. This container image and its contents are governed by the NVIDIA Deep Learning Container License. By pulling and using the container, you accept the terms and conditions of this license:. https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license. A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience. 2024-07-10 12:07:21.275077: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. I0710 12:07:24.889796 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: sample1. I0710 12:09:25.874185 139944337696576 postprocess_variants.py:1313] CVO sorting took 2.0161957065264384 minutes. I0710 12:09:25.874843 139944337696576 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0710 12:09:25.874915 139944337696576 postprocess_variants.py:1318] Using 19 CPUs for parallelization of variant transformation. I0710 12:09:45.096508 139944337696576 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:4605,deployability,modul,module,4605," line 1036, in _transform_call_variant_group_to_output_variant. return add_call_to_variant(. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 434, in add_call_to_variant. gq, variant.quality = compute_quals(predictions, index). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 469, in compute_quals. genomics_math.ptrue_to_bounded_phred(predictions[prediction_index]). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/third_party/nucleus/util/genomics_math.py"", line 143, in ptrue_to_bounded_phred. raise ValueError('ptrue must be between zero and one: {}'.format(ptrue)). ValueError: ptrue must be between zero and one: nan. """""". The above exception was the direct cause of the following exception:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1419, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/absl_py/absl/app.py"", line 312, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/absl_py/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1385, in main. tmp_variant_file = dump_variants_to_temp_file(variant_generator). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1067, in dump_variants_to_temp_file. tfrecord.write_tfrecords(variant_protos, temp.name). File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/third_party/nucleus/io/tfrecord.py"", line 190, in write_tfrecords. for proto in protos:. File ""/tmp/Bazel.runfiles_i47tupw0/runfiles/com_google_deepvariant/deepvariant/haplotypes.py"", line 91, in maybe_resolve_conflicting_variants. for overlapping_candidates in _group_overlapping_variants(sorted_varia",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
