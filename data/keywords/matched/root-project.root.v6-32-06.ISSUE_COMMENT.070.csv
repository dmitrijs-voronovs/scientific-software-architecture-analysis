id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/root-project/root/pull/11360:252,usability,tool,tools,252,"> Should we have this in a dedicated directory, say `interpreter/cling/docs/sphinx` or `interpreter/cling/sphinx-docs`? `interpreter/cling/docs` currently contains doxygen files, release notes, and `CMakeLists.txt`. It looks like `interpreter/llvm/src/tools/clang` have the same structure. I'd rather keep it like that as we are reusing documentation settings and build rules which then we will have to tweak and maintain ourselves.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11360
https://github.com/root-project/root/pull/11360:337,usability,document,documentation,337,"> Should we have this in a dedicated directory, say `interpreter/cling/docs/sphinx` or `interpreter/cling/sphinx-docs`? `interpreter/cling/docs` currently contains doxygen files, release notes, and `CMakeLists.txt`. It looks like `interpreter/llvm/src/tools/clang` have the same structure. I'd rather keep it like that as we are reusing documentation settings and build rules which then we will have to tweak and maintain ourselves.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11360
https://github.com/root-project/root/issues/11372:114,availability,Operat,Operating,114,"After this bug fix: https://github.com/root-project/root/pull/3914. Testing now in a newer version, ROOT 6.24/07. Operating system:. ```. cat /etc/redhat-release. CentOS Linux release 7.8.2003 (Core). ```. ROOT version:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.24/07 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 21 2022, 09:57:00 |. | From tag , 2 September 2021 |. | With g++ (GCC) 10.3.0 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. Setup:. ```. scram list -a | grep CMSSW_12_4_0. export SCRAM_ARCH=slc7_amd64_gcc10. cmsrel CMSSW_12_4_0. cd CMSSW_12_4_0/src. cmsenv. ```. This works without errors in ROOT 6.24/07:. ```. hadd -v 0 target.root file_1.root file_2.root. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11372
https://github.com/root-project/root/issues/11372:820,availability,error,errors,820,"After this bug fix: https://github.com/root-project/root/pull/3914. Testing now in a newer version, ROOT 6.24/07. Operating system:. ```. cat /etc/redhat-release. CentOS Linux release 7.8.2003 (Core). ```. ROOT version:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.24/07 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 21 2022, 09:57:00 |. | From tag , 2 September 2021 |. | With g++ (GCC) 10.3.0 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. Setup:. ```. scram list -a | grep CMSSW_12_4_0. export SCRAM_ARCH=slc7_amd64_gcc10. cmsrel CMSSW_12_4_0. cd CMSSW_12_4_0/src. cmsenv. ```. This works without errors in ROOT 6.24/07:. ```. hadd -v 0 target.root file_1.root file_2.root. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11372
https://github.com/root-project/root/issues/11372:91,deployability,version,version,91,"After this bug fix: https://github.com/root-project/root/pull/3914. Testing now in a newer version, ROOT 6.24/07. Operating system:. ```. cat /etc/redhat-release. CentOS Linux release 7.8.2003 (Core). ```. ROOT version:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.24/07 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 21 2022, 09:57:00 |. | From tag , 2 September 2021 |. | With g++ (GCC) 10.3.0 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. Setup:. ```. scram list -a | grep CMSSW_12_4_0. export SCRAM_ARCH=slc7_amd64_gcc10. cmsrel CMSSW_12_4_0. cd CMSSW_12_4_0/src. cmsenv. ```. This works without errors in ROOT 6.24/07:. ```. hadd -v 0 target.root file_1.root file_2.root. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11372
https://github.com/root-project/root/issues/11372:154,deployability,releas,release,154,"After this bug fix: https://github.com/root-project/root/pull/3914. Testing now in a newer version, ROOT 6.24/07. Operating system:. ```. cat /etc/redhat-release. CentOS Linux release 7.8.2003 (Core). ```. ROOT version:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.24/07 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 21 2022, 09:57:00 |. | From tag , 2 September 2021 |. | With g++ (GCC) 10.3.0 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. Setup:. ```. scram list -a | grep CMSSW_12_4_0. export SCRAM_ARCH=slc7_amd64_gcc10. cmsrel CMSSW_12_4_0. cd CMSSW_12_4_0/src. cmsenv. ```. This works without errors in ROOT 6.24/07:. ```. hadd -v 0 target.root file_1.root file_2.root. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11372
https://github.com/root-project/root/issues/11372:176,deployability,releas,release,176,"After this bug fix: https://github.com/root-project/root/pull/3914. Testing now in a newer version, ROOT 6.24/07. Operating system:. ```. cat /etc/redhat-release. CentOS Linux release 7.8.2003 (Core). ```. ROOT version:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.24/07 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 21 2022, 09:57:00 |. | From tag , 2 September 2021 |. | With g++ (GCC) 10.3.0 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. Setup:. ```. scram list -a | grep CMSSW_12_4_0. export SCRAM_ARCH=slc7_amd64_gcc10. cmsrel CMSSW_12_4_0. cd CMSSW_12_4_0/src. cmsenv. ```. This works without errors in ROOT 6.24/07:. ```. hadd -v 0 target.root file_1.root file_2.root. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11372
https://github.com/root-project/root/issues/11372:211,deployability,version,version,211,"After this bug fix: https://github.com/root-project/root/pull/3914. Testing now in a newer version, ROOT 6.24/07. Operating system:. ```. cat /etc/redhat-release. CentOS Linux release 7.8.2003 (Core). ```. ROOT version:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.24/07 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 21 2022, 09:57:00 |. | From tag , 2 September 2021 |. | With g++ (GCC) 10.3.0 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. Setup:. ```. scram list -a | grep CMSSW_12_4_0. export SCRAM_ARCH=slc7_amd64_gcc10. cmsrel CMSSW_12_4_0. cd CMSSW_12_4_0/src. cmsenv. ```. This works without errors in ROOT 6.24/07:. ```. hadd -v 0 target.root file_1.root file_2.root. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11372
https://github.com/root-project/root/issues/11372:194,energy efficiency,Core,Core,194,"After this bug fix: https://github.com/root-project/root/pull/3914. Testing now in a newer version, ROOT 6.24/07. Operating system:. ```. cat /etc/redhat-release. CentOS Linux release 7.8.2003 (Core). ```. ROOT version:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.24/07 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 21 2022, 09:57:00 |. | From tag , 2 September 2021 |. | With g++ (GCC) 10.3.0 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. Setup:. ```. scram list -a | grep CMSSW_12_4_0. export SCRAM_ARCH=slc7_amd64_gcc10. cmsrel CMSSW_12_4_0. cd CMSSW_12_4_0/src. cmsenv. ```. This works without errors in ROOT 6.24/07:. ```. hadd -v 0 target.root file_1.root file_2.root. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11372
https://github.com/root-project/root/issues/11372:91,integrability,version,version,91,"After this bug fix: https://github.com/root-project/root/pull/3914. Testing now in a newer version, ROOT 6.24/07. Operating system:. ```. cat /etc/redhat-release. CentOS Linux release 7.8.2003 (Core). ```. ROOT version:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.24/07 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 21 2022, 09:57:00 |. | From tag , 2 September 2021 |. | With g++ (GCC) 10.3.0 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. Setup:. ```. scram list -a | grep CMSSW_12_4_0. export SCRAM_ARCH=slc7_amd64_gcc10. cmsrel CMSSW_12_4_0. cd CMSSW_12_4_0/src. cmsenv. ```. This works without errors in ROOT 6.24/07:. ```. hadd -v 0 target.root file_1.root file_2.root. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11372
https://github.com/root-project/root/issues/11372:211,integrability,version,version,211,"After this bug fix: https://github.com/root-project/root/pull/3914. Testing now in a newer version, ROOT 6.24/07. Operating system:. ```. cat /etc/redhat-release. CentOS Linux release 7.8.2003 (Core). ```. ROOT version:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.24/07 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 21 2022, 09:57:00 |. | From tag , 2 September 2021 |. | With g++ (GCC) 10.3.0 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. Setup:. ```. scram list -a | grep CMSSW_12_4_0. export SCRAM_ARCH=slc7_amd64_gcc10. cmsrel CMSSW_12_4_0. cd CMSSW_12_4_0/src. cmsenv. ```. This works without errors in ROOT 6.24/07:. ```. hadd -v 0 target.root file_1.root file_2.root. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11372
https://github.com/root-project/root/issues/11372:91,modifiability,version,version,91,"After this bug fix: https://github.com/root-project/root/pull/3914. Testing now in a newer version, ROOT 6.24/07. Operating system:. ```. cat /etc/redhat-release. CentOS Linux release 7.8.2003 (Core). ```. ROOT version:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.24/07 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 21 2022, 09:57:00 |. | From tag , 2 September 2021 |. | With g++ (GCC) 10.3.0 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. Setup:. ```. scram list -a | grep CMSSW_12_4_0. export SCRAM_ARCH=slc7_amd64_gcc10. cmsrel CMSSW_12_4_0. cd CMSSW_12_4_0/src. cmsenv. ```. This works without errors in ROOT 6.24/07:. ```. hadd -v 0 target.root file_1.root file_2.root. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11372
https://github.com/root-project/root/issues/11372:211,modifiability,version,version,211,"After this bug fix: https://github.com/root-project/root/pull/3914. Testing now in a newer version, ROOT 6.24/07. Operating system:. ```. cat /etc/redhat-release. CentOS Linux release 7.8.2003 (Core). ```. ROOT version:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.24/07 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 21 2022, 09:57:00 |. | From tag , 2 September 2021 |. | With g++ (GCC) 10.3.0 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. Setup:. ```. scram list -a | grep CMSSW_12_4_0. export SCRAM_ARCH=slc7_amd64_gcc10. cmsrel CMSSW_12_4_0. cd CMSSW_12_4_0/src. cmsenv. ```. This works without errors in ROOT 6.24/07:. ```. hadd -v 0 target.root file_1.root file_2.root. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11372
https://github.com/root-project/root/issues/11372:820,performance,error,errors,820,"After this bug fix: https://github.com/root-project/root/pull/3914. Testing now in a newer version, ROOT 6.24/07. Operating system:. ```. cat /etc/redhat-release. CentOS Linux release 7.8.2003 (Core). ```. ROOT version:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.24/07 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 21 2022, 09:57:00 |. | From tag , 2 September 2021 |. | With g++ (GCC) 10.3.0 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. Setup:. ```. scram list -a | grep CMSSW_12_4_0. export SCRAM_ARCH=slc7_amd64_gcc10. cmsrel CMSSW_12_4_0. cd CMSSW_12_4_0/src. cmsenv. ```. This works without errors in ROOT 6.24/07:. ```. hadd -v 0 target.root file_1.root file_2.root. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11372
https://github.com/root-project/root/issues/11372:68,safety,Test,Testing,68,"After this bug fix: https://github.com/root-project/root/pull/3914. Testing now in a newer version, ROOT 6.24/07. Operating system:. ```. cat /etc/redhat-release. CentOS Linux release 7.8.2003 (Core). ```. ROOT version:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.24/07 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 21 2022, 09:57:00 |. | From tag , 2 September 2021 |. | With g++ (GCC) 10.3.0 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. Setup:. ```. scram list -a | grep CMSSW_12_4_0. export SCRAM_ARCH=slc7_amd64_gcc10. cmsrel CMSSW_12_4_0. cd CMSSW_12_4_0/src. cmsenv. ```. This works without errors in ROOT 6.24/07:. ```. hadd -v 0 target.root file_1.root file_2.root. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11372
https://github.com/root-project/root/issues/11372:820,safety,error,errors,820,"After this bug fix: https://github.com/root-project/root/pull/3914. Testing now in a newer version, ROOT 6.24/07. Operating system:. ```. cat /etc/redhat-release. CentOS Linux release 7.8.2003 (Core). ```. ROOT version:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.24/07 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 21 2022, 09:57:00 |. | From tag , 2 September 2021 |. | With g++ (GCC) 10.3.0 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. Setup:. ```. scram list -a | grep CMSSW_12_4_0. export SCRAM_ARCH=slc7_amd64_gcc10. cmsrel CMSSW_12_4_0. cd CMSSW_12_4_0/src. cmsenv. ```. This works without errors in ROOT 6.24/07:. ```. hadd -v 0 target.root file_1.root file_2.root. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11372
https://github.com/root-project/root/issues/11372:367,security,Team,Team,367,"After this bug fix: https://github.com/root-project/root/pull/3914. Testing now in a newer version, ROOT 6.24/07. Operating system:. ```. cat /etc/redhat-release. CentOS Linux release 7.8.2003 (Core). ```. ROOT version:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.24/07 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 21 2022, 09:57:00 |. | From tag , 2 September 2021 |. | With g++ (GCC) 10.3.0 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. Setup:. ```. scram list -a | grep CMSSW_12_4_0. export SCRAM_ARCH=slc7_amd64_gcc10. cmsrel CMSSW_12_4_0. cd CMSSW_12_4_0/src. cmsenv. ```. This works without errors in ROOT 6.24/07:. ```. hadd -v 0 target.root file_1.root file_2.root. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11372
https://github.com/root-project/root/issues/11372:68,testability,Test,Testing,68,"After this bug fix: https://github.com/root-project/root/pull/3914. Testing now in a newer version, ROOT 6.24/07. Operating system:. ```. cat /etc/redhat-release. CentOS Linux release 7.8.2003 (Core). ```. ROOT version:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.24/07 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 21 2022, 09:57:00 |. | From tag , 2 September 2021 |. | With g++ (GCC) 10.3.0 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. Setup:. ```. scram list -a | grep CMSSW_12_4_0. export SCRAM_ARCH=slc7_amd64_gcc10. cmsrel CMSSW_12_4_0. cd CMSSW_12_4_0/src. cmsenv. ```. This works without errors in ROOT 6.24/07:. ```. hadd -v 0 target.root file_1.root file_2.root. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11372
https://github.com/root-project/root/issues/11372:533,usability,help,help,533,"After this bug fix: https://github.com/root-project/root/pull/3914. Testing now in a newer version, ROOT 6.24/07. Operating system:. ```. cat /etc/redhat-release. CentOS Linux release 7.8.2003 (Core). ```. ROOT version:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.24/07 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 21 2022, 09:57:00 |. | From tag , 2 September 2021 |. | With g++ (GCC) 10.3.0 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. Setup:. ```. scram list -a | grep CMSSW_12_4_0. export SCRAM_ARCH=slc7_amd64_gcc10. cmsrel CMSSW_12_4_0. cd CMSSW_12_4_0/src. cmsenv. ```. This works without errors in ROOT 6.24/07:. ```. hadd -v 0 target.root file_1.root file_2.root. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11372
https://github.com/root-project/root/issues/11372:820,usability,error,errors,820,"After this bug fix: https://github.com/root-project/root/pull/3914. Testing now in a newer version, ROOT 6.24/07. Operating system:. ```. cat /etc/redhat-release. CentOS Linux release 7.8.2003 (Core). ```. ROOT version:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.24/07 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 21 2022, 09:57:00 |. | From tag , 2 September 2021 |. | With g++ (GCC) 10.3.0 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. Setup:. ```. scram list -a | grep CMSSW_12_4_0. export SCRAM_ARCH=slc7_amd64_gcc10. cmsrel CMSSW_12_4_0. cd CMSSW_12_4_0/src. cmsenv. ```. This works without errors in ROOT 6.24/07:. ```. hadd -v 0 target.root file_1.root file_2.root. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11372
https://github.com/root-project/root/pull/11379:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2204/default, ROOT-ubuntu18.04/default with flags -Dtmva-sofie=On",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11379
https://github.com/root-project/root/pull/11380:38,availability,failur,failures,38,"This was just to see if there are any failures, apologies for the noise.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11380
https://github.com/root-project/root/pull/11380:38,deployability,fail,failures,38,"This was just to see if there are any failures, apologies for the noise.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11380
https://github.com/root-project/root/pull/11380:38,performance,failur,failures,38,"This was just to see if there are any failures, apologies for the noise.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11380
https://github.com/root-project/root/pull/11380:38,reliability,fail,failures,38,"This was just to see if there are any failures, apologies for the noise.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11380
https://github.com/root-project/root/issues/11381:114,deployability,version,version,114,This sounds similar to https://github.com/root-project/root/issues/11312 and would indirectly be connected to the version of nlohmann_json be fixed by https://github.com/root-project/root/pull/11111.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11381
https://github.com/root-project/root/issues/11381:114,integrability,version,version,114,This sounds similar to https://github.com/root-project/root/issues/11312 and would indirectly be connected to the version of nlohmann_json be fixed by https://github.com/root-project/root/pull/11111.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11381
https://github.com/root-project/root/issues/11381:114,modifiability,version,version,114,This sounds similar to https://github.com/root-project/root/issues/11312 and would indirectly be connected to the version of nlohmann_json be fixed by https://github.com/root-project/root/pull/11111.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11381
https://github.com/root-project/root/pull/11382:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2204/default, ROOT-ubuntu18.04/default with flags -Dtmva-sofie=On",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11382
https://github.com/root-project/root/pull/11384:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11384
https://github.com/root-project/root/pull/11387:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2204/default, ROOT-ubuntu18.04/default with flags -Dtmva-sofie=On",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11387
https://github.com/root-project/root/pull/11387:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2204/default, ROOT-ubuntu18.04/default",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11387
https://github.com/root-project/root/pull/11387:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2204/default, ROOT-ubuntu18.04/nortcxxmod",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11387
https://github.com/root-project/root/pull/11389:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2204/default, ROOT-ubuntu18.04/default with flags -Dtmva-sofie=On",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11389
https://github.com/root-project/root/issues/11390:1399,availability,operat,operation,1399,"s are left to be displayed at https://github.com/root-project/root/blob/3160daafc008d8080cb9b3c602f4134b521ca8ad/tree/dataframe/inc/ROOT/RDF/RDisplay.hxx#L227. 2. Check whether there are no more entries to be displayed (`!fDisplayerHelper->HasNext()`). 3. If so, signal the previous node that this node has finished its job through the `StopProcessing` method. There are a bunch of flaws in this workflow. Uncoditionally calling `AddRow` may trigger the integer underflow by calling `fEntries--` when `fEntries==0`. This can be seen quite simply with the following example. ```cpp. root [0] ROOT::RDataFrame d{1};. root [1] auto dd = d.Define(""b1"", [] { return 42; }).Display<int>({""b1""}, 0);. root [2] dd->Print(). +-----+----+. | Row | b1 | . +-----+----+. | 0 | 42 | . +-----+----+. ```. The row is printed even though the user asked for `0` entries to be displayed. The other problem, more subtle and the actual culprit of the reproducer above, is when there is more than just the `Display` operation in the computation graph. `DisplayHelper::Exec` is called once per entry to be processed, as this is the normal working condition in `RLoopManager::Run`. When there is only the `Display` operation, the moment there are no more entries to be displayed, `DisplayHelper` will tell `RLoopManager` that it has finished, thus triggering an early stop of the execution (e.g. if a tree has 100 entries but we only want to display 5). When there is more than one operation, i.e. more than one child of the `RLoopManager`, the call to `StopProcessing` coming from `DisplayHelper::Exec` is not enough to stop the execution. Taking as an example the repro above, there is one `Display` and one `Count` operation, thus 2 children, thus 2 calls to `StopProcessing` must be issued in order to stop the execution. From the point of view of `DisplayHelper::Exec`, the moment `fEntries` reaches zero it will call `StopProcessing`. But `RLoopManager` will still process the next entry because of the other child pr",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11390
https://github.com/root-project/root/issues/11390:1596,availability,operat,operation,1596,"tries to be displayed (`!fDisplayerHelper->HasNext()`). 3. If so, signal the previous node that this node has finished its job through the `StopProcessing` method. There are a bunch of flaws in this workflow. Uncoditionally calling `AddRow` may trigger the integer underflow by calling `fEntries--` when `fEntries==0`. This can be seen quite simply with the following example. ```cpp. root [0] ROOT::RDataFrame d{1};. root [1] auto dd = d.Define(""b1"", [] { return 42; }).Display<int>({""b1""}, 0);. root [2] dd->Print(). +-----+----+. | Row | b1 | . +-----+----+. | 0 | 42 | . +-----+----+. ```. The row is printed even though the user asked for `0` entries to be displayed. The other problem, more subtle and the actual culprit of the reproducer above, is when there is more than just the `Display` operation in the computation graph. `DisplayHelper::Exec` is called once per entry to be processed, as this is the normal working condition in `RLoopManager::Run`. When there is only the `Display` operation, the moment there are no more entries to be displayed, `DisplayHelper` will tell `RLoopManager` that it has finished, thus triggering an early stop of the execution (e.g. if a tree has 100 entries but we only want to display 5). When there is more than one operation, i.e. more than one child of the `RLoopManager`, the call to `StopProcessing` coming from `DisplayHelper::Exec` is not enough to stop the execution. Taking as an example the repro above, there is one `Display` and one `Count` operation, thus 2 children, thus 2 calls to `StopProcessing` must be issued in order to stop the execution. From the point of view of `DisplayHelper::Exec`, the moment `fEntries` reaches zero it will call `StopProcessing`. But `RLoopManager` will still process the next entry because of the other child present. This means we are now calling again `DisplayHelper::Exec`, thus also `RDisplay::AddRow`, thus calling `fEntries--`, thus triggering an integer underflow. The final result is that the whole d",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11390
https://github.com/root-project/root/issues/11390:1863,availability,operat,operation,1863," so, signal the previous node that this node has finished its job through the `StopProcessing` method. There are a bunch of flaws in this workflow. Uncoditionally calling `AddRow` may trigger the integer underflow by calling `fEntries--` when `fEntries==0`. This can be seen quite simply with the following example. ```cpp. root [0] ROOT::RDataFrame d{1};. root [1] auto dd = d.Define(""b1"", [] { return 42; }).Display<int>({""b1""}, 0);. root [2] dd->Print(). +-----+----+. | Row | b1 | . +-----+----+. | 0 | 42 | . +-----+----+. ```. The row is printed even though the user asked for `0` entries to be displayed. The other problem, more subtle and the actual culprit of the reproducer above, is when there is more than just the `Display` operation in the computation graph. `DisplayHelper::Exec` is called once per entry to be processed, as this is the normal working condition in `RLoopManager::Run`. When there is only the `Display` operation, the moment there are no more entries to be displayed, `DisplayHelper` will tell `RLoopManager` that it has finished, thus triggering an early stop of the execution (e.g. if a tree has 100 entries but we only want to display 5). When there is more than one operation, i.e. more than one child of the `RLoopManager`, the call to `StopProcessing` coming from `DisplayHelper::Exec` is not enough to stop the execution. Taking as an example the repro above, there is one `Display` and one `Count` operation, thus 2 children, thus 2 calls to `StopProcessing` must be issued in order to stop the execution. From the point of view of `DisplayHelper::Exec`, the moment `fEntries` reaches zero it will call `StopProcessing`. But `RLoopManager` will still process the next entry because of the other child present. This means we are now calling again `DisplayHelper::Exec`, thus also `RDisplay::AddRow`, thus calling `fEntries--`, thus triggering an integer underflow. The final result is that the whole dataset will be displayed even though the user asked for less.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11390
https://github.com/root-project/root/issues/11390:2099,availability,operat,operation,2099," so, signal the previous node that this node has finished its job through the `StopProcessing` method. There are a bunch of flaws in this workflow. Uncoditionally calling `AddRow` may trigger the integer underflow by calling `fEntries--` when `fEntries==0`. This can be seen quite simply with the following example. ```cpp. root [0] ROOT::RDataFrame d{1};. root [1] auto dd = d.Define(""b1"", [] { return 42; }).Display<int>({""b1""}, 0);. root [2] dd->Print(). +-----+----+. | Row | b1 | . +-----+----+. | 0 | 42 | . +-----+----+. ```. The row is printed even though the user asked for `0` entries to be displayed. The other problem, more subtle and the actual culprit of the reproducer above, is when there is more than just the `Display` operation in the computation graph. `DisplayHelper::Exec` is called once per entry to be processed, as this is the normal working condition in `RLoopManager::Run`. When there is only the `Display` operation, the moment there are no more entries to be displayed, `DisplayHelper` will tell `RLoopManager` that it has finished, thus triggering an early stop of the execution (e.g. if a tree has 100 entries but we only want to display 5). When there is more than one operation, i.e. more than one child of the `RLoopManager`, the call to `StopProcessing` coming from `DisplayHelper::Exec` is not enough to stop the execution. Taking as an example the repro above, there is one `Display` and one `Count` operation, thus 2 children, thus 2 calls to `StopProcessing` must be issued in order to stop the execution. From the point of view of `DisplayHelper::Exec`, the moment `fEntries` reaches zero it will call `StopProcessing`. But `RLoopManager` will still process the next entry because of the other child present. This means we are now calling again `DisplayHelper::Exec`, thus also `RDisplay::AddRow`, thus calling `fEntries--`, thus triggering an integer underflow. The final result is that the whole dataset will be displayed even though the user asked for less.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11390
https://github.com/root-project/root/issues/11390:1298,integrability,sub,subtle,1298,"isplayed to the `RDisplay` object. The `AddRow` method decreases an internal counter of how many entries are left to be displayed at https://github.com/root-project/root/blob/3160daafc008d8080cb9b3c602f4134b521ca8ad/tree/dataframe/inc/ROOT/RDF/RDisplay.hxx#L227. 2. Check whether there are no more entries to be displayed (`!fDisplayerHelper->HasNext()`). 3. If so, signal the previous node that this node has finished its job through the `StopProcessing` method. There are a bunch of flaws in this workflow. Uncoditionally calling `AddRow` may trigger the integer underflow by calling `fEntries--` when `fEntries==0`. This can be seen quite simply with the following example. ```cpp. root [0] ROOT::RDataFrame d{1};. root [1] auto dd = d.Define(""b1"", [] { return 42; }).Display<int>({""b1""}, 0);. root [2] dd->Print(). +-----+----+. | Row | b1 | . +-----+----+. | 0 | 42 | . +-----+----+. ```. The row is printed even though the user asked for `0` entries to be displayed. The other problem, more subtle and the actual culprit of the reproducer above, is when there is more than just the `Display` operation in the computation graph. `DisplayHelper::Exec` is called once per entry to be processed, as this is the normal working condition in `RLoopManager::Run`. When there is only the `Display` operation, the moment there are no more entries to be displayed, `DisplayHelper` will tell `RLoopManager` that it has finished, thus triggering an early stop of the execution (e.g. if a tree has 100 entries but we only want to display 5). When there is more than one operation, i.e. more than one child of the `RLoopManager`, the call to `StopProcessing` coming from `DisplayHelper::Exec` is not enough to stop the execution. Taking as an example the repro above, there is one `Display` and one `Count` operation, thus 2 children, thus 2 calls to `StopProcessing` must be issued in order to stop the execution. From the point of view of `DisplayHelper::Exec`, the moment `fEntries` reaches zero it will ca",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11390
https://github.com/root-project/root/issues/11390:667,security,sign,signal,667,"It turns out this is due to an integer underflow that is triggered by the machinery of `DisplayHelper`:. https://github.com/root-project/root/blob/3160daafc008d8080cb9b3c602f4134b521ca8ad/tree/dataframe/inc/ROOT/RDF/ActionHelpers.hxx#L1334-L1337. The intended workflow is:. 1. Add the next row to be displayed to the `RDisplay` object. The `AddRow` method decreases an internal counter of how many entries are left to be displayed at https://github.com/root-project/root/blob/3160daafc008d8080cb9b3c602f4134b521ca8ad/tree/dataframe/inc/ROOT/RDF/RDisplay.hxx#L227. 2. Check whether there are no more entries to be displayed (`!fDisplayerHelper->HasNext()`). 3. If so, signal the previous node that this node has finished its job through the `StopProcessing` method. There are a bunch of flaws in this workflow. Uncoditionally calling `AddRow` may trigger the integer underflow by calling `fEntries--` when `fEntries==0`. This can be seen quite simply with the following example. ```cpp. root [0] ROOT::RDataFrame d{1};. root [1] auto dd = d.Define(""b1"", [] { return 42; }).Display<int>({""b1""}, 0);. root [2] dd->Print(). +-----+----+. | Row | b1 | . +-----+----+. | 0 | 42 | . +-----+----+. ```. The row is printed even though the user asked for `0` entries to be displayed. The other problem, more subtle and the actual culprit of the reproducer above, is when there is more than just the `Display` operation in the computation graph. `DisplayHelper::Exec` is called once per entry to be processed, as this is the normal working condition in `RLoopManager::Run`. When there is only the `Display` operation, the moment there are no more entries to be displayed, `DisplayHelper` will tell `RLoopManager` that it has finished, thus triggering an early stop of the execution (e.g. if a tree has 100 entries but we only want to display 5). When there is more than one operation, i.e. more than one child of the `RLoopManager`, the call to `StopProcessing` coming from `DisplayHelper::Exec` is not enough t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11390
https://github.com/root-project/root/issues/11390:943,testability,simpl,simply,943,"It turns out this is due to an integer underflow that is triggered by the machinery of `DisplayHelper`:. https://github.com/root-project/root/blob/3160daafc008d8080cb9b3c602f4134b521ca8ad/tree/dataframe/inc/ROOT/RDF/ActionHelpers.hxx#L1334-L1337. The intended workflow is:. 1. Add the next row to be displayed to the `RDisplay` object. The `AddRow` method decreases an internal counter of how many entries are left to be displayed at https://github.com/root-project/root/blob/3160daafc008d8080cb9b3c602f4134b521ca8ad/tree/dataframe/inc/ROOT/RDF/RDisplay.hxx#L227. 2. Check whether there are no more entries to be displayed (`!fDisplayerHelper->HasNext()`). 3. If so, signal the previous node that this node has finished its job through the `StopProcessing` method. There are a bunch of flaws in this workflow. Uncoditionally calling `AddRow` may trigger the integer underflow by calling `fEntries--` when `fEntries==0`. This can be seen quite simply with the following example. ```cpp. root [0] ROOT::RDataFrame d{1};. root [1] auto dd = d.Define(""b1"", [] { return 42; }).Display<int>({""b1""}, 0);. root [2] dd->Print(). +-----+----+. | Row | b1 | . +-----+----+. | 0 | 42 | . +-----+----+. ```. The row is printed even though the user asked for `0` entries to be displayed. The other problem, more subtle and the actual culprit of the reproducer above, is when there is more than just the `Display` operation in the computation graph. `DisplayHelper::Exec` is called once per entry to be processed, as this is the normal working condition in `RLoopManager::Run`. When there is only the `Display` operation, the moment there are no more entries to be displayed, `DisplayHelper` will tell `RLoopManager` that it has finished, thus triggering an early stop of the execution (e.g. if a tree has 100 entries but we only want to display 5). When there is more than one operation, i.e. more than one child of the `RLoopManager`, the call to `StopProcessing` coming from `DisplayHelper::Exec` is not enough t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11390
https://github.com/root-project/root/issues/11390:260,usability,workflow,workflow,260,"It turns out this is due to an integer underflow that is triggered by the machinery of `DisplayHelper`:. https://github.com/root-project/root/blob/3160daafc008d8080cb9b3c602f4134b521ca8ad/tree/dataframe/inc/ROOT/RDF/ActionHelpers.hxx#L1334-L1337. The intended workflow is:. 1. Add the next row to be displayed to the `RDisplay` object. The `AddRow` method decreases an internal counter of how many entries are left to be displayed at https://github.com/root-project/root/blob/3160daafc008d8080cb9b3c602f4134b521ca8ad/tree/dataframe/inc/ROOT/RDF/RDisplay.hxx#L227. 2. Check whether there are no more entries to be displayed (`!fDisplayerHelper->HasNext()`). 3. If so, signal the previous node that this node has finished its job through the `StopProcessing` method. There are a bunch of flaws in this workflow. Uncoditionally calling `AddRow` may trigger the integer underflow by calling `fEntries--` when `fEntries==0`. This can be seen quite simply with the following example. ```cpp. root [0] ROOT::RDataFrame d{1};. root [1] auto dd = d.Define(""b1"", [] { return 42; }).Display<int>({""b1""}, 0);. root [2] dd->Print(). +-----+----+. | Row | b1 | . +-----+----+. | 0 | 42 | . +-----+----+. ```. The row is printed even though the user asked for `0` entries to be displayed. The other problem, more subtle and the actual culprit of the reproducer above, is when there is more than just the `Display` operation in the computation graph. `DisplayHelper::Exec` is called once per entry to be processed, as this is the normal working condition in `RLoopManager::Run`. When there is only the `Display` operation, the moment there are no more entries to be displayed, `DisplayHelper` will tell `RLoopManager` that it has finished, thus triggering an early stop of the execution (e.g. if a tree has 100 entries but we only want to display 5). When there is more than one operation, i.e. more than one child of the `RLoopManager`, the call to `StopProcessing` coming from `DisplayHelper::Exec` is not enough t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11390
https://github.com/root-project/root/issues/11390:741,usability,Stop,StopProcessing,741,"It turns out this is due to an integer underflow that is triggered by the machinery of `DisplayHelper`:. https://github.com/root-project/root/blob/3160daafc008d8080cb9b3c602f4134b521ca8ad/tree/dataframe/inc/ROOT/RDF/ActionHelpers.hxx#L1334-L1337. The intended workflow is:. 1. Add the next row to be displayed to the `RDisplay` object. The `AddRow` method decreases an internal counter of how many entries are left to be displayed at https://github.com/root-project/root/blob/3160daafc008d8080cb9b3c602f4134b521ca8ad/tree/dataframe/inc/ROOT/RDF/RDisplay.hxx#L227. 2. Check whether there are no more entries to be displayed (`!fDisplayerHelper->HasNext()`). 3. If so, signal the previous node that this node has finished its job through the `StopProcessing` method. There are a bunch of flaws in this workflow. Uncoditionally calling `AddRow` may trigger the integer underflow by calling `fEntries--` when `fEntries==0`. This can be seen quite simply with the following example. ```cpp. root [0] ROOT::RDataFrame d{1};. root [1] auto dd = d.Define(""b1"", [] { return 42; }).Display<int>({""b1""}, 0);. root [2] dd->Print(). +-----+----+. | Row | b1 | . +-----+----+. | 0 | 42 | . +-----+----+. ```. The row is printed even though the user asked for `0` entries to be displayed. The other problem, more subtle and the actual culprit of the reproducer above, is when there is more than just the `Display` operation in the computation graph. `DisplayHelper::Exec` is called once per entry to be processed, as this is the normal working condition in `RLoopManager::Run`. When there is only the `Display` operation, the moment there are no more entries to be displayed, `DisplayHelper` will tell `RLoopManager` that it has finished, thus triggering an early stop of the execution (e.g. if a tree has 100 entries but we only want to display 5). When there is more than one operation, i.e. more than one child of the `RLoopManager`, the call to `StopProcessing` coming from `DisplayHelper::Exec` is not enough t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11390
https://github.com/root-project/root/issues/11390:800,usability,workflow,workflow,800,"It turns out this is due to an integer underflow that is triggered by the machinery of `DisplayHelper`:. https://github.com/root-project/root/blob/3160daafc008d8080cb9b3c602f4134b521ca8ad/tree/dataframe/inc/ROOT/RDF/ActionHelpers.hxx#L1334-L1337. The intended workflow is:. 1. Add the next row to be displayed to the `RDisplay` object. The `AddRow` method decreases an internal counter of how many entries are left to be displayed at https://github.com/root-project/root/blob/3160daafc008d8080cb9b3c602f4134b521ca8ad/tree/dataframe/inc/ROOT/RDF/RDisplay.hxx#L227. 2. Check whether there are no more entries to be displayed (`!fDisplayerHelper->HasNext()`). 3. If so, signal the previous node that this node has finished its job through the `StopProcessing` method. There are a bunch of flaws in this workflow. Uncoditionally calling `AddRow` may trigger the integer underflow by calling `fEntries--` when `fEntries==0`. This can be seen quite simply with the following example. ```cpp. root [0] ROOT::RDataFrame d{1};. root [1] auto dd = d.Define(""b1"", [] { return 42; }).Display<int>({""b1""}, 0);. root [2] dd->Print(). +-----+----+. | Row | b1 | . +-----+----+. | 0 | 42 | . +-----+----+. ```. The row is printed even though the user asked for `0` entries to be displayed. The other problem, more subtle and the actual culprit of the reproducer above, is when there is more than just the `Display` operation in the computation graph. `DisplayHelper::Exec` is called once per entry to be processed, as this is the normal working condition in `RLoopManager::Run`. When there is only the `Display` operation, the moment there are no more entries to be displayed, `DisplayHelper` will tell `RLoopManager` that it has finished, thus triggering an early stop of the execution (e.g. if a tree has 100 entries but we only want to display 5). When there is more than one operation, i.e. more than one child of the `RLoopManager`, the call to `StopProcessing` coming from `DisplayHelper::Exec` is not enough t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11390
https://github.com/root-project/root/issues/11390:943,usability,simpl,simply,943,"It turns out this is due to an integer underflow that is triggered by the machinery of `DisplayHelper`:. https://github.com/root-project/root/blob/3160daafc008d8080cb9b3c602f4134b521ca8ad/tree/dataframe/inc/ROOT/RDF/ActionHelpers.hxx#L1334-L1337. The intended workflow is:. 1. Add the next row to be displayed to the `RDisplay` object. The `AddRow` method decreases an internal counter of how many entries are left to be displayed at https://github.com/root-project/root/blob/3160daafc008d8080cb9b3c602f4134b521ca8ad/tree/dataframe/inc/ROOT/RDF/RDisplay.hxx#L227. 2. Check whether there are no more entries to be displayed (`!fDisplayerHelper->HasNext()`). 3. If so, signal the previous node that this node has finished its job through the `StopProcessing` method. There are a bunch of flaws in this workflow. Uncoditionally calling `AddRow` may trigger the integer underflow by calling `fEntries--` when `fEntries==0`. This can be seen quite simply with the following example. ```cpp. root [0] ROOT::RDataFrame d{1};. root [1] auto dd = d.Define(""b1"", [] { return 42; }).Display<int>({""b1""}, 0);. root [2] dd->Print(). +-----+----+. | Row | b1 | . +-----+----+. | 0 | 42 | . +-----+----+. ```. The row is printed even though the user asked for `0` entries to be displayed. The other problem, more subtle and the actual culprit of the reproducer above, is when there is more than just the `Display` operation in the computation graph. `DisplayHelper::Exec` is called once per entry to be processed, as this is the normal working condition in `RLoopManager::Run`. When there is only the `Display` operation, the moment there are no more entries to be displayed, `DisplayHelper` will tell `RLoopManager` that it has finished, thus triggering an early stop of the execution (e.g. if a tree has 100 entries but we only want to display 5). When there is more than one operation, i.e. more than one child of the `RLoopManager`, the call to `StopProcessing` coming from `DisplayHelper::Exec` is not enough t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11390
https://github.com/root-project/root/issues/11390:1230,usability,user,user,1230,"x#L1334-L1337. The intended workflow is:. 1. Add the next row to be displayed to the `RDisplay` object. The `AddRow` method decreases an internal counter of how many entries are left to be displayed at https://github.com/root-project/root/blob/3160daafc008d8080cb9b3c602f4134b521ca8ad/tree/dataframe/inc/ROOT/RDF/RDisplay.hxx#L227. 2. Check whether there are no more entries to be displayed (`!fDisplayerHelper->HasNext()`). 3. If so, signal the previous node that this node has finished its job through the `StopProcessing` method. There are a bunch of flaws in this workflow. Uncoditionally calling `AddRow` may trigger the integer underflow by calling `fEntries--` when `fEntries==0`. This can be seen quite simply with the following example. ```cpp. root [0] ROOT::RDataFrame d{1};. root [1] auto dd = d.Define(""b1"", [] { return 42; }).Display<int>({""b1""}, 0);. root [2] dd->Print(). +-----+----+. | Row | b1 | . +-----+----+. | 0 | 42 | . +-----+----+. ```. The row is printed even though the user asked for `0` entries to be displayed. The other problem, more subtle and the actual culprit of the reproducer above, is when there is more than just the `Display` operation in the computation graph. `DisplayHelper::Exec` is called once per entry to be processed, as this is the normal working condition in `RLoopManager::Run`. When there is only the `Display` operation, the moment there are no more entries to be displayed, `DisplayHelper` will tell `RLoopManager` that it has finished, thus triggering an early stop of the execution (e.g. if a tree has 100 entries but we only want to display 5). When there is more than one operation, i.e. more than one child of the `RLoopManager`, the call to `StopProcessing` coming from `DisplayHelper::Exec` is not enough to stop the execution. Taking as an example the repro above, there is one `Display` and one `Count` operation, thus 2 children, thus 2 calls to `StopProcessing` must be issued in order to stop the execution. From the point of view of",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11390
https://github.com/root-project/root/issues/11390:1749,usability,stop,stop,1749," so, signal the previous node that this node has finished its job through the `StopProcessing` method. There are a bunch of flaws in this workflow. Uncoditionally calling `AddRow` may trigger the integer underflow by calling `fEntries--` when `fEntries==0`. This can be seen quite simply with the following example. ```cpp. root [0] ROOT::RDataFrame d{1};. root [1] auto dd = d.Define(""b1"", [] { return 42; }).Display<int>({""b1""}, 0);. root [2] dd->Print(). +-----+----+. | Row | b1 | . +-----+----+. | 0 | 42 | . +-----+----+. ```. The row is printed even though the user asked for `0` entries to be displayed. The other problem, more subtle and the actual culprit of the reproducer above, is when there is more than just the `Display` operation in the computation graph. `DisplayHelper::Exec` is called once per entry to be processed, as this is the normal working condition in `RLoopManager::Run`. When there is only the `Display` operation, the moment there are no more entries to be displayed, `DisplayHelper` will tell `RLoopManager` that it has finished, thus triggering an early stop of the execution (e.g. if a tree has 100 entries but we only want to display 5). When there is more than one operation, i.e. more than one child of the `RLoopManager`, the call to `StopProcessing` coming from `DisplayHelper::Exec` is not enough to stop the execution. Taking as an example the repro above, there is one `Display` and one `Count` operation, thus 2 children, thus 2 calls to `StopProcessing` must be issued in order to stop the execution. From the point of view of `DisplayHelper::Exec`, the moment `fEntries` reaches zero it will call `StopProcessing`. But `RLoopManager` will still process the next entry because of the other child present. This means we are now calling again `DisplayHelper::Exec`, thus also `RDisplay::AddRow`, thus calling `fEntries--`, thus triggering an integer underflow. The final result is that the whole dataset will be displayed even though the user asked for less.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11390
https://github.com/root-project/root/issues/11390:1935,usability,Stop,StopProcessing,1935," so, signal the previous node that this node has finished its job through the `StopProcessing` method. There are a bunch of flaws in this workflow. Uncoditionally calling `AddRow` may trigger the integer underflow by calling `fEntries--` when `fEntries==0`. This can be seen quite simply with the following example. ```cpp. root [0] ROOT::RDataFrame d{1};. root [1] auto dd = d.Define(""b1"", [] { return 42; }).Display<int>({""b1""}, 0);. root [2] dd->Print(). +-----+----+. | Row | b1 | . +-----+----+. | 0 | 42 | . +-----+----+. ```. The row is printed even though the user asked for `0` entries to be displayed. The other problem, more subtle and the actual culprit of the reproducer above, is when there is more than just the `Display` operation in the computation graph. `DisplayHelper::Exec` is called once per entry to be processed, as this is the normal working condition in `RLoopManager::Run`. When there is only the `Display` operation, the moment there are no more entries to be displayed, `DisplayHelper` will tell `RLoopManager` that it has finished, thus triggering an early stop of the execution (e.g. if a tree has 100 entries but we only want to display 5). When there is more than one operation, i.e. more than one child of the `RLoopManager`, the call to `StopProcessing` coming from `DisplayHelper::Exec` is not enough to stop the execution. Taking as an example the repro above, there is one `Display` and one `Count` operation, thus 2 children, thus 2 calls to `StopProcessing` must be issued in order to stop the execution. From the point of view of `DisplayHelper::Exec`, the moment `fEntries` reaches zero it will call `StopProcessing`. But `RLoopManager` will still process the next entry because of the other child present. This means we are now calling again `DisplayHelper::Exec`, thus also `RDisplay::AddRow`, thus calling `fEntries--`, thus triggering an integer underflow. The final result is that the whole dataset will be displayed even though the user asked for less.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11390
https://github.com/root-project/root/issues/11390:2002,usability,stop,stop,2002," so, signal the previous node that this node has finished its job through the `StopProcessing` method. There are a bunch of flaws in this workflow. Uncoditionally calling `AddRow` may trigger the integer underflow by calling `fEntries--` when `fEntries==0`. This can be seen quite simply with the following example. ```cpp. root [0] ROOT::RDataFrame d{1};. root [1] auto dd = d.Define(""b1"", [] { return 42; }).Display<int>({""b1""}, 0);. root [2] dd->Print(). +-----+----+. | Row | b1 | . +-----+----+. | 0 | 42 | . +-----+----+. ```. The row is printed even though the user asked for `0` entries to be displayed. The other problem, more subtle and the actual culprit of the reproducer above, is when there is more than just the `Display` operation in the computation graph. `DisplayHelper::Exec` is called once per entry to be processed, as this is the normal working condition in `RLoopManager::Run`. When there is only the `Display` operation, the moment there are no more entries to be displayed, `DisplayHelper` will tell `RLoopManager` that it has finished, thus triggering an early stop of the execution (e.g. if a tree has 100 entries but we only want to display 5). When there is more than one operation, i.e. more than one child of the `RLoopManager`, the call to `StopProcessing` coming from `DisplayHelper::Exec` is not enough to stop the execution. Taking as an example the repro above, there is one `Display` and one `Count` operation, thus 2 children, thus 2 calls to `StopProcessing` must be issued in order to stop the execution. From the point of view of `DisplayHelper::Exec`, the moment `fEntries` reaches zero it will call `StopProcessing`. But `RLoopManager` will still process the next entry because of the other child present. This means we are now calling again `DisplayHelper::Exec`, thus also `RDisplay::AddRow`, thus calling `fEntries--`, thus triggering an integer underflow. The final result is that the whole dataset will be displayed even though the user asked for less.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11390
https://github.com/root-project/root/issues/11390:2144,usability,Stop,StopProcessing,2144," so, signal the previous node that this node has finished its job through the `StopProcessing` method. There are a bunch of flaws in this workflow. Uncoditionally calling `AddRow` may trigger the integer underflow by calling `fEntries--` when `fEntries==0`. This can be seen quite simply with the following example. ```cpp. root [0] ROOT::RDataFrame d{1};. root [1] auto dd = d.Define(""b1"", [] { return 42; }).Display<int>({""b1""}, 0);. root [2] dd->Print(). +-----+----+. | Row | b1 | . +-----+----+. | 0 | 42 | . +-----+----+. ```. The row is printed even though the user asked for `0` entries to be displayed. The other problem, more subtle and the actual culprit of the reproducer above, is when there is more than just the `Display` operation in the computation graph. `DisplayHelper::Exec` is called once per entry to be processed, as this is the normal working condition in `RLoopManager::Run`. When there is only the `Display` operation, the moment there are no more entries to be displayed, `DisplayHelper` will tell `RLoopManager` that it has finished, thus triggering an early stop of the execution (e.g. if a tree has 100 entries but we only want to display 5). When there is more than one operation, i.e. more than one child of the `RLoopManager`, the call to `StopProcessing` coming from `DisplayHelper::Exec` is not enough to stop the execution. Taking as an example the repro above, there is one `Display` and one `Count` operation, thus 2 children, thus 2 calls to `StopProcessing` must be issued in order to stop the execution. From the point of view of `DisplayHelper::Exec`, the moment `fEntries` reaches zero it will call `StopProcessing`. But `RLoopManager` will still process the next entry because of the other child present. This means we are now calling again `DisplayHelper::Exec`, thus also `RDisplay::AddRow`, thus calling `fEntries--`, thus triggering an integer underflow. The final result is that the whole dataset will be displayed even though the user asked for less.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11390
https://github.com/root-project/root/issues/11390:2187,usability,stop,stop,2187," so, signal the previous node that this node has finished its job through the `StopProcessing` method. There are a bunch of flaws in this workflow. Uncoditionally calling `AddRow` may trigger the integer underflow by calling `fEntries--` when `fEntries==0`. This can be seen quite simply with the following example. ```cpp. root [0] ROOT::RDataFrame d{1};. root [1] auto dd = d.Define(""b1"", [] { return 42; }).Display<int>({""b1""}, 0);. root [2] dd->Print(). +-----+----+. | Row | b1 | . +-----+----+. | 0 | 42 | . +-----+----+. ```. The row is printed even though the user asked for `0` entries to be displayed. The other problem, more subtle and the actual culprit of the reproducer above, is when there is more than just the `Display` operation in the computation graph. `DisplayHelper::Exec` is called once per entry to be processed, as this is the normal working condition in `RLoopManager::Run`. When there is only the `Display` operation, the moment there are no more entries to be displayed, `DisplayHelper` will tell `RLoopManager` that it has finished, thus triggering an early stop of the execution (e.g. if a tree has 100 entries but we only want to display 5). When there is more than one operation, i.e. more than one child of the `RLoopManager`, the call to `StopProcessing` coming from `DisplayHelper::Exec` is not enough to stop the execution. Taking as an example the repro above, there is one `Display` and one `Count` operation, thus 2 children, thus 2 calls to `StopProcessing` must be issued in order to stop the execution. From the point of view of `DisplayHelper::Exec`, the moment `fEntries` reaches zero it will call `StopProcessing`. But `RLoopManager` will still process the next entry because of the other child present. This means we are now calling again `DisplayHelper::Exec`, thus also `RDisplay::AddRow`, thus calling `fEntries--`, thus triggering an integer underflow. The final result is that the whole dataset will be displayed even though the user asked for less.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11390
https://github.com/root-project/root/issues/11390:2305,usability,Stop,StopProcessing,2305," so, signal the previous node that this node has finished its job through the `StopProcessing` method. There are a bunch of flaws in this workflow. Uncoditionally calling `AddRow` may trigger the integer underflow by calling `fEntries--` when `fEntries==0`. This can be seen quite simply with the following example. ```cpp. root [0] ROOT::RDataFrame d{1};. root [1] auto dd = d.Define(""b1"", [] { return 42; }).Display<int>({""b1""}, 0);. root [2] dd->Print(). +-----+----+. | Row | b1 | . +-----+----+. | 0 | 42 | . +-----+----+. ```. The row is printed even though the user asked for `0` entries to be displayed. The other problem, more subtle and the actual culprit of the reproducer above, is when there is more than just the `Display` operation in the computation graph. `DisplayHelper::Exec` is called once per entry to be processed, as this is the normal working condition in `RLoopManager::Run`. When there is only the `Display` operation, the moment there are no more entries to be displayed, `DisplayHelper` will tell `RLoopManager` that it has finished, thus triggering an early stop of the execution (e.g. if a tree has 100 entries but we only want to display 5). When there is more than one operation, i.e. more than one child of the `RLoopManager`, the call to `StopProcessing` coming from `DisplayHelper::Exec` is not enough to stop the execution. Taking as an example the repro above, there is one `Display` and one `Count` operation, thus 2 children, thus 2 calls to `StopProcessing` must be issued in order to stop the execution. From the point of view of `DisplayHelper::Exec`, the moment `fEntries` reaches zero it will call `StopProcessing`. But `RLoopManager` will still process the next entry because of the other child present. This means we are now calling again `DisplayHelper::Exec`, thus also `RDisplay::AddRow`, thus calling `fEntries--`, thus triggering an integer underflow. The final result is that the whole dataset will be displayed even though the user asked for less.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11390
https://github.com/root-project/root/issues/11390:2642,usability,user,user,2642," so, signal the previous node that this node has finished its job through the `StopProcessing` method. There are a bunch of flaws in this workflow. Uncoditionally calling `AddRow` may trigger the integer underflow by calling `fEntries--` when `fEntries==0`. This can be seen quite simply with the following example. ```cpp. root [0] ROOT::RDataFrame d{1};. root [1] auto dd = d.Define(""b1"", [] { return 42; }).Display<int>({""b1""}, 0);. root [2] dd->Print(). +-----+----+. | Row | b1 | . +-----+----+. | 0 | 42 | . +-----+----+. ```. The row is printed even though the user asked for `0` entries to be displayed. The other problem, more subtle and the actual culprit of the reproducer above, is when there is more than just the `Display` operation in the computation graph. `DisplayHelper::Exec` is called once per entry to be processed, as this is the normal working condition in `RLoopManager::Run`. When there is only the `Display` operation, the moment there are no more entries to be displayed, `DisplayHelper` will tell `RLoopManager` that it has finished, thus triggering an early stop of the execution (e.g. if a tree has 100 entries but we only want to display 5). When there is more than one operation, i.e. more than one child of the `RLoopManager`, the call to `StopProcessing` coming from `DisplayHelper::Exec` is not enough to stop the execution. Taking as an example the repro above, there is one `Display` and one `Count` operation, thus 2 children, thus 2 calls to `StopProcessing` must be issued in order to stop the execution. From the point of view of `DisplayHelper::Exec`, the moment `fEntries` reaches zero it will call `StopProcessing`. But `RLoopManager` will still process the next entry because of the other child present. This means we are now calling again `DisplayHelper::Exec`, thus also `RDisplay::AddRow`, thus calling `fEntries--`, thus triggering an integer underflow. The final result is that the whole dataset will be displayed even though the user asked for less.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11390
https://github.com/root-project/root/pull/11391:4,availability,error,errors,4,The errors are unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11391
https://github.com/root-project/root/pull/11391:4,performance,error,errors,4,The errors are unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11391
https://github.com/root-project/root/pull/11391:4,safety,error,errors,4,The errors are unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11391
https://github.com/root-project/root/pull/11391:4,usability,error,errors,4,The errors are unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11391
https://github.com/root-project/root/pull/11393:18,availability,failur,failure,18,"Warnings and test failure are not related to this PR, merging.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11393
https://github.com/root-project/root/pull/11393:18,deployability,fail,failure,18,"Warnings and test failure are not related to this PR, merging.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11393
https://github.com/root-project/root/pull/11393:18,performance,failur,failure,18,"Warnings and test failure are not related to this PR, merging.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11393
https://github.com/root-project/root/pull/11393:18,reliability,fail,failure,18,"Warnings and test failure are not related to this PR, merging.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11393
https://github.com/root-project/root/pull/11393:13,safety,test,test,13,"Warnings and test failure are not related to this PR, merging.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11393
https://github.com/root-project/root/pull/11393:13,testability,test,test,13,"Warnings and test failure are not related to this PR, merging.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11393
https://github.com/root-project/root/issues/11395:115,deployability,stack,stackoverflow,115,"I did TPMERegexp, not sure who did TPRegexp. It seem sit would not be a major issue to swap over to pcre2. https://stackoverflow.com/questions/70273084/regex-differences-between-pcre-and-pcre2",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11395
https://github.com/root-project/root/issues/11397:98,deployability,releas,release,98,"Hi @AlkaidCheng, thanks for reporting this. This is a known issue that I want to fix for the next release 6.28. All functions that return an owning pointer in C++ like `createNLL` and many others result in a memory leak in Python, because Python doesn't know it should delete the object. That means Python code with RooFit has leaks all over the place as it is now, and it's not worth to open an issue for all of them. But let's leave this one open because it's actually the first issue about this. The reason it is not so quickly fixed is that I'm still investigating how I might flag functions on the C++ side such that PyROOT automatically knows that it should take ownership, without having to make an explicit Pythonization. My WIP is in this PR: https://github.com/root-project/root/pull/9392. But for now, you can circumvent the problem by telling PyROOT explicitly that it owns the returned NLL:. ```Python. def test(pdf, ds):. nll = pdf.createNLL(ds). ROOT.SetOwnership(nll, True). ```. This method works for all the objects that you would have to `delete` yourself in C++.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11397
https://github.com/root-project/root/issues/11397:629,deployability,automat,automatically,629,"Hi @AlkaidCheng, thanks for reporting this. This is a known issue that I want to fix for the next release 6.28. All functions that return an owning pointer in C++ like `createNLL` and many others result in a memory leak in Python, because Python doesn't know it should delete the object. That means Python code with RooFit has leaks all over the place as it is now, and it's not worth to open an issue for all of them. But let's leave this one open because it's actually the first issue about this. The reason it is not so quickly fixed is that I'm still investigating how I might flag functions on the C++ side such that PyROOT automatically knows that it should take ownership, without having to make an explicit Pythonization. My WIP is in this PR: https://github.com/root-project/root/pull/9392. But for now, you can circumvent the problem by telling PyROOT explicitly that it owns the returned NLL:. ```Python. def test(pdf, ds):. nll = pdf.createNLL(ds). ROOT.SetOwnership(nll, True). ```. This method works for all the objects that you would have to `delete` yourself in C++.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11397
https://github.com/root-project/root/issues/11397:208,performance,memor,memory,208,"Hi @AlkaidCheng, thanks for reporting this. This is a known issue that I want to fix for the next release 6.28. All functions that return an owning pointer in C++ like `createNLL` and many others result in a memory leak in Python, because Python doesn't know it should delete the object. That means Python code with RooFit has leaks all over the place as it is now, and it's not worth to open an issue for all of them. But let's leave this one open because it's actually the first issue about this. The reason it is not so quickly fixed is that I'm still investigating how I might flag functions on the C++ side such that PyROOT automatically knows that it should take ownership, without having to make an explicit Pythonization. My WIP is in this PR: https://github.com/root-project/root/pull/9392. But for now, you can circumvent the problem by telling PyROOT explicitly that it owns the returned NLL:. ```Python. def test(pdf, ds):. nll = pdf.createNLL(ds). ROOT.SetOwnership(nll, True). ```. This method works for all the objects that you would have to `delete` yourself in C++.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11397
https://github.com/root-project/root/issues/11397:246,reliability,doe,doesn,246,"Hi @AlkaidCheng, thanks for reporting this. This is a known issue that I want to fix for the next release 6.28. All functions that return an owning pointer in C++ like `createNLL` and many others result in a memory leak in Python, because Python doesn't know it should delete the object. That means Python code with RooFit has leaks all over the place as it is now, and it's not worth to open an issue for all of them. But let's leave this one open because it's actually the first issue about this. The reason it is not so quickly fixed is that I'm still investigating how I might flag functions on the C++ side such that PyROOT automatically knows that it should take ownership, without having to make an explicit Pythonization. My WIP is in this PR: https://github.com/root-project/root/pull/9392. But for now, you can circumvent the problem by telling PyROOT explicitly that it owns the returned NLL:. ```Python. def test(pdf, ds):. nll = pdf.createNLL(ds). ROOT.SetOwnership(nll, True). ```. This method works for all the objects that you would have to `delete` yourself in C++.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11397
https://github.com/root-project/root/issues/11397:920,safety,test,test,920,"Hi @AlkaidCheng, thanks for reporting this. This is a known issue that I want to fix for the next release 6.28. All functions that return an owning pointer in C++ like `createNLL` and many others result in a memory leak in Python, because Python doesn't know it should delete the object. That means Python code with RooFit has leaks all over the place as it is now, and it's not worth to open an issue for all of them. But let's leave this one open because it's actually the first issue about this. The reason it is not so quickly fixed is that I'm still investigating how I might flag functions on the C++ side such that PyROOT automatically knows that it should take ownership, without having to make an explicit Pythonization. My WIP is in this PR: https://github.com/root-project/root/pull/9392. But for now, you can circumvent the problem by telling PyROOT explicitly that it owns the returned NLL:. ```Python. def test(pdf, ds):. nll = pdf.createNLL(ds). ROOT.SetOwnership(nll, True). ```. This method works for all the objects that you would have to `delete` yourself in C++.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11397
https://github.com/root-project/root/issues/11397:629,testability,automat,automatically,629,"Hi @AlkaidCheng, thanks for reporting this. This is a known issue that I want to fix for the next release 6.28. All functions that return an owning pointer in C++ like `createNLL` and many others result in a memory leak in Python, because Python doesn't know it should delete the object. That means Python code with RooFit has leaks all over the place as it is now, and it's not worth to open an issue for all of them. But let's leave this one open because it's actually the first issue about this. The reason it is not so quickly fixed is that I'm still investigating how I might flag functions on the C++ side such that PyROOT automatically knows that it should take ownership, without having to make an explicit Pythonization. My WIP is in this PR: https://github.com/root-project/root/pull/9392. But for now, you can circumvent the problem by telling PyROOT explicitly that it owns the returned NLL:. ```Python. def test(pdf, ds):. nll = pdf.createNLL(ds). ROOT.SetOwnership(nll, True). ```. This method works for all the objects that you would have to `delete` yourself in C++.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11397
https://github.com/root-project/root/issues/11397:920,testability,test,test,920,"Hi @AlkaidCheng, thanks for reporting this. This is a known issue that I want to fix for the next release 6.28. All functions that return an owning pointer in C++ like `createNLL` and many others result in a memory leak in Python, because Python doesn't know it should delete the object. That means Python code with RooFit has leaks all over the place as it is now, and it's not worth to open an issue for all of them. But let's leave this one open because it's actually the first issue about this. The reason it is not so quickly fixed is that I'm still investigating how I might flag functions on the C++ side such that PyROOT automatically knows that it should take ownership, without having to make an explicit Pythonization. My WIP is in this PR: https://github.com/root-project/root/pull/9392. But for now, you can circumvent the problem by telling PyROOT explicitly that it owns the returned NLL:. ```Python. def test(pdf, ds):. nll = pdf.createNLL(ds). ROOT.SetOwnership(nll, True). ```. This method works for all the objects that you would have to `delete` yourself in C++.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11397
https://github.com/root-project/root/issues/11397:208,usability,memor,memory,208,"Hi @AlkaidCheng, thanks for reporting this. This is a known issue that I want to fix for the next release 6.28. All functions that return an owning pointer in C++ like `createNLL` and many others result in a memory leak in Python, because Python doesn't know it should delete the object. That means Python code with RooFit has leaks all over the place as it is now, and it's not worth to open an issue for all of them. But let's leave this one open because it's actually the first issue about this. The reason it is not so quickly fixed is that I'm still investigating how I might flag functions on the C++ side such that PyROOT automatically knows that it should take ownership, without having to make an explicit Pythonization. My WIP is in this PR: https://github.com/root-project/root/pull/9392. But for now, you can circumvent the problem by telling PyROOT explicitly that it owns the returned NLL:. ```Python. def test(pdf, ds):. nll = pdf.createNLL(ds). ROOT.SetOwnership(nll, True). ```. This method works for all the objects that you would have to `delete` yourself in C++.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11397
https://github.com/root-project/root/issues/11397:435,deployability,automat,automatically,435,"There is still no fix for this yet, but I have changed the title to make clear that this problem is more general. Also there is the same issue in JIRA, that I'll now close because it is a duplicate of this GitHub issue:. https://sft.its.cern.ch/jira/browse/ROOT-9776. The proper fix would be in my opinion to tag the relevant functions in C++ with an attribute, and then have these considered by PyROOT to set the `_creates` attribute automatically.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11397
https://github.com/root-project/root/issues/11397:435,testability,automat,automatically,435,"There is still no fix for this yet, but I have changed the title to make clear that this problem is more general. Also there is the same issue in JIRA, that I'll now close because it is a duplicate of this GitHub issue:. https://sft.its.cern.ch/jira/browse/ROOT-9776. The proper fix would be in my opinion to tag the relevant functions in C++ with an attribute, and then have these considered by PyROOT to set the `_creates` attribute automatically.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11397
https://github.com/root-project/root/issues/11397:73,usability,clear,clear,73,"There is still no fix for this yet, but I have changed the title to make clear that this problem is more general. Also there is the same issue in JIRA, that I'll now close because it is a duplicate of this GitHub issue:. https://sft.its.cern.ch/jira/browse/ROOT-9776. The proper fix would be in my opinion to tag the relevant functions in C++ with an attribute, and then have these considered by PyROOT to set the `_creates` attribute automatically.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11397
https://github.com/root-project/root/issues/11397:166,usability,close,close,166,"There is still no fix for this yet, but I have changed the title to make clear that this problem is more general. Also there is the same issue in JIRA, that I'll now close because it is a duplicate of this GitHub issue:. https://sft.its.cern.ch/jira/browse/ROOT-9776. The proper fix would be in my opinion to tag the relevant functions in C++ with an attribute, and then have these considered by PyROOT to set the `_creates` attribute automatically.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11397
https://github.com/root-project/root/issues/11397:205,performance,memor,memory,205,"Hi @guitargeek , I assume this problem still persists? Is there a quick way to figure out which PyROOT/RooFit objects this affects? . We are running large number of fits (~1000s) and see large increase in memory throughout I suspect comes from RooFit, I already see ~20% smaller memory increase if I set the ownership of the nll but since we use lot of RooFit objects it would be lot of work to trace all the objects and test if they cause this (I could just set ownership of each roofit objects in the code but that is also not ideal ...). I guess it just affects objects which are returned by functions and not objects I explicitly create?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11397
https://github.com/root-project/root/issues/11397:279,performance,memor,memory,279,"Hi @guitargeek , I assume this problem still persists? Is there a quick way to figure out which PyROOT/RooFit objects this affects? . We are running large number of fits (~1000s) and see large increase in memory throughout I suspect comes from RooFit, I already see ~20% smaller memory increase if I set the ownership of the nll but since we use lot of RooFit objects it would be lot of work to trace all the objects and test if they cause this (I could just set ownership of each roofit objects in the code but that is also not ideal ...). I guess it just affects objects which are returned by functions and not objects I explicitly create?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11397
https://github.com/root-project/root/issues/11397:421,safety,test,test,421,"Hi @guitargeek , I assume this problem still persists? Is there a quick way to figure out which PyROOT/RooFit objects this affects? . We are running large number of fits (~1000s) and see large increase in memory throughout I suspect comes from RooFit, I already see ~20% smaller memory increase if I set the ownership of the nll but since we use lot of RooFit objects it would be lot of work to trace all the objects and test if they cause this (I could just set ownership of each roofit objects in the code but that is also not ideal ...). I guess it just affects objects which are returned by functions and not objects I explicitly create?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11397
https://github.com/root-project/root/issues/11397:395,testability,trace,trace,395,"Hi @guitargeek , I assume this problem still persists? Is there a quick way to figure out which PyROOT/RooFit objects this affects? . We are running large number of fits (~1000s) and see large increase in memory throughout I suspect comes from RooFit, I already see ~20% smaller memory increase if I set the ownership of the nll but since we use lot of RooFit objects it would be lot of work to trace all the objects and test if they cause this (I could just set ownership of each roofit objects in the code but that is also not ideal ...). I guess it just affects objects which are returned by functions and not objects I explicitly create?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11397
https://github.com/root-project/root/issues/11397:421,testability,test,test,421,"Hi @guitargeek , I assume this problem still persists? Is there a quick way to figure out which PyROOT/RooFit objects this affects? . We are running large number of fits (~1000s) and see large increase in memory throughout I suspect comes from RooFit, I already see ~20% smaller memory increase if I set the ownership of the nll but since we use lot of RooFit objects it would be lot of work to trace all the objects and test if they cause this (I could just set ownership of each roofit objects in the code but that is also not ideal ...). I guess it just affects objects which are returned by functions and not objects I explicitly create?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11397
https://github.com/root-project/root/issues/11397:205,usability,memor,memory,205,"Hi @guitargeek , I assume this problem still persists? Is there a quick way to figure out which PyROOT/RooFit objects this affects? . We are running large number of fits (~1000s) and see large increase in memory throughout I suspect comes from RooFit, I already see ~20% smaller memory increase if I set the ownership of the nll but since we use lot of RooFit objects it would be lot of work to trace all the objects and test if they cause this (I could just set ownership of each roofit objects in the code but that is also not ideal ...). I guess it just affects objects which are returned by functions and not objects I explicitly create?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11397
https://github.com/root-project/root/issues/11397:279,usability,memor,memory,279,"Hi @guitargeek , I assume this problem still persists? Is there a quick way to figure out which PyROOT/RooFit objects this affects? . We are running large number of fits (~1000s) and see large increase in memory throughout I suspect comes from RooFit, I already see ~20% smaller memory increase if I set the ownership of the nll but since we use lot of RooFit objects it would be lot of work to trace all the objects and test if they cause this (I could just set ownership of each roofit objects in the code but that is also not ideal ...). I guess it just affects objects which are returned by functions and not objects I explicitly create?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11397
https://github.com/root-project/root/issues/11397:277,performance,time,time,277,"Hi @fnechans, sorry for the late answer, I missed your comment here! It's hard to tell which functions are affected by this. `RooAbsPdf::createNLL()` or `RooAbsPdf::fitTo()` are big offenders, but also `getParameters()` returns an owning pointer for example. It will take some time for me to solve this problem sustanably, but maybe for ROOT 7 we'll change these functions to return `std::unique_ptr` such that leaks can't happen. Until then, the return type is `RooFit::OwningPtr<T>`, which is just an alias to `T*`, but it tells the reader of the documentation that this pointer needs to be deleted . See for example the documentation of [RooAbsPdf](https://root.cern.ch/doc/master/classRooAbsPdf.html#a24b1afec4fd149e08967eac4285800de).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11397
https://github.com/root-project/root/issues/11397:549,usability,document,documentation,549,"Hi @fnechans, sorry for the late answer, I missed your comment here! It's hard to tell which functions are affected by this. `RooAbsPdf::createNLL()` or `RooAbsPdf::fitTo()` are big offenders, but also `getParameters()` returns an owning pointer for example. It will take some time for me to solve this problem sustanably, but maybe for ROOT 7 we'll change these functions to return `std::unique_ptr` such that leaks can't happen. Until then, the return type is `RooFit::OwningPtr<T>`, which is just an alias to `T*`, but it tells the reader of the documentation that this pointer needs to be deleted . See for example the documentation of [RooAbsPdf](https://root.cern.ch/doc/master/classRooAbsPdf.html#a24b1afec4fd149e08967eac4285800de).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11397
https://github.com/root-project/root/issues/11397:623,usability,document,documentation,623,"Hi @fnechans, sorry for the late answer, I missed your comment here! It's hard to tell which functions are affected by this. `RooAbsPdf::createNLL()` or `RooAbsPdf::fitTo()` are big offenders, but also `getParameters()` returns an owning pointer for example. It will take some time for me to solve this problem sustanably, but maybe for ROOT 7 we'll change these functions to return `std::unique_ptr` such that leaks can't happen. Until then, the return type is `RooFit::OwningPtr<T>`, which is just an alias to `T*`, but it tells the reader of the documentation that this pointer needs to be deleted . See for example the documentation of [RooAbsPdf](https://root.cern.ch/doc/master/classRooAbsPdf.html#a24b1afec4fd149e08967eac4285800de).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11397
https://github.com/root-project/root/issues/11397:168,deployability,build,build,168,"Related to this problems, there was also a question on the forum:. * https://root-forum.cern.ch/t/roofit-numcpu-in-pyroot/57424. Then, there is also the possibility to build ROOT with the `std::unique_ptr` interfaces already:. * https://root.cern/doc/master/release-notes.html#compile-your-code-with-memory-safe-interfaces",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11397
https://github.com/root-project/root/issues/11397:258,deployability,releas,release-notes,258,"Related to this problems, there was also a question on the forum:. * https://root-forum.cern.ch/t/roofit-numcpu-in-pyroot/57424. Then, there is also the possibility to build ROOT with the `std::unique_ptr` interfaces already:. * https://root.cern/doc/master/release-notes.html#compile-your-code-with-memory-safe-interfaces",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11397
https://github.com/root-project/root/issues/11397:206,integrability,interfac,interfaces,206,"Related to this problems, there was also a question on the forum:. * https://root-forum.cern.ch/t/roofit-numcpu-in-pyroot/57424. Then, there is also the possibility to build ROOT with the `std::unique_ptr` interfaces already:. * https://root.cern/doc/master/release-notes.html#compile-your-code-with-memory-safe-interfaces",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11397
https://github.com/root-project/root/issues/11397:312,integrability,interfac,interfaces,312,"Related to this problems, there was also a question on the forum:. * https://root-forum.cern.ch/t/roofit-numcpu-in-pyroot/57424. Then, there is also the possibility to build ROOT with the `std::unique_ptr` interfaces already:. * https://root.cern/doc/master/release-notes.html#compile-your-code-with-memory-safe-interfaces",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11397
https://github.com/root-project/root/issues/11397:206,interoperability,interfac,interfaces,206,"Related to this problems, there was also a question on the forum:. * https://root-forum.cern.ch/t/roofit-numcpu-in-pyroot/57424. Then, there is also the possibility to build ROOT with the `std::unique_ptr` interfaces already:. * https://root.cern/doc/master/release-notes.html#compile-your-code-with-memory-safe-interfaces",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11397
https://github.com/root-project/root/issues/11397:312,interoperability,interfac,interfaces,312,"Related to this problems, there was also a question on the forum:. * https://root-forum.cern.ch/t/roofit-numcpu-in-pyroot/57424. Then, there is also the possibility to build ROOT with the `std::unique_ptr` interfaces already:. * https://root.cern/doc/master/release-notes.html#compile-your-code-with-memory-safe-interfaces",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11397
https://github.com/root-project/root/issues/11397:206,modifiability,interfac,interfaces,206,"Related to this problems, there was also a question on the forum:. * https://root-forum.cern.ch/t/roofit-numcpu-in-pyroot/57424. Then, there is also the possibility to build ROOT with the `std::unique_ptr` interfaces already:. * https://root.cern/doc/master/release-notes.html#compile-your-code-with-memory-safe-interfaces",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11397
https://github.com/root-project/root/issues/11397:312,modifiability,interfac,interfaces,312,"Related to this problems, there was also a question on the forum:. * https://root-forum.cern.ch/t/roofit-numcpu-in-pyroot/57424. Then, there is also the possibility to build ROOT with the `std::unique_ptr` interfaces already:. * https://root.cern/doc/master/release-notes.html#compile-your-code-with-memory-safe-interfaces",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11397
https://github.com/root-project/root/issues/11397:300,performance,memor,memory-safe-interfaces,300,"Related to this problems, there was also a question on the forum:. * https://root-forum.cern.ch/t/roofit-numcpu-in-pyroot/57424. Then, there is also the possibility to build ROOT with the `std::unique_ptr` interfaces already:. * https://root.cern/doc/master/release-notes.html#compile-your-code-with-memory-safe-interfaces",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11397
https://github.com/root-project/root/issues/11397:307,safety,safe,safe-interfaces,307,"Related to this problems, there was also a question on the forum:. * https://root-forum.cern.ch/t/roofit-numcpu-in-pyroot/57424. Then, there is also the possibility to build ROOT with the `std::unique_ptr` interfaces already:. * https://root.cern/doc/master/release-notes.html#compile-your-code-with-memory-safe-interfaces",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11397
https://github.com/root-project/root/issues/11397:300,usability,memor,memory-safe-interfaces,300,"Related to this problems, there was also a question on the forum:. * https://root-forum.cern.ch/t/roofit-numcpu-in-pyroot/57424. Then, there is also the possibility to build ROOT with the `std::unique_ptr` interfaces already:. * https://root.cern/doc/master/release-notes.html#compile-your-code-with-memory-safe-interfaces",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11397
https://github.com/root-project/root/pull/11398:3,deployability,build,build,3,"PR build will fail because of missing: https://github.com/root-project/root/pull/11490, so cancelling for now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11398
https://github.com/root-project/root/pull/11398:14,deployability,fail,fail,14,"PR build will fail because of missing: https://github.com/root-project/root/pull/11490, so cancelling for now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11398
https://github.com/root-project/root/pull/11398:14,reliability,fail,fail,14,"PR build will fail because of missing: https://github.com/root-project/root/pull/11490, so cancelling for now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11398
https://github.com/root-project/root/pull/11398:91,usability,cancel,cancelling,91,"PR build will fail because of missing: https://github.com/root-project/root/pull/11490, so cancelling for now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11398
https://github.com/root-project/root/pull/11398:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11398
https://github.com/root-project/root/pull/11398:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11398
https://github.com/root-project/root/pull/11401:7,deployability,updat,update,7,Little update to `testRooSimultaneous` because one of the unit tests was using the `SplitRange()` command argument in the wrong way.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11401
https://github.com/root-project/root/pull/11401:7,safety,updat,update,7,Little update to `testRooSimultaneous` because one of the unit tests was using the `SplitRange()` command argument in the wrong way.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11401
https://github.com/root-project/root/pull/11401:18,safety,test,testRooSimultaneous,18,Little update to `testRooSimultaneous` because one of the unit tests was using the `SplitRange()` command argument in the wrong way.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11401
https://github.com/root-project/root/pull/11401:63,safety,test,tests,63,Little update to `testRooSimultaneous` because one of the unit tests was using the `SplitRange()` command argument in the wrong way.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11401
https://github.com/root-project/root/pull/11401:7,security,updat,update,7,Little update to `testRooSimultaneous` because one of the unit tests was using the `SplitRange()` command argument in the wrong way.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11401
https://github.com/root-project/root/pull/11401:18,testability,test,testRooSimultaneous,18,Little update to `testRooSimultaneous` because one of the unit tests was using the `SplitRange()` command argument in the wrong way.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11401
https://github.com/root-project/root/pull/11401:58,testability,unit,unit,58,Little update to `testRooSimultaneous` because one of the unit tests was using the `SplitRange()` command argument in the wrong way.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11401
https://github.com/root-project/root/pull/11401:63,testability,test,tests,63,Little update to `testRooSimultaneous` because one of the unit tests was using the `SplitRange()` command argument in the wrong way.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11401
https://github.com/root-project/root/pull/11401:98,usability,command,command,98,Little update to `testRooSimultaneous` because one of the unit tests was using the `SplitRange()` command argument in the wrong way.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11401
https://github.com/root-project/root/pull/11403:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2204/default, ROOT-ubuntu18.04/default with flags -Dtmva-sofie=On",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11403
https://github.com/root-project/root/pull/11405:21,deployability,build,build,21,The corresponding PR build succeeded: https://github.com/root-project/roottest/pull/903,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11405
https://github.com/root-project/root/pull/11408:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11408
https://github.com/root-project/root/pull/11409:13,deployability,patch,patch,13,"Applying the patch causes a crash when cloning a `THnD`. Here is a simple code reproducing this:. ```. int bins[] = {10}; double xmin[] = {0}; double xmax[] = {10}; . auto h = new THnD(""h"",""h"",1,bins,xmin,xmax);. h->Sumw2();. h->Clone();. ```. @pcanal , any idea what could be the problem ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11409
https://github.com/root-project/root/pull/11409:13,safety,patch,patch,13,"Applying the patch causes a crash when cloning a `THnD`. Here is a simple code reproducing this:. ```. int bins[] = {10}; double xmin[] = {0}; double xmax[] = {10}; . auto h = new THnD(""h"",""h"",1,bins,xmin,xmax);. h->Sumw2();. h->Clone();. ```. @pcanal , any idea what could be the problem ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11409
https://github.com/root-project/root/pull/11409:13,security,patch,patch,13,"Applying the patch causes a crash when cloning a `THnD`. Here is a simple code reproducing this:. ```. int bins[] = {10}; double xmin[] = {0}; double xmax[] = {10}; . auto h = new THnD(""h"",""h"",1,bins,xmin,xmax);. h->Sumw2();. h->Clone();. ```. @pcanal , any idea what could be the problem ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11409
https://github.com/root-project/root/pull/11409:67,testability,simpl,simple,67,"Applying the patch causes a crash when cloning a `THnD`. Here is a simple code reproducing this:. ```. int bins[] = {10}; double xmin[] = {0}; double xmax[] = {10}; . auto h = new THnD(""h"",""h"",1,bins,xmin,xmax);. h->Sumw2();. h->Clone();. ```. @pcanal , any idea what could be the problem ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11409
https://github.com/root-project/root/pull/11409:67,usability,simpl,simple,67,"Applying the patch causes a crash when cloning a `THnD`. Here is a simple code reproducing this:. ```. int bins[] = {10}; double xmin[] = {0}; double xmax[] = {10}; . auto h = new THnD(""h"",""h"",1,bins,xmin,xmax);. h->Sumw2();. h->Clone();. ```. @pcanal , any idea what could be the problem ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11409
https://github.com/root-project/root/pull/11409:61,deployability,version,version,61,"I think in the I/O rule define in the `Linkdef.h` should be `version` and not `versions`, otherwise the rule is applied to all versions, including the current one. . The next patch should fix this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11409
https://github.com/root-project/root/pull/11409:79,deployability,version,versions,79,"I think in the I/O rule define in the `Linkdef.h` should be `version` and not `versions`, otherwise the rule is applied to all versions, including the current one. . The next patch should fix this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11409
https://github.com/root-project/root/pull/11409:127,deployability,version,versions,127,"I think in the I/O rule define in the `Linkdef.h` should be `version` and not `versions`, otherwise the rule is applied to all versions, including the current one. . The next patch should fix this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11409
https://github.com/root-project/root/pull/11409:175,deployability,patch,patch,175,"I think in the I/O rule define in the `Linkdef.h` should be `version` and not `versions`, otherwise the rule is applied to all versions, including the current one. . The next patch should fix this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11409
https://github.com/root-project/root/pull/11409:151,energy efficiency,current,current,151,"I think in the I/O rule define in the `Linkdef.h` should be `version` and not `versions`, otherwise the rule is applied to all versions, including the current one. . The next patch should fix this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11409
https://github.com/root-project/root/pull/11409:61,integrability,version,version,61,"I think in the I/O rule define in the `Linkdef.h` should be `version` and not `versions`, otherwise the rule is applied to all versions, including the current one. . The next patch should fix this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11409
https://github.com/root-project/root/pull/11409:79,integrability,version,versions,79,"I think in the I/O rule define in the `Linkdef.h` should be `version` and not `versions`, otherwise the rule is applied to all versions, including the current one. . The next patch should fix this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11409
https://github.com/root-project/root/pull/11409:127,integrability,version,versions,127,"I think in the I/O rule define in the `Linkdef.h` should be `version` and not `versions`, otherwise the rule is applied to all versions, including the current one. . The next patch should fix this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11409
https://github.com/root-project/root/pull/11409:61,modifiability,version,version,61,"I think in the I/O rule define in the `Linkdef.h` should be `version` and not `versions`, otherwise the rule is applied to all versions, including the current one. . The next patch should fix this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11409
https://github.com/root-project/root/pull/11409:79,modifiability,version,versions,79,"I think in the I/O rule define in the `Linkdef.h` should be `version` and not `versions`, otherwise the rule is applied to all versions, including the current one. . The next patch should fix this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11409
https://github.com/root-project/root/pull/11409:127,modifiability,version,versions,127,"I think in the I/O rule define in the `Linkdef.h` should be `version` and not `versions`, otherwise the rule is applied to all versions, including the current one. . The next patch should fix this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11409
https://github.com/root-project/root/pull/11409:15,performance,I/O,I/O,15,"I think in the I/O rule define in the `Linkdef.h` should be `version` and not `versions`, otherwise the rule is applied to all versions, including the current one. . The next patch should fix this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11409
https://github.com/root-project/root/pull/11409:175,safety,patch,patch,175,"I think in the I/O rule define in the `Linkdef.h` should be `version` and not `versions`, otherwise the rule is applied to all versions, including the current one. . The next patch should fix this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11409
https://github.com/root-project/root/pull/11409:175,security,patch,patch,175,"I think in the I/O rule define in the `Linkdef.h` should be `version` and not `versions`, otherwise the rule is applied to all versions, including the current one. . The next patch should fix this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11409
https://github.com/root-project/root/issues/11411:16,reliability,doe,does,16,Interesting. It does crash on linux but not on macos.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11411
https://github.com/root-project/root/issues/11411:173,deployability,fail,fails,173,"On which Linux, @dpiparo? For me on Arch Linux it works with ROOT `master`. I have created a unit test for ROOT test, like this we can maybe see on which platforms it still fails:. https://github.com/root-project/roottest/pull/1052",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11411
https://github.com/root-project/root/issues/11411:154,interoperability,platform,platforms,154,"On which Linux, @dpiparo? For me on Arch Linux it works with ROOT `master`. I have created a unit test for ROOT test, like this we can maybe see on which platforms it still fails:. https://github.com/root-project/roottest/pull/1052",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11411
https://github.com/root-project/root/issues/11411:173,reliability,fail,fails,173,"On which Linux, @dpiparo? For me on Arch Linux it works with ROOT `master`. I have created a unit test for ROOT test, like this we can maybe see on which platforms it still fails:. https://github.com/root-project/roottest/pull/1052",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11411
https://github.com/root-project/root/issues/11411:98,safety,test,test,98,"On which Linux, @dpiparo? For me on Arch Linux it works with ROOT `master`. I have created a unit test for ROOT test, like this we can maybe see on which platforms it still fails:. https://github.com/root-project/roottest/pull/1052",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11411
https://github.com/root-project/root/issues/11411:112,safety,test,test,112,"On which Linux, @dpiparo? For me on Arch Linux it works with ROOT `master`. I have created a unit test for ROOT test, like this we can maybe see on which platforms it still fails:. https://github.com/root-project/roottest/pull/1052",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11411
https://github.com/root-project/root/issues/11411:93,testability,unit,unit,93,"On which Linux, @dpiparo? For me on Arch Linux it works with ROOT `master`. I have created a unit test for ROOT test, like this we can maybe see on which platforms it still fails:. https://github.com/root-project/roottest/pull/1052",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11411
https://github.com/root-project/root/issues/11411:98,testability,test,test,98,"On which Linux, @dpiparo? For me on Arch Linux it works with ROOT `master`. I have created a unit test for ROOT test, like this we can maybe see on which platforms it still fails:. https://github.com/root-project/roottest/pull/1052",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11411
https://github.com/root-project/root/issues/11411:112,testability,test,test,112,"On which Linux, @dpiparo? For me on Arch Linux it works with ROOT `master`. I have created a unit test for ROOT test, like this we can maybe see on which platforms it still fails:. https://github.com/root-project/roottest/pull/1052",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11411
https://github.com/root-project/root/issues/11411:404,availability,failur,failures,404,"New insights:. * when adding the reproducer to `roottest`, most of the Jenkins platforms will fail:. https://github.com/root-project/roottest/pull/1052. * when testing the reproducer together with the CPyCppyy upgrade, the test `projectroot.roottest.python.cpp.roottest_python_cpp_cpp11` will instead pass on all platforms:. https://github.com/root-project/roottest/pull/1071. (note that there are other failures related to the CPyCppyy upgrade that are unrelated to the issue). Therefore, I can attest that this issue will be fixed with the CPyCppyy upgrade. This makes total sense, because the upgrade includes a patch that fixes the conversion of initializer lists:. https://github.com/wlav/CPyCppyy/pull/14",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11411
https://github.com/root-project/root/issues/11411:94,deployability,fail,fail,94,"New insights:. * when adding the reproducer to `roottest`, most of the Jenkins platforms will fail:. https://github.com/root-project/roottest/pull/1052. * when testing the reproducer together with the CPyCppyy upgrade, the test `projectroot.roottest.python.cpp.roottest_python_cpp_cpp11` will instead pass on all platforms:. https://github.com/root-project/roottest/pull/1071. (note that there are other failures related to the CPyCppyy upgrade that are unrelated to the issue). Therefore, I can attest that this issue will be fixed with the CPyCppyy upgrade. This makes total sense, because the upgrade includes a patch that fixes the conversion of initializer lists:. https://github.com/wlav/CPyCppyy/pull/14",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11411
https://github.com/root-project/root/issues/11411:210,deployability,upgrad,upgrade,210,"New insights:. * when adding the reproducer to `roottest`, most of the Jenkins platforms will fail:. https://github.com/root-project/roottest/pull/1052. * when testing the reproducer together with the CPyCppyy upgrade, the test `projectroot.roottest.python.cpp.roottest_python_cpp_cpp11` will instead pass on all platforms:. https://github.com/root-project/roottest/pull/1071. (note that there are other failures related to the CPyCppyy upgrade that are unrelated to the issue). Therefore, I can attest that this issue will be fixed with the CPyCppyy upgrade. This makes total sense, because the upgrade includes a patch that fixes the conversion of initializer lists:. https://github.com/wlav/CPyCppyy/pull/14",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11411
https://github.com/root-project/root/issues/11411:404,deployability,fail,failures,404,"New insights:. * when adding the reproducer to `roottest`, most of the Jenkins platforms will fail:. https://github.com/root-project/roottest/pull/1052. * when testing the reproducer together with the CPyCppyy upgrade, the test `projectroot.roottest.python.cpp.roottest_python_cpp_cpp11` will instead pass on all platforms:. https://github.com/root-project/roottest/pull/1071. (note that there are other failures related to the CPyCppyy upgrade that are unrelated to the issue). Therefore, I can attest that this issue will be fixed with the CPyCppyy upgrade. This makes total sense, because the upgrade includes a patch that fixes the conversion of initializer lists:. https://github.com/wlav/CPyCppyy/pull/14",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11411
https://github.com/root-project/root/issues/11411:437,deployability,upgrad,upgrade,437,"New insights:. * when adding the reproducer to `roottest`, most of the Jenkins platforms will fail:. https://github.com/root-project/roottest/pull/1052. * when testing the reproducer together with the CPyCppyy upgrade, the test `projectroot.roottest.python.cpp.roottest_python_cpp_cpp11` will instead pass on all platforms:. https://github.com/root-project/roottest/pull/1071. (note that there are other failures related to the CPyCppyy upgrade that are unrelated to the issue). Therefore, I can attest that this issue will be fixed with the CPyCppyy upgrade. This makes total sense, because the upgrade includes a patch that fixes the conversion of initializer lists:. https://github.com/wlav/CPyCppyy/pull/14",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11411
https://github.com/root-project/root/issues/11411:551,deployability,upgrad,upgrade,551,"New insights:. * when adding the reproducer to `roottest`, most of the Jenkins platforms will fail:. https://github.com/root-project/roottest/pull/1052. * when testing the reproducer together with the CPyCppyy upgrade, the test `projectroot.roottest.python.cpp.roottest_python_cpp_cpp11` will instead pass on all platforms:. https://github.com/root-project/roottest/pull/1071. (note that there are other failures related to the CPyCppyy upgrade that are unrelated to the issue). Therefore, I can attest that this issue will be fixed with the CPyCppyy upgrade. This makes total sense, because the upgrade includes a patch that fixes the conversion of initializer lists:. https://github.com/wlav/CPyCppyy/pull/14",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11411
https://github.com/root-project/root/issues/11411:596,deployability,upgrad,upgrade,596,"New insights:. * when adding the reproducer to `roottest`, most of the Jenkins platforms will fail:. https://github.com/root-project/roottest/pull/1052. * when testing the reproducer together with the CPyCppyy upgrade, the test `projectroot.roottest.python.cpp.roottest_python_cpp_cpp11` will instead pass on all platforms:. https://github.com/root-project/roottest/pull/1071. (note that there are other failures related to the CPyCppyy upgrade that are unrelated to the issue). Therefore, I can attest that this issue will be fixed with the CPyCppyy upgrade. This makes total sense, because the upgrade includes a patch that fixes the conversion of initializer lists:. https://github.com/wlav/CPyCppyy/pull/14",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11411
https://github.com/root-project/root/issues/11411:615,deployability,patch,patch,615,"New insights:. * when adding the reproducer to `roottest`, most of the Jenkins platforms will fail:. https://github.com/root-project/roottest/pull/1052. * when testing the reproducer together with the CPyCppyy upgrade, the test `projectroot.roottest.python.cpp.roottest_python_cpp_cpp11` will instead pass on all platforms:. https://github.com/root-project/roottest/pull/1071. (note that there are other failures related to the CPyCppyy upgrade that are unrelated to the issue). Therefore, I can attest that this issue will be fixed with the CPyCppyy upgrade. This makes total sense, because the upgrade includes a patch that fixes the conversion of initializer lists:. https://github.com/wlav/CPyCppyy/pull/14",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11411
https://github.com/root-project/root/issues/11411:79,interoperability,platform,platforms,79,"New insights:. * when adding the reproducer to `roottest`, most of the Jenkins platforms will fail:. https://github.com/root-project/roottest/pull/1052. * when testing the reproducer together with the CPyCppyy upgrade, the test `projectroot.roottest.python.cpp.roottest_python_cpp_cpp11` will instead pass on all platforms:. https://github.com/root-project/roottest/pull/1071. (note that there are other failures related to the CPyCppyy upgrade that are unrelated to the issue). Therefore, I can attest that this issue will be fixed with the CPyCppyy upgrade. This makes total sense, because the upgrade includes a patch that fixes the conversion of initializer lists:. https://github.com/wlav/CPyCppyy/pull/14",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11411
https://github.com/root-project/root/issues/11411:313,interoperability,platform,platforms,313,"New insights:. * when adding the reproducer to `roottest`, most of the Jenkins platforms will fail:. https://github.com/root-project/roottest/pull/1052. * when testing the reproducer together with the CPyCppyy upgrade, the test `projectroot.roottest.python.cpp.roottest_python_cpp_cpp11` will instead pass on all platforms:. https://github.com/root-project/roottest/pull/1071. (note that there are other failures related to the CPyCppyy upgrade that are unrelated to the issue). Therefore, I can attest that this issue will be fixed with the CPyCppyy upgrade. This makes total sense, because the upgrade includes a patch that fixes the conversion of initializer lists:. https://github.com/wlav/CPyCppyy/pull/14",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11411
https://github.com/root-project/root/issues/11411:636,interoperability,convers,conversion,636,"New insights:. * when adding the reproducer to `roottest`, most of the Jenkins platforms will fail:. https://github.com/root-project/roottest/pull/1052. * when testing the reproducer together with the CPyCppyy upgrade, the test `projectroot.roottest.python.cpp.roottest_python_cpp_cpp11` will instead pass on all platforms:. https://github.com/root-project/roottest/pull/1071. (note that there are other failures related to the CPyCppyy upgrade that are unrelated to the issue). Therefore, I can attest that this issue will be fixed with the CPyCppyy upgrade. This makes total sense, because the upgrade includes a patch that fixes the conversion of initializer lists:. https://github.com/wlav/CPyCppyy/pull/14",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11411
https://github.com/root-project/root/issues/11411:210,modifiability,upgrad,upgrade,210,"New insights:. * when adding the reproducer to `roottest`, most of the Jenkins platforms will fail:. https://github.com/root-project/roottest/pull/1052. * when testing the reproducer together with the CPyCppyy upgrade, the test `projectroot.roottest.python.cpp.roottest_python_cpp_cpp11` will instead pass on all platforms:. https://github.com/root-project/roottest/pull/1071. (note that there are other failures related to the CPyCppyy upgrade that are unrelated to the issue). Therefore, I can attest that this issue will be fixed with the CPyCppyy upgrade. This makes total sense, because the upgrade includes a patch that fixes the conversion of initializer lists:. https://github.com/wlav/CPyCppyy/pull/14",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11411
https://github.com/root-project/root/issues/11411:437,modifiability,upgrad,upgrade,437,"New insights:. * when adding the reproducer to `roottest`, most of the Jenkins platforms will fail:. https://github.com/root-project/roottest/pull/1052. * when testing the reproducer together with the CPyCppyy upgrade, the test `projectroot.roottest.python.cpp.roottest_python_cpp_cpp11` will instead pass on all platforms:. https://github.com/root-project/roottest/pull/1071. (note that there are other failures related to the CPyCppyy upgrade that are unrelated to the issue). Therefore, I can attest that this issue will be fixed with the CPyCppyy upgrade. This makes total sense, because the upgrade includes a patch that fixes the conversion of initializer lists:. https://github.com/wlav/CPyCppyy/pull/14",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11411
https://github.com/root-project/root/issues/11411:551,modifiability,upgrad,upgrade,551,"New insights:. * when adding the reproducer to `roottest`, most of the Jenkins platforms will fail:. https://github.com/root-project/roottest/pull/1052. * when testing the reproducer together with the CPyCppyy upgrade, the test `projectroot.roottest.python.cpp.roottest_python_cpp_cpp11` will instead pass on all platforms:. https://github.com/root-project/roottest/pull/1071. (note that there are other failures related to the CPyCppyy upgrade that are unrelated to the issue). Therefore, I can attest that this issue will be fixed with the CPyCppyy upgrade. This makes total sense, because the upgrade includes a patch that fixes the conversion of initializer lists:. https://github.com/wlav/CPyCppyy/pull/14",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11411
https://github.com/root-project/root/issues/11411:596,modifiability,upgrad,upgrade,596,"New insights:. * when adding the reproducer to `roottest`, most of the Jenkins platforms will fail:. https://github.com/root-project/roottest/pull/1052. * when testing the reproducer together with the CPyCppyy upgrade, the test `projectroot.roottest.python.cpp.roottest_python_cpp_cpp11` will instead pass on all platforms:. https://github.com/root-project/roottest/pull/1071. (note that there are other failures related to the CPyCppyy upgrade that are unrelated to the issue). Therefore, I can attest that this issue will be fixed with the CPyCppyy upgrade. This makes total sense, because the upgrade includes a patch that fixes the conversion of initializer lists:. https://github.com/wlav/CPyCppyy/pull/14",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11411
https://github.com/root-project/root/issues/11411:404,performance,failur,failures,404,"New insights:. * when adding the reproducer to `roottest`, most of the Jenkins platforms will fail:. https://github.com/root-project/roottest/pull/1052. * when testing the reproducer together with the CPyCppyy upgrade, the test `projectroot.roottest.python.cpp.roottest_python_cpp_cpp11` will instead pass on all platforms:. https://github.com/root-project/roottest/pull/1071. (note that there are other failures related to the CPyCppyy upgrade that are unrelated to the issue). Therefore, I can attest that this issue will be fixed with the CPyCppyy upgrade. This makes total sense, because the upgrade includes a patch that fixes the conversion of initializer lists:. https://github.com/wlav/CPyCppyy/pull/14",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11411
https://github.com/root-project/root/issues/11411:94,reliability,fail,fail,94,"New insights:. * when adding the reproducer to `roottest`, most of the Jenkins platforms will fail:. https://github.com/root-project/roottest/pull/1052. * when testing the reproducer together with the CPyCppyy upgrade, the test `projectroot.roottest.python.cpp.roottest_python_cpp_cpp11` will instead pass on all platforms:. https://github.com/root-project/roottest/pull/1071. (note that there are other failures related to the CPyCppyy upgrade that are unrelated to the issue). Therefore, I can attest that this issue will be fixed with the CPyCppyy upgrade. This makes total sense, because the upgrade includes a patch that fixes the conversion of initializer lists:. https://github.com/wlav/CPyCppyy/pull/14",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11411
https://github.com/root-project/root/issues/11411:404,reliability,fail,failures,404,"New insights:. * when adding the reproducer to `roottest`, most of the Jenkins platforms will fail:. https://github.com/root-project/roottest/pull/1052. * when testing the reproducer together with the CPyCppyy upgrade, the test `projectroot.roottest.python.cpp.roottest_python_cpp_cpp11` will instead pass on all platforms:. https://github.com/root-project/roottest/pull/1071. (note that there are other failures related to the CPyCppyy upgrade that are unrelated to the issue). Therefore, I can attest that this issue will be fixed with the CPyCppyy upgrade. This makes total sense, because the upgrade includes a patch that fixes the conversion of initializer lists:. https://github.com/wlav/CPyCppyy/pull/14",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11411
https://github.com/root-project/root/issues/11411:160,safety,test,testing,160,"New insights:. * when adding the reproducer to `roottest`, most of the Jenkins platforms will fail:. https://github.com/root-project/roottest/pull/1052. * when testing the reproducer together with the CPyCppyy upgrade, the test `projectroot.roottest.python.cpp.roottest_python_cpp_cpp11` will instead pass on all platforms:. https://github.com/root-project/roottest/pull/1071. (note that there are other failures related to the CPyCppyy upgrade that are unrelated to the issue). Therefore, I can attest that this issue will be fixed with the CPyCppyy upgrade. This makes total sense, because the upgrade includes a patch that fixes the conversion of initializer lists:. https://github.com/wlav/CPyCppyy/pull/14",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11411
https://github.com/root-project/root/issues/11411:223,safety,test,test,223,"New insights:. * when adding the reproducer to `roottest`, most of the Jenkins platforms will fail:. https://github.com/root-project/roottest/pull/1052. * when testing the reproducer together with the CPyCppyy upgrade, the test `projectroot.roottest.python.cpp.roottest_python_cpp_cpp11` will instead pass on all platforms:. https://github.com/root-project/roottest/pull/1071. (note that there are other failures related to the CPyCppyy upgrade that are unrelated to the issue). Therefore, I can attest that this issue will be fixed with the CPyCppyy upgrade. This makes total sense, because the upgrade includes a patch that fixes the conversion of initializer lists:. https://github.com/wlav/CPyCppyy/pull/14",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11411
https://github.com/root-project/root/issues/11411:615,safety,patch,patch,615,"New insights:. * when adding the reproducer to `roottest`, most of the Jenkins platforms will fail:. https://github.com/root-project/roottest/pull/1052. * when testing the reproducer together with the CPyCppyy upgrade, the test `projectroot.roottest.python.cpp.roottest_python_cpp_cpp11` will instead pass on all platforms:. https://github.com/root-project/roottest/pull/1071. (note that there are other failures related to the CPyCppyy upgrade that are unrelated to the issue). Therefore, I can attest that this issue will be fixed with the CPyCppyy upgrade. This makes total sense, because the upgrade includes a patch that fixes the conversion of initializer lists:. https://github.com/wlav/CPyCppyy/pull/14",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11411
https://github.com/root-project/root/issues/11411:496,security,attest,attest,496,"New insights:. * when adding the reproducer to `roottest`, most of the Jenkins platforms will fail:. https://github.com/root-project/roottest/pull/1052. * when testing the reproducer together with the CPyCppyy upgrade, the test `projectroot.roottest.python.cpp.roottest_python_cpp_cpp11` will instead pass on all platforms:. https://github.com/root-project/roottest/pull/1071. (note that there are other failures related to the CPyCppyy upgrade that are unrelated to the issue). Therefore, I can attest that this issue will be fixed with the CPyCppyy upgrade. This makes total sense, because the upgrade includes a patch that fixes the conversion of initializer lists:. https://github.com/wlav/CPyCppyy/pull/14",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11411
https://github.com/root-project/root/issues/11411:615,security,patch,patch,615,"New insights:. * when adding the reproducer to `roottest`, most of the Jenkins platforms will fail:. https://github.com/root-project/roottest/pull/1052. * when testing the reproducer together with the CPyCppyy upgrade, the test `projectroot.roottest.python.cpp.roottest_python_cpp_cpp11` will instead pass on all platforms:. https://github.com/root-project/roottest/pull/1071. (note that there are other failures related to the CPyCppyy upgrade that are unrelated to the issue). Therefore, I can attest that this issue will be fixed with the CPyCppyy upgrade. This makes total sense, because the upgrade includes a patch that fixes the conversion of initializer lists:. https://github.com/wlav/CPyCppyy/pull/14",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11411
https://github.com/root-project/root/issues/11411:160,testability,test,testing,160,"New insights:. * when adding the reproducer to `roottest`, most of the Jenkins platforms will fail:. https://github.com/root-project/roottest/pull/1052. * when testing the reproducer together with the CPyCppyy upgrade, the test `projectroot.roottest.python.cpp.roottest_python_cpp_cpp11` will instead pass on all platforms:. https://github.com/root-project/roottest/pull/1071. (note that there are other failures related to the CPyCppyy upgrade that are unrelated to the issue). Therefore, I can attest that this issue will be fixed with the CPyCppyy upgrade. This makes total sense, because the upgrade includes a patch that fixes the conversion of initializer lists:. https://github.com/wlav/CPyCppyy/pull/14",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11411
https://github.com/root-project/root/issues/11411:223,testability,test,test,223,"New insights:. * when adding the reproducer to `roottest`, most of the Jenkins platforms will fail:. https://github.com/root-project/roottest/pull/1052. * when testing the reproducer together with the CPyCppyy upgrade, the test `projectroot.roottest.python.cpp.roottest_python_cpp_cpp11` will instead pass on all platforms:. https://github.com/root-project/roottest/pull/1071. (note that there are other failures related to the CPyCppyy upgrade that are unrelated to the issue). Therefore, I can attest that this issue will be fixed with the CPyCppyy upgrade. This makes total sense, because the upgrade includes a patch that fixes the conversion of initializer lists:. https://github.com/wlav/CPyCppyy/pull/14",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11411
https://github.com/root-project/root/pull/11412:88,deployability,fail,fail,88,@vepadulano Can you check why this seemingly straightforward change is making some test fail?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11412
https://github.com/root-project/root/pull/11412:88,reliability,fail,fail,88,@vepadulano Can you check why this seemingly straightforward change is making some test fail?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11412
https://github.com/root-project/root/pull/11412:83,safety,test,test,83,@vepadulano Can you check why this seemingly straightforward change is making some test fail?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11412
https://github.com/root-project/root/pull/11412:83,testability,test,test,83,@vepadulano Can you check why this seemingly straightforward change is making some test fail?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11412
https://github.com/root-project/root/pull/11412:80,deployability,patch,patch,80,"Revamp the tests. Adding in the loop @aaronj0 and @guitargeek , since this is a patch to Cppyy.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11412
https://github.com/root-project/root/pull/11412:11,safety,test,tests,11,"Revamp the tests. Adding in the loop @aaronj0 and @guitargeek , since this is a patch to Cppyy.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11412
https://github.com/root-project/root/pull/11412:80,safety,patch,patch,80,"Revamp the tests. Adding in the loop @aaronj0 and @guitargeek , since this is a patch to Cppyy.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11412
https://github.com/root-project/root/pull/11412:80,security,patch,patch,80,"Revamp the tests. Adding in the loop @aaronj0 and @guitargeek , since this is a patch to Cppyy.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11412
https://github.com/root-project/root/pull/11412:11,testability,test,tests,11,"Revamp the tests. Adding in the loop @aaronj0 and @guitargeek , since this is a patch to Cppyy.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11412
https://github.com/root-project/root/pull/11415:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2204/default, ROOT-ubuntu18.04/default with flags -Dtmva-sofie=On",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11415
https://github.com/root-project/root/pull/11415:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2204/default, ROOT-ubuntu2004/default, ROOT-ubuntu18.04/default",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11415
https://github.com/root-project/root/pull/11415:102,availability,operat,operator,102,"> Thank you for this improvement. It would be nice to have a test of broadcasting , for example using operator Add ? I added some tests in this commit https://github.com/root-project/root/pull/11415/commits/3ddd5c51ebe5cef2a3b73220cb6e56539726e6bd",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11415
https://github.com/root-project/root/pull/11415:61,safety,test,test,61,"> Thank you for this improvement. It would be nice to have a test of broadcasting , for example using operator Add ? I added some tests in this commit https://github.com/root-project/root/pull/11415/commits/3ddd5c51ebe5cef2a3b73220cb6e56539726e6bd",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11415
https://github.com/root-project/root/pull/11415:130,safety,test,tests,130,"> Thank you for this improvement. It would be nice to have a test of broadcasting , for example using operator Add ? I added some tests in this commit https://github.com/root-project/root/pull/11415/commits/3ddd5c51ebe5cef2a3b73220cb6e56539726e6bd",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11415
https://github.com/root-project/root/pull/11415:61,testability,test,test,61,"> Thank you for this improvement. It would be nice to have a test of broadcasting , for example using operator Add ? I added some tests in this commit https://github.com/root-project/root/pull/11415/commits/3ddd5c51ebe5cef2a3b73220cb6e56539726e6bd",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11415
https://github.com/root-project/root/pull/11415:130,testability,test,tests,130,"> Thank you for this improvement. It would be nice to have a test of broadcasting , for example using operator Add ? I added some tests in this commit https://github.com/root-project/root/pull/11415/commits/3ddd5c51ebe5cef2a3b73220cb6e56539726e6bd",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11415
https://github.com/root-project/root/pull/11415:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2204/default, ROOT-ubuntu2004/default, ROOT-ubuntu18.04/nortcxxmod",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11415
https://github.com/root-project/root/pull/11415:11,deployability,build,build,11,@phsft-bot build just on ROOT-ubuntu2004/default,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11415
https://github.com/root-project/root/issues/11421:296,energy efficiency,power,power,296,"Hi, thanks for reporting this and trying out the new pythonizations! I guess you also know about `to/from_numpy/pandas`, which is quite useful too I think. This RooArgSet issue is known, I just didn't fix it for all the command arguments yet. But I will do it know. Since you seem to be a RooFit power use I wanted to ask you: do you have any suggestions for further Pythonizations or PyROOT-exclusive RooFit features?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11421
https://github.com/root-project/root/issues/11421:220,usability,command,command,220,"Hi, thanks for reporting this and trying out the new pythonizations! I guess you also know about `to/from_numpy/pandas`, which is quite useful too I think. This RooArgSet issue is known, I just didn't fix it for all the command arguments yet. But I will do it know. Since you seem to be a RooFit power use I wanted to ask you: do you have any suggestions for further Pythonizations or PyROOT-exclusive RooFit features?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11421
https://github.com/root-project/root/issues/11421:102,deployability,fail,failing,102,"Hi, I thought this had been fixed with the addition of `RooCmdArg::take` (which _is_ used even in the failing arguments), so this seemed to be a new bug. I know about the numpy/pandas conversion, but I have not tried them yet as my analysis is TTree based. . While I can be considered a RooFit power user, I don't have that much experience with its PyROOT bindings. I started using RooFit from PyROOT only relatively recently, because especially in ROOT 6.26 it's much nicer. From my experience now:. - sometimes I would have found useful to be able to pass python number anywhere a `RooAbsReal` is required, although I suspect this may require a pythonization for each pdf. - `RooSimultaneous` map constructor does not accept a python dictionary yet. - one thing that surprised me a couple of times at the beginning is that `RooAbsArg` does not keep its servers alive from the python GC so you actually need the same workarounds as in C++ (importing frequently to a workspace). However, I suspect that if they did keep servers alive, server redirection would likely lead to desync between the C++ and python views of the graph.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11421
https://github.com/root-project/root/issues/11421:294,energy efficiency,power,power,294,"Hi, I thought this had been fixed with the addition of `RooCmdArg::take` (which _is_ used even in the failing arguments), so this seemed to be a new bug. I know about the numpy/pandas conversion, but I have not tried them yet as my analysis is TTree based. . While I can be considered a RooFit power user, I don't have that much experience with its PyROOT bindings. I started using RooFit from PyROOT only relatively recently, because especially in ROOT 6.26 it's much nicer. From my experience now:. - sometimes I would have found useful to be able to pass python number anywhere a `RooAbsReal` is required, although I suspect this may require a pythonization for each pdf. - `RooSimultaneous` map constructor does not accept a python dictionary yet. - one thing that surprised me a couple of times at the beginning is that `RooAbsArg` does not keep its servers alive from the python GC so you actually need the same workarounds as in C++ (importing frequently to a workspace). However, I suspect that if they did keep servers alive, server redirection would likely lead to desync between the C++ and python views of the graph.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11421
https://github.com/root-project/root/issues/11421:784,integrability,coupl,couple,784,"Hi, I thought this had been fixed with the addition of `RooCmdArg::take` (which _is_ used even in the failing arguments), so this seemed to be a new bug. I know about the numpy/pandas conversion, but I have not tried them yet as my analysis is TTree based. . While I can be considered a RooFit power user, I don't have that much experience with its PyROOT bindings. I started using RooFit from PyROOT only relatively recently, because especially in ROOT 6.26 it's much nicer. From my experience now:. - sometimes I would have found useful to be able to pass python number anywhere a `RooAbsReal` is required, although I suspect this may require a pythonization for each pdf. - `RooSimultaneous` map constructor does not accept a python dictionary yet. - one thing that surprised me a couple of times at the beginning is that `RooAbsArg` does not keep its servers alive from the python GC so you actually need the same workarounds as in C++ (importing frequently to a workspace). However, I suspect that if they did keep servers alive, server redirection would likely lead to desync between the C++ and python views of the graph.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11421
https://github.com/root-project/root/issues/11421:184,interoperability,convers,conversion,184,"Hi, I thought this had been fixed with the addition of `RooCmdArg::take` (which _is_ used even in the failing arguments), so this seemed to be a new bug. I know about the numpy/pandas conversion, but I have not tried them yet as my analysis is TTree based. . While I can be considered a RooFit power user, I don't have that much experience with its PyROOT bindings. I started using RooFit from PyROOT only relatively recently, because especially in ROOT 6.26 it's much nicer. From my experience now:. - sometimes I would have found useful to be able to pass python number anywhere a `RooAbsReal` is required, although I suspect this may require a pythonization for each pdf. - `RooSimultaneous` map constructor does not accept a python dictionary yet. - one thing that surprised me a couple of times at the beginning is that `RooAbsArg` does not keep its servers alive from the python GC so you actually need the same workarounds as in C++ (importing frequently to a workspace). However, I suspect that if they did keep servers alive, server redirection would likely lead to desync between the C++ and python views of the graph.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11421
https://github.com/root-project/root/issues/11421:356,interoperability,bind,bindings,356,"Hi, I thought this had been fixed with the addition of `RooCmdArg::take` (which _is_ used even in the failing arguments), so this seemed to be a new bug. I know about the numpy/pandas conversion, but I have not tried them yet as my analysis is TTree based. . While I can be considered a RooFit power user, I don't have that much experience with its PyROOT bindings. I started using RooFit from PyROOT only relatively recently, because especially in ROOT 6.26 it's much nicer. From my experience now:. - sometimes I would have found useful to be able to pass python number anywhere a `RooAbsReal` is required, although I suspect this may require a pythonization for each pdf. - `RooSimultaneous` map constructor does not accept a python dictionary yet. - one thing that surprised me a couple of times at the beginning is that `RooAbsArg` does not keep its servers alive from the python GC so you actually need the same workarounds as in C++ (importing frequently to a workspace). However, I suspect that if they did keep servers alive, server redirection would likely lead to desync between the C++ and python views of the graph.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11421
https://github.com/root-project/root/issues/11421:356,modifiability,bind,bindings,356,"Hi, I thought this had been fixed with the addition of `RooCmdArg::take` (which _is_ used even in the failing arguments), so this seemed to be a new bug. I know about the numpy/pandas conversion, but I have not tried them yet as my analysis is TTree based. . While I can be considered a RooFit power user, I don't have that much experience with its PyROOT bindings. I started using RooFit from PyROOT only relatively recently, because especially in ROOT 6.26 it's much nicer. From my experience now:. - sometimes I would have found useful to be able to pass python number anywhere a `RooAbsReal` is required, although I suspect this may require a pythonization for each pdf. - `RooSimultaneous` map constructor does not accept a python dictionary yet. - one thing that surprised me a couple of times at the beginning is that `RooAbsArg` does not keep its servers alive from the python GC so you actually need the same workarounds as in C++ (importing frequently to a workspace). However, I suspect that if they did keep servers alive, server redirection would likely lead to desync between the C++ and python views of the graph.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11421
https://github.com/root-project/root/issues/11421:784,modifiability,coupl,couple,784,"Hi, I thought this had been fixed with the addition of `RooCmdArg::take` (which _is_ used even in the failing arguments), so this seemed to be a new bug. I know about the numpy/pandas conversion, but I have not tried them yet as my analysis is TTree based. . While I can be considered a RooFit power user, I don't have that much experience with its PyROOT bindings. I started using RooFit from PyROOT only relatively recently, because especially in ROOT 6.26 it's much nicer. From my experience now:. - sometimes I would have found useful to be able to pass python number anywhere a `RooAbsReal` is required, although I suspect this may require a pythonization for each pdf. - `RooSimultaneous` map constructor does not accept a python dictionary yet. - one thing that surprised me a couple of times at the beginning is that `RooAbsArg` does not keep its servers alive from the python GC so you actually need the same workarounds as in C++ (importing frequently to a workspace). However, I suspect that if they did keep servers alive, server redirection would likely lead to desync between the C++ and python views of the graph.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11421
https://github.com/root-project/root/issues/11421:794,performance,time,times,794,"Hi, I thought this had been fixed with the addition of `RooCmdArg::take` (which _is_ used even in the failing arguments), so this seemed to be a new bug. I know about the numpy/pandas conversion, but I have not tried them yet as my analysis is TTree based. . While I can be considered a RooFit power user, I don't have that much experience with its PyROOT bindings. I started using RooFit from PyROOT only relatively recently, because especially in ROOT 6.26 it's much nicer. From my experience now:. - sometimes I would have found useful to be able to pass python number anywhere a `RooAbsReal` is required, although I suspect this may require a pythonization for each pdf. - `RooSimultaneous` map constructor does not accept a python dictionary yet. - one thing that surprised me a couple of times at the beginning is that `RooAbsArg` does not keep its servers alive from the python GC so you actually need the same workarounds as in C++ (importing frequently to a workspace). However, I suspect that if they did keep servers alive, server redirection would likely lead to desync between the C++ and python views of the graph.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11421
https://github.com/root-project/root/issues/11421:102,reliability,fail,failing,102,"Hi, I thought this had been fixed with the addition of `RooCmdArg::take` (which _is_ used even in the failing arguments), so this seemed to be a new bug. I know about the numpy/pandas conversion, but I have not tried them yet as my analysis is TTree based. . While I can be considered a RooFit power user, I don't have that much experience with its PyROOT bindings. I started using RooFit from PyROOT only relatively recently, because especially in ROOT 6.26 it's much nicer. From my experience now:. - sometimes I would have found useful to be able to pass python number anywhere a `RooAbsReal` is required, although I suspect this may require a pythonization for each pdf. - `RooSimultaneous` map constructor does not accept a python dictionary yet. - one thing that surprised me a couple of times at the beginning is that `RooAbsArg` does not keep its servers alive from the python GC so you actually need the same workarounds as in C++ (importing frequently to a workspace). However, I suspect that if they did keep servers alive, server redirection would likely lead to desync between the C++ and python views of the graph.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11421
https://github.com/root-project/root/issues/11421:711,reliability,doe,does,711,"Hi, I thought this had been fixed with the addition of `RooCmdArg::take` (which _is_ used even in the failing arguments), so this seemed to be a new bug. I know about the numpy/pandas conversion, but I have not tried them yet as my analysis is TTree based. . While I can be considered a RooFit power user, I don't have that much experience with its PyROOT bindings. I started using RooFit from PyROOT only relatively recently, because especially in ROOT 6.26 it's much nicer. From my experience now:. - sometimes I would have found useful to be able to pass python number anywhere a `RooAbsReal` is required, although I suspect this may require a pythonization for each pdf. - `RooSimultaneous` map constructor does not accept a python dictionary yet. - one thing that surprised me a couple of times at the beginning is that `RooAbsArg` does not keep its servers alive from the python GC so you actually need the same workarounds as in C++ (importing frequently to a workspace). However, I suspect that if they did keep servers alive, server redirection would likely lead to desync between the C++ and python views of the graph.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11421
https://github.com/root-project/root/issues/11421:837,reliability,doe,does,837,"Hi, I thought this had been fixed with the addition of `RooCmdArg::take` (which _is_ used even in the failing arguments), so this seemed to be a new bug. I know about the numpy/pandas conversion, but I have not tried them yet as my analysis is TTree based. . While I can be considered a RooFit power user, I don't have that much experience with its PyROOT bindings. I started using RooFit from PyROOT only relatively recently, because especially in ROOT 6.26 it's much nicer. From my experience now:. - sometimes I would have found useful to be able to pass python number anywhere a `RooAbsReal` is required, although I suspect this may require a pythonization for each pdf. - `RooSimultaneous` map constructor does not accept a python dictionary yet. - one thing that surprised me a couple of times at the beginning is that `RooAbsArg` does not keep its servers alive from the python GC so you actually need the same workarounds as in C++ (importing frequently to a workspace). However, I suspect that if they did keep servers alive, server redirection would likely lead to desync between the C++ and python views of the graph.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11421
https://github.com/root-project/root/issues/11421:784,testability,coupl,couple,784,"Hi, I thought this had been fixed with the addition of `RooCmdArg::take` (which _is_ used even in the failing arguments), so this seemed to be a new bug. I know about the numpy/pandas conversion, but I have not tried them yet as my analysis is TTree based. . While I can be considered a RooFit power user, I don't have that much experience with its PyROOT bindings. I started using RooFit from PyROOT only relatively recently, because especially in ROOT 6.26 it's much nicer. From my experience now:. - sometimes I would have found useful to be able to pass python number anywhere a `RooAbsReal` is required, although I suspect this may require a pythonization for each pdf. - `RooSimultaneous` map constructor does not accept a python dictionary yet. - one thing that surprised me a couple of times at the beginning is that `RooAbsArg` does not keep its servers alive from the python GC so you actually need the same workarounds as in C++ (importing frequently to a workspace). However, I suspect that if they did keep servers alive, server redirection would likely lead to desync between the C++ and python views of the graph.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11421
https://github.com/root-project/root/issues/11421:300,usability,user,user,300,"Hi, I thought this had been fixed with the addition of `RooCmdArg::take` (which _is_ used even in the failing arguments), so this seemed to be a new bug. I know about the numpy/pandas conversion, but I have not tried them yet as my analysis is TTree based. . While I can be considered a RooFit power user, I don't have that much experience with its PyROOT bindings. I started using RooFit from PyROOT only relatively recently, because especially in ROOT 6.26 it's much nicer. From my experience now:. - sometimes I would have found useful to be able to pass python number anywhere a `RooAbsReal` is required, although I suspect this may require a pythonization for each pdf. - `RooSimultaneous` map constructor does not accept a python dictionary yet. - one thing that surprised me a couple of times at the beginning is that `RooAbsArg` does not keep its servers alive from the python GC so you actually need the same workarounds as in C++ (importing frequently to a workspace). However, I suspect that if they did keep servers alive, server redirection would likely lead to desync between the C++ and python views of the graph.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11421
https://github.com/root-project/root/issues/11421:329,usability,experien,experience,329,"Hi, I thought this had been fixed with the addition of `RooCmdArg::take` (which _is_ used even in the failing arguments), so this seemed to be a new bug. I know about the numpy/pandas conversion, but I have not tried them yet as my analysis is TTree based. . While I can be considered a RooFit power user, I don't have that much experience with its PyROOT bindings. I started using RooFit from PyROOT only relatively recently, because especially in ROOT 6.26 it's much nicer. From my experience now:. - sometimes I would have found useful to be able to pass python number anywhere a `RooAbsReal` is required, although I suspect this may require a pythonization for each pdf. - `RooSimultaneous` map constructor does not accept a python dictionary yet. - one thing that surprised me a couple of times at the beginning is that `RooAbsArg` does not keep its servers alive from the python GC so you actually need the same workarounds as in C++ (importing frequently to a workspace). However, I suspect that if they did keep servers alive, server redirection would likely lead to desync between the C++ and python views of the graph.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11421
https://github.com/root-project/root/issues/11421:484,usability,experien,experience,484,"Hi, I thought this had been fixed with the addition of `RooCmdArg::take` (which _is_ used even in the failing arguments), so this seemed to be a new bug. I know about the numpy/pandas conversion, but I have not tried them yet as my analysis is TTree based. . While I can be considered a RooFit power user, I don't have that much experience with its PyROOT bindings. I started using RooFit from PyROOT only relatively recently, because especially in ROOT 6.26 it's much nicer. From my experience now:. - sometimes I would have found useful to be able to pass python number anywhere a `RooAbsReal` is required, although I suspect this may require a pythonization for each pdf. - `RooSimultaneous` map constructor does not accept a python dictionary yet. - one thing that surprised me a couple of times at the beginning is that `RooAbsArg` does not keep its servers alive from the python GC so you actually need the same workarounds as in C++ (importing frequently to a workspace). However, I suspect that if they did keep servers alive, server redirection would likely lead to desync between the C++ and python views of the graph.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11421
https://github.com/root-project/root/issues/11421:551,integrability,coupl,couple,551,"Thanks a lot for your comment! > * sometimes I would have found useful to be able to pass python number anywhere a RooAbsReal is required, although I suspect this may require a pythonization for each pdf. Yes, I would like this too, but it's technically not easy to implement without changing the source for all PDFs. Maybe I will have an idea at some point as I learn more about PyROOT, but for now I have none. > * `RooSimultaneous` map constructor does not accept a python dictionary yet. That's a very good idea! > * one thing that surprised me a couple of times at the beginning is that `RooAbsArg` does not keep its servers alive from the python GC so you actually need the same workarounds as in C++ (importing frequently to a workspace). However, I suspect that if they did keep servers alive, server redirection would likely lead to desync between the C++ and python views of the graph. That's a pretty good idea too. I guess one can simply create new Python references to each server that are set as an attribute of the server, such that they are always kept alive. But you're right, server redirection would break this, unless there are Pythonizations for that one too.... So I still need to think if this is worth it, also considering that users can also use the RooWorkspace factory interface to create PDFs, which doesn't have this problem.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11421
https://github.com/root-project/root/issues/11421:1296,integrability,interfac,interface,1296,"Thanks a lot for your comment! > * sometimes I would have found useful to be able to pass python number anywhere a RooAbsReal is required, although I suspect this may require a pythonization for each pdf. Yes, I would like this too, but it's technically not easy to implement without changing the source for all PDFs. Maybe I will have an idea at some point as I learn more about PyROOT, but for now I have none. > * `RooSimultaneous` map constructor does not accept a python dictionary yet. That's a very good idea! > * one thing that surprised me a couple of times at the beginning is that `RooAbsArg` does not keep its servers alive from the python GC so you actually need the same workarounds as in C++ (importing frequently to a workspace). However, I suspect that if they did keep servers alive, server redirection would likely lead to desync between the C++ and python views of the graph. That's a pretty good idea too. I guess one can simply create new Python references to each server that are set as an attribute of the server, such that they are always kept alive. But you're right, server redirection would break this, unless there are Pythonizations for that one too.... So I still need to think if this is worth it, also considering that users can also use the RooWorkspace factory interface to create PDFs, which doesn't have this problem.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11421
https://github.com/root-project/root/issues/11421:1296,interoperability,interfac,interface,1296,"Thanks a lot for your comment! > * sometimes I would have found useful to be able to pass python number anywhere a RooAbsReal is required, although I suspect this may require a pythonization for each pdf. Yes, I would like this too, but it's technically not easy to implement without changing the source for all PDFs. Maybe I will have an idea at some point as I learn more about PyROOT, but for now I have none. > * `RooSimultaneous` map constructor does not accept a python dictionary yet. That's a very good idea! > * one thing that surprised me a couple of times at the beginning is that `RooAbsArg` does not keep its servers alive from the python GC so you actually need the same workarounds as in C++ (importing frequently to a workspace). However, I suspect that if they did keep servers alive, server redirection would likely lead to desync between the C++ and python views of the graph. That's a pretty good idea too. I guess one can simply create new Python references to each server that are set as an attribute of the server, such that they are always kept alive. But you're right, server redirection would break this, unless there are Pythonizations for that one too.... So I still need to think if this is worth it, also considering that users can also use the RooWorkspace factory interface to create PDFs, which doesn't have this problem.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11421
https://github.com/root-project/root/issues/11421:551,modifiability,coupl,couple,551,"Thanks a lot for your comment! > * sometimes I would have found useful to be able to pass python number anywhere a RooAbsReal is required, although I suspect this may require a pythonization for each pdf. Yes, I would like this too, but it's technically not easy to implement without changing the source for all PDFs. Maybe I will have an idea at some point as I learn more about PyROOT, but for now I have none. > * `RooSimultaneous` map constructor does not accept a python dictionary yet. That's a very good idea! > * one thing that surprised me a couple of times at the beginning is that `RooAbsArg` does not keep its servers alive from the python GC so you actually need the same workarounds as in C++ (importing frequently to a workspace). However, I suspect that if they did keep servers alive, server redirection would likely lead to desync between the C++ and python views of the graph. That's a pretty good idea too. I guess one can simply create new Python references to each server that are set as an attribute of the server, such that they are always kept alive. But you're right, server redirection would break this, unless there are Pythonizations for that one too.... So I still need to think if this is worth it, also considering that users can also use the RooWorkspace factory interface to create PDFs, which doesn't have this problem.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11421
https://github.com/root-project/root/issues/11421:1296,modifiability,interfac,interface,1296,"Thanks a lot for your comment! > * sometimes I would have found useful to be able to pass python number anywhere a RooAbsReal is required, although I suspect this may require a pythonization for each pdf. Yes, I would like this too, but it's technically not easy to implement without changing the source for all PDFs. Maybe I will have an idea at some point as I learn more about PyROOT, but for now I have none. > * `RooSimultaneous` map constructor does not accept a python dictionary yet. That's a very good idea! > * one thing that surprised me a couple of times at the beginning is that `RooAbsArg` does not keep its servers alive from the python GC so you actually need the same workarounds as in C++ (importing frequently to a workspace). However, I suspect that if they did keep servers alive, server redirection would likely lead to desync between the C++ and python views of the graph. That's a pretty good idea too. I guess one can simply create new Python references to each server that are set as an attribute of the server, such that they are always kept alive. But you're right, server redirection would break this, unless there are Pythonizations for that one too.... So I still need to think if this is worth it, also considering that users can also use the RooWorkspace factory interface to create PDFs, which doesn't have this problem.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11421
https://github.com/root-project/root/issues/11421:561,performance,time,times,561,"Thanks a lot for your comment! > * sometimes I would have found useful to be able to pass python number anywhere a RooAbsReal is required, although I suspect this may require a pythonization for each pdf. Yes, I would like this too, but it's technically not easy to implement without changing the source for all PDFs. Maybe I will have an idea at some point as I learn more about PyROOT, but for now I have none. > * `RooSimultaneous` map constructor does not accept a python dictionary yet. That's a very good idea! > * one thing that surprised me a couple of times at the beginning is that `RooAbsArg` does not keep its servers alive from the python GC so you actually need the same workarounds as in C++ (importing frequently to a workspace). However, I suspect that if they did keep servers alive, server redirection would likely lead to desync between the C++ and python views of the graph. That's a pretty good idea too. I guess one can simply create new Python references to each server that are set as an attribute of the server, such that they are always kept alive. But you're right, server redirection would break this, unless there are Pythonizations for that one too.... So I still need to think if this is worth it, also considering that users can also use the RooWorkspace factory interface to create PDFs, which doesn't have this problem.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11421
https://github.com/root-project/root/issues/11421:451,reliability,doe,does,451,"Thanks a lot for your comment! > * sometimes I would have found useful to be able to pass python number anywhere a RooAbsReal is required, although I suspect this may require a pythonization for each pdf. Yes, I would like this too, but it's technically not easy to implement without changing the source for all PDFs. Maybe I will have an idea at some point as I learn more about PyROOT, but for now I have none. > * `RooSimultaneous` map constructor does not accept a python dictionary yet. That's a very good idea! > * one thing that surprised me a couple of times at the beginning is that `RooAbsArg` does not keep its servers alive from the python GC so you actually need the same workarounds as in C++ (importing frequently to a workspace). However, I suspect that if they did keep servers alive, server redirection would likely lead to desync between the C++ and python views of the graph. That's a pretty good idea too. I guess one can simply create new Python references to each server that are set as an attribute of the server, such that they are always kept alive. But you're right, server redirection would break this, unless there are Pythonizations for that one too.... So I still need to think if this is worth it, also considering that users can also use the RooWorkspace factory interface to create PDFs, which doesn't have this problem.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11421
https://github.com/root-project/root/issues/11421:604,reliability,doe,does,604,"Thanks a lot for your comment! > * sometimes I would have found useful to be able to pass python number anywhere a RooAbsReal is required, although I suspect this may require a pythonization for each pdf. Yes, I would like this too, but it's technically not easy to implement without changing the source for all PDFs. Maybe I will have an idea at some point as I learn more about PyROOT, but for now I have none. > * `RooSimultaneous` map constructor does not accept a python dictionary yet. That's a very good idea! > * one thing that surprised me a couple of times at the beginning is that `RooAbsArg` does not keep its servers alive from the python GC so you actually need the same workarounds as in C++ (importing frequently to a workspace). However, I suspect that if they did keep servers alive, server redirection would likely lead to desync between the C++ and python views of the graph. That's a pretty good idea too. I guess one can simply create new Python references to each server that are set as an attribute of the server, such that they are always kept alive. But you're right, server redirection would break this, unless there are Pythonizations for that one too.... So I still need to think if this is worth it, also considering that users can also use the RooWorkspace factory interface to create PDFs, which doesn't have this problem.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11421
https://github.com/root-project/root/issues/11421:1328,reliability,doe,doesn,1328,"Thanks a lot for your comment! > * sometimes I would have found useful to be able to pass python number anywhere a RooAbsReal is required, although I suspect this may require a pythonization for each pdf. Yes, I would like this too, but it's technically not easy to implement without changing the source for all PDFs. Maybe I will have an idea at some point as I learn more about PyROOT, but for now I have none. > * `RooSimultaneous` map constructor does not accept a python dictionary yet. That's a very good idea! > * one thing that surprised me a couple of times at the beginning is that `RooAbsArg` does not keep its servers alive from the python GC so you actually need the same workarounds as in C++ (importing frequently to a workspace). However, I suspect that if they did keep servers alive, server redirection would likely lead to desync between the C++ and python views of the graph. That's a pretty good idea too. I guess one can simply create new Python references to each server that are set as an attribute of the server, such that they are always kept alive. But you're right, server redirection would break this, unless there are Pythonizations for that one too.... So I still need to think if this is worth it, also considering that users can also use the RooWorkspace factory interface to create PDFs, which doesn't have this problem.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11421
https://github.com/root-project/root/issues/11421:551,testability,coupl,couple,551,"Thanks a lot for your comment! > * sometimes I would have found useful to be able to pass python number anywhere a RooAbsReal is required, although I suspect this may require a pythonization for each pdf. Yes, I would like this too, but it's technically not easy to implement without changing the source for all PDFs. Maybe I will have an idea at some point as I learn more about PyROOT, but for now I have none. > * `RooSimultaneous` map constructor does not accept a python dictionary yet. That's a very good idea! > * one thing that surprised me a couple of times at the beginning is that `RooAbsArg` does not keep its servers alive from the python GC so you actually need the same workarounds as in C++ (importing frequently to a workspace). However, I suspect that if they did keep servers alive, server redirection would likely lead to desync between the C++ and python views of the graph. That's a pretty good idea too. I guess one can simply create new Python references to each server that are set as an attribute of the server, such that they are always kept alive. But you're right, server redirection would break this, unless there are Pythonizations for that one too.... So I still need to think if this is worth it, also considering that users can also use the RooWorkspace factory interface to create PDFs, which doesn't have this problem.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11421
https://github.com/root-project/root/issues/11421:943,testability,simpl,simply,943,"Thanks a lot for your comment! > * sometimes I would have found useful to be able to pass python number anywhere a RooAbsReal is required, although I suspect this may require a pythonization for each pdf. Yes, I would like this too, but it's technically not easy to implement without changing the source for all PDFs. Maybe I will have an idea at some point as I learn more about PyROOT, but for now I have none. > * `RooSimultaneous` map constructor does not accept a python dictionary yet. That's a very good idea! > * one thing that surprised me a couple of times at the beginning is that `RooAbsArg` does not keep its servers alive from the python GC so you actually need the same workarounds as in C++ (importing frequently to a workspace). However, I suspect that if they did keep servers alive, server redirection would likely lead to desync between the C++ and python views of the graph. That's a pretty good idea too. I guess one can simply create new Python references to each server that are set as an attribute of the server, such that they are always kept alive. But you're right, server redirection would break this, unless there are Pythonizations for that one too.... So I still need to think if this is worth it, also considering that users can also use the RooWorkspace factory interface to create PDFs, which doesn't have this problem.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11421
https://github.com/root-project/root/issues/11421:363,usability,learn,learn,363,"Thanks a lot for your comment! > * sometimes I would have found useful to be able to pass python number anywhere a RooAbsReal is required, although I suspect this may require a pythonization for each pdf. Yes, I would like this too, but it's technically not easy to implement without changing the source for all PDFs. Maybe I will have an idea at some point as I learn more about PyROOT, but for now I have none. > * `RooSimultaneous` map constructor does not accept a python dictionary yet. That's a very good idea! > * one thing that surprised me a couple of times at the beginning is that `RooAbsArg` does not keep its servers alive from the python GC so you actually need the same workarounds as in C++ (importing frequently to a workspace). However, I suspect that if they did keep servers alive, server redirection would likely lead to desync between the C++ and python views of the graph. That's a pretty good idea too. I guess one can simply create new Python references to each server that are set as an attribute of the server, such that they are always kept alive. But you're right, server redirection would break this, unless there are Pythonizations for that one too.... So I still need to think if this is worth it, also considering that users can also use the RooWorkspace factory interface to create PDFs, which doesn't have this problem.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11421
https://github.com/root-project/root/issues/11421:943,usability,simpl,simply,943,"Thanks a lot for your comment! > * sometimes I would have found useful to be able to pass python number anywhere a RooAbsReal is required, although I suspect this may require a pythonization for each pdf. Yes, I would like this too, but it's technically not easy to implement without changing the source for all PDFs. Maybe I will have an idea at some point as I learn more about PyROOT, but for now I have none. > * `RooSimultaneous` map constructor does not accept a python dictionary yet. That's a very good idea! > * one thing that surprised me a couple of times at the beginning is that `RooAbsArg` does not keep its servers alive from the python GC so you actually need the same workarounds as in C++ (importing frequently to a workspace). However, I suspect that if they did keep servers alive, server redirection would likely lead to desync between the C++ and python views of the graph. That's a pretty good idea too. I guess one can simply create new Python references to each server that are set as an attribute of the server, such that they are always kept alive. But you're right, server redirection would break this, unless there are Pythonizations for that one too.... So I still need to think if this is worth it, also considering that users can also use the RooWorkspace factory interface to create PDFs, which doesn't have this problem.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11421
https://github.com/root-project/root/issues/11421:1252,usability,user,users,1252,"Thanks a lot for your comment! > * sometimes I would have found useful to be able to pass python number anywhere a RooAbsReal is required, although I suspect this may require a pythonization for each pdf. Yes, I would like this too, but it's technically not easy to implement without changing the source for all PDFs. Maybe I will have an idea at some point as I learn more about PyROOT, but for now I have none. > * `RooSimultaneous` map constructor does not accept a python dictionary yet. That's a very good idea! > * one thing that surprised me a couple of times at the beginning is that `RooAbsArg` does not keep its servers alive from the python GC so you actually need the same workarounds as in C++ (importing frequently to a workspace). However, I suspect that if they did keep servers alive, server redirection would likely lead to desync between the C++ and python views of the graph. That's a pretty good idea too. I guess one can simply create new Python references to each server that are set as an attribute of the server, such that they are always kept alive. But you're right, server redirection would break this, unless there are Pythonizations for that one too.... So I still need to think if this is worth it, also considering that users can also use the RooWorkspace factory interface to create PDFs, which doesn't have this problem.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11421
https://github.com/root-project/root/pull/11422:11,deployability,build,build,11,"@phsft-bot build just on ROOT-debian10-i386/default, ROOT-ubuntu2004/python3",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11422
https://github.com/root-project/root/pull/11422:11,deployability,build,build,11,"@phsft-bot build just on ROOT-debian10-i386/default, ROOT-ubuntu2004/python3 with flags -DCTEST_TEST_EXCLUDE_NONE=On",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11422
https://github.com/root-project/root/pull/11422:11,deployability,build,build,11,"@phsft-bot build just on ROOT-debian10-i386/default, ROOT-ubuntu2004/python3 with flags -DCTEST_TEST_EXCLUDE_NONE=On",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11422
https://github.com/root-project/root/pull/11422:11,deployability,build,build,11,"@phsft-bot build just on ROOT-debian10-i386/default, ROOT-ubuntu2004/python3 with flags -DCTEST_TEST_EXCLUDE_NONE=On",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11422
https://github.com/root-project/root/pull/11422:11,deployability,build,build,11,"@phsft-bot build just on ROOT-debian10-i386/default, ROOT-ubuntu2004/python3 with flags -DCTEST_TEST_EXCLUDE_NONE=On.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11422
https://github.com/root-project/root/pull/11422:137,deployability,build,builds,137,"Hi @lmoneta, this seems to have broken basically all platforms. AFAICT CI didn't run (don't know why), can you please make sure that the builds pass for future PRs? I'm fixing this particular missing import in https://github.com/root-project/root/pull/11490",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11422
https://github.com/root-project/root/pull/11422:53,interoperability,platform,platforms,53,"Hi @lmoneta, this seems to have broken basically all platforms. AFAICT CI didn't run (don't know why), can you please make sure that the builds pass for future PRs? I'm fixing this particular missing import in https://github.com/root-project/root/pull/11490",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11422
https://github.com/root-project/root/pull/11423:84,performance,memor,memory,84,"@junaire, this looks good to me, but can you check if we do not regress in terms of memory. I think `time -v` on `hsimple.C` should be good enough.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11423
https://github.com/root-project/root/pull/11423:101,performance,time,time,101,"@junaire, this looks good to me, but can you check if we do not regress in terms of memory. I think `time -v` on `hsimple.C` should be good enough.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11423
https://github.com/root-project/root/pull/11423:64,testability,regress,regress,64,"@junaire, this looks good to me, but can you check if we do not regress in terms of memory. I think `time -v` on `hsimple.C` should be good enough.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11423
https://github.com/root-project/root/pull/11423:84,usability,memor,memory,84,"@junaire, this looks good to me, but can you check if we do not regress in terms of memory. I think `time -v` on `hsimple.C` should be good enough.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11423
https://github.com/root-project/root/pull/11423:171,deployability,build,build,171,"> @junaire, this looks good to me, but can you check if we do not regress in terms of memory. I think `time -v` on `hsimple.C` should be good enough. Sure, I'll trigger a build for CMSSW. BTW, I think this is a **fix** so we shouldn't be blocked by performance issues.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11423
https://github.com/root-project/root/pull/11423:86,performance,memor,memory,86,"> @junaire, this looks good to me, but can you check if we do not regress in terms of memory. I think `time -v` on `hsimple.C` should be good enough. Sure, I'll trigger a build for CMSSW. BTW, I think this is a **fix** so we shouldn't be blocked by performance issues.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11423
https://github.com/root-project/root/pull/11423:103,performance,time,time,103,"> @junaire, this looks good to me, but can you check if we do not regress in terms of memory. I think `time -v` on `hsimple.C` should be good enough. Sure, I'll trigger a build for CMSSW. BTW, I think this is a **fix** so we shouldn't be blocked by performance issues.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11423
https://github.com/root-project/root/pull/11423:249,performance,performance issu,performance issues,249,"> @junaire, this looks good to me, but can you check if we do not regress in terms of memory. I think `time -v` on `hsimple.C` should be good enough. Sure, I'll trigger a build for CMSSW. BTW, I think this is a **fix** so we shouldn't be blocked by performance issues.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11423
https://github.com/root-project/root/pull/11423:66,testability,regress,regress,66,"> @junaire, this looks good to me, but can you check if we do not regress in terms of memory. I think `time -v` on `hsimple.C` should be good enough. Sure, I'll trigger a build for CMSSW. BTW, I think this is a **fix** so we shouldn't be blocked by performance issues.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11423
https://github.com/root-project/root/pull/11423:86,usability,memor,memory,86,"> @junaire, this looks good to me, but can you check if we do not regress in terms of memory. I think `time -v` on `hsimple.C` should be good enough. Sure, I'll trigger a build for CMSSW. BTW, I think this is a **fix** so we shouldn't be blocked by performance issues.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11423
https://github.com/root-project/root/pull/11423:249,usability,perform,performance,249,"> @junaire, this looks good to me, but can you check if we do not regress in terms of memory. I think `time -v` on `hsimple.C` should be good enough. Sure, I'll trigger a build for CMSSW. BTW, I think this is a **fix** so we shouldn't be blocked by performance issues.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11423
https://github.com/root-project/root/pull/11423:29,deployability,patch,patch,29,"So I compared root with this patch and the root in the mainline. Here're some results. I'm using `/usr/bin/time -v root.exe -l -b -q ${test_name}` and the results are `Maximum resident set size (kbytes)`. | test name | with my patch | main line |. | :-----------------------------------: | :-----------: | :-------: |. | `hsimple.C` | 156756 | 161204 |. | `dataframe/df018_customActions.C` | 228800 | 265468 |. | `dataframe/df010_trivialDataSource.C` | 229428 | 229920 |. | `tmva/tmva003_RReader.C` | 286044 | 279764 |. | `tmva/tmva002_RDataFrameAsTensor.C` | 217628 | 243740 |. | `multicore/mp001_fillHistos.C` | 149196 | 180392 |. | `fit/multidimfit.C` | 137932 | 159296 |. So the result shows that the patch improves memory usage a little bit, which is excellent! . Cheers! ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11423
https://github.com/root-project/root/pull/11423:227,deployability,patch,patch,227,"So I compared root with this patch and the root in the mainline. Here're some results. I'm using `/usr/bin/time -v root.exe -l -b -q ${test_name}` and the results are `Maximum resident set size (kbytes)`. | test name | with my patch | main line |. | :-----------------------------------: | :-----------: | :-------: |. | `hsimple.C` | 156756 | 161204 |. | `dataframe/df018_customActions.C` | 228800 | 265468 |. | `dataframe/df010_trivialDataSource.C` | 229428 | 229920 |. | `tmva/tmva003_RReader.C` | 286044 | 279764 |. | `tmva/tmva002_RDataFrameAsTensor.C` | 217628 | 243740 |. | `multicore/mp001_fillHistos.C` | 149196 | 180392 |. | `fit/multidimfit.C` | 137932 | 159296 |. So the result shows that the patch improves memory usage a little bit, which is excellent! . Cheers! ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11423
https://github.com/root-project/root/pull/11423:705,deployability,patch,patch,705,"So I compared root with this patch and the root in the mainline. Here're some results. I'm using `/usr/bin/time -v root.exe -l -b -q ${test_name}` and the results are `Maximum resident set size (kbytes)`. | test name | with my patch | main line |. | :-----------------------------------: | :-----------: | :-------: |. | `hsimple.C` | 156756 | 161204 |. | `dataframe/df018_customActions.C` | 228800 | 265468 |. | `dataframe/df010_trivialDataSource.C` | 229428 | 229920 |. | `tmva/tmva003_RReader.C` | 286044 | 279764 |. | `tmva/tmva002_RDataFrameAsTensor.C` | 217628 | 243740 |. | `multicore/mp001_fillHistos.C` | 149196 | 180392 |. | `fit/multidimfit.C` | 137932 | 159296 |. So the result shows that the patch improves memory usage a little bit, which is excellent! . Cheers! ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11423
https://github.com/root-project/root/pull/11423:107,performance,time,time,107,"So I compared root with this patch and the root in the mainline. Here're some results. I'm using `/usr/bin/time -v root.exe -l -b -q ${test_name}` and the results are `Maximum resident set size (kbytes)`. | test name | with my patch | main line |. | :-----------------------------------: | :-----------: | :-------: |. | `hsimple.C` | 156756 | 161204 |. | `dataframe/df018_customActions.C` | 228800 | 265468 |. | `dataframe/df010_trivialDataSource.C` | 229428 | 229920 |. | `tmva/tmva003_RReader.C` | 286044 | 279764 |. | `tmva/tmva002_RDataFrameAsTensor.C` | 217628 | 243740 |. | `multicore/mp001_fillHistos.C` | 149196 | 180392 |. | `fit/multidimfit.C` | 137932 | 159296 |. So the result shows that the patch improves memory usage a little bit, which is excellent! . Cheers! ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11423
https://github.com/root-project/root/pull/11423:720,performance,memor,memory,720,"So I compared root with this patch and the root in the mainline. Here're some results. I'm using `/usr/bin/time -v root.exe -l -b -q ${test_name}` and the results are `Maximum resident set size (kbytes)`. | test name | with my patch | main line |. | :-----------------------------------: | :-----------: | :-------: |. | `hsimple.C` | 156756 | 161204 |. | `dataframe/df018_customActions.C` | 228800 | 265468 |. | `dataframe/df010_trivialDataSource.C` | 229428 | 229920 |. | `tmva/tmva003_RReader.C` | 286044 | 279764 |. | `tmva/tmva002_RDataFrameAsTensor.C` | 217628 | 243740 |. | `multicore/mp001_fillHistos.C` | 149196 | 180392 |. | `fit/multidimfit.C` | 137932 | 159296 |. So the result shows that the patch improves memory usage a little bit, which is excellent! . Cheers! ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11423
https://github.com/root-project/root/pull/11423:29,safety,patch,patch,29,"So I compared root with this patch and the root in the mainline. Here're some results. I'm using `/usr/bin/time -v root.exe -l -b -q ${test_name}` and the results are `Maximum resident set size (kbytes)`. | test name | with my patch | main line |. | :-----------------------------------: | :-----------: | :-------: |. | `hsimple.C` | 156756 | 161204 |. | `dataframe/df018_customActions.C` | 228800 | 265468 |. | `dataframe/df010_trivialDataSource.C` | 229428 | 229920 |. | `tmva/tmva003_RReader.C` | 286044 | 279764 |. | `tmva/tmva002_RDataFrameAsTensor.C` | 217628 | 243740 |. | `multicore/mp001_fillHistos.C` | 149196 | 180392 |. | `fit/multidimfit.C` | 137932 | 159296 |. So the result shows that the patch improves memory usage a little bit, which is excellent! . Cheers! ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11423
https://github.com/root-project/root/pull/11423:207,safety,test,test,207,"So I compared root with this patch and the root in the mainline. Here're some results. I'm using `/usr/bin/time -v root.exe -l -b -q ${test_name}` and the results are `Maximum resident set size (kbytes)`. | test name | with my patch | main line |. | :-----------------------------------: | :-----------: | :-------: |. | `hsimple.C` | 156756 | 161204 |. | `dataframe/df018_customActions.C` | 228800 | 265468 |. | `dataframe/df010_trivialDataSource.C` | 229428 | 229920 |. | `tmva/tmva003_RReader.C` | 286044 | 279764 |. | `tmva/tmva002_RDataFrameAsTensor.C` | 217628 | 243740 |. | `multicore/mp001_fillHistos.C` | 149196 | 180392 |. | `fit/multidimfit.C` | 137932 | 159296 |. So the result shows that the patch improves memory usage a little bit, which is excellent! . Cheers! ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11423
https://github.com/root-project/root/pull/11423:227,safety,patch,patch,227,"So I compared root with this patch and the root in the mainline. Here're some results. I'm using `/usr/bin/time -v root.exe -l -b -q ${test_name}` and the results are `Maximum resident set size (kbytes)`. | test name | with my patch | main line |. | :-----------------------------------: | :-----------: | :-------: |. | `hsimple.C` | 156756 | 161204 |. | `dataframe/df018_customActions.C` | 228800 | 265468 |. | `dataframe/df010_trivialDataSource.C` | 229428 | 229920 |. | `tmva/tmva003_RReader.C` | 286044 | 279764 |. | `tmva/tmva002_RDataFrameAsTensor.C` | 217628 | 243740 |. | `multicore/mp001_fillHistos.C` | 149196 | 180392 |. | `fit/multidimfit.C` | 137932 | 159296 |. So the result shows that the patch improves memory usage a little bit, which is excellent! . Cheers! ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11423
https://github.com/root-project/root/pull/11423:705,safety,patch,patch,705,"So I compared root with this patch and the root in the mainline. Here're some results. I'm using `/usr/bin/time -v root.exe -l -b -q ${test_name}` and the results are `Maximum resident set size (kbytes)`. | test name | with my patch | main line |. | :-----------------------------------: | :-----------: | :-------: |. | `hsimple.C` | 156756 | 161204 |. | `dataframe/df018_customActions.C` | 228800 | 265468 |. | `dataframe/df010_trivialDataSource.C` | 229428 | 229920 |. | `tmva/tmva003_RReader.C` | 286044 | 279764 |. | `tmva/tmva002_RDataFrameAsTensor.C` | 217628 | 243740 |. | `multicore/mp001_fillHistos.C` | 149196 | 180392 |. | `fit/multidimfit.C` | 137932 | 159296 |. So the result shows that the patch improves memory usage a little bit, which is excellent! . Cheers! ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11423
https://github.com/root-project/root/pull/11423:29,security,patch,patch,29,"So I compared root with this patch and the root in the mainline. Here're some results. I'm using `/usr/bin/time -v root.exe -l -b -q ${test_name}` and the results are `Maximum resident set size (kbytes)`. | test name | with my patch | main line |. | :-----------------------------------: | :-----------: | :-------: |. | `hsimple.C` | 156756 | 161204 |. | `dataframe/df018_customActions.C` | 228800 | 265468 |. | `dataframe/df010_trivialDataSource.C` | 229428 | 229920 |. | `tmva/tmva003_RReader.C` | 286044 | 279764 |. | `tmva/tmva002_RDataFrameAsTensor.C` | 217628 | 243740 |. | `multicore/mp001_fillHistos.C` | 149196 | 180392 |. | `fit/multidimfit.C` | 137932 | 159296 |. So the result shows that the patch improves memory usage a little bit, which is excellent! . Cheers! ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11423
https://github.com/root-project/root/pull/11423:227,security,patch,patch,227,"So I compared root with this patch and the root in the mainline. Here're some results. I'm using `/usr/bin/time -v root.exe -l -b -q ${test_name}` and the results are `Maximum resident set size (kbytes)`. | test name | with my patch | main line |. | :-----------------------------------: | :-----------: | :-------: |. | `hsimple.C` | 156756 | 161204 |. | `dataframe/df018_customActions.C` | 228800 | 265468 |. | `dataframe/df010_trivialDataSource.C` | 229428 | 229920 |. | `tmva/tmva003_RReader.C` | 286044 | 279764 |. | `tmva/tmva002_RDataFrameAsTensor.C` | 217628 | 243740 |. | `multicore/mp001_fillHistos.C` | 149196 | 180392 |. | `fit/multidimfit.C` | 137932 | 159296 |. So the result shows that the patch improves memory usage a little bit, which is excellent! . Cheers! ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11423
https://github.com/root-project/root/pull/11423:705,security,patch,patch,705,"So I compared root with this patch and the root in the mainline. Here're some results. I'm using `/usr/bin/time -v root.exe -l -b -q ${test_name}` and the results are `Maximum resident set size (kbytes)`. | test name | with my patch | main line |. | :-----------------------------------: | :-----------: | :-------: |. | `hsimple.C` | 156756 | 161204 |. | `dataframe/df018_customActions.C` | 228800 | 265468 |. | `dataframe/df010_trivialDataSource.C` | 229428 | 229920 |. | `tmva/tmva003_RReader.C` | 286044 | 279764 |. | `tmva/tmva002_RDataFrameAsTensor.C` | 217628 | 243740 |. | `multicore/mp001_fillHistos.C` | 149196 | 180392 |. | `fit/multidimfit.C` | 137932 | 159296 |. So the result shows that the patch improves memory usage a little bit, which is excellent! . Cheers! ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11423
https://github.com/root-project/root/pull/11423:207,testability,test,test,207,"So I compared root with this patch and the root in the mainline. Here're some results. I'm using `/usr/bin/time -v root.exe -l -b -q ${test_name}` and the results are `Maximum resident set size (kbytes)`. | test name | with my patch | main line |. | :-----------------------------------: | :-----------: | :-------: |. | `hsimple.C` | 156756 | 161204 |. | `dataframe/df018_customActions.C` | 228800 | 265468 |. | `dataframe/df010_trivialDataSource.C` | 229428 | 229920 |. | `tmva/tmva003_RReader.C` | 286044 | 279764 |. | `tmva/tmva002_RDataFrameAsTensor.C` | 217628 | 243740 |. | `multicore/mp001_fillHistos.C` | 149196 | 180392 |. | `fit/multidimfit.C` | 137932 | 159296 |. So the result shows that the patch improves memory usage a little bit, which is excellent! . Cheers! ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11423
https://github.com/root-project/root/pull/11423:720,usability,memor,memory,720,"So I compared root with this patch and the root in the mainline. Here're some results. I'm using `/usr/bin/time -v root.exe -l -b -q ${test_name}` and the results are `Maximum resident set size (kbytes)`. | test name | with my patch | main line |. | :-----------------------------------: | :-----------: | :-------: |. | `hsimple.C` | 156756 | 161204 |. | `dataframe/df018_customActions.C` | 228800 | 265468 |. | `dataframe/df010_trivialDataSource.C` | 229428 | 229920 |. | `tmva/tmva003_RReader.C` | 286044 | 279764 |. | `tmva/tmva002_RDataFrameAsTensor.C` | 217628 | 243740 |. | `multicore/mp001_fillHistos.C` | 149196 | 180392 |. | `fit/multidimfit.C` | 137932 | 159296 |. So the result shows that the patch improves memory usage a little bit, which is excellent! . Cheers! ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11423
https://github.com/root-project/root/pull/11423:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11423
https://github.com/root-project/root/pull/11423:6,availability,failur,failures,6,These failures are present elsewhere too.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11423
https://github.com/root-project/root/pull/11423:6,deployability,fail,failures,6,These failures are present elsewhere too.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11423
https://github.com/root-project/root/pull/11423:6,performance,failur,failures,6,These failures are present elsewhere too.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11423
https://github.com/root-project/root/pull/11423:6,reliability,fail,failures,6,These failures are present elsewhere too.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11423
https://github.com/root-project/root/pull/11424:11,deployability,build,build,11,@phsft-bot build just on mac12/default,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11424
https://github.com/root-project/root/pull/11424:11,deployability,build,build,11,@phsft-bot build just on mac11/cxx14,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11424
https://github.com/root-project/root/pull/11424:11,deployability,build,build,11,"@phsft-bot build just on mac12/default, mac11/cxx14",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11424
https://github.com/root-project/root/pull/11424:11,deployability,build,build,11,"@phsft-bot build just on mac12/default, mac11/cxx14",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11424
https://github.com/root-project/root/pull/11424:11,deployability,build,build,11,"@phsft-bot build just on mac12/default, mac11/cxx14",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11424
https://github.com/root-project/root/pull/11424:11,availability,failur,failures,11,mac12 test failures are *partially* fixed by #11432.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11424
https://github.com/root-project/root/pull/11424:11,deployability,fail,failures,11,mac12 test failures are *partially* fixed by #11432.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11424
https://github.com/root-project/root/pull/11424:11,performance,failur,failures,11,mac12 test failures are *partially* fixed by #11432.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11424
https://github.com/root-project/root/pull/11424:11,reliability,fail,failures,11,mac12 test failures are *partially* fixed by #11432.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11424
https://github.com/root-project/root/pull/11424:6,safety,test,test,6,mac12 test failures are *partially* fixed by #11432.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11424
https://github.com/root-project/root/pull/11424:6,testability,test,test,6,mac12 test failures are *partially* fixed by #11432.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11424
https://github.com/root-project/root/pull/11424:97,availability,failur,failures,97,The last push was only tested on mac11 and mac12; mac1015 seems completely broken with 300+ test failures...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11424
https://github.com/root-project/root/pull/11424:97,deployability,fail,failures,97,The last push was only tested on mac11 and mac12; mac1015 seems completely broken with 300+ test failures...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11424
https://github.com/root-project/root/pull/11424:97,performance,failur,failures,97,The last push was only tested on mac11 and mac12; mac1015 seems completely broken with 300+ test failures...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11424
https://github.com/root-project/root/pull/11424:97,reliability,fail,failures,97,The last push was only tested on mac11 and mac12; mac1015 seems completely broken with 300+ test failures...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11424
https://github.com/root-project/root/pull/11424:23,safety,test,tested,23,The last push was only tested on mac11 and mac12; mac1015 seems completely broken with 300+ test failures...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11424
https://github.com/root-project/root/pull/11424:64,safety,compl,completely,64,The last push was only tested on mac11 and mac12; mac1015 seems completely broken with 300+ test failures...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11424
https://github.com/root-project/root/pull/11424:92,safety,test,test,92,The last push was only tested on mac11 and mac12; mac1015 seems completely broken with 300+ test failures...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11424
https://github.com/root-project/root/pull/11424:64,security,compl,completely,64,The last push was only tested on mac11 and mac12; mac1015 seems completely broken with 300+ test failures...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11424
https://github.com/root-project/root/pull/11424:23,testability,test,tested,23,The last push was only tested on mac11 and mac12; mac1015 seems completely broken with 300+ test failures...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11424
https://github.com/root-project/root/pull/11424:92,testability,test,test,92,The last push was only tested on mac11 and mac12; mac1015 seems completely broken with 300+ test failures...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11424
https://github.com/root-project/root/pull/11424:13,energy efficiency,power,powers,13,"I used admin powers to push directly without PR, given that this literally rewinds to before my PR. Thanks for letting me know!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11424
https://github.com/root-project/root/pull/11425:8,availability,failur,failures,8,All the failures are unrelated to RooFit.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11425
https://github.com/root-project/root/pull/11425:8,deployability,fail,failures,8,All the failures are unrelated to RooFit.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11425
https://github.com/root-project/root/pull/11425:8,performance,failur,failures,8,All the failures are unrelated to RooFit.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11425
https://github.com/root-project/root/pull/11425:8,reliability,fail,failures,8,All the failures are unrelated to RooFit.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11425
https://github.com/root-project/root/pull/11428:98,energy efficiency,reduc,reduction,98,Closing for now because it's low priority and the idea didn't result in the drastic number of LOC reduction I was expecting.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11428
https://github.com/root-project/root/issues/11429:25,reliability,doe,does,25,I am not sure. The issue does not mention concrete examples of what gets rebuilt while it should not.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11429
https://github.com/root-project/root/issues/11429:61,deployability,build,building,61,"This is not about unnecessary rebuilding, but unreproducible building. I.e. take a (any) pristine source tree and build it on two different computers. The created files should be identical on both computers. (Alternatively, built it twice on the same computer, from a clean source tree).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11429
https://github.com/root-project/root/issues/11429:114,deployability,build,build,114,"This is not about unnecessary rebuilding, but unreproducible building. I.e. take a (any) pristine source tree and build it on two different computers. The created files should be identical on both computers. (Alternatively, built it twice on the same computer, from a clean source tree).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11429
https://github.com/root-project/root/issues/11429:179,security,ident,identical,179,"This is not about unnecessary rebuilding, but unreproducible building. I.e. take a (any) pristine source tree and build it on two different computers. The created files should be identical on both computers. (Alternatively, built it twice on the same computer, from a clean source tree).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11429
https://github.com/root-project/root/issues/11429:2,testability,understand,understand,2,"I understand now. In this case I do not think that has been an explicit requirement for ROOT. Maybe it should be, but I am not sure what needs to be done concretely here.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11429
https://github.com/root-project/root/pull/11432:11,deployability,build,build,11,@phsft-bot build just on mac12/default,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11432
https://github.com/root-project/root/pull/11432:11,deployability,build,build,11,@phsft-bot build just on mac12/default,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11432
https://github.com/root-project/root/pull/11432:11,deployability,build,build,11,@phsft-bot build just on mac12/default,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11432
https://github.com/root-project/root/pull/11432:11,deployability,build,build,11,@phsft-bot build just on mac12/default,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11432
https://github.com/root-project/root/pull/11432:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11432
https://github.com/root-project/root/pull/11432:11,deployability,build,build,11,@phsft-bot build just on mac13/default,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11432
https://github.com/root-project/root/pull/11432:11,deployability,build,build,11,@phsft-bot build just on mac12/default,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11432
https://github.com/root-project/root/pull/11432:30,deployability,build,build,30,I'll split the remaining ROOT build warnings off into a separate PR: this PR here fixes the PR builds / roottest.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11432
https://github.com/root-project/root/pull/11432:95,deployability,build,builds,95,I'll split the remaining ROOT build warnings off into a separate PR: this PR here fixes the PR builds / roottest.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11432
https://github.com/root-project/root/pull/11435:11,deployability,build,build,11,"@phsft-bot build just on ROOT-debian10-i386/default, ROOT-ubuntu2004/python3 with flags -DCTEST_TEST_EXCLUDE_NONE=On",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11435
https://github.com/root-project/root/pull/11435:78,availability,failur,failures,78,"The long tests requested by @lmoneta finished now. There are indeed some test failures on `ROOT-debian10-i386/default` that seem related to this PR, which I will investigate",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11435
https://github.com/root-project/root/pull/11435:78,deployability,fail,failures,78,"The long tests requested by @lmoneta finished now. There are indeed some test failures on `ROOT-debian10-i386/default` that seem related to this PR, which I will investigate",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11435
https://github.com/root-project/root/pull/11435:78,performance,failur,failures,78,"The long tests requested by @lmoneta finished now. There are indeed some test failures on `ROOT-debian10-i386/default` that seem related to this PR, which I will investigate",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11435
https://github.com/root-project/root/pull/11435:78,reliability,fail,failures,78,"The long tests requested by @lmoneta finished now. There are indeed some test failures on `ROOT-debian10-i386/default` that seem related to this PR, which I will investigate",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11435
https://github.com/root-project/root/pull/11435:9,safety,test,tests,9,"The long tests requested by @lmoneta finished now. There are indeed some test failures on `ROOT-debian10-i386/default` that seem related to this PR, which I will investigate",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11435
https://github.com/root-project/root/pull/11435:73,safety,test,test,73,"The long tests requested by @lmoneta finished now. There are indeed some test failures on `ROOT-debian10-i386/default` that seem related to this PR, which I will investigate",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11435
https://github.com/root-project/root/pull/11435:9,testability,test,tests,9,"The long tests requested by @lmoneta finished now. There are indeed some test failures on `ROOT-debian10-i386/default` that seem related to this PR, which I will investigate",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11435
https://github.com/root-project/root/pull/11435:73,testability,test,test,73,"The long tests requested by @lmoneta finished now. There are indeed some test failures on `ROOT-debian10-i386/default` that seem related to this PR, which I will investigate",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11435
https://github.com/root-project/root/pull/11435:4,availability,failur,failures,4,The failures are already present in master. There are not related to this PR and I am working on fixing them (see #11422),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11435
https://github.com/root-project/root/pull/11435:4,deployability,fail,failures,4,The failures are already present in master. There are not related to this PR and I am working on fixing them (see #11422),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11435
https://github.com/root-project/root/pull/11435:4,performance,failur,failures,4,The failures are already present in master. There are not related to this PR and I am working on fixing them (see #11422),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11435
https://github.com/root-project/root/pull/11435:4,reliability,fail,failures,4,The failures are already present in master. There are not related to this PR and I am working on fixing them (see #11422),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11435
https://github.com/root-project/root/pull/11435:11,deployability,build,build,11,"@phsft-bot build (the tests succeeded before, this is just a final check)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11435
https://github.com/root-project/root/pull/11435:22,safety,test,tests,22,"@phsft-bot build (the tests succeeded before, this is just a final check)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11435
https://github.com/root-project/root/pull/11435:22,testability,test,tests,22,"@phsft-bot build (the tests succeeded before, this is just a final check)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11435
https://github.com/root-project/root/issues/11436:77,deployability,releas,release,77,"There is two ways to work-around the problem. (a) Fix the file. With the old release setup. ```. auto f = TFile::Open(filename, ""UPDATE"");. TClass::GetClass(missingClassName)->GetStreamerInfo()->ForceWriteInfo();. delete f;. ```. (b) Create a fixit file that would then need to be loaded as part of any jobs that needs this type of broken file:. ```. auto f = TFile::Open(""fixitfile.root"", ""NEW"");. TClass::GetClass(missingClassName)->GetStreamerInfo()->ForceWriteInfo();. delete f;. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11436
https://github.com/root-project/root/issues/11436:129,deployability,UPDAT,UPDATE,129,"There is two ways to work-around the problem. (a) Fix the file. With the old release setup. ```. auto f = TFile::Open(filename, ""UPDATE"");. TClass::GetClass(missingClassName)->GetStreamerInfo()->ForceWriteInfo();. delete f;. ```. (b) Create a fixit file that would then need to be loaded as part of any jobs that needs this type of broken file:. ```. auto f = TFile::Open(""fixitfile.root"", ""NEW"");. TClass::GetClass(missingClassName)->GetStreamerInfo()->ForceWriteInfo();. delete f;. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11436
https://github.com/root-project/root/issues/11436:281,energy efficiency,load,loaded,281,"There is two ways to work-around the problem. (a) Fix the file. With the old release setup. ```. auto f = TFile::Open(filename, ""UPDATE"");. TClass::GetClass(missingClassName)->GetStreamerInfo()->ForceWriteInfo();. delete f;. ```. (b) Create a fixit file that would then need to be loaded as part of any jobs that needs this type of broken file:. ```. auto f = TFile::Open(""fixitfile.root"", ""NEW"");. TClass::GetClass(missingClassName)->GetStreamerInfo()->ForceWriteInfo();. delete f;. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11436
https://github.com/root-project/root/issues/11436:281,performance,load,loaded,281,"There is two ways to work-around the problem. (a) Fix the file. With the old release setup. ```. auto f = TFile::Open(filename, ""UPDATE"");. TClass::GetClass(missingClassName)->GetStreamerInfo()->ForceWriteInfo();. delete f;. ```. (b) Create a fixit file that would then need to be loaded as part of any jobs that needs this type of broken file:. ```. auto f = TFile::Open(""fixitfile.root"", ""NEW"");. TClass::GetClass(missingClassName)->GetStreamerInfo()->ForceWriteInfo();. delete f;. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11436
https://github.com/root-project/root/issues/11436:129,safety,UPDAT,UPDATE,129,"There is two ways to work-around the problem. (a) Fix the file. With the old release setup. ```. auto f = TFile::Open(filename, ""UPDATE"");. TClass::GetClass(missingClassName)->GetStreamerInfo()->ForceWriteInfo();. delete f;. ```. (b) Create a fixit file that would then need to be loaded as part of any jobs that needs this type of broken file:. ```. auto f = TFile::Open(""fixitfile.root"", ""NEW"");. TClass::GetClass(missingClassName)->GetStreamerInfo()->ForceWriteInfo();. delete f;. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11436
https://github.com/root-project/root/issues/11436:129,security,UPDAT,UPDATE,129,"There is two ways to work-around the problem. (a) Fix the file. With the old release setup. ```. auto f = TFile::Open(filename, ""UPDATE"");. TClass::GetClass(missingClassName)->GetStreamerInfo()->ForceWriteInfo();. delete f;. ```. (b) Create a fixit file that would then need to be loaded as part of any jobs that needs this type of broken file:. ```. auto f = TFile::Open(""fixitfile.root"", ""NEW"");. TClass::GetClass(missingClassName)->GetStreamerInfo()->ForceWriteInfo();. delete f;. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11436
https://github.com/root-project/root/pull/11438:99,deployability,build,build,99,"OK from me - but we need @bellenot because much of this is `periodic` and GUI, and he knows how to build + test!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11438
https://github.com/root-project/root/pull/11438:107,safety,test,test,107,"OK from me - but we need @bellenot because much of this is `periodic` and GUI, and he knows how to build + test!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11438
https://github.com/root-project/root/pull/11438:107,testability,test,test,107,"OK from me - but we need @bellenot because much of this is `periodic` and GUI, and he knows how to build + test!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11438
https://github.com/root-project/root/pull/11439:11,deployability,build,build,11,"@phsft-bot build just on mac1015/default, mac11/default, mac12/default with flags -DCTEST_TEST_EXCLUDE_NONE=On",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11439
https://github.com/root-project/root/pull/11439:11,deployability,build,build,11,"@phsft-bot build just on mac1015/default, mac11/default with flags -DCTEST_TEST_EXCLUDE_NONE=On",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11439
https://github.com/root-project/root/issues/11440:8,energy efficiency,Draw,Draw,8,"`TTree::Draw` can only find histogram in the current `TDirectory` which in the code snippet above is the `TFile`. Try:. ```. void ntuple_example() {. auto currentDirectory = gDirectory;. auto hpx = new TH1F(""hpx"", ""hpx"", 100, -1., 1.);. auto f = new TFile(""hsimple.root""); // We now have gDirectory == f. auto tree = (TTree*)f->Get(""ntuple"");. currentDirectory->cd();. tree->Draw(""px >> hpx"","""",""goff"");. hpx->Draw();. }. ```. Cheers,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11440
https://github.com/root-project/root/issues/11440:45,energy efficiency,current,current,45,"`TTree::Draw` can only find histogram in the current `TDirectory` which in the code snippet above is the `TFile`. Try:. ```. void ntuple_example() {. auto currentDirectory = gDirectory;. auto hpx = new TH1F(""hpx"", ""hpx"", 100, -1., 1.);. auto f = new TFile(""hsimple.root""); // We now have gDirectory == f. auto tree = (TTree*)f->Get(""ntuple"");. currentDirectory->cd();. tree->Draw(""px >> hpx"","""",""goff"");. hpx->Draw();. }. ```. Cheers,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11440
https://github.com/root-project/root/issues/11440:155,energy efficiency,current,currentDirectory,155,"`TTree::Draw` can only find histogram in the current `TDirectory` which in the code snippet above is the `TFile`. Try:. ```. void ntuple_example() {. auto currentDirectory = gDirectory;. auto hpx = new TH1F(""hpx"", ""hpx"", 100, -1., 1.);. auto f = new TFile(""hsimple.root""); // We now have gDirectory == f. auto tree = (TTree*)f->Get(""ntuple"");. currentDirectory->cd();. tree->Draw(""px >> hpx"","""",""goff"");. hpx->Draw();. }. ```. Cheers,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11440
https://github.com/root-project/root/issues/11440:344,energy efficiency,current,currentDirectory,344,"`TTree::Draw` can only find histogram in the current `TDirectory` which in the code snippet above is the `TFile`. Try:. ```. void ntuple_example() {. auto currentDirectory = gDirectory;. auto hpx = new TH1F(""hpx"", ""hpx"", 100, -1., 1.);. auto f = new TFile(""hsimple.root""); // We now have gDirectory == f. auto tree = (TTree*)f->Get(""ntuple"");. currentDirectory->cd();. tree->Draw(""px >> hpx"","""",""goff"");. hpx->Draw();. }. ```. Cheers,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11440
https://github.com/root-project/root/issues/11440:375,energy efficiency,Draw,Draw,375,"`TTree::Draw` can only find histogram in the current `TDirectory` which in the code snippet above is the `TFile`. Try:. ```. void ntuple_example() {. auto currentDirectory = gDirectory;. auto hpx = new TH1F(""hpx"", ""hpx"", 100, -1., 1.);. auto f = new TFile(""hsimple.root""); // We now have gDirectory == f. auto tree = (TTree*)f->Get(""ntuple"");. currentDirectory->cd();. tree->Draw(""px >> hpx"","""",""goff"");. hpx->Draw();. }. ```. Cheers,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11440
https://github.com/root-project/root/issues/11440:410,energy efficiency,Draw,Draw,410,"`TTree::Draw` can only find histogram in the current `TDirectory` which in the code snippet above is the `TFile`. Try:. ```. void ntuple_example() {. auto currentDirectory = gDirectory;. auto hpx = new TH1F(""hpx"", ""hpx"", 100, -1., 1.);. auto f = new TFile(""hsimple.root""); // We now have gDirectory == f. auto tree = (TTree*)f->Get(""ntuple"");. currentDirectory->cd();. tree->Draw(""px >> hpx"","""",""goff"");. hpx->Draw();. }. ```. Cheers,. Philippe.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11440
https://github.com/root-project/root/pull/11441:24,deployability,patch,patch,24,Could you also create a patch for cppyy in our cppyy/patches directory with these changes and add it as another commit here?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11441
https://github.com/root-project/root/pull/11441:53,deployability,patch,patches,53,Could you also create a patch for cppyy in our cppyy/patches directory with these changes and add it as another commit here?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11441
https://github.com/root-project/root/pull/11441:24,safety,patch,patch,24,Could you also create a patch for cppyy in our cppyy/patches directory with these changes and add it as another commit here?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11441
https://github.com/root-project/root/pull/11441:53,safety,patch,patches,53,Could you also create a patch for cppyy in our cppyy/patches directory with these changes and add it as another commit here?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11441
https://github.com/root-project/root/pull/11441:24,security,patch,patch,24,Could you also create a patch for cppyy in our cppyy/patches directory with these changes and add it as another commit here?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11441
https://github.com/root-project/root/pull/11441:53,security,patch,patches,53,Could you also create a patch for cppyy in our cppyy/patches directory with these changes and add it as another commit here?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11441
https://github.com/root-project/root/issues/11442:18,safety,risk,risky,18,Too late (aka too risky) at this point for v6.28/00.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11442
https://github.com/root-project/root/issues/11442:18,security,risk,risky,18,Too late (aka too risky) at this point for v6.28/00.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11442
https://github.com/root-project/root/pull/11443:221,reliability,doe,does,221,"> While we are at it, could you add `[[noreturn]]` to `TSystem::Exit` and `TRint/TApplication::Terminate`? For the same reason, I can't mark TApplication::Terminate as no return, as there is a branch of the function that does return, if the user has called before `SetReturnFromRun`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11443
https://github.com/root-project/root/pull/11443:241,usability,user,user,241,"> While we are at it, could you add `[[noreturn]]` to `TSystem::Exit` and `TRint/TApplication::Terminate`? For the same reason, I can't mark TApplication::Terminate as no return, as there is a branch of the function that does return, if the user has called before `SetReturnFromRun`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11443
https://github.com/root-project/root/pull/11443:3,deployability,build,build,3,"PR build will fail because of missing: https://github.com/root-project/root/pull/11490, so cancelling for now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11443
https://github.com/root-project/root/pull/11443:14,deployability,fail,fail,14,"PR build will fail because of missing: https://github.com/root-project/root/pull/11490, so cancelling for now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11443
https://github.com/root-project/root/pull/11443:14,reliability,fail,fail,14,"PR build will fail because of missing: https://github.com/root-project/root/pull/11490, so cancelling for now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11443
https://github.com/root-project/root/pull/11443:91,usability,cancel,cancelling,91,"PR build will fail because of missing: https://github.com/root-project/root/pull/11490, so cancelling for now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11443
https://github.com/root-project/root/pull/11443:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11443
https://github.com/root-project/root/pull/11443:46,deployability,build,build,46,"> * [2022-10-04T14:48:40.884Z] /home/sftnight/build/workspace/root-pullrequests-build/root/core/base/src/TSystem.cxx:722:1: warning: noreturn function does return. Well, so this doesn't work either, because TObject::AbstractMethod is not marked as noreturn. should I remove it? or create a TObject::AbstractNoReturnMethod function?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11443
https://github.com/root-project/root/pull/11443:80,deployability,build,build,80,"> * [2022-10-04T14:48:40.884Z] /home/sftnight/build/workspace/root-pullrequests-build/root/core/base/src/TSystem.cxx:722:1: warning: noreturn function does return. Well, so this doesn't work either, because TObject::AbstractMethod is not marked as noreturn. should I remove it? or create a TObject::AbstractNoReturnMethod function?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11443
https://github.com/root-project/root/pull/11443:91,energy efficiency,core,core,91,"> * [2022-10-04T14:48:40.884Z] /home/sftnight/build/workspace/root-pullrequests-build/root/core/base/src/TSystem.cxx:722:1: warning: noreturn function does return. Well, so this doesn't work either, because TObject::AbstractMethod is not marked as noreturn. should I remove it? or create a TObject::AbstractNoReturnMethod function?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11443
https://github.com/root-project/root/pull/11443:218,integrability,Abstract,AbstractMethod,218,"> * [2022-10-04T14:48:40.884Z] /home/sftnight/build/workspace/root-pullrequests-build/root/core/base/src/TSystem.cxx:722:1: warning: noreturn function does return. Well, so this doesn't work either, because TObject::AbstractMethod is not marked as noreturn. should I remove it? or create a TObject::AbstractNoReturnMethod function?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11443
https://github.com/root-project/root/pull/11443:301,integrability,Abstract,AbstractNoReturnMethod,301,"> * [2022-10-04T14:48:40.884Z] /home/sftnight/build/workspace/root-pullrequests-build/root/core/base/src/TSystem.cxx:722:1: warning: noreturn function does return. Well, so this doesn't work either, because TObject::AbstractMethod is not marked as noreturn. should I remove it? or create a TObject::AbstractNoReturnMethod function?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11443
https://github.com/root-project/root/pull/11443:218,modifiability,Abstract,AbstractMethod,218,"> * [2022-10-04T14:48:40.884Z] /home/sftnight/build/workspace/root-pullrequests-build/root/core/base/src/TSystem.cxx:722:1: warning: noreturn function does return. Well, so this doesn't work either, because TObject::AbstractMethod is not marked as noreturn. should I remove it? or create a TObject::AbstractNoReturnMethod function?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11443
https://github.com/root-project/root/pull/11443:301,modifiability,Abstract,AbstractNoReturnMethod,301,"> * [2022-10-04T14:48:40.884Z] /home/sftnight/build/workspace/root-pullrequests-build/root/core/base/src/TSystem.cxx:722:1: warning: noreturn function does return. Well, so this doesn't work either, because TObject::AbstractMethod is not marked as noreturn. should I remove it? or create a TObject::AbstractNoReturnMethod function?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11443
https://github.com/root-project/root/pull/11443:153,reliability,doe,does,153,"> * [2022-10-04T14:48:40.884Z] /home/sftnight/build/workspace/root-pullrequests-build/root/core/base/src/TSystem.cxx:722:1: warning: noreturn function does return. Well, so this doesn't work either, because TObject::AbstractMethod is not marked as noreturn. should I remove it? or create a TObject::AbstractNoReturnMethod function?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11443
https://github.com/root-project/root/pull/11443:180,reliability,doe,doesn,180,"> * [2022-10-04T14:48:40.884Z] /home/sftnight/build/workspace/root-pullrequests-build/root/core/base/src/TSystem.cxx:722:1: warning: noreturn function does return. Well, so this doesn't work either, because TObject::AbstractMethod is not marked as noreturn. should I remove it? or create a TObject::AbstractNoReturnMethod function?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11443
https://github.com/root-project/root/pull/11443:62,integrability,Abstract,AbstractMethod,62,For `TSystem's Exit and Abort` I would add a throw after the `AbstractMethod` (At first I thought about calling `Fatal` but those 2 routines could be involved in the implementation of `Fatal` causing more trouble).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11443
https://github.com/root-project/root/pull/11443:132,integrability,rout,routines,132,For `TSystem's Exit and Abort` I would add a throw after the `AbstractMethod` (At first I thought about calling `Fatal` but those 2 routines could be involved in the implementation of `Fatal` causing more trouble).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11443
https://github.com/root-project/root/pull/11443:62,modifiability,Abstract,AbstractMethod,62,For `TSystem's Exit and Abort` I would add a throw after the `AbstractMethod` (At first I thought about calling `Fatal` but those 2 routines could be involved in the implementation of `Fatal` causing more trouble).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11443
https://github.com/root-project/root/pull/11443:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11443
https://github.com/root-project/root/pull/11443:4,availability,failur,failures,4,The failures on windows are unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11443
https://github.com/root-project/root/pull/11443:4,deployability,fail,failures,4,The failures on windows are unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11443
https://github.com/root-project/root/pull/11443:4,performance,failur,failures,4,The failures on windows are unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11443
https://github.com/root-project/root/pull/11443:4,reliability,fail,failures,4,The failures on windows are unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11443
https://github.com/root-project/root/pull/11444:2643,deployability,continu,continues,2643,se in TString.cxx:2176. 12: Left side of '&&' is true in TString.cxx:2176. 13: Assuming the condition is false in TString.cxx:2176. 14: Taking false branch in TString.cxx:2176. 15: Assuming 'base_in' is not equal to 16 in TString.cxx:2177. 16: Left side of '&&' is false in TString.cxx:2177. 17: Assuming the condition is false in TString.cxx:2179. 18: Taking false branch in TString.cxx:2179. 19: Calling 'TString::IsInBaseN' in TString.cxx:2181. 20: 'base' is >= 2 in TString.cxx:1926. 21: Left side of '||' is false in TString.cxx:1926. 22: 'base' is <= 36 in TString.cxx:1926. 23: Taking false branch in TString.cxx:1926. 24: Assuming the condition is false in TString.cxx:1930. 25: Taking false branch in TString.cxx:1930. 26: Calling 'TString::Remove' in TString.cxx:1938. 27: Calling 'TString::Replace' in /tmp/root/core/base/inc/TString.h:674. 28: 'pos' is > 'kNPOS' in TString.cxx:1015. 29: Left side of '||' is false in TString.cxx:1015. 30: Assuming 'pos' is <= 'len' in TString.cxx:1015. 31: Taking false branch in TString.cxx:1015. 32: 'n1' is >= 0 in TString.cxx:1020. 33: Taking false branch in TString.cxx:1020. 34: 'n2' is >= 0 in TString.cxx:1024. 35: Taking false branch in TString.cxx:1024. 36: 'cs' is null in TString.cxx:1030. 37: Taking true branch in TString.cxx:1030. 38: Assuming 'capac' is < 'tot' in TString.cxx:1038. 39: Taking false branch in TString.cxx:1038. 40: Memory is allocated in TString.cxx:1067. 41: 'pos' is not equal to 0 in TString.cxx:1068. 42: Taking true branch in TString.cxx:1068. 43: 'n2' is 0 in TString.cxx:1069. 44: Taking false branch in TString.cxx:1069. 45: Assuming 'rem' is 0 in TString.cxx:1070. 46: Taking false branch in TString.cxx:1070. 47: Returned allocated memory in /tmp/root/core/base/inc/TString.h:674. 48: Returned allocated memory in TString.cxx:1938. 49: Loop condition is false. Execution continues on line 1946 in TString.cxx:1940. 50: Potential leak of memory pointed to by 'str_ref.fRep..fLong.fData' in TString.cxx:1947. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:1605,energy efficiency,core,core,1605,xx:2165. 8: Taking false branch in TString.cxx:2165. 9: Assuming the condition is false in TString.cxx:2172. 10: Taking false branch in TString.cxx:2172. 11: 'isSigned' is false in TString.cxx:2176. 12: Left side of '&&' is true in TString.cxx:2176. 13: Assuming the condition is false in TString.cxx:2176. 14: Taking false branch in TString.cxx:2176. 15: Assuming 'base_in' is not equal to 16 in TString.cxx:2177. 16: Left side of '&&' is false in TString.cxx:2177. 17: Assuming the condition is false in TString.cxx:2179. 18: Taking false branch in TString.cxx:2179. 19: Calling 'TString::IsInBaseN' in TString.cxx:2181. 20: 'base' is >= 2 in TString.cxx:1926. 21: Left side of '||' is false in TString.cxx:1926. 22: 'base' is <= 36 in TString.cxx:1926. 23: Taking false branch in TString.cxx:1926. 24: Assuming the condition is false in TString.cxx:1930. 25: Taking false branch in TString.cxx:1930. 26: Calling 'TString::Remove' in TString.cxx:1938. 27: Calling 'TString::Replace' in /tmp/root/core/base/inc/TString.h:674. 28: 'pos' is > 'kNPOS' in TString.cxx:1015. 29: Left side of '||' is false in TString.cxx:1015. 30: Assuming 'pos' is <= 'len' in TString.cxx:1015. 31: Taking false branch in TString.cxx:1015. 32: 'n1' is >= 0 in TString.cxx:1020. 33: Taking false branch in TString.cxx:1020. 34: 'n2' is >= 0 in TString.cxx:1024. 35: Taking false branch in TString.cxx:1024. 36: 'cs' is null in TString.cxx:1030. 37: Taking true branch in TString.cxx:1030. 38: Assuming 'capac' is < 'tot' in TString.cxx:1038. 39: Taking false branch in TString.cxx:1038. 40: Memory is allocated in TString.cxx:1067. 41: 'pos' is not equal to 0 in TString.cxx:1068. 42: Taking true branch in TString.cxx:1068. 43: 'n2' is 0 in TString.cxx:1069. 44: Taking false branch in TString.cxx:1069. 45: Assuming 'rem' is 0 in TString.cxx:1070. 46: Taking false branch in TString.cxx:1070. 47: Returned allocated memory in /tmp/root/core/base/inc/TString.h:674. 48: Returned allocated memory in TString.cxx:1938. 49:,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:2187,energy efficiency,alloc,allocated,2187,se in TString.cxx:2176. 12: Left side of '&&' is true in TString.cxx:2176. 13: Assuming the condition is false in TString.cxx:2176. 14: Taking false branch in TString.cxx:2176. 15: Assuming 'base_in' is not equal to 16 in TString.cxx:2177. 16: Left side of '&&' is false in TString.cxx:2177. 17: Assuming the condition is false in TString.cxx:2179. 18: Taking false branch in TString.cxx:2179. 19: Calling 'TString::IsInBaseN' in TString.cxx:2181. 20: 'base' is >= 2 in TString.cxx:1926. 21: Left side of '||' is false in TString.cxx:1926. 22: 'base' is <= 36 in TString.cxx:1926. 23: Taking false branch in TString.cxx:1926. 24: Assuming the condition is false in TString.cxx:1930. 25: Taking false branch in TString.cxx:1930. 26: Calling 'TString::Remove' in TString.cxx:1938. 27: Calling 'TString::Replace' in /tmp/root/core/base/inc/TString.h:674. 28: 'pos' is > 'kNPOS' in TString.cxx:1015. 29: Left side of '||' is false in TString.cxx:1015. 30: Assuming 'pos' is <= 'len' in TString.cxx:1015. 31: Taking false branch in TString.cxx:1015. 32: 'n1' is >= 0 in TString.cxx:1020. 33: Taking false branch in TString.cxx:1020. 34: 'n2' is >= 0 in TString.cxx:1024. 35: Taking false branch in TString.cxx:1024. 36: 'cs' is null in TString.cxx:1030. 37: Taking true branch in TString.cxx:1030. 38: Assuming 'capac' is < 'tot' in TString.cxx:1038. 39: Taking false branch in TString.cxx:1038. 40: Memory is allocated in TString.cxx:1067. 41: 'pos' is not equal to 0 in TString.cxx:1068. 42: Taking true branch in TString.cxx:1068. 43: 'n2' is 0 in TString.cxx:1069. 44: Taking false branch in TString.cxx:1069. 45: Assuming 'rem' is 0 in TString.cxx:1070. 46: Taking false branch in TString.cxx:1070. 47: Returned allocated memory in /tmp/root/core/base/inc/TString.h:674. 48: Returned allocated memory in TString.cxx:1938. 49: Loop condition is false. Execution continues on line 1946 in TString.cxx:1940. 50: Potential leak of memory pointed to by 'str_ref.fRep..fLong.fData' in TString.cxx:1947. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:2494,energy efficiency,alloc,allocated,2494,se in TString.cxx:2176. 12: Left side of '&&' is true in TString.cxx:2176. 13: Assuming the condition is false in TString.cxx:2176. 14: Taking false branch in TString.cxx:2176. 15: Assuming 'base_in' is not equal to 16 in TString.cxx:2177. 16: Left side of '&&' is false in TString.cxx:2177. 17: Assuming the condition is false in TString.cxx:2179. 18: Taking false branch in TString.cxx:2179. 19: Calling 'TString::IsInBaseN' in TString.cxx:2181. 20: 'base' is >= 2 in TString.cxx:1926. 21: Left side of '||' is false in TString.cxx:1926. 22: 'base' is <= 36 in TString.cxx:1926. 23: Taking false branch in TString.cxx:1926. 24: Assuming the condition is false in TString.cxx:1930. 25: Taking false branch in TString.cxx:1930. 26: Calling 'TString::Remove' in TString.cxx:1938. 27: Calling 'TString::Replace' in /tmp/root/core/base/inc/TString.h:674. 28: 'pos' is > 'kNPOS' in TString.cxx:1015. 29: Left side of '||' is false in TString.cxx:1015. 30: Assuming 'pos' is <= 'len' in TString.cxx:1015. 31: Taking false branch in TString.cxx:1015. 32: 'n1' is >= 0 in TString.cxx:1020. 33: Taking false branch in TString.cxx:1020. 34: 'n2' is >= 0 in TString.cxx:1024. 35: Taking false branch in TString.cxx:1024. 36: 'cs' is null in TString.cxx:1030. 37: Taking true branch in TString.cxx:1030. 38: Assuming 'capac' is < 'tot' in TString.cxx:1038. 39: Taking false branch in TString.cxx:1038. 40: Memory is allocated in TString.cxx:1067. 41: 'pos' is not equal to 0 in TString.cxx:1068. 42: Taking true branch in TString.cxx:1068. 43: 'n2' is 0 in TString.cxx:1069. 44: Taking false branch in TString.cxx:1069. 45: Assuming 'rem' is 0 in TString.cxx:1070. 46: Taking false branch in TString.cxx:1070. 47: Returned allocated memory in /tmp/root/core/base/inc/TString.h:674. 48: Returned allocated memory in TString.cxx:1938. 49: Loop condition is false. Execution continues on line 1946 in TString.cxx:1940. 50: Potential leak of memory pointed to by 'str_ref.fRep..fLong.fData' in TString.cxx:1947. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:2524,energy efficiency,core,core,2524,se in TString.cxx:2176. 12: Left side of '&&' is true in TString.cxx:2176. 13: Assuming the condition is false in TString.cxx:2176. 14: Taking false branch in TString.cxx:2176. 15: Assuming 'base_in' is not equal to 16 in TString.cxx:2177. 16: Left side of '&&' is false in TString.cxx:2177. 17: Assuming the condition is false in TString.cxx:2179. 18: Taking false branch in TString.cxx:2179. 19: Calling 'TString::IsInBaseN' in TString.cxx:2181. 20: 'base' is >= 2 in TString.cxx:1926. 21: Left side of '||' is false in TString.cxx:1926. 22: 'base' is <= 36 in TString.cxx:1926. 23: Taking false branch in TString.cxx:1926. 24: Assuming the condition is false in TString.cxx:1930. 25: Taking false branch in TString.cxx:1930. 26: Calling 'TString::Remove' in TString.cxx:1938. 27: Calling 'TString::Replace' in /tmp/root/core/base/inc/TString.h:674. 28: 'pos' is > 'kNPOS' in TString.cxx:1015. 29: Left side of '||' is false in TString.cxx:1015. 30: Assuming 'pos' is <= 'len' in TString.cxx:1015. 31: Taking false branch in TString.cxx:1015. 32: 'n1' is >= 0 in TString.cxx:1020. 33: Taking false branch in TString.cxx:1020. 34: 'n2' is >= 0 in TString.cxx:1024. 35: Taking false branch in TString.cxx:1024. 36: 'cs' is null in TString.cxx:1030. 37: Taking true branch in TString.cxx:1030. 38: Assuming 'capac' is < 'tot' in TString.cxx:1038. 39: Taking false branch in TString.cxx:1038. 40: Memory is allocated in TString.cxx:1067. 41: 'pos' is not equal to 0 in TString.cxx:1068. 42: Taking true branch in TString.cxx:1068. 43: 'n2' is 0 in TString.cxx:1069. 44: Taking false branch in TString.cxx:1069. 45: Assuming 'rem' is 0 in TString.cxx:1070. 46: Taking false branch in TString.cxx:1070. 47: Returned allocated memory in /tmp/root/core/base/inc/TString.h:674. 48: Returned allocated memory in TString.cxx:1938. 49: Loop condition is false. Execution continues on line 1946 in TString.cxx:1940. 50: Potential leak of memory pointed to by 'str_ref.fRep..fLong.fData' in TString.cxx:1947. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:2566,energy efficiency,alloc,allocated,2566,se in TString.cxx:2176. 12: Left side of '&&' is true in TString.cxx:2176. 13: Assuming the condition is false in TString.cxx:2176. 14: Taking false branch in TString.cxx:2176. 15: Assuming 'base_in' is not equal to 16 in TString.cxx:2177. 16: Left side of '&&' is false in TString.cxx:2177. 17: Assuming the condition is false in TString.cxx:2179. 18: Taking false branch in TString.cxx:2179. 19: Calling 'TString::IsInBaseN' in TString.cxx:2181. 20: 'base' is >= 2 in TString.cxx:1926. 21: Left side of '||' is false in TString.cxx:1926. 22: 'base' is <= 36 in TString.cxx:1926. 23: Taking false branch in TString.cxx:1926. 24: Assuming the condition is false in TString.cxx:1930. 25: Taking false branch in TString.cxx:1930. 26: Calling 'TString::Remove' in TString.cxx:1938. 27: Calling 'TString::Replace' in /tmp/root/core/base/inc/TString.h:674. 28: 'pos' is > 'kNPOS' in TString.cxx:1015. 29: Left side of '||' is false in TString.cxx:1015. 30: Assuming 'pos' is <= 'len' in TString.cxx:1015. 31: Taking false branch in TString.cxx:1015. 32: 'n1' is >= 0 in TString.cxx:1020. 33: Taking false branch in TString.cxx:1020. 34: 'n2' is >= 0 in TString.cxx:1024. 35: Taking false branch in TString.cxx:1024. 36: 'cs' is null in TString.cxx:1030. 37: Taking true branch in TString.cxx:1030. 38: Assuming 'capac' is < 'tot' in TString.cxx:1038. 39: Taking false branch in TString.cxx:1038. 40: Memory is allocated in TString.cxx:1067. 41: 'pos' is not equal to 0 in TString.cxx:1068. 42: Taking true branch in TString.cxx:1068. 43: 'n2' is 0 in TString.cxx:1069. 44: Taking false branch in TString.cxx:1069. 45: Assuming 'rem' is 0 in TString.cxx:1070. 46: Taking false branch in TString.cxx:1070. 47: Returned allocated memory in /tmp/root/core/base/inc/TString.h:674. 48: Returned allocated memory in TString.cxx:1938. 49: Loop condition is false. Execution continues on line 1946 in TString.cxx:1940. 50: Potential leak of memory pointed to by 'str_ref.fRep..fLong.fData' in TString.cxx:1947. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:163,performance,memor,memory,163,"There is still one more memleak warning, but I cannot find the reason / solution, maybe it's a false positive. ```. TString.cxx:1947:1: warning: Potential leak of memory pointed to by 'str_ref.fRep..fLong.fData' [clang-analyzer-cplusplus.NewDeleteLeaks]. 1: Assuming 'base_in' is >= 2 in TString.cxx:2165. 2: Left side of '||' is false in TString.cxx:2165. 3: Assuming 'base_in' is <= 36 in TString.cxx:2165. 4: Left side of '||' is false in TString.cxx:2165. 5: Assuming 'base_out' is >= 2 in TString.cxx:2165. 6: Left side of '||' is false in TString.cxx:2165. 7: Assuming 'base_out' is <= 36 in TString.cxx:2165. 8: Taking false branch in TString.cxx:2165. 9: Assuming the condition is false in TString.cxx:2172. 10: Taking false branch in TString.cxx:2172. 11: 'isSigned' is false in TString.cxx:2176. 12: Left side of '&&' is true in TString.cxx:2176. 13: Assuming the condition is false in TString.cxx:2176. 14: Taking false branch in TString.cxx:2176. 15: Assuming 'base_in' is not equal to 16 in TString.cxx:2177. 16: Left side of '&&' is false in TString.cxx:2177. 17: Assuming the condition is false in TString.cxx:2179. 18: Taking false branch in TString.cxx:2179. 19: Calling 'TString::IsInBaseN' in TString.cxx:2181. 20: 'base' is >= 2 in TString.cxx:1926. 21: Left side of '||' is false in TString.cxx:1926. 22: 'base' is <= 36 in TString.cxx:1926. 23: Taking false branch in TString.cxx:1926. 24: Assuming the condition is false in TString.cxx:1930. 25: Taking false branch in TString.cxx:1930. 26: Calling 'TString::Remove' in TString.cxx:1938. 27: Calling 'TString::Replace' in /tmp/root/core/base/inc/TString.h:674. 28: 'pos' is > 'kNPOS' in TString.cxx:1015. 29: Left side of '||' is false in TString.cxx:1015. 30: Assuming 'pos' is <= 'len' in TString.cxx:1015. 31: Taking false branch in TString.cxx:1015. 32: 'n1' is >= 0 in TString.cxx:1020. 33: Taking false branch in TString.cxx:1020. 34: 'n2' is >= 0 in TString.cxx:1024. 35: Taking false branch in TString.cxx:1024. 36: 'cs",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:2177,performance,Memor,Memory,2177,se in TString.cxx:2176. 12: Left side of '&&' is true in TString.cxx:2176. 13: Assuming the condition is false in TString.cxx:2176. 14: Taking false branch in TString.cxx:2176. 15: Assuming 'base_in' is not equal to 16 in TString.cxx:2177. 16: Left side of '&&' is false in TString.cxx:2177. 17: Assuming the condition is false in TString.cxx:2179. 18: Taking false branch in TString.cxx:2179. 19: Calling 'TString::IsInBaseN' in TString.cxx:2181. 20: 'base' is >= 2 in TString.cxx:1926. 21: Left side of '||' is false in TString.cxx:1926. 22: 'base' is <= 36 in TString.cxx:1926. 23: Taking false branch in TString.cxx:1926. 24: Assuming the condition is false in TString.cxx:1930. 25: Taking false branch in TString.cxx:1930. 26: Calling 'TString::Remove' in TString.cxx:1938. 27: Calling 'TString::Replace' in /tmp/root/core/base/inc/TString.h:674. 28: 'pos' is > 'kNPOS' in TString.cxx:1015. 29: Left side of '||' is false in TString.cxx:1015. 30: Assuming 'pos' is <= 'len' in TString.cxx:1015. 31: Taking false branch in TString.cxx:1015. 32: 'n1' is >= 0 in TString.cxx:1020. 33: Taking false branch in TString.cxx:1020. 34: 'n2' is >= 0 in TString.cxx:1024. 35: Taking false branch in TString.cxx:1024. 36: 'cs' is null in TString.cxx:1030. 37: Taking true branch in TString.cxx:1030. 38: Assuming 'capac' is < 'tot' in TString.cxx:1038. 39: Taking false branch in TString.cxx:1038. 40: Memory is allocated in TString.cxx:1067. 41: 'pos' is not equal to 0 in TString.cxx:1068. 42: Taking true branch in TString.cxx:1068. 43: 'n2' is 0 in TString.cxx:1069. 44: Taking false branch in TString.cxx:1069. 45: Assuming 'rem' is 0 in TString.cxx:1070. 46: Taking false branch in TString.cxx:1070. 47: Returned allocated memory in /tmp/root/core/base/inc/TString.h:674. 48: Returned allocated memory in TString.cxx:1938. 49: Loop condition is false. Execution continues on line 1946 in TString.cxx:1940. 50: Potential leak of memory pointed to by 'str_ref.fRep..fLong.fData' in TString.cxx:1947. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:2504,performance,memor,memory,2504,se in TString.cxx:2176. 12: Left side of '&&' is true in TString.cxx:2176. 13: Assuming the condition is false in TString.cxx:2176. 14: Taking false branch in TString.cxx:2176. 15: Assuming 'base_in' is not equal to 16 in TString.cxx:2177. 16: Left side of '&&' is false in TString.cxx:2177. 17: Assuming the condition is false in TString.cxx:2179. 18: Taking false branch in TString.cxx:2179. 19: Calling 'TString::IsInBaseN' in TString.cxx:2181. 20: 'base' is >= 2 in TString.cxx:1926. 21: Left side of '||' is false in TString.cxx:1926. 22: 'base' is <= 36 in TString.cxx:1926. 23: Taking false branch in TString.cxx:1926. 24: Assuming the condition is false in TString.cxx:1930. 25: Taking false branch in TString.cxx:1930. 26: Calling 'TString::Remove' in TString.cxx:1938. 27: Calling 'TString::Replace' in /tmp/root/core/base/inc/TString.h:674. 28: 'pos' is > 'kNPOS' in TString.cxx:1015. 29: Left side of '||' is false in TString.cxx:1015. 30: Assuming 'pos' is <= 'len' in TString.cxx:1015. 31: Taking false branch in TString.cxx:1015. 32: 'n1' is >= 0 in TString.cxx:1020. 33: Taking false branch in TString.cxx:1020. 34: 'n2' is >= 0 in TString.cxx:1024. 35: Taking false branch in TString.cxx:1024. 36: 'cs' is null in TString.cxx:1030. 37: Taking true branch in TString.cxx:1030. 38: Assuming 'capac' is < 'tot' in TString.cxx:1038. 39: Taking false branch in TString.cxx:1038. 40: Memory is allocated in TString.cxx:1067. 41: 'pos' is not equal to 0 in TString.cxx:1068. 42: Taking true branch in TString.cxx:1068. 43: 'n2' is 0 in TString.cxx:1069. 44: Taking false branch in TString.cxx:1069. 45: Assuming 'rem' is 0 in TString.cxx:1070. 46: Taking false branch in TString.cxx:1070. 47: Returned allocated memory in /tmp/root/core/base/inc/TString.h:674. 48: Returned allocated memory in TString.cxx:1938. 49: Loop condition is false. Execution continues on line 1946 in TString.cxx:1940. 50: Potential leak of memory pointed to by 'str_ref.fRep..fLong.fData' in TString.cxx:1947. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:2576,performance,memor,memory,2576,se in TString.cxx:2176. 12: Left side of '&&' is true in TString.cxx:2176. 13: Assuming the condition is false in TString.cxx:2176. 14: Taking false branch in TString.cxx:2176. 15: Assuming 'base_in' is not equal to 16 in TString.cxx:2177. 16: Left side of '&&' is false in TString.cxx:2177. 17: Assuming the condition is false in TString.cxx:2179. 18: Taking false branch in TString.cxx:2179. 19: Calling 'TString::IsInBaseN' in TString.cxx:2181. 20: 'base' is >= 2 in TString.cxx:1926. 21: Left side of '||' is false in TString.cxx:1926. 22: 'base' is <= 36 in TString.cxx:1926. 23: Taking false branch in TString.cxx:1926. 24: Assuming the condition is false in TString.cxx:1930. 25: Taking false branch in TString.cxx:1930. 26: Calling 'TString::Remove' in TString.cxx:1938. 27: Calling 'TString::Replace' in /tmp/root/core/base/inc/TString.h:674. 28: 'pos' is > 'kNPOS' in TString.cxx:1015. 29: Left side of '||' is false in TString.cxx:1015. 30: Assuming 'pos' is <= 'len' in TString.cxx:1015. 31: Taking false branch in TString.cxx:1015. 32: 'n1' is >= 0 in TString.cxx:1020. 33: Taking false branch in TString.cxx:1020. 34: 'n2' is >= 0 in TString.cxx:1024. 35: Taking false branch in TString.cxx:1024. 36: 'cs' is null in TString.cxx:1030. 37: Taking true branch in TString.cxx:1030. 38: Assuming 'capac' is < 'tot' in TString.cxx:1038. 39: Taking false branch in TString.cxx:1038. 40: Memory is allocated in TString.cxx:1067. 41: 'pos' is not equal to 0 in TString.cxx:1068. 42: Taking true branch in TString.cxx:1068. 43: 'n2' is 0 in TString.cxx:1069. 44: Taking false branch in TString.cxx:1069. 45: Assuming 'rem' is 0 in TString.cxx:1070. 46: Taking false branch in TString.cxx:1070. 47: Returned allocated memory in /tmp/root/core/base/inc/TString.h:674. 48: Returned allocated memory in TString.cxx:1938. 49: Loop condition is false. Execution continues on line 1946 in TString.cxx:1940. 50: Potential leak of memory pointed to by 'str_ref.fRep..fLong.fData' in TString.cxx:1947. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:2709,performance,memor,memory,2709,se in TString.cxx:2176. 12: Left side of '&&' is true in TString.cxx:2176. 13: Assuming the condition is false in TString.cxx:2176. 14: Taking false branch in TString.cxx:2176. 15: Assuming 'base_in' is not equal to 16 in TString.cxx:2177. 16: Left side of '&&' is false in TString.cxx:2177. 17: Assuming the condition is false in TString.cxx:2179. 18: Taking false branch in TString.cxx:2179. 19: Calling 'TString::IsInBaseN' in TString.cxx:2181. 20: 'base' is >= 2 in TString.cxx:1926. 21: Left side of '||' is false in TString.cxx:1926. 22: 'base' is <= 36 in TString.cxx:1926. 23: Taking false branch in TString.cxx:1926. 24: Assuming the condition is false in TString.cxx:1930. 25: Taking false branch in TString.cxx:1930. 26: Calling 'TString::Remove' in TString.cxx:1938. 27: Calling 'TString::Replace' in /tmp/root/core/base/inc/TString.h:674. 28: 'pos' is > 'kNPOS' in TString.cxx:1015. 29: Left side of '||' is false in TString.cxx:1015. 30: Assuming 'pos' is <= 'len' in TString.cxx:1015. 31: Taking false branch in TString.cxx:1015. 32: 'n1' is >= 0 in TString.cxx:1020. 33: Taking false branch in TString.cxx:1020. 34: 'n2' is >= 0 in TString.cxx:1024. 35: Taking false branch in TString.cxx:1024. 36: 'cs' is null in TString.cxx:1030. 37: Taking true branch in TString.cxx:1030. 38: Assuming 'capac' is < 'tot' in TString.cxx:1038. 39: Taking false branch in TString.cxx:1038. 40: Memory is allocated in TString.cxx:1067. 41: 'pos' is not equal to 0 in TString.cxx:1068. 42: Taking true branch in TString.cxx:1068. 43: 'n2' is 0 in TString.cxx:1069. 44: Taking false branch in TString.cxx:1069. 45: Assuming 'rem' is 0 in TString.cxx:1070. 46: Taking false branch in TString.cxx:1070. 47: Returned allocated memory in /tmp/root/core/base/inc/TString.h:674. 48: Returned allocated memory in TString.cxx:1938. 49: Loop condition is false. Execution continues on line 1946 in TString.cxx:1940. 50: Potential leak of memory pointed to by 'str_ref.fRep..fLong.fData' in TString.cxx:1947. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:163,usability,memor,memory,163,"There is still one more memleak warning, but I cannot find the reason / solution, maybe it's a false positive. ```. TString.cxx:1947:1: warning: Potential leak of memory pointed to by 'str_ref.fRep..fLong.fData' [clang-analyzer-cplusplus.NewDeleteLeaks]. 1: Assuming 'base_in' is >= 2 in TString.cxx:2165. 2: Left side of '||' is false in TString.cxx:2165. 3: Assuming 'base_in' is <= 36 in TString.cxx:2165. 4: Left side of '||' is false in TString.cxx:2165. 5: Assuming 'base_out' is >= 2 in TString.cxx:2165. 6: Left side of '||' is false in TString.cxx:2165. 7: Assuming 'base_out' is <= 36 in TString.cxx:2165. 8: Taking false branch in TString.cxx:2165. 9: Assuming the condition is false in TString.cxx:2172. 10: Taking false branch in TString.cxx:2172. 11: 'isSigned' is false in TString.cxx:2176. 12: Left side of '&&' is true in TString.cxx:2176. 13: Assuming the condition is false in TString.cxx:2176. 14: Taking false branch in TString.cxx:2176. 15: Assuming 'base_in' is not equal to 16 in TString.cxx:2177. 16: Left side of '&&' is false in TString.cxx:2177. 17: Assuming the condition is false in TString.cxx:2179. 18: Taking false branch in TString.cxx:2179. 19: Calling 'TString::IsInBaseN' in TString.cxx:2181. 20: 'base' is >= 2 in TString.cxx:1926. 21: Left side of '||' is false in TString.cxx:1926. 22: 'base' is <= 36 in TString.cxx:1926. 23: Taking false branch in TString.cxx:1926. 24: Assuming the condition is false in TString.cxx:1930. 25: Taking false branch in TString.cxx:1930. 26: Calling 'TString::Remove' in TString.cxx:1938. 27: Calling 'TString::Replace' in /tmp/root/core/base/inc/TString.h:674. 28: 'pos' is > 'kNPOS' in TString.cxx:1015. 29: Left side of '||' is false in TString.cxx:1015. 30: Assuming 'pos' is <= 'len' in TString.cxx:1015. 31: Taking false branch in TString.cxx:1015. 32: 'n1' is >= 0 in TString.cxx:1020. 33: Taking false branch in TString.cxx:1020. 34: 'n2' is >= 0 in TString.cxx:1024. 35: Taking false branch in TString.cxx:1024. 36: 'cs",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:2177,usability,Memor,Memory,2177,se in TString.cxx:2176. 12: Left side of '&&' is true in TString.cxx:2176. 13: Assuming the condition is false in TString.cxx:2176. 14: Taking false branch in TString.cxx:2176. 15: Assuming 'base_in' is not equal to 16 in TString.cxx:2177. 16: Left side of '&&' is false in TString.cxx:2177. 17: Assuming the condition is false in TString.cxx:2179. 18: Taking false branch in TString.cxx:2179. 19: Calling 'TString::IsInBaseN' in TString.cxx:2181. 20: 'base' is >= 2 in TString.cxx:1926. 21: Left side of '||' is false in TString.cxx:1926. 22: 'base' is <= 36 in TString.cxx:1926. 23: Taking false branch in TString.cxx:1926. 24: Assuming the condition is false in TString.cxx:1930. 25: Taking false branch in TString.cxx:1930. 26: Calling 'TString::Remove' in TString.cxx:1938. 27: Calling 'TString::Replace' in /tmp/root/core/base/inc/TString.h:674. 28: 'pos' is > 'kNPOS' in TString.cxx:1015. 29: Left side of '||' is false in TString.cxx:1015. 30: Assuming 'pos' is <= 'len' in TString.cxx:1015. 31: Taking false branch in TString.cxx:1015. 32: 'n1' is >= 0 in TString.cxx:1020. 33: Taking false branch in TString.cxx:1020. 34: 'n2' is >= 0 in TString.cxx:1024. 35: Taking false branch in TString.cxx:1024. 36: 'cs' is null in TString.cxx:1030. 37: Taking true branch in TString.cxx:1030. 38: Assuming 'capac' is < 'tot' in TString.cxx:1038. 39: Taking false branch in TString.cxx:1038. 40: Memory is allocated in TString.cxx:1067. 41: 'pos' is not equal to 0 in TString.cxx:1068. 42: Taking true branch in TString.cxx:1068. 43: 'n2' is 0 in TString.cxx:1069. 44: Taking false branch in TString.cxx:1069. 45: Assuming 'rem' is 0 in TString.cxx:1070. 46: Taking false branch in TString.cxx:1070. 47: Returned allocated memory in /tmp/root/core/base/inc/TString.h:674. 48: Returned allocated memory in TString.cxx:1938. 49: Loop condition is false. Execution continues on line 1946 in TString.cxx:1940. 50: Potential leak of memory pointed to by 'str_ref.fRep..fLong.fData' in TString.cxx:1947. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:2504,usability,memor,memory,2504,se in TString.cxx:2176. 12: Left side of '&&' is true in TString.cxx:2176. 13: Assuming the condition is false in TString.cxx:2176. 14: Taking false branch in TString.cxx:2176. 15: Assuming 'base_in' is not equal to 16 in TString.cxx:2177. 16: Left side of '&&' is false in TString.cxx:2177. 17: Assuming the condition is false in TString.cxx:2179. 18: Taking false branch in TString.cxx:2179. 19: Calling 'TString::IsInBaseN' in TString.cxx:2181. 20: 'base' is >= 2 in TString.cxx:1926. 21: Left side of '||' is false in TString.cxx:1926. 22: 'base' is <= 36 in TString.cxx:1926. 23: Taking false branch in TString.cxx:1926. 24: Assuming the condition is false in TString.cxx:1930. 25: Taking false branch in TString.cxx:1930. 26: Calling 'TString::Remove' in TString.cxx:1938. 27: Calling 'TString::Replace' in /tmp/root/core/base/inc/TString.h:674. 28: 'pos' is > 'kNPOS' in TString.cxx:1015. 29: Left side of '||' is false in TString.cxx:1015. 30: Assuming 'pos' is <= 'len' in TString.cxx:1015. 31: Taking false branch in TString.cxx:1015. 32: 'n1' is >= 0 in TString.cxx:1020. 33: Taking false branch in TString.cxx:1020. 34: 'n2' is >= 0 in TString.cxx:1024. 35: Taking false branch in TString.cxx:1024. 36: 'cs' is null in TString.cxx:1030. 37: Taking true branch in TString.cxx:1030. 38: Assuming 'capac' is < 'tot' in TString.cxx:1038. 39: Taking false branch in TString.cxx:1038. 40: Memory is allocated in TString.cxx:1067. 41: 'pos' is not equal to 0 in TString.cxx:1068. 42: Taking true branch in TString.cxx:1068. 43: 'n2' is 0 in TString.cxx:1069. 44: Taking false branch in TString.cxx:1069. 45: Assuming 'rem' is 0 in TString.cxx:1070. 46: Taking false branch in TString.cxx:1070. 47: Returned allocated memory in /tmp/root/core/base/inc/TString.h:674. 48: Returned allocated memory in TString.cxx:1938. 49: Loop condition is false. Execution continues on line 1946 in TString.cxx:1940. 50: Potential leak of memory pointed to by 'str_ref.fRep..fLong.fData' in TString.cxx:1947. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:2576,usability,memor,memory,2576,se in TString.cxx:2176. 12: Left side of '&&' is true in TString.cxx:2176. 13: Assuming the condition is false in TString.cxx:2176. 14: Taking false branch in TString.cxx:2176. 15: Assuming 'base_in' is not equal to 16 in TString.cxx:2177. 16: Left side of '&&' is false in TString.cxx:2177. 17: Assuming the condition is false in TString.cxx:2179. 18: Taking false branch in TString.cxx:2179. 19: Calling 'TString::IsInBaseN' in TString.cxx:2181. 20: 'base' is >= 2 in TString.cxx:1926. 21: Left side of '||' is false in TString.cxx:1926. 22: 'base' is <= 36 in TString.cxx:1926. 23: Taking false branch in TString.cxx:1926. 24: Assuming the condition is false in TString.cxx:1930. 25: Taking false branch in TString.cxx:1930. 26: Calling 'TString::Remove' in TString.cxx:1938. 27: Calling 'TString::Replace' in /tmp/root/core/base/inc/TString.h:674. 28: 'pos' is > 'kNPOS' in TString.cxx:1015. 29: Left side of '||' is false in TString.cxx:1015. 30: Assuming 'pos' is <= 'len' in TString.cxx:1015. 31: Taking false branch in TString.cxx:1015. 32: 'n1' is >= 0 in TString.cxx:1020. 33: Taking false branch in TString.cxx:1020. 34: 'n2' is >= 0 in TString.cxx:1024. 35: Taking false branch in TString.cxx:1024. 36: 'cs' is null in TString.cxx:1030. 37: Taking true branch in TString.cxx:1030. 38: Assuming 'capac' is < 'tot' in TString.cxx:1038. 39: Taking false branch in TString.cxx:1038. 40: Memory is allocated in TString.cxx:1067. 41: 'pos' is not equal to 0 in TString.cxx:1068. 42: Taking true branch in TString.cxx:1068. 43: 'n2' is 0 in TString.cxx:1069. 44: Taking false branch in TString.cxx:1069. 45: Assuming 'rem' is 0 in TString.cxx:1070. 46: Taking false branch in TString.cxx:1070. 47: Returned allocated memory in /tmp/root/core/base/inc/TString.h:674. 48: Returned allocated memory in TString.cxx:1938. 49: Loop condition is false. Execution continues on line 1946 in TString.cxx:1940. 50: Potential leak of memory pointed to by 'str_ref.fRep..fLong.fData' in TString.cxx:1947. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:2709,usability,memor,memory,2709,se in TString.cxx:2176. 12: Left side of '&&' is true in TString.cxx:2176. 13: Assuming the condition is false in TString.cxx:2176. 14: Taking false branch in TString.cxx:2176. 15: Assuming 'base_in' is not equal to 16 in TString.cxx:2177. 16: Left side of '&&' is false in TString.cxx:2177. 17: Assuming the condition is false in TString.cxx:2179. 18: Taking false branch in TString.cxx:2179. 19: Calling 'TString::IsInBaseN' in TString.cxx:2181. 20: 'base' is >= 2 in TString.cxx:1926. 21: Left side of '||' is false in TString.cxx:1926. 22: 'base' is <= 36 in TString.cxx:1926. 23: Taking false branch in TString.cxx:1926. 24: Assuming the condition is false in TString.cxx:1930. 25: Taking false branch in TString.cxx:1930. 26: Calling 'TString::Remove' in TString.cxx:1938. 27: Calling 'TString::Replace' in /tmp/root/core/base/inc/TString.h:674. 28: 'pos' is > 'kNPOS' in TString.cxx:1015. 29: Left side of '||' is false in TString.cxx:1015. 30: Assuming 'pos' is <= 'len' in TString.cxx:1015. 31: Taking false branch in TString.cxx:1015. 32: 'n1' is >= 0 in TString.cxx:1020. 33: Taking false branch in TString.cxx:1020. 34: 'n2' is >= 0 in TString.cxx:1024. 35: Taking false branch in TString.cxx:1024. 36: 'cs' is null in TString.cxx:1030. 37: Taking true branch in TString.cxx:1030. 38: Assuming 'capac' is < 'tot' in TString.cxx:1038. 39: Taking false branch in TString.cxx:1038. 40: Memory is allocated in TString.cxx:1067. 41: 'pos' is not equal to 0 in TString.cxx:1068. 42: Taking true branch in TString.cxx:1068. 43: 'n2' is 0 in TString.cxx:1069. 44: Taking false branch in TString.cxx:1069. 45: Assuming 'rem' is 0 in TString.cxx:1070. 46: Taking false branch in TString.cxx:1070. 47: Returned allocated memory in /tmp/root/core/base/inc/TString.h:674. 48: Returned allocated memory in TString.cxx:1938. 49: Loop condition is false. Execution continues on line 1946 in TString.cxx:1940. 50: Potential leak of memory pointed to by 'str_ref.fRep..fLong.fData' in TString.cxx:1947. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:147,energy efficiency,core,core,147,As well as:. ```. /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18:29: expanded from macro 'va_end'. /tmp/root/core/base/src/TString.cxx:2328:4: warning: va_end() is called on an uninitialized va_list [clang-analyzer-valist.Uninitialized]. 1: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 2: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2326. 3: expanded from macro 'va_start' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:17. 4: Calling 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 5: Assuming the condition is true in /tmp/root/core/base/src/TString.cxx:2290. 6: Left side of '||' is true in /tmp/root/core/base/src/TString.cxx:2290. 7: Taking true branch in /tmp/root/core/base/src/TString.cxx:2291. 8: Ended va_list in /tmp/root/core/base/src/TString.cxx:2296. 9: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 10: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2297. 11: expanded from macro 'R__VA_COPY' in /tmp/root/core/base/inc/Varargs.h:48. 12: expanded from macro 'va_copy' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:27. 13: Control jumps to line 2287 in /tmp/root/core/base/src/TString.cxx:2299. 14: Assuming the condition is false in /tmp/root/core/base/src/TString.cxx:2290. 15: Left side of '||' is false in /tmp/root/core/base/src/TString.cxx:2290. 16: Assuming 'n' is < 'buflen' in /tmp/root/core/base/src/TString.cxx:2290. 17: Taking false branch in /tmp/root/core/base/src/TString.cxx:2290. 18: 'vc' is 1 in /tmp/root/core/base/src/TString.cxx:2302. 19: Taking true branch in /tmp/root/core/base/src/TString.cxx:2302. 20: Ended va_list in /tmp/root/core/base/src/TString.cxx:2303. 21: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:433,energy efficiency,core,core,433,As well as:. ```. /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18:29: expanded from macro 'va_end'. /tmp/root/core/base/src/TString.cxx:2328:4: warning: va_end() is called on an uninitialized va_list [clang-analyzer-valist.Uninitialized]. 1: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 2: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2326. 3: expanded from macro 'va_start' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:17. 4: Calling 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 5: Assuming the condition is true in /tmp/root/core/base/src/TString.cxx:2290. 6: Left side of '||' is true in /tmp/root/core/base/src/TString.cxx:2290. 7: Taking true branch in /tmp/root/core/base/src/TString.cxx:2291. 8: Ended va_list in /tmp/root/core/base/src/TString.cxx:2296. 9: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 10: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2297. 11: expanded from macro 'R__VA_COPY' in /tmp/root/core/base/inc/Varargs.h:48. 12: expanded from macro 'va_copy' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:27. 13: Control jumps to line 2287 in /tmp/root/core/base/src/TString.cxx:2299. 14: Assuming the condition is false in /tmp/root/core/base/src/TString.cxx:2290. 15: Left side of '||' is false in /tmp/root/core/base/src/TString.cxx:2290. 16: Assuming 'n' is < 'buflen' in /tmp/root/core/base/src/TString.cxx:2290. 17: Taking false branch in /tmp/root/core/base/src/TString.cxx:2290. 18: 'vc' is 1 in /tmp/root/core/base/src/TString.cxx:2302. 19: Taking true branch in /tmp/root/core/base/src/TString.cxx:2302. 20: Ended va_list in /tmp/root/core/base/src/TString.cxx:2303. 21: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:631,energy efficiency,core,core,631,As well as:. ```. /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18:29: expanded from macro 'va_end'. /tmp/root/core/base/src/TString.cxx:2328:4: warning: va_end() is called on an uninitialized va_list [clang-analyzer-valist.Uninitialized]. 1: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 2: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2326. 3: expanded from macro 'va_start' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:17. 4: Calling 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 5: Assuming the condition is true in /tmp/root/core/base/src/TString.cxx:2290. 6: Left side of '||' is true in /tmp/root/core/base/src/TString.cxx:2290. 7: Taking true branch in /tmp/root/core/base/src/TString.cxx:2291. 8: Ended va_list in /tmp/root/core/base/src/TString.cxx:2296. 9: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 10: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2297. 11: expanded from macro 'R__VA_COPY' in /tmp/root/core/base/inc/Varargs.h:48. 12: expanded from macro 'va_copy' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:27. 13: Control jumps to line 2287 in /tmp/root/core/base/src/TString.cxx:2299. 14: Assuming the condition is false in /tmp/root/core/base/src/TString.cxx:2290. 15: Left side of '||' is false in /tmp/root/core/base/src/TString.cxx:2290. 16: Assuming 'n' is < 'buflen' in /tmp/root/core/base/src/TString.cxx:2290. 17: Taking false branch in /tmp/root/core/base/src/TString.cxx:2290. 18: 'vc' is 1 in /tmp/root/core/base/src/TString.cxx:2302. 19: Taking true branch in /tmp/root/core/base/src/TString.cxx:2302. 20: Ended va_list in /tmp/root/core/base/src/TString.cxx:2303. 21: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:710,energy efficiency,core,core,710,As well as:. ```. /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18:29: expanded from macro 'va_end'. /tmp/root/core/base/src/TString.cxx:2328:4: warning: va_end() is called on an uninitialized va_list [clang-analyzer-valist.Uninitialized]. 1: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 2: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2326. 3: expanded from macro 'va_start' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:17. 4: Calling 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 5: Assuming the condition is true in /tmp/root/core/base/src/TString.cxx:2290. 6: Left side of '||' is true in /tmp/root/core/base/src/TString.cxx:2290. 7: Taking true branch in /tmp/root/core/base/src/TString.cxx:2291. 8: Ended va_list in /tmp/root/core/base/src/TString.cxx:2296. 9: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 10: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2297. 11: expanded from macro 'R__VA_COPY' in /tmp/root/core/base/inc/Varargs.h:48. 12: expanded from macro 'va_copy' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:27. 13: Control jumps to line 2287 in /tmp/root/core/base/src/TString.cxx:2299. 14: Assuming the condition is false in /tmp/root/core/base/src/TString.cxx:2290. 15: Left side of '||' is false in /tmp/root/core/base/src/TString.cxx:2290. 16: Assuming 'n' is < 'buflen' in /tmp/root/core/base/src/TString.cxx:2290. 17: Taking false branch in /tmp/root/core/base/src/TString.cxx:2290. 18: 'vc' is 1 in /tmp/root/core/base/src/TString.cxx:2302. 19: Taking true branch in /tmp/root/core/base/src/TString.cxx:2302. 20: Ended va_list in /tmp/root/core/base/src/TString.cxx:2303. 21: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:784,energy efficiency,core,core,784,As well as:. ```. /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18:29: expanded from macro 'va_end'. /tmp/root/core/base/src/TString.cxx:2328:4: warning: va_end() is called on an uninitialized va_list [clang-analyzer-valist.Uninitialized]. 1: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 2: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2326. 3: expanded from macro 'va_start' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:17. 4: Calling 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 5: Assuming the condition is true in /tmp/root/core/base/src/TString.cxx:2290. 6: Left side of '||' is true in /tmp/root/core/base/src/TString.cxx:2290. 7: Taking true branch in /tmp/root/core/base/src/TString.cxx:2291. 8: Ended va_list in /tmp/root/core/base/src/TString.cxx:2296. 9: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 10: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2297. 11: expanded from macro 'R__VA_COPY' in /tmp/root/core/base/inc/Varargs.h:48. 12: expanded from macro 'va_copy' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:27. 13: Control jumps to line 2287 in /tmp/root/core/base/src/TString.cxx:2299. 14: Assuming the condition is false in /tmp/root/core/base/src/TString.cxx:2290. 15: Left side of '||' is false in /tmp/root/core/base/src/TString.cxx:2290. 16: Assuming 'n' is < 'buflen' in /tmp/root/core/base/src/TString.cxx:2290. 17: Taking false branch in /tmp/root/core/base/src/TString.cxx:2290. 18: 'vc' is 1 in /tmp/root/core/base/src/TString.cxx:2302. 19: Taking true branch in /tmp/root/core/base/src/TString.cxx:2302. 20: Ended va_list in /tmp/root/core/base/src/TString.cxx:2303. 21: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:851,energy efficiency,core,core,851,As well as:. ```. /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18:29: expanded from macro 'va_end'. /tmp/root/core/base/src/TString.cxx:2328:4: warning: va_end() is called on an uninitialized va_list [clang-analyzer-valist.Uninitialized]. 1: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 2: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2326. 3: expanded from macro 'va_start' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:17. 4: Calling 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 5: Assuming the condition is true in /tmp/root/core/base/src/TString.cxx:2290. 6: Left side of '||' is true in /tmp/root/core/base/src/TString.cxx:2290. 7: Taking true branch in /tmp/root/core/base/src/TString.cxx:2291. 8: Ended va_list in /tmp/root/core/base/src/TString.cxx:2296. 9: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 10: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2297. 11: expanded from macro 'R__VA_COPY' in /tmp/root/core/base/inc/Varargs.h:48. 12: expanded from macro 'va_copy' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:27. 13: Control jumps to line 2287 in /tmp/root/core/base/src/TString.cxx:2299. 14: Assuming the condition is false in /tmp/root/core/base/src/TString.cxx:2290. 15: Left side of '||' is false in /tmp/root/core/base/src/TString.cxx:2290. 16: Assuming 'n' is < 'buflen' in /tmp/root/core/base/src/TString.cxx:2290. 17: Taking false branch in /tmp/root/core/base/src/TString.cxx:2290. 18: 'vc' is 1 in /tmp/root/core/base/src/TString.cxx:2302. 19: Taking true branch in /tmp/root/core/base/src/TString.cxx:2302. 20: Ended va_list in /tmp/root/core/base/src/TString.cxx:2303. 21: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:913,energy efficiency,core,core,913,As well as:. ```. /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18:29: expanded from macro 'va_end'. /tmp/root/core/base/src/TString.cxx:2328:4: warning: va_end() is called on an uninitialized va_list [clang-analyzer-valist.Uninitialized]. 1: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 2: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2326. 3: expanded from macro 'va_start' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:17. 4: Calling 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 5: Assuming the condition is true in /tmp/root/core/base/src/TString.cxx:2290. 6: Left side of '||' is true in /tmp/root/core/base/src/TString.cxx:2290. 7: Taking true branch in /tmp/root/core/base/src/TString.cxx:2291. 8: Ended va_list in /tmp/root/core/base/src/TString.cxx:2296. 9: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 10: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2297. 11: expanded from macro 'R__VA_COPY' in /tmp/root/core/base/inc/Varargs.h:48. 12: expanded from macro 'va_copy' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:27. 13: Control jumps to line 2287 in /tmp/root/core/base/src/TString.cxx:2299. 14: Assuming the condition is false in /tmp/root/core/base/src/TString.cxx:2290. 15: Left side of '||' is false in /tmp/root/core/base/src/TString.cxx:2290. 16: Assuming 'n' is < 'buflen' in /tmp/root/core/base/src/TString.cxx:2290. 17: Taking false branch in /tmp/root/core/base/src/TString.cxx:2290. 18: 'vc' is 1 in /tmp/root/core/base/src/TString.cxx:2302. 19: Taking true branch in /tmp/root/core/base/src/TString.cxx:2302. 20: Ended va_list in /tmp/root/core/base/src/TString.cxx:2303. 21: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:1103,energy efficiency,core,core,1103,: expanded from macro 'va_end'. /tmp/root/core/base/src/TString.cxx:2328:4: warning: va_end() is called on an uninitialized va_list [clang-analyzer-valist.Uninitialized]. 1: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 2: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2326. 3: expanded from macro 'va_start' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:17. 4: Calling 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 5: Assuming the condition is true in /tmp/root/core/base/src/TString.cxx:2290. 6: Left side of '||' is true in /tmp/root/core/base/src/TString.cxx:2290. 7: Taking true branch in /tmp/root/core/base/src/TString.cxx:2291. 8: Ended va_list in /tmp/root/core/base/src/TString.cxx:2296. 9: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 10: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2297. 11: expanded from macro 'R__VA_COPY' in /tmp/root/core/base/inc/Varargs.h:48. 12: expanded from macro 'va_copy' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:27. 13: Control jumps to line 2287 in /tmp/root/core/base/src/TString.cxx:2299. 14: Assuming the condition is false in /tmp/root/core/base/src/TString.cxx:2290. 15: Left side of '||' is false in /tmp/root/core/base/src/TString.cxx:2290. 16: Assuming 'n' is < 'buflen' in /tmp/root/core/base/src/TString.cxx:2290. 17: Taking false branch in /tmp/root/core/base/src/TString.cxx:2290. 18: 'vc' is 1 in /tmp/root/core/base/src/TString.cxx:2302. 19: Taking true branch in /tmp/root/core/base/src/TString.cxx:2302. 20: Ended va_list in /tmp/root/core/base/src/TString.cxx:2303. 21: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 22: Returning from 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:23,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:1185,energy efficiency,core,core,1185,g: va_end() is called on an uninitialized va_list [clang-analyzer-valist.Uninitialized]. 1: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 2: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2326. 3: expanded from macro 'va_start' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:17. 4: Calling 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 5: Assuming the condition is true in /tmp/root/core/base/src/TString.cxx:2290. 6: Left side of '||' is true in /tmp/root/core/base/src/TString.cxx:2290. 7: Taking true branch in /tmp/root/core/base/src/TString.cxx:2291. 8: Ended va_list in /tmp/root/core/base/src/TString.cxx:2296. 9: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 10: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2297. 11: expanded from macro 'R__VA_COPY' in /tmp/root/core/base/inc/Varargs.h:48. 12: expanded from macro 'va_copy' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:27. 13: Control jumps to line 2287 in /tmp/root/core/base/src/TString.cxx:2299. 14: Assuming the condition is false in /tmp/root/core/base/src/TString.cxx:2290. 15: Left side of '||' is false in /tmp/root/core/base/src/TString.cxx:2290. 16: Assuming 'n' is < 'buflen' in /tmp/root/core/base/src/TString.cxx:2290. 17: Taking false branch in /tmp/root/core/base/src/TString.cxx:2290. 18: 'vc' is 1 in /tmp/root/core/base/src/TString.cxx:2302. 19: Taking true branch in /tmp/root/core/base/src/TString.cxx:2302. 20: Ended va_list in /tmp/root/core/base/src/TString.cxx:2303. 21: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 22: Returning from 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 23: va_end() is called on an uninitialized va_list in /tmp/root/core/base/src/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:1380,energy efficiency,core,core,1380,ator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 2: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2326. 3: expanded from macro 'va_start' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:17. 4: Calling 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 5: Assuming the condition is true in /tmp/root/core/base/src/TString.cxx:2290. 6: Left side of '||' is true in /tmp/root/core/base/src/TString.cxx:2290. 7: Taking true branch in /tmp/root/core/base/src/TString.cxx:2291. 8: Ended va_list in /tmp/root/core/base/src/TString.cxx:2296. 9: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 10: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2297. 11: expanded from macro 'R__VA_COPY' in /tmp/root/core/base/inc/Varargs.h:48. 12: expanded from macro 'va_copy' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:27. 13: Control jumps to line 2287 in /tmp/root/core/base/src/TString.cxx:2299. 14: Assuming the condition is false in /tmp/root/core/base/src/TString.cxx:2290. 15: Left side of '||' is false in /tmp/root/core/base/src/TString.cxx:2290. 16: Assuming 'n' is < 'buflen' in /tmp/root/core/base/src/TString.cxx:2290. 17: Taking false branch in /tmp/root/core/base/src/TString.cxx:2290. 18: 'vc' is 1 in /tmp/root/core/base/src/TString.cxx:2302. 19: Taking true branch in /tmp/root/core/base/src/TString.cxx:2302. 20: Ended va_list in /tmp/root/core/base/src/TString.cxx:2303. 21: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 22: Returning from 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 23: va_end() is called on an uninitialized va_list in /tmp/root/core/base/src/TString.cxx:2328. 24: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:1461,energy efficiency,core,core,1461,ator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 2: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2326. 3: expanded from macro 'va_start' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:17. 4: Calling 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 5: Assuming the condition is true in /tmp/root/core/base/src/TString.cxx:2290. 6: Left side of '||' is true in /tmp/root/core/base/src/TString.cxx:2290. 7: Taking true branch in /tmp/root/core/base/src/TString.cxx:2291. 8: Ended va_list in /tmp/root/core/base/src/TString.cxx:2296. 9: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 10: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2297. 11: expanded from macro 'R__VA_COPY' in /tmp/root/core/base/inc/Varargs.h:48. 12: expanded from macro 'va_copy' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:27. 13: Control jumps to line 2287 in /tmp/root/core/base/src/TString.cxx:2299. 14: Assuming the condition is false in /tmp/root/core/base/src/TString.cxx:2290. 15: Left side of '||' is false in /tmp/root/core/base/src/TString.cxx:2290. 16: Assuming 'n' is < 'buflen' in /tmp/root/core/base/src/TString.cxx:2290. 17: Taking false branch in /tmp/root/core/base/src/TString.cxx:2290. 18: 'vc' is 1 in /tmp/root/core/base/src/TString.cxx:2302. 19: Taking true branch in /tmp/root/core/base/src/TString.cxx:2302. 20: Ended va_list in /tmp/root/core/base/src/TString.cxx:2303. 21: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 22: Returning from 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 23: va_end() is called on an uninitialized va_list in /tmp/root/core/base/src/TString.cxx:2328. 24: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:1537,energy efficiency,core,core,1537,ator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 2: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2326. 3: expanded from macro 'va_start' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:17. 4: Calling 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 5: Assuming the condition is true in /tmp/root/core/base/src/TString.cxx:2290. 6: Left side of '||' is true in /tmp/root/core/base/src/TString.cxx:2290. 7: Taking true branch in /tmp/root/core/base/src/TString.cxx:2291. 8: Ended va_list in /tmp/root/core/base/src/TString.cxx:2296. 9: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 10: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2297. 11: expanded from macro 'R__VA_COPY' in /tmp/root/core/base/inc/Varargs.h:48. 12: expanded from macro 'va_copy' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:27. 13: Control jumps to line 2287 in /tmp/root/core/base/src/TString.cxx:2299. 14: Assuming the condition is false in /tmp/root/core/base/src/TString.cxx:2290. 15: Left side of '||' is false in /tmp/root/core/base/src/TString.cxx:2290. 16: Assuming 'n' is < 'buflen' in /tmp/root/core/base/src/TString.cxx:2290. 17: Taking false branch in /tmp/root/core/base/src/TString.cxx:2290. 18: 'vc' is 1 in /tmp/root/core/base/src/TString.cxx:2302. 19: Taking true branch in /tmp/root/core/base/src/TString.cxx:2302. 20: Ended va_list in /tmp/root/core/base/src/TString.cxx:2303. 21: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 22: Returning from 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 23: va_end() is called on an uninitialized va_list in /tmp/root/core/base/src/TString.cxx:2328. 24: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:1613,energy efficiency,core,core,1613,ator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 2: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2326. 3: expanded from macro 'va_start' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:17. 4: Calling 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 5: Assuming the condition is true in /tmp/root/core/base/src/TString.cxx:2290. 6: Left side of '||' is true in /tmp/root/core/base/src/TString.cxx:2290. 7: Taking true branch in /tmp/root/core/base/src/TString.cxx:2291. 8: Ended va_list in /tmp/root/core/base/src/TString.cxx:2296. 9: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 10: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2297. 11: expanded from macro 'R__VA_COPY' in /tmp/root/core/base/inc/Varargs.h:48. 12: expanded from macro 'va_copy' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:27. 13: Control jumps to line 2287 in /tmp/root/core/base/src/TString.cxx:2299. 14: Assuming the condition is false in /tmp/root/core/base/src/TString.cxx:2290. 15: Left side of '||' is false in /tmp/root/core/base/src/TString.cxx:2290. 16: Assuming 'n' is < 'buflen' in /tmp/root/core/base/src/TString.cxx:2290. 17: Taking false branch in /tmp/root/core/base/src/TString.cxx:2290. 18: 'vc' is 1 in /tmp/root/core/base/src/TString.cxx:2302. 19: Taking true branch in /tmp/root/core/base/src/TString.cxx:2302. 20: Ended va_list in /tmp/root/core/base/src/TString.cxx:2303. 21: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 22: Returning from 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 23: va_end() is called on an uninitialized va_list in /tmp/root/core/base/src/TString.cxx:2328. 24: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:1682,energy efficiency,core,core,1682,ator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 2: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2326. 3: expanded from macro 'va_start' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:17. 4: Calling 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 5: Assuming the condition is true in /tmp/root/core/base/src/TString.cxx:2290. 6: Left side of '||' is true in /tmp/root/core/base/src/TString.cxx:2290. 7: Taking true branch in /tmp/root/core/base/src/TString.cxx:2291. 8: Ended va_list in /tmp/root/core/base/src/TString.cxx:2296. 9: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 10: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2297. 11: expanded from macro 'R__VA_COPY' in /tmp/root/core/base/inc/Varargs.h:48. 12: expanded from macro 'va_copy' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:27. 13: Control jumps to line 2287 in /tmp/root/core/base/src/TString.cxx:2299. 14: Assuming the condition is false in /tmp/root/core/base/src/TString.cxx:2290. 15: Left side of '||' is false in /tmp/root/core/base/src/TString.cxx:2290. 16: Assuming 'n' is < 'buflen' in /tmp/root/core/base/src/TString.cxx:2290. 17: Taking false branch in /tmp/root/core/base/src/TString.cxx:2290. 18: 'vc' is 1 in /tmp/root/core/base/src/TString.cxx:2302. 19: Taking true branch in /tmp/root/core/base/src/TString.cxx:2302. 20: Ended va_list in /tmp/root/core/base/src/TString.cxx:2303. 21: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 22: Returning from 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 23: va_end() is called on an uninitialized va_list in /tmp/root/core/base/src/TString.cxx:2328. 24: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:1741,energy efficiency,core,core,1741,ator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 2: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2326. 3: expanded from macro 'va_start' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:17. 4: Calling 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 5: Assuming the condition is true in /tmp/root/core/base/src/TString.cxx:2290. 6: Left side of '||' is true in /tmp/root/core/base/src/TString.cxx:2290. 7: Taking true branch in /tmp/root/core/base/src/TString.cxx:2291. 8: Ended va_list in /tmp/root/core/base/src/TString.cxx:2296. 9: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 10: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2297. 11: expanded from macro 'R__VA_COPY' in /tmp/root/core/base/inc/Varargs.h:48. 12: expanded from macro 'va_copy' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:27. 13: Control jumps to line 2287 in /tmp/root/core/base/src/TString.cxx:2299. 14: Assuming the condition is false in /tmp/root/core/base/src/TString.cxx:2290. 15: Left side of '||' is false in /tmp/root/core/base/src/TString.cxx:2290. 16: Assuming 'n' is < 'buflen' in /tmp/root/core/base/src/TString.cxx:2290. 17: Taking false branch in /tmp/root/core/base/src/TString.cxx:2290. 18: 'vc' is 1 in /tmp/root/core/base/src/TString.cxx:2302. 19: Taking true branch in /tmp/root/core/base/src/TString.cxx:2302. 20: Ended va_list in /tmp/root/core/base/src/TString.cxx:2303. 21: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 22: Returning from 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 23: va_end() is called on an uninitialized va_list in /tmp/root/core/base/src/TString.cxx:2328. 24: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:1809,energy efficiency,core,core,1809,ator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 2: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2326. 3: expanded from macro 'va_start' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:17. 4: Calling 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 5: Assuming the condition is true in /tmp/root/core/base/src/TString.cxx:2290. 6: Left side of '||' is true in /tmp/root/core/base/src/TString.cxx:2290. 7: Taking true branch in /tmp/root/core/base/src/TString.cxx:2291. 8: Ended va_list in /tmp/root/core/base/src/TString.cxx:2296. 9: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 10: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2297. 11: expanded from macro 'R__VA_COPY' in /tmp/root/core/base/inc/Varargs.h:48. 12: expanded from macro 'va_copy' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:27. 13: Control jumps to line 2287 in /tmp/root/core/base/src/TString.cxx:2299. 14: Assuming the condition is false in /tmp/root/core/base/src/TString.cxx:2290. 15: Left side of '||' is false in /tmp/root/core/base/src/TString.cxx:2290. 16: Assuming 'n' is < 'buflen' in /tmp/root/core/base/src/TString.cxx:2290. 17: Taking false branch in /tmp/root/core/base/src/TString.cxx:2290. 18: 'vc' is 1 in /tmp/root/core/base/src/TString.cxx:2302. 19: Taking true branch in /tmp/root/core/base/src/TString.cxx:2302. 20: Ended va_list in /tmp/root/core/base/src/TString.cxx:2303. 21: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 22: Returning from 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 23: va_end() is called on an uninitialized va_list in /tmp/root/core/base/src/TString.cxx:2328. 24: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:1872,energy efficiency,core,core,1872,ator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 2: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2326. 3: expanded from macro 'va_start' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:17. 4: Calling 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 5: Assuming the condition is true in /tmp/root/core/base/src/TString.cxx:2290. 6: Left side of '||' is true in /tmp/root/core/base/src/TString.cxx:2290. 7: Taking true branch in /tmp/root/core/base/src/TString.cxx:2291. 8: Ended va_list in /tmp/root/core/base/src/TString.cxx:2296. 9: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 10: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2297. 11: expanded from macro 'R__VA_COPY' in /tmp/root/core/base/inc/Varargs.h:48. 12: expanded from macro 'va_copy' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:27. 13: Control jumps to line 2287 in /tmp/root/core/base/src/TString.cxx:2299. 14: Assuming the condition is false in /tmp/root/core/base/src/TString.cxx:2290. 15: Left side of '||' is false in /tmp/root/core/base/src/TString.cxx:2290. 16: Assuming 'n' is < 'buflen' in /tmp/root/core/base/src/TString.cxx:2290. 17: Taking false branch in /tmp/root/core/base/src/TString.cxx:2290. 18: 'vc' is 1 in /tmp/root/core/base/src/TString.cxx:2302. 19: Taking true branch in /tmp/root/core/base/src/TString.cxx:2302. 20: Ended va_list in /tmp/root/core/base/src/TString.cxx:2303. 21: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 22: Returning from 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 23: va_end() is called on an uninitialized va_list in /tmp/root/core/base/src/TString.cxx:2328. 24: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:2077,energy efficiency,core,core,2077,ator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 2: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2326. 3: expanded from macro 'va_start' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:17. 4: Calling 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 5: Assuming the condition is true in /tmp/root/core/base/src/TString.cxx:2290. 6: Left side of '||' is true in /tmp/root/core/base/src/TString.cxx:2290. 7: Taking true branch in /tmp/root/core/base/src/TString.cxx:2291. 8: Ended va_list in /tmp/root/core/base/src/TString.cxx:2296. 9: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 10: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2297. 11: expanded from macro 'R__VA_COPY' in /tmp/root/core/base/inc/Varargs.h:48. 12: expanded from macro 'va_copy' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:27. 13: Control jumps to line 2287 in /tmp/root/core/base/src/TString.cxx:2299. 14: Assuming the condition is false in /tmp/root/core/base/src/TString.cxx:2290. 15: Left side of '||' is false in /tmp/root/core/base/src/TString.cxx:2290. 16: Assuming 'n' is < 'buflen' in /tmp/root/core/base/src/TString.cxx:2290. 17: Taking false branch in /tmp/root/core/base/src/TString.cxx:2290. 18: 'vc' is 1 in /tmp/root/core/base/src/TString.cxx:2302. 19: Taking true branch in /tmp/root/core/base/src/TString.cxx:2302. 20: Ended va_list in /tmp/root/core/base/src/TString.cxx:2303. 21: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 22: Returning from 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 23: va_end() is called on an uninitialized va_list in /tmp/root/core/base/src/TString.cxx:2328. 24: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:2173,energy efficiency,core,core,2173,ator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 2: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2326. 3: expanded from macro 'va_start' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:17. 4: Calling 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 5: Assuming the condition is true in /tmp/root/core/base/src/TString.cxx:2290. 6: Left side of '||' is true in /tmp/root/core/base/src/TString.cxx:2290. 7: Taking true branch in /tmp/root/core/base/src/TString.cxx:2291. 8: Ended va_list in /tmp/root/core/base/src/TString.cxx:2296. 9: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 10: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2297. 11: expanded from macro 'R__VA_COPY' in /tmp/root/core/base/inc/Varargs.h:48. 12: expanded from macro 'va_copy' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:27. 13: Control jumps to line 2287 in /tmp/root/core/base/src/TString.cxx:2299. 14: Assuming the condition is false in /tmp/root/core/base/src/TString.cxx:2290. 15: Left side of '||' is false in /tmp/root/core/base/src/TString.cxx:2290. 16: Assuming 'n' is < 'buflen' in /tmp/root/core/base/src/TString.cxx:2290. 17: Taking false branch in /tmp/root/core/base/src/TString.cxx:2290. 18: 'vc' is 1 in /tmp/root/core/base/src/TString.cxx:2302. 19: Taking true branch in /tmp/root/core/base/src/TString.cxx:2302. 20: Ended va_list in /tmp/root/core/base/src/TString.cxx:2303. 21: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 22: Returning from 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 23: va_end() is called on an uninitialized va_list in /tmp/root/core/base/src/TString.cxx:2328. 24: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:1340,security,Control,Control,1340,ator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 2: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2326. 3: expanded from macro 'va_start' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:17. 4: Calling 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 5: Assuming the condition is true in /tmp/root/core/base/src/TString.cxx:2290. 6: Left side of '||' is true in /tmp/root/core/base/src/TString.cxx:2290. 7: Taking true branch in /tmp/root/core/base/src/TString.cxx:2291. 8: Ended va_list in /tmp/root/core/base/src/TString.cxx:2296. 9: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 10: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2297. 11: expanded from macro 'R__VA_COPY' in /tmp/root/core/base/inc/Varargs.h:48. 12: expanded from macro 'va_copy' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:27. 13: Control jumps to line 2287 in /tmp/root/core/base/src/TString.cxx:2299. 14: Assuming the condition is false in /tmp/root/core/base/src/TString.cxx:2290. 15: Left side of '||' is false in /tmp/root/core/base/src/TString.cxx:2290. 16: Assuming 'n' is < 'buflen' in /tmp/root/core/base/src/TString.cxx:2290. 17: Taking false branch in /tmp/root/core/base/src/TString.cxx:2290. 18: 'vc' is 1 in /tmp/root/core/base/src/TString.cxx:2302. 19: Taking true branch in /tmp/root/core/base/src/TString.cxx:2302. 20: Ended va_list in /tmp/root/core/base/src/TString.cxx:2303. 21: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 22: Returning from 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 23: va_end() is called on an uninitialized va_list in /tmp/root/core/base/src/TString.cxx:2328. 24: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:1340,testability,Control,Control,1340,ator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 2: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2326. 3: expanded from macro 'va_start' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:17. 4: Calling 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 5: Assuming the condition is true in /tmp/root/core/base/src/TString.cxx:2290. 6: Left side of '||' is true in /tmp/root/core/base/src/TString.cxx:2290. 7: Taking true branch in /tmp/root/core/base/src/TString.cxx:2291. 8: Ended va_list in /tmp/root/core/base/src/TString.cxx:2296. 9: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 10: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2297. 11: expanded from macro 'R__VA_COPY' in /tmp/root/core/base/inc/Varargs.h:48. 12: expanded from macro 'va_copy' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:27. 13: Control jumps to line 2287 in /tmp/root/core/base/src/TString.cxx:2299. 14: Assuming the condition is false in /tmp/root/core/base/src/TString.cxx:2290. 15: Left side of '||' is false in /tmp/root/core/base/src/TString.cxx:2290. 16: Assuming 'n' is < 'buflen' in /tmp/root/core/base/src/TString.cxx:2290. 17: Taking false branch in /tmp/root/core/base/src/TString.cxx:2290. 18: 'vc' is 1 in /tmp/root/core/base/src/TString.cxx:2302. 19: Taking true branch in /tmp/root/core/base/src/TString.cxx:2302. 20: Ended va_list in /tmp/root/core/base/src/TString.cxx:2303. 21: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 22: Returning from 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 23: va_end() is called on an uninitialized va_list in /tmp/root/core/base/src/TString.cxx:2328. 24: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:26,usability,Tool,Tools,26,As well as:. ```. /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18:29: expanded from macro 'va_end'. /tmp/root/core/base/src/TString.cxx:2328:4: warning: va_end() is called on an uninitialized va_list [clang-analyzer-valist.Uninitialized]. 1: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 2: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2326. 3: expanded from macro 'va_start' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:17. 4: Calling 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 5: Assuming the condition is true in /tmp/root/core/base/src/TString.cxx:2290. 6: Left side of '||' is true in /tmp/root/core/base/src/TString.cxx:2290. 7: Taking true branch in /tmp/root/core/base/src/TString.cxx:2291. 8: Ended va_list in /tmp/root/core/base/src/TString.cxx:2296. 9: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 10: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2297. 11: expanded from macro 'R__VA_COPY' in /tmp/root/core/base/inc/Varargs.h:48. 12: expanded from macro 'va_copy' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:27. 13: Control jumps to line 2287 in /tmp/root/core/base/src/TString.cxx:2299. 14: Assuming the condition is false in /tmp/root/core/base/src/TString.cxx:2290. 15: Left side of '||' is false in /tmp/root/core/base/src/TString.cxx:2290. 16: Assuming 'n' is < 'buflen' in /tmp/root/core/base/src/TString.cxx:2290. 17: Taking false branch in /tmp/root/core/base/src/TString.cxx:2290. 18: 'vc' is 1 in /tmp/root/core/base/src/TString.cxx:2302. 19: Taking true branch in /tmp/root/core/base/src/TString.cxx:2302. 20: Ended va_list in /tmp/root/core/base/src/TString.cxx:2303. 21: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:319,usability,Tool,Tools,319,As well as:. ```. /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18:29: expanded from macro 'va_end'. /tmp/root/core/base/src/TString.cxx:2328:4: warning: va_end() is called on an uninitialized va_list [clang-analyzer-valist.Uninitialized]. 1: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 2: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2326. 3: expanded from macro 'va_start' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:17. 4: Calling 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 5: Assuming the condition is true in /tmp/root/core/base/src/TString.cxx:2290. 6: Left side of '||' is true in /tmp/root/core/base/src/TString.cxx:2290. 7: Taking true branch in /tmp/root/core/base/src/TString.cxx:2291. 8: Ended va_list in /tmp/root/core/base/src/TString.cxx:2296. 9: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 10: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2297. 11: expanded from macro 'R__VA_COPY' in /tmp/root/core/base/inc/Varargs.h:48. 12: expanded from macro 'va_copy' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:27. 13: Control jumps to line 2287 in /tmp/root/core/base/src/TString.cxx:2299. 14: Assuming the condition is false in /tmp/root/core/base/src/TString.cxx:2290. 15: Left side of '||' is false in /tmp/root/core/base/src/TString.cxx:2290. 16: Assuming 'n' is < 'buflen' in /tmp/root/core/base/src/TString.cxx:2290. 17: Taking false branch in /tmp/root/core/base/src/TString.cxx:2290. 18: 'vc' is 1 in /tmp/root/core/base/src/TString.cxx:2302. 19: Taking true branch in /tmp/root/core/base/src/TString.cxx:2302. 20: Ended va_list in /tmp/root/core/base/src/TString.cxx:2303. 21: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:510,usability,Tool,Tools,510,As well as:. ```. /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18:29: expanded from macro 'va_end'. /tmp/root/core/base/src/TString.cxx:2328:4: warning: va_end() is called on an uninitialized va_list [clang-analyzer-valist.Uninitialized]. 1: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 2: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2326. 3: expanded from macro 'va_start' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:17. 4: Calling 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 5: Assuming the condition is true in /tmp/root/core/base/src/TString.cxx:2290. 6: Left side of '||' is true in /tmp/root/core/base/src/TString.cxx:2290. 7: Taking true branch in /tmp/root/core/base/src/TString.cxx:2291. 8: Ended va_list in /tmp/root/core/base/src/TString.cxx:2296. 9: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 10: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2297. 11: expanded from macro 'R__VA_COPY' in /tmp/root/core/base/inc/Varargs.h:48. 12: expanded from macro 'va_copy' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:27. 13: Control jumps to line 2287 in /tmp/root/core/base/src/TString.cxx:2299. 14: Assuming the condition is false in /tmp/root/core/base/src/TString.cxx:2290. 15: Left side of '||' is false in /tmp/root/core/base/src/TString.cxx:2290. 16: Assuming 'n' is < 'buflen' in /tmp/root/core/base/src/TString.cxx:2290. 17: Taking false branch in /tmp/root/core/base/src/TString.cxx:2290. 18: 'vc' is 1 in /tmp/root/core/base/src/TString.cxx:2302. 19: Taking true branch in /tmp/root/core/base/src/TString.cxx:2302. 20: Ended va_list in /tmp/root/core/base/src/TString.cxx:2303. 21: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:988,usability,Tool,Tools,988,As well as:. ```. /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18:29: expanded from macro 'va_end'. /tmp/root/core/base/src/TString.cxx:2328:4: warning: va_end() is called on an uninitialized va_list [clang-analyzer-valist.Uninitialized]. 1: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 2: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2326. 3: expanded from macro 'va_start' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:17. 4: Calling 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 5: Assuming the condition is true in /tmp/root/core/base/src/TString.cxx:2290. 6: Left side of '||' is true in /tmp/root/core/base/src/TString.cxx:2290. 7: Taking true branch in /tmp/root/core/base/src/TString.cxx:2291. 8: Ended va_list in /tmp/root/core/base/src/TString.cxx:2296. 9: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 10: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2297. 11: expanded from macro 'R__VA_COPY' in /tmp/root/core/base/inc/Varargs.h:48. 12: expanded from macro 'va_copy' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:27. 13: Control jumps to line 2287 in /tmp/root/core/base/src/TString.cxx:2299. 14: Assuming the condition is false in /tmp/root/core/base/src/TString.cxx:2290. 15: Left side of '||' is false in /tmp/root/core/base/src/TString.cxx:2290. 16: Assuming 'n' is < 'buflen' in /tmp/root/core/base/src/TString.cxx:2290. 17: Taking false branch in /tmp/root/core/base/src/TString.cxx:2290. 18: 'vc' is 1 in /tmp/root/core/base/src/TString.cxx:2302. 19: Taking true branch in /tmp/root/core/base/src/TString.cxx:2302. 20: Ended va_list in /tmp/root/core/base/src/TString.cxx:2303. 21: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:1258,usability,Tool,Tools,1258,ninitialized]. 1: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 2: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2326. 3: expanded from macro 'va_start' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:17. 4: Calling 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 5: Assuming the condition is true in /tmp/root/core/base/src/TString.cxx:2290. 6: Left side of '||' is true in /tmp/root/core/base/src/TString.cxx:2290. 7: Taking true branch in /tmp/root/core/base/src/TString.cxx:2291. 8: Ended va_list in /tmp/root/core/base/src/TString.cxx:2296. 9: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 10: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2297. 11: expanded from macro 'R__VA_COPY' in /tmp/root/core/base/inc/Varargs.h:48. 12: expanded from macro 'va_copy' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:27. 13: Control jumps to line 2287 in /tmp/root/core/base/src/TString.cxx:2299. 14: Assuming the condition is false in /tmp/root/core/base/src/TString.cxx:2290. 15: Left side of '||' is false in /tmp/root/core/base/src/TString.cxx:2290. 16: Assuming 'n' is < 'buflen' in /tmp/root/core/base/src/TString.cxx:2290. 17: Taking false branch in /tmp/root/core/base/src/TString.cxx:2290. 18: 'vc' is 1 in /tmp/root/core/base/src/TString.cxx:2302. 19: Taking true branch in /tmp/root/core/base/src/TString.cxx:2302. 20: Ended va_list in /tmp/root/core/base/src/TString.cxx:2303. 21: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 22: Returning from 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 23: va_end() is called on an uninitialized va_list in /tmp/root/core/base/src/TString.cxx:2328. 24: expanded from macro 'va_end' in /opt/Qt/Tools/QtCrea,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:1948,usability,Tool,Tools,1948,ator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 2: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2326. 3: expanded from macro 'va_start' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:17. 4: Calling 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 5: Assuming the condition is true in /tmp/root/core/base/src/TString.cxx:2290. 6: Left side of '||' is true in /tmp/root/core/base/src/TString.cxx:2290. 7: Taking true branch in /tmp/root/core/base/src/TString.cxx:2291. 8: Ended va_list in /tmp/root/core/base/src/TString.cxx:2296. 9: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 10: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2297. 11: expanded from macro 'R__VA_COPY' in /tmp/root/core/base/inc/Varargs.h:48. 12: expanded from macro 'va_copy' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:27. 13: Control jumps to line 2287 in /tmp/root/core/base/src/TString.cxx:2299. 14: Assuming the condition is false in /tmp/root/core/base/src/TString.cxx:2290. 15: Left side of '||' is false in /tmp/root/core/base/src/TString.cxx:2290. 16: Assuming 'n' is < 'buflen' in /tmp/root/core/base/src/TString.cxx:2290. 17: Taking false branch in /tmp/root/core/base/src/TString.cxx:2290. 18: 'vc' is 1 in /tmp/root/core/base/src/TString.cxx:2302. 19: Taking true branch in /tmp/root/core/base/src/TString.cxx:2302. 20: Ended va_list in /tmp/root/core/base/src/TString.cxx:2303. 21: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 22: Returning from 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 23: va_end() is called on an uninitialized va_list in /tmp/root/core/base/src/TString.cxx:2328. 24: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:2249,usability,Tool,Tools,2249,ator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 2: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2326. 3: expanded from macro 'va_start' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:17. 4: Calling 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 5: Assuming the condition is true in /tmp/root/core/base/src/TString.cxx:2290. 6: Left side of '||' is true in /tmp/root/core/base/src/TString.cxx:2290. 7: Taking true branch in /tmp/root/core/base/src/TString.cxx:2291. 8: Ended va_list in /tmp/root/core/base/src/TString.cxx:2296. 9: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 10: Initialized va_list in /tmp/root/core/base/src/TString.cxx:2297. 11: expanded from macro 'R__VA_COPY' in /tmp/root/core/base/inc/Varargs.h:48. 12: expanded from macro 'va_copy' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:27. 13: Control jumps to line 2287 in /tmp/root/core/base/src/TString.cxx:2299. 14: Assuming the condition is false in /tmp/root/core/base/src/TString.cxx:2290. 15: Left side of '||' is false in /tmp/root/core/base/src/TString.cxx:2290. 16: Assuming 'n' is < 'buflen' in /tmp/root/core/base/src/TString.cxx:2290. 17: Taking false branch in /tmp/root/core/base/src/TString.cxx:2290. 18: 'vc' is 1 in /tmp/root/core/base/src/TString.cxx:2302. 19: Taking true branch in /tmp/root/core/base/src/TString.cxx:2302. 20: Ended va_list in /tmp/root/core/base/src/TString.cxx:2303. 21: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. 22: Returning from 'TString::FormImp' in /tmp/root/core/base/src/TString.cxx:2327. 23: va_end() is called on an uninitialized va_list in /tmp/root/core/base/src/TString.cxx:2328. 24: expanded from macro 'va_end' in /opt/Qt/Tools/QtCreator/libexec/qtcreator/clang/lib/clang/14.0.3/include/stdarg.h:18. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:49,performance,memor,memory,49,> TString.cxx:1947:1: warning: Potential leak of memory pointed to by 'str_ref.fRep..fLong.fData' [clang-analyzer-cplusplus.NewDeleteLeaks]. Apriori there is no leaks unless somehow `TString::IsLong()` is not returning the right value.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11444:49,usability,memor,memory,49,> TString.cxx:1947:1: warning: Potential leak of memory pointed to by 'str_ref.fRep..fLong.fData' [clang-analyzer-cplusplus.NewDeleteLeaks]. Apriori there is no leaks unless somehow `TString::IsLong()` is not returning the right value.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11444
https://github.com/root-project/root/pull/11445:65,modifiability,variab,variables,65,"The last push didn't change much, just commenting out the unused variables",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11445
https://github.com/root-project/root/pull/11446:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11446
https://github.com/root-project/root/pull/11446:4,safety,test,test,4,All test passes as reported my the related roottest PR: https://github.com/root-project/roottest/pull/906#issuecomment-1265687117.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11446
https://github.com/root-project/root/pull/11446:4,testability,test,test,4,All test passes as reported my the related roottest PR: https://github.com/root-project/roottest/pull/906#issuecomment-1265687117.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11446
https://github.com/root-project/root/issues/11447:307,energy efficiency,model,models,307,"Hi @guitargeek ,. Thanks a lot for checking this. I wonder what is the implication of this inconsistency in NLL values though. Does it mean a multi-range fit using RooFit is fundamentally flawed and should not be used? In our use case, we are trying to obtain the values of the parameters in our background models by fitting to the data sideband. So we are more concerned about the best fit values of the variables in the workspace than the value of the NLL itself. Though from our validation plots, our background model shape obtained from the multi-range fit seems to agree well with the data. My question is then what is the right thing to do if we want to perform a multi-range fit using RooFit? This could potentially have a big impact on the community since a lot of analysis codes/frameworks rely on this multi-range fit method.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:515,energy efficiency,model,model,515,"Hi @guitargeek ,. Thanks a lot for checking this. I wonder what is the implication of this inconsistency in NLL values though. Does it mean a multi-range fit using RooFit is fundamentally flawed and should not be used? In our use case, we are trying to obtain the values of the parameters in our background models by fitting to the data sideband. So we are more concerned about the best fit values of the variables in the workspace than the value of the NLL itself. Though from our validation plots, our background model shape obtained from the multi-range fit seems to agree well with the data. My question is then what is the right thing to do if we want to perform a multi-range fit using RooFit? This could potentially have a big impact on the community since a lot of analysis codes/frameworks rely on this multi-range fit method.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:278,modifiability,paramet,parameters,278,"Hi @guitargeek ,. Thanks a lot for checking this. I wonder what is the implication of this inconsistency in NLL values though. Does it mean a multi-range fit using RooFit is fundamentally flawed and should not be used? In our use case, we are trying to obtain the values of the parameters in our background models by fitting to the data sideband. So we are more concerned about the best fit values of the variables in the workspace than the value of the NLL itself. Though from our validation plots, our background model shape obtained from the multi-range fit seems to agree well with the data. My question is then what is the right thing to do if we want to perform a multi-range fit using RooFit? This could potentially have a big impact on the community since a lot of analysis codes/frameworks rely on this multi-range fit method.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:362,modifiability,concern,concerned,362,"Hi @guitargeek ,. Thanks a lot for checking this. I wonder what is the implication of this inconsistency in NLL values though. Does it mean a multi-range fit using RooFit is fundamentally flawed and should not be used? In our use case, we are trying to obtain the values of the parameters in our background models by fitting to the data sideband. So we are more concerned about the best fit values of the variables in the workspace than the value of the NLL itself. Though from our validation plots, our background model shape obtained from the multi-range fit seems to agree well with the data. My question is then what is the right thing to do if we want to perform a multi-range fit using RooFit? This could potentially have a big impact on the community since a lot of analysis codes/frameworks rely on this multi-range fit method.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:405,modifiability,variab,variables,405,"Hi @guitargeek ,. Thanks a lot for checking this. I wonder what is the implication of this inconsistency in NLL values though. Does it mean a multi-range fit using RooFit is fundamentally flawed and should not be used? In our use case, we are trying to obtain the values of the parameters in our background models by fitting to the data sideband. So we are more concerned about the best fit values of the variables in the workspace than the value of the NLL itself. Though from our validation plots, our background model shape obtained from the multi-range fit seems to agree well with the data. My question is then what is the right thing to do if we want to perform a multi-range fit using RooFit? This could potentially have a big impact on the community since a lot of analysis codes/frameworks rely on this multi-range fit method.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:660,performance,perform,perform,660,"Hi @guitargeek ,. Thanks a lot for checking this. I wonder what is the implication of this inconsistency in NLL values though. Does it mean a multi-range fit using RooFit is fundamentally flawed and should not be used? In our use case, we are trying to obtain the values of the parameters in our background models by fitting to the data sideband. So we are more concerned about the best fit values of the variables in the workspace than the value of the NLL itself. Though from our validation plots, our background model shape obtained from the multi-range fit seems to agree well with the data. My question is then what is the right thing to do if we want to perform a multi-range fit using RooFit? This could potentially have a big impact on the community since a lot of analysis codes/frameworks rely on this multi-range fit method.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:127,reliability,Doe,Does,127,"Hi @guitargeek ,. Thanks a lot for checking this. I wonder what is the implication of this inconsistency in NLL values though. Does it mean a multi-range fit using RooFit is fundamentally flawed and should not be used? In our use case, we are trying to obtain the values of the parameters in our background models by fitting to the data sideband. So we are more concerned about the best fit values of the variables in the workspace than the value of the NLL itself. Though from our validation plots, our background model shape obtained from the multi-range fit seems to agree well with the data. My question is then what is the right thing to do if we want to perform a multi-range fit using RooFit? This could potentially have a big impact on the community since a lot of analysis codes/frameworks rely on this multi-range fit method.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:482,safety,valid,validation,482,"Hi @guitargeek ,. Thanks a lot for checking this. I wonder what is the implication of this inconsistency in NLL values though. Does it mean a multi-range fit using RooFit is fundamentally flawed and should not be used? In our use case, we are trying to obtain the values of the parameters in our background models by fitting to the data sideband. So we are more concerned about the best fit values of the variables in the workspace than the value of the NLL itself. Though from our validation plots, our background model shape obtained from the multi-range fit seems to agree well with the data. My question is then what is the right thing to do if we want to perform a multi-range fit using RooFit? This could potentially have a big impact on the community since a lot of analysis codes/frameworks rely on this multi-range fit method.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:307,security,model,models,307,"Hi @guitargeek ,. Thanks a lot for checking this. I wonder what is the implication of this inconsistency in NLL values though. Does it mean a multi-range fit using RooFit is fundamentally flawed and should not be used? In our use case, we are trying to obtain the values of the parameters in our background models by fitting to the data sideband. So we are more concerned about the best fit values of the variables in the workspace than the value of the NLL itself. Though from our validation plots, our background model shape obtained from the multi-range fit seems to agree well with the data. My question is then what is the right thing to do if we want to perform a multi-range fit using RooFit? This could potentially have a big impact on the community since a lot of analysis codes/frameworks rely on this multi-range fit method.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:482,security,validat,validation,482,"Hi @guitargeek ,. Thanks a lot for checking this. I wonder what is the implication of this inconsistency in NLL values though. Does it mean a multi-range fit using RooFit is fundamentally flawed and should not be used? In our use case, we are trying to obtain the values of the parameters in our background models by fitting to the data sideband. So we are more concerned about the best fit values of the variables in the workspace than the value of the NLL itself. Though from our validation plots, our background model shape obtained from the multi-range fit seems to agree well with the data. My question is then what is the right thing to do if we want to perform a multi-range fit using RooFit? This could potentially have a big impact on the community since a lot of analysis codes/frameworks rely on this multi-range fit method.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:515,security,model,model,515,"Hi @guitargeek ,. Thanks a lot for checking this. I wonder what is the implication of this inconsistency in NLL values though. Does it mean a multi-range fit using RooFit is fundamentally flawed and should not be used? In our use case, we are trying to obtain the values of the parameters in our background models by fitting to the data sideband. So we are more concerned about the best fit values of the variables in the workspace than the value of the NLL itself. Though from our validation plots, our background model shape obtained from the multi-range fit seems to agree well with the data. My question is then what is the right thing to do if we want to perform a multi-range fit using RooFit? This could potentially have a big impact on the community since a lot of analysis codes/frameworks rely on this multi-range fit method.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:362,testability,concern,concerned,362,"Hi @guitargeek ,. Thanks a lot for checking this. I wonder what is the implication of this inconsistency in NLL values though. Does it mean a multi-range fit using RooFit is fundamentally flawed and should not be used? In our use case, we are trying to obtain the values of the parameters in our background models by fitting to the data sideband. So we are more concerned about the best fit values of the variables in the workspace than the value of the NLL itself. Though from our validation plots, our background model shape obtained from the multi-range fit seems to agree well with the data. My question is then what is the right thing to do if we want to perform a multi-range fit using RooFit? This could potentially have a big impact on the community since a lot of analysis codes/frameworks rely on this multi-range fit method.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:660,usability,perform,perform,660,"Hi @guitargeek ,. Thanks a lot for checking this. I wonder what is the implication of this inconsistency in NLL values though. Does it mean a multi-range fit using RooFit is fundamentally flawed and should not be used? In our use case, we are trying to obtain the values of the parameters in our background models by fitting to the data sideband. So we are more concerned about the best fit values of the variables in the workspace than the value of the NLL itself. Though from our validation plots, our background model shape obtained from the multi-range fit seems to agree well with the data. My question is then what is the right thing to do if we want to perform a multi-range fit using RooFit? This could potentially have a big impact on the community since a lot of analysis codes/frameworks rely on this multi-range fit method.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:1540,availability,Error,Error,1540,"nd fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.0295e+00 +/- 1.88e-02. muCat2 5.9955e+00 +/- 1.79e-02. sigma_cat1 1.0105e+00 +/- 2.54e-02. sigma_cat2 9.6702e-01 +/- 2.47e-02. ```. You see that after the fix, you can expect that the precision on some parameters that are sensitive to the relative number of events in the sidebands improves. I hope this clarifies the situation a bit, If you want to discuss and ask more about this, feel free to do so here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:1960,availability,Error,Error,1960,"nd fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.0295e+00 +/- 1.88e-02. muCat2 5.9955e+00 +/- 1.79e-02. sigma_cat1 1.0105e+00 +/- 2.54e-02. sigma_cat2 9.6702e-01 +/- 2.47e-02. ```. You see that after the fix, you can expect that the precision on some parameters that are sensitive to the relative number of events in the sidebands improves. I hope this clarifies the situation a bit, If you want to discuss and ask more about this, feel free to do so here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:249,energy efficiency,optim,optimal,249,"Multi-range fits in RooFit used to behave much different from what the user expected, until I fixed this for 6.26 with PR #7719. Before 6.26, the relative number of events in the different ranges was not considered as information, which lead to sub-optimal fit results because often the relative number of events in the two sidebands can constrain the shape quite a lot. And this is also what people expect: you would expect a sideband fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- -----------",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:1030,energy efficiency,optim,optimal,1030," behave much different from what the user expected, until I fixed this for 6.26 with PR #7719. Before 6.26, the relative number of events in the different ranges was not considered as information, which lead to sub-optimal fit results because often the relative number of events in the two sidebands can constrain the shape quite a lot. And this is also what people expect: you would expect a sideband fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.0295e+00",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:1379,energy efficiency,estimat,estimated,1379,"lso what people expect: you would expect a sideband fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.0295e+00 +/- 1.88e-02. muCat2 5.9955e+00 +/- 1.79e-02. sigma_cat1 1.0105e+00 +/- 2.54e-02. sigma_cat2 9.6702e-01 +/- 2.47e-02. ```. You see that after the fix, you can expect that the precision on some parameters that are sensitive to the relative number of events in the sidebands improves. I hope this clarifies the situation a bit, If you want to discuss ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:1799,energy efficiency,estimat,estimated,1799,"nd fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.0295e+00 +/- 1.88e-02. muCat2 5.9955e+00 +/- 1.79e-02. sigma_cat1 1.0105e+00 +/- 2.54e-02. sigma_cat2 9.6702e-01 +/- 2.47e-02. ```. You see that after the fix, you can expect that the precision on some parameters that are sensitive to the relative number of events in the sidebands improves. I hope this clarifies the situation a bit, If you want to discuss and ask more about this, feel free to do so here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:165,integrability,event,events,165,"Multi-range fits in RooFit used to behave much different from what the user expected, until I fixed this for 6.26 with PR #7719. Before 6.26, the relative number of events in the different ranges was not considered as information, which lead to sub-optimal fit results because often the relative number of events in the two sidebands can constrain the shape quite a lot. And this is also what people expect: you would expect a sideband fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- -----------",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:245,integrability,sub,sub-optimal,245,"Multi-range fits in RooFit used to behave much different from what the user expected, until I fixed this for 6.26 with PR #7719. Before 6.26, the relative number of events in the different ranges was not considered as information, which lead to sub-optimal fit results because often the relative number of events in the two sidebands can constrain the shape quite a lot. And this is also what people expect: you would expect a sideband fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- -----------",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:306,integrability,event,events,306,"Multi-range fits in RooFit used to behave much different from what the user expected, until I fixed this for 6.26 with PR #7719. Before 6.26, the relative number of events in the different ranges was not considered as information, which lead to sub-optimal fit results because often the relative number of events in the two sidebands can constrain the shape quite a lot. And this is also what people expect: you would expect a sideband fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- -----------",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:2284,integrability,event,events,2284,"nd fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.0295e+00 +/- 1.88e-02. muCat2 5.9955e+00 +/- 1.79e-02. sigma_cat1 1.0105e+00 +/- 2.54e-02. sigma_cat2 9.6702e-01 +/- 2.47e-02. ```. You see that after the fix, you can expect that the precision on some parameters that are sensitive to the relative number of events in the sidebands improves. I hope this clarifies the situation a bit, If you want to discuss and ask more about this, feel free to do so here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:1515,modifiability,Paramet,Parameter,1515,"nd fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.0295e+00 +/- 1.88e-02. muCat2 5.9955e+00 +/- 1.79e-02. sigma_cat1 1.0105e+00 +/- 2.54e-02. sigma_cat2 9.6702e-01 +/- 2.47e-02. ```. You see that after the fix, you can expect that the precision on some parameters that are sensitive to the relative number of events in the sidebands improves. I hope this clarifies the situation a bit, If you want to discuss and ask more about this, feel free to do so here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:1935,modifiability,Paramet,Parameter,1935,"nd fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.0295e+00 +/- 1.88e-02. muCat2 5.9955e+00 +/- 1.79e-02. sigma_cat1 1.0105e+00 +/- 2.54e-02. sigma_cat2 9.6702e-01 +/- 2.47e-02. ```. You see that after the fix, you can expect that the precision on some parameters that are sensitive to the relative number of events in the sidebands improves. I hope this clarifies the situation a bit, If you want to discuss and ask more about this, feel free to do so here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:2228,modifiability,paramet,parameters,2228,"nd fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.0295e+00 +/- 1.88e-02. muCat2 5.9955e+00 +/- 1.79e-02. sigma_cat1 1.0105e+00 +/- 2.54e-02. sigma_cat2 9.6702e-01 +/- 2.47e-02. ```. You see that after the fix, you can expect that the precision on some parameters that are sensitive to the relative number of events in the sidebands improves. I hope this clarifies the situation a bit, If you want to discuss and ask more about this, feel free to do so here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:1540,performance,Error,Error,1540,"nd fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.0295e+00 +/- 1.88e-02. muCat2 5.9955e+00 +/- 1.79e-02. sigma_cat1 1.0105e+00 +/- 2.54e-02. sigma_cat2 9.6702e-01 +/- 2.47e-02. ```. You see that after the fix, you can expect that the precision on some parameters that are sensitive to the relative number of events in the sidebands improves. I hope this clarifies the situation a bit, If you want to discuss and ask more about this, feel free to do so here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:1960,performance,Error,Error,1960,"nd fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.0295e+00 +/- 1.88e-02. muCat2 5.9955e+00 +/- 1.79e-02. sigma_cat1 1.0105e+00 +/- 2.54e-02. sigma_cat2 9.6702e-01 +/- 2.47e-02. ```. You see that after the fix, you can expect that the precision on some parameters that are sensitive to the relative number of events in the sidebands improves. I hope this clarifies the situation a bit, If you want to discuss and ask more about this, feel free to do so here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:1146,safety,test,test,1146,"lative number of events in the different ranges was not considered as information, which lead to sub-optimal fit results because often the relative number of events in the two sidebands can constrain the shape quite a lot. And this is also what people expect: you would expect a sideband fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.0295e+00 +/- 1.88e-02. muCat2 5.9955e+00 +/- 1.79e-02. sigma_cat1 1.0105e+00 +/- 2.54e-02. sigma_cat2 9.6702e-01 +/- 2.47e",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:1219,safety,test,test,1219,"ormation, which lead to sub-optimal fit results because often the relative number of events in the two sidebands can constrain the shape quite a lot. And this is also what people expect: you would expect a sideband fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.0295e+00 +/- 1.88e-02. muCat2 5.9955e+00 +/- 1.79e-02. sigma_cat1 1.0105e+00 +/- 2.54e-02. sigma_cat2 9.6702e-01 +/- 2.47e-02. ```. You see that after the fix, you can expect that the precision o",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:1224,safety,test,testRooSimultaneous,1224,"ch lead to sub-optimal fit results because often the relative number of events in the two sidebands can constrain the shape quite a lot. And this is also what people expect: you would expect a sideband fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.0295e+00 +/- 1.88e-02. muCat2 5.9955e+00 +/- 1.79e-02. sigma_cat1 1.0105e+00 +/- 2.54e-02. sigma_cat2 9.6702e-01 +/- 2.47e-02. ```. You see that after the fix, you can expect that the precision on some parame",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:1540,safety,Error,Error,1540,"nd fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.0295e+00 +/- 1.88e-02. muCat2 5.9955e+00 +/- 1.79e-02. sigma_cat1 1.0105e+00 +/- 2.54e-02. sigma_cat2 9.6702e-01 +/- 2.47e-02. ```. You see that after the fix, you can expect that the precision on some parameters that are sensitive to the relative number of events in the sidebands improves. I hope this clarifies the situation a bit, If you want to discuss and ask more about this, feel free to do so here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:1960,safety,Error,Error,1960,"nd fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.0295e+00 +/- 1.88e-02. muCat2 5.9955e+00 +/- 1.79e-02. sigma_cat1 1.0105e+00 +/- 2.54e-02. sigma_cat2 9.6702e-01 +/- 2.47e-02. ```. You see that after the fix, you can expect that the precision on some parameters that are sensitive to the relative number of events in the sidebands improves. I hope this clarifies the situation a bit, If you want to discuss and ask more about this, feel free to do so here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:506,security,sign,signal,506,"Multi-range fits in RooFit used to behave much different from what the user expected, until I fixed this for 6.26 with PR #7719. Before 6.26, the relative number of events in the different ranges was not considered as information, which lead to sub-optimal fit results because often the relative number of events in the two sidebands can constrain the shape quite a lot. And this is also what people expect: you would expect a sideband fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- -----------",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:670,testability,simul,simultaneous,670,"Multi-range fits in RooFit used to behave much different from what the user expected, until I fixed this for 6.26 with PR #7719. Before 6.26, the relative number of events in the different ranges was not considered as information, which lead to sub-optimal fit results because often the relative number of events in the two sidebands can constrain the shape quite a lot. And this is also what people expect: you would expect a sideband fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- -----------",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:721,testability,simul,simultaneous,721,"Multi-range fits in RooFit used to behave much different from what the user expected, until I fixed this for 6.26 with PR #7719. Before 6.26, the relative number of events in the different ranges was not considered as information, which lead to sub-optimal fit results because often the relative number of events in the two sidebands can constrain the shape quite a lot. And this is also what people expect: you would expect a sideband fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- -----------",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:1110,testability,simul,simultaneous,1110,"th PR #7719. Before 6.26, the relative number of events in the different ranges was not considered as information, which lead to sub-optimal fit results because often the relative number of events in the two sidebands can constrain the shape quite a lot. And this is also what people expect: you would expect a sideband fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.0295e+00 +/- 1.88e-02. muCat2 5.9955e+00 +/- 1.79e-02. sigma_cat1 1.0105e+00 +/- 2.54e-02.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:1141,testability,unit,unit,1141,"he relative number of events in the different ranges was not considered as information, which lead to sub-optimal fit results because often the relative number of events in the two sidebands can constrain the shape quite a lot. And this is also what people expect: you would expect a sideband fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.0295e+00 +/- 1.88e-02. muCat2 5.9955e+00 +/- 1.79e-02. sigma_cat1 1.0105e+00 +/- 2.54e-02. sigma_cat2 9.6702e-01 +/- ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:1146,testability,test,test,1146,"lative number of events in the different ranges was not considered as information, which lead to sub-optimal fit results because often the relative number of events in the two sidebands can constrain the shape quite a lot. And this is also what people expect: you would expect a sideband fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.0295e+00 +/- 1.88e-02. muCat2 5.9955e+00 +/- 1.79e-02. sigma_cat1 1.0105e+00 +/- 2.54e-02. sigma_cat2 9.6702e-01 +/- 2.47e",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:1219,testability,test,test,1219,"ormation, which lead to sub-optimal fit results because often the relative number of events in the two sidebands can constrain the shape quite a lot. And this is also what people expect: you would expect a sideband fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.0295e+00 +/- 1.88e-02. muCat2 5.9955e+00 +/- 1.79e-02. sigma_cat1 1.0105e+00 +/- 2.54e-02. sigma_cat2 9.6702e-01 +/- 2.47e-02. ```. You see that after the fix, you can expect that the precision o",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:1224,testability,test,testRooSimultaneous,1224,"ch lead to sub-optimal fit results because often the relative number of events in the two sidebands can constrain the shape quite a lot. And this is also what people expect: you would expect a sideband fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.0295e+00 +/- 1.88e-02. muCat2 5.9955e+00 +/- 1.79e-02. sigma_cat1 1.0105e+00 +/- 2.54e-02. sigma_cat2 9.6702e-01 +/- 2.47e-02. ```. You see that after the fix, you can expect that the precision on some parame",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:71,usability,user,user,71,"Multi-range fits in RooFit used to behave much different from what the user expected, until I fixed this for 6.26 with PR #7719. Before 6.26, the relative number of events in the different ranges was not considered as information, which lead to sub-optimal fit results because often the relative number of events in the two sidebands can constrain the shape quite a lot. And this is also what people expect: you would expect a sideband fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- -----------",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:1051,usability,user,users,1051,"nt from what the user expected, until I fixed this for 6.26 with PR #7719. Before 6.26, the relative number of events in the different ranges was not considered as information, which lead to sub-optimal fit results because often the relative number of events in the two sidebands can constrain the shape quite a lot. And this is also what people expect: you would expect a sideband fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.0295e+00 +/- 1.88e-02. muCat",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:1349,usability,minim,minimized,1349,"ape quite a lot. And this is also what people expect: you would expect a sideband fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.0295e+00 +/- 1.88e-02. muCat2 5.9955e+00 +/- 1.79e-02. sigma_cat1 1.0105e+00 +/- 2.54e-02. sigma_cat2 9.6702e-01 +/- 2.47e-02. ```. You see that after the fix, you can expect that the precision on some parameters that are sensitive to the relative number of events in the sidebands improves. I hope this clarifies the situation ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:1401,usability,minim,minimum,1401,"t: you would expect a sideband fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.0295e+00 +/- 1.88e-02. muCat2 5.9955e+00 +/- 1.79e-02. sigma_cat1 1.0105e+00 +/- 2.54e-02. sigma_cat2 9.6702e-01 +/- 2.47e-02. ```. You see that after the fix, you can expect that the precision on some parameters that are sensitive to the relative number of events in the sidebands improves. I hope this clarifies the situation a bit, If you want to discuss and ask more about th",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:1484,usability,Statu,Status,1484,"nd fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.0295e+00 +/- 1.88e-02. muCat2 5.9955e+00 +/- 1.79e-02. sigma_cat1 1.0105e+00 +/- 2.54e-02. sigma_cat2 9.6702e-01 +/- 2.47e-02. ```. You see that after the fix, you can expect that the precision on some parameters that are sensitive to the relative number of events in the sidebands improves. I hope this clarifies the situation a bit, If you want to discuss and ask more about this, feel free to do so here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:1493,usability,MINIM,MINIMIZE,1493,"nd fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.0295e+00 +/- 1.88e-02. muCat2 5.9955e+00 +/- 1.79e-02. sigma_cat1 1.0105e+00 +/- 2.54e-02. sigma_cat2 9.6702e-01 +/- 2.47e-02. ```. You see that after the fix, you can expect that the precision on some parameters that are sensitive to the relative number of events in the sidebands improves. I hope this clarifies the situation a bit, If you want to discuss and ask more about this, feel free to do so here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:1540,usability,Error,Error,1540,"nd fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.0295e+00 +/- 1.88e-02. muCat2 5.9955e+00 +/- 1.79e-02. sigma_cat1 1.0105e+00 +/- 2.54e-02. sigma_cat2 9.6702e-01 +/- 2.47e-02. ```. You see that after the fix, you can expect that the precision on some parameters that are sensitive to the relative number of events in the sidebands improves. I hope this clarifies the situation a bit, If you want to discuss and ask more about this, feel free to do so here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:1769,usability,minim,minimized,1769,"nd fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.0295e+00 +/- 1.88e-02. muCat2 5.9955e+00 +/- 1.79e-02. sigma_cat1 1.0105e+00 +/- 2.54e-02. sigma_cat2 9.6702e-01 +/- 2.47e-02. ```. You see that after the fix, you can expect that the precision on some parameters that are sensitive to the relative number of events in the sidebands improves. I hope this clarifies the situation a bit, If you want to discuss and ask more about this, feel free to do so here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:1821,usability,minim,minimum,1821,"nd fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.0295e+00 +/- 1.88e-02. muCat2 5.9955e+00 +/- 1.79e-02. sigma_cat1 1.0105e+00 +/- 2.54e-02. sigma_cat2 9.6702e-01 +/- 2.47e-02. ```. You see that after the fix, you can expect that the precision on some parameters that are sensitive to the relative number of events in the sidebands improves. I hope this clarifies the situation a bit, If you want to discuss and ask more about this, feel free to do so here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:1904,usability,Statu,Status,1904,"nd fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.0295e+00 +/- 1.88e-02. muCat2 5.9955e+00 +/- 1.79e-02. sigma_cat1 1.0105e+00 +/- 2.54e-02. sigma_cat2 9.6702e-01 +/- 2.47e-02. ```. You see that after the fix, you can expect that the precision on some parameters that are sensitive to the relative number of events in the sidebands improves. I hope this clarifies the situation a bit, If you want to discuss and ask more about this, feel free to do so here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:1913,usability,MINIM,MINIMIZE,1913,"nd fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.0295e+00 +/- 1.88e-02. muCat2 5.9955e+00 +/- 1.79e-02. sigma_cat1 1.0105e+00 +/- 2.54e-02. sigma_cat2 9.6702e-01 +/- 2.47e-02. ```. You see that after the fix, you can expect that the precision on some parameters that are sensitive to the relative number of events in the sidebands improves. I hope this clarifies the situation a bit, If you want to discuss and ask more about this, feel free to do so here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:1960,usability,Error,Error,1960,"nd fit to be equivalent to the full fit, only with some information in a signal region left out. While I thought I have fixed this problem for good, you revealed with one of your earlier GitHub issues that I have only solved it for *non-simultaneous fits*, and for 6.28 I will fix it for simultaneous PDFs too, with the PR linked in this issue. So yes, this issue affects the best fit values for multi-range fits with RooSimultaneous and you should take all these results with a grain of salt. While the results are fortunately still well defined mathematically as I explained above, they are not optimal and not what users expect. For illustration, here I fit the multi-range simultaneous NLL [from the new unit test](https://github.com/root-project/root/blob/master/roofit/roofitcore/test/testRooSimultaneous.cxx#L136) before and after the fix that yet has to be merged to master:. **Before:**. ```. RooFitResult: minimized FCN value: 31174.6, estimated distance to minimum: 9.97488e-07. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.1762e+00 +/- 1.32e-01. muCat2 6.2315e+00 +/- 1.33e-01. sigma_cat1 1.0064e+00 +/- 2.54e-02. sigma_cat2 9.6606e-01 +/- 2.48e-02. ```. **After:**. ```. RooFitResult: minimized FCN value: 1368.32, estimated distance to minimum: 9.21927e-06. covariance matrix quality: Full, accurate covariance matrix. Status : MINIMIZE=0 . Floating Parameter FinalValue +/- Error . -------------------- --------------------------. muCat1 4.0295e+00 +/- 1.88e-02. muCat2 5.9955e+00 +/- 1.79e-02. sigma_cat1 1.0105e+00 +/- 2.54e-02. sigma_cat2 9.6702e-01 +/- 2.47e-02. ```. You see that after the fix, you can expect that the precision on some parameters that are sensitive to the relative number of events in the sidebands improves. I hope this clarifies the situation a bit, If you want to discuss and ask more about this, feel free to do so here!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:70,deployability,version,versions,70,"Thanks @guitargeek,. Is there a workaround for users using older root versions to get the expected behavior? Or we can only wait until the patches are made e.g. in 6.28?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:139,deployability,patch,patches,139,"Thanks @guitargeek,. Is there a workaround for users using older root versions to get the expected behavior? Or we can only wait until the patches are made e.g. in 6.28?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:70,integrability,version,versions,70,"Thanks @guitargeek,. Is there a workaround for users using older root versions to get the expected behavior? Or we can only wait until the patches are made e.g. in 6.28?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:70,modifiability,version,versions,70,"Thanks @guitargeek,. Is there a workaround for users using older root versions to get the expected behavior? Or we can only wait until the patches are made e.g. in 6.28?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:139,safety,patch,patches,139,"Thanks @guitargeek,. Is there a workaround for users using older root versions to get the expected behavior? Or we can only wait until the patches are made e.g. in 6.28?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:139,security,patch,patches,139,"Thanks @guitargeek,. Is there a workaround for users using older root versions to get the expected behavior? Or we can only wait until the patches are made e.g. in 6.28?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:47,usability,user,users,47,"Thanks @guitargeek,. Is there a workaround for users using older root versions to get the expected behavior? Or we can only wait until the patches are made e.g. in 6.28?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:99,usability,behavi,behavior,99,"Thanks @guitargeek,. Is there a workaround for users using older root versions to get the expected behavior? Or we can only wait until the patches are made e.g. in 6.28?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:48,deployability,build,build,48,"In 6.26, just don't use the RooSimultaneous and build your NLL as a sum of per-channel NLLs instead, using RooAddition. This is what I also do in the updated cross-check for the simultaneous fit in this PR #11455 ( see the `testRooSimultaneous` file). In 6.24 or older, you would have to further all all these multi-range normalization correction integrals to the RooAddition, like I introduced it under the hood in #7719. But I would not advice doing this unless you carefully validate that you implemented the math correctly. Then, I also have a little hack for you that would work in all ROOT versions: the whole problem **does not affect extended fits**, as explained in this tutorial from ROOT 6.24: https://root.cern.ch/doc/v624/rf204b__extendedLikelihood__rangedFit_8C.html. So even if you don't care about doing an extended fit, by making your PDF an extended one and then ignoring the normalization parameter you're all set. If you already do an extended fit, you also don't have to worry at all about the multi-ranged fits,even with the RooSimultaneous.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:150,deployability,updat,updated,150,"In 6.26, just don't use the RooSimultaneous and build your NLL as a sum of per-channel NLLs instead, using RooAddition. This is what I also do in the updated cross-check for the simultaneous fit in this PR #11455 ( see the `testRooSimultaneous` file). In 6.24 or older, you would have to further all all these multi-range normalization correction integrals to the RooAddition, like I introduced it under the hood in #7719. But I would not advice doing this unless you carefully validate that you implemented the math correctly. Then, I also have a little hack for you that would work in all ROOT versions: the whole problem **does not affect extended fits**, as explained in this tutorial from ROOT 6.24: https://root.cern.ch/doc/v624/rf204b__extendedLikelihood__rangedFit_8C.html. So even if you don't care about doing an extended fit, by making your PDF an extended one and then ignoring the normalization parameter you're all set. If you already do an extended fit, you also don't have to worry at all about the multi-ranged fits,even with the RooSimultaneous.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:347,deployability,integr,integrals,347,"In 6.26, just don't use the RooSimultaneous and build your NLL as a sum of per-channel NLLs instead, using RooAddition. This is what I also do in the updated cross-check for the simultaneous fit in this PR #11455 ( see the `testRooSimultaneous` file). In 6.24 or older, you would have to further all all these multi-range normalization correction integrals to the RooAddition, like I introduced it under the hood in #7719. But I would not advice doing this unless you carefully validate that you implemented the math correctly. Then, I also have a little hack for you that would work in all ROOT versions: the whole problem **does not affect extended fits**, as explained in this tutorial from ROOT 6.24: https://root.cern.ch/doc/v624/rf204b__extendedLikelihood__rangedFit_8C.html. So even if you don't care about doing an extended fit, by making your PDF an extended one and then ignoring the normalization parameter you're all set. If you already do an extended fit, you also don't have to worry at all about the multi-ranged fits,even with the RooSimultaneous.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:596,deployability,version,versions,596,"In 6.26, just don't use the RooSimultaneous and build your NLL as a sum of per-channel NLLs instead, using RooAddition. This is what I also do in the updated cross-check for the simultaneous fit in this PR #11455 ( see the `testRooSimultaneous` file). In 6.24 or older, you would have to further all all these multi-range normalization correction integrals to the RooAddition, like I introduced it under the hood in #7719. But I would not advice doing this unless you carefully validate that you implemented the math correctly. Then, I also have a little hack for you that would work in all ROOT versions: the whole problem **does not affect extended fits**, as explained in this tutorial from ROOT 6.24: https://root.cern.ch/doc/v624/rf204b__extendedLikelihood__rangedFit_8C.html. So even if you don't care about doing an extended fit, by making your PDF an extended one and then ignoring the normalization parameter you're all set. If you already do an extended fit, you also don't have to worry at all about the multi-ranged fits,even with the RooSimultaneous.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:347,integrability,integr,integrals,347,"In 6.26, just don't use the RooSimultaneous and build your NLL as a sum of per-channel NLLs instead, using RooAddition. This is what I also do in the updated cross-check for the simultaneous fit in this PR #11455 ( see the `testRooSimultaneous` file). In 6.24 or older, you would have to further all all these multi-range normalization correction integrals to the RooAddition, like I introduced it under the hood in #7719. But I would not advice doing this unless you carefully validate that you implemented the math correctly. Then, I also have a little hack for you that would work in all ROOT versions: the whole problem **does not affect extended fits**, as explained in this tutorial from ROOT 6.24: https://root.cern.ch/doc/v624/rf204b__extendedLikelihood__rangedFit_8C.html. So even if you don't care about doing an extended fit, by making your PDF an extended one and then ignoring the normalization parameter you're all set. If you already do an extended fit, you also don't have to worry at all about the multi-ranged fits,even with the RooSimultaneous.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:596,integrability,version,versions,596,"In 6.26, just don't use the RooSimultaneous and build your NLL as a sum of per-channel NLLs instead, using RooAddition. This is what I also do in the updated cross-check for the simultaneous fit in this PR #11455 ( see the `testRooSimultaneous` file). In 6.24 or older, you would have to further all all these multi-range normalization correction integrals to the RooAddition, like I introduced it under the hood in #7719. But I would not advice doing this unless you carefully validate that you implemented the math correctly. Then, I also have a little hack for you that would work in all ROOT versions: the whole problem **does not affect extended fits**, as explained in this tutorial from ROOT 6.24: https://root.cern.ch/doc/v624/rf204b__extendedLikelihood__rangedFit_8C.html. So even if you don't care about doing an extended fit, by making your PDF an extended one and then ignoring the normalization parameter you're all set. If you already do an extended fit, you also don't have to worry at all about the multi-ranged fits,even with the RooSimultaneous.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:347,interoperability,integr,integrals,347,"In 6.26, just don't use the RooSimultaneous and build your NLL as a sum of per-channel NLLs instead, using RooAddition. This is what I also do in the updated cross-check for the simultaneous fit in this PR #11455 ( see the `testRooSimultaneous` file). In 6.24 or older, you would have to further all all these multi-range normalization correction integrals to the RooAddition, like I introduced it under the hood in #7719. But I would not advice doing this unless you carefully validate that you implemented the math correctly. Then, I also have a little hack for you that would work in all ROOT versions: the whole problem **does not affect extended fits**, as explained in this tutorial from ROOT 6.24: https://root.cern.ch/doc/v624/rf204b__extendedLikelihood__rangedFit_8C.html. So even if you don't care about doing an extended fit, by making your PDF an extended one and then ignoring the normalization parameter you're all set. If you already do an extended fit, you also don't have to worry at all about the multi-ranged fits,even with the RooSimultaneous.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:347,modifiability,integr,integrals,347,"In 6.26, just don't use the RooSimultaneous and build your NLL as a sum of per-channel NLLs instead, using RooAddition. This is what I also do in the updated cross-check for the simultaneous fit in this PR #11455 ( see the `testRooSimultaneous` file). In 6.24 or older, you would have to further all all these multi-range normalization correction integrals to the RooAddition, like I introduced it under the hood in #7719. But I would not advice doing this unless you carefully validate that you implemented the math correctly. Then, I also have a little hack for you that would work in all ROOT versions: the whole problem **does not affect extended fits**, as explained in this tutorial from ROOT 6.24: https://root.cern.ch/doc/v624/rf204b__extendedLikelihood__rangedFit_8C.html. So even if you don't care about doing an extended fit, by making your PDF an extended one and then ignoring the normalization parameter you're all set. If you already do an extended fit, you also don't have to worry at all about the multi-ranged fits,even with the RooSimultaneous.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:596,modifiability,version,versions,596,"In 6.26, just don't use the RooSimultaneous and build your NLL as a sum of per-channel NLLs instead, using RooAddition. This is what I also do in the updated cross-check for the simultaneous fit in this PR #11455 ( see the `testRooSimultaneous` file). In 6.24 or older, you would have to further all all these multi-range normalization correction integrals to the RooAddition, like I introduced it under the hood in #7719. But I would not advice doing this unless you carefully validate that you implemented the math correctly. Then, I also have a little hack for you that would work in all ROOT versions: the whole problem **does not affect extended fits**, as explained in this tutorial from ROOT 6.24: https://root.cern.ch/doc/v624/rf204b__extendedLikelihood__rangedFit_8C.html. So even if you don't care about doing an extended fit, by making your PDF an extended one and then ignoring the normalization parameter you're all set. If you already do an extended fit, you also don't have to worry at all about the multi-ranged fits,even with the RooSimultaneous.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:642,modifiability,exten,extended,642,"In 6.26, just don't use the RooSimultaneous and build your NLL as a sum of per-channel NLLs instead, using RooAddition. This is what I also do in the updated cross-check for the simultaneous fit in this PR #11455 ( see the `testRooSimultaneous` file). In 6.24 or older, you would have to further all all these multi-range normalization correction integrals to the RooAddition, like I introduced it under the hood in #7719. But I would not advice doing this unless you carefully validate that you implemented the math correctly. Then, I also have a little hack for you that would work in all ROOT versions: the whole problem **does not affect extended fits**, as explained in this tutorial from ROOT 6.24: https://root.cern.ch/doc/v624/rf204b__extendedLikelihood__rangedFit_8C.html. So even if you don't care about doing an extended fit, by making your PDF an extended one and then ignoring the normalization parameter you're all set. If you already do an extended fit, you also don't have to worry at all about the multi-ranged fits,even with the RooSimultaneous.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:823,modifiability,exten,extended,823,"In 6.26, just don't use the RooSimultaneous and build your NLL as a sum of per-channel NLLs instead, using RooAddition. This is what I also do in the updated cross-check for the simultaneous fit in this PR #11455 ( see the `testRooSimultaneous` file). In 6.24 or older, you would have to further all all these multi-range normalization correction integrals to the RooAddition, like I introduced it under the hood in #7719. But I would not advice doing this unless you carefully validate that you implemented the math correctly. Then, I also have a little hack for you that would work in all ROOT versions: the whole problem **does not affect extended fits**, as explained in this tutorial from ROOT 6.24: https://root.cern.ch/doc/v624/rf204b__extendedLikelihood__rangedFit_8C.html. So even if you don't care about doing an extended fit, by making your PDF an extended one and then ignoring the normalization parameter you're all set. If you already do an extended fit, you also don't have to worry at all about the multi-ranged fits,even with the RooSimultaneous.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:859,modifiability,exten,extended,859,"In 6.26, just don't use the RooSimultaneous and build your NLL as a sum of per-channel NLLs instead, using RooAddition. This is what I also do in the updated cross-check for the simultaneous fit in this PR #11455 ( see the `testRooSimultaneous` file). In 6.24 or older, you would have to further all all these multi-range normalization correction integrals to the RooAddition, like I introduced it under the hood in #7719. But I would not advice doing this unless you carefully validate that you implemented the math correctly. Then, I also have a little hack for you that would work in all ROOT versions: the whole problem **does not affect extended fits**, as explained in this tutorial from ROOT 6.24: https://root.cern.ch/doc/v624/rf204b__extendedLikelihood__rangedFit_8C.html. So even if you don't care about doing an extended fit, by making your PDF an extended one and then ignoring the normalization parameter you're all set. If you already do an extended fit, you also don't have to worry at all about the multi-ranged fits,even with the RooSimultaneous.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:908,modifiability,paramet,parameter,908,"In 6.26, just don't use the RooSimultaneous and build your NLL as a sum of per-channel NLLs instead, using RooAddition. This is what I also do in the updated cross-check for the simultaneous fit in this PR #11455 ( see the `testRooSimultaneous` file). In 6.24 or older, you would have to further all all these multi-range normalization correction integrals to the RooAddition, like I introduced it under the hood in #7719. But I would not advice doing this unless you carefully validate that you implemented the math correctly. Then, I also have a little hack for you that would work in all ROOT versions: the whole problem **does not affect extended fits**, as explained in this tutorial from ROOT 6.24: https://root.cern.ch/doc/v624/rf204b__extendedLikelihood__rangedFit_8C.html. So even if you don't care about doing an extended fit, by making your PDF an extended one and then ignoring the normalization parameter you're all set. If you already do an extended fit, you also don't have to worry at all about the multi-ranged fits,even with the RooSimultaneous.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:955,modifiability,exten,extended,955,"In 6.26, just don't use the RooSimultaneous and build your NLL as a sum of per-channel NLLs instead, using RooAddition. This is what I also do in the updated cross-check for the simultaneous fit in this PR #11455 ( see the `testRooSimultaneous` file). In 6.24 or older, you would have to further all all these multi-range normalization correction integrals to the RooAddition, like I introduced it under the hood in #7719. But I would not advice doing this unless you carefully validate that you implemented the math correctly. Then, I also have a little hack for you that would work in all ROOT versions: the whole problem **does not affect extended fits**, as explained in this tutorial from ROOT 6.24: https://root.cern.ch/doc/v624/rf204b__extendedLikelihood__rangedFit_8C.html. So even if you don't care about doing an extended fit, by making your PDF an extended one and then ignoring the normalization parameter you're all set. If you already do an extended fit, you also don't have to worry at all about the multi-ranged fits,even with the RooSimultaneous.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:347,reliability,integr,integrals,347,"In 6.26, just don't use the RooSimultaneous and build your NLL as a sum of per-channel NLLs instead, using RooAddition. This is what I also do in the updated cross-check for the simultaneous fit in this PR #11455 ( see the `testRooSimultaneous` file). In 6.24 or older, you would have to further all all these multi-range normalization correction integrals to the RooAddition, like I introduced it under the hood in #7719. But I would not advice doing this unless you carefully validate that you implemented the math correctly. Then, I also have a little hack for you that would work in all ROOT versions: the whole problem **does not affect extended fits**, as explained in this tutorial from ROOT 6.24: https://root.cern.ch/doc/v624/rf204b__extendedLikelihood__rangedFit_8C.html. So even if you don't care about doing an extended fit, by making your PDF an extended one and then ignoring the normalization parameter you're all set. If you already do an extended fit, you also don't have to worry at all about the multi-ranged fits,even with the RooSimultaneous.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:626,reliability,doe,does,626,"In 6.26, just don't use the RooSimultaneous and build your NLL as a sum of per-channel NLLs instead, using RooAddition. This is what I also do in the updated cross-check for the simultaneous fit in this PR #11455 ( see the `testRooSimultaneous` file). In 6.24 or older, you would have to further all all these multi-range normalization correction integrals to the RooAddition, like I introduced it under the hood in #7719. But I would not advice doing this unless you carefully validate that you implemented the math correctly. Then, I also have a little hack for you that would work in all ROOT versions: the whole problem **does not affect extended fits**, as explained in this tutorial from ROOT 6.24: https://root.cern.ch/doc/v624/rf204b__extendedLikelihood__rangedFit_8C.html. So even if you don't care about doing an extended fit, by making your PDF an extended one and then ignoring the normalization parameter you're all set. If you already do an extended fit, you also don't have to worry at all about the multi-ranged fits,even with the RooSimultaneous.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:150,safety,updat,updated,150,"In 6.26, just don't use the RooSimultaneous and build your NLL as a sum of per-channel NLLs instead, using RooAddition. This is what I also do in the updated cross-check for the simultaneous fit in this PR #11455 ( see the `testRooSimultaneous` file). In 6.24 or older, you would have to further all all these multi-range normalization correction integrals to the RooAddition, like I introduced it under the hood in #7719. But I would not advice doing this unless you carefully validate that you implemented the math correctly. Then, I also have a little hack for you that would work in all ROOT versions: the whole problem **does not affect extended fits**, as explained in this tutorial from ROOT 6.24: https://root.cern.ch/doc/v624/rf204b__extendedLikelihood__rangedFit_8C.html. So even if you don't care about doing an extended fit, by making your PDF an extended one and then ignoring the normalization parameter you're all set. If you already do an extended fit, you also don't have to worry at all about the multi-ranged fits,even with the RooSimultaneous.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:224,safety,test,testRooSimultaneous,224,"In 6.26, just don't use the RooSimultaneous and build your NLL as a sum of per-channel NLLs instead, using RooAddition. This is what I also do in the updated cross-check for the simultaneous fit in this PR #11455 ( see the `testRooSimultaneous` file). In 6.24 or older, you would have to further all all these multi-range normalization correction integrals to the RooAddition, like I introduced it under the hood in #7719. But I would not advice doing this unless you carefully validate that you implemented the math correctly. Then, I also have a little hack for you that would work in all ROOT versions: the whole problem **does not affect extended fits**, as explained in this tutorial from ROOT 6.24: https://root.cern.ch/doc/v624/rf204b__extendedLikelihood__rangedFit_8C.html. So even if you don't care about doing an extended fit, by making your PDF an extended one and then ignoring the normalization parameter you're all set. If you already do an extended fit, you also don't have to worry at all about the multi-ranged fits,even with the RooSimultaneous.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:478,safety,valid,validate,478,"In 6.26, just don't use the RooSimultaneous and build your NLL as a sum of per-channel NLLs instead, using RooAddition. This is what I also do in the updated cross-check for the simultaneous fit in this PR #11455 ( see the `testRooSimultaneous` file). In 6.24 or older, you would have to further all all these multi-range normalization correction integrals to the RooAddition, like I introduced it under the hood in #7719. But I would not advice doing this unless you carefully validate that you implemented the math correctly. Then, I also have a little hack for you that would work in all ROOT versions: the whole problem **does not affect extended fits**, as explained in this tutorial from ROOT 6.24: https://root.cern.ch/doc/v624/rf204b__extendedLikelihood__rangedFit_8C.html. So even if you don't care about doing an extended fit, by making your PDF an extended one and then ignoring the normalization parameter you're all set. If you already do an extended fit, you also don't have to worry at all about the multi-ranged fits,even with the RooSimultaneous.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:150,security,updat,updated,150,"In 6.26, just don't use the RooSimultaneous and build your NLL as a sum of per-channel NLLs instead, using RooAddition. This is what I also do in the updated cross-check for the simultaneous fit in this PR #11455 ( see the `testRooSimultaneous` file). In 6.24 or older, you would have to further all all these multi-range normalization correction integrals to the RooAddition, like I introduced it under the hood in #7719. But I would not advice doing this unless you carefully validate that you implemented the math correctly. Then, I also have a little hack for you that would work in all ROOT versions: the whole problem **does not affect extended fits**, as explained in this tutorial from ROOT 6.24: https://root.cern.ch/doc/v624/rf204b__extendedLikelihood__rangedFit_8C.html. So even if you don't care about doing an extended fit, by making your PDF an extended one and then ignoring the normalization parameter you're all set. If you already do an extended fit, you also don't have to worry at all about the multi-ranged fits,even with the RooSimultaneous.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:347,security,integr,integrals,347,"In 6.26, just don't use the RooSimultaneous and build your NLL as a sum of per-channel NLLs instead, using RooAddition. This is what I also do in the updated cross-check for the simultaneous fit in this PR #11455 ( see the `testRooSimultaneous` file). In 6.24 or older, you would have to further all all these multi-range normalization correction integrals to the RooAddition, like I introduced it under the hood in #7719. But I would not advice doing this unless you carefully validate that you implemented the math correctly. Then, I also have a little hack for you that would work in all ROOT versions: the whole problem **does not affect extended fits**, as explained in this tutorial from ROOT 6.24: https://root.cern.ch/doc/v624/rf204b__extendedLikelihood__rangedFit_8C.html. So even if you don't care about doing an extended fit, by making your PDF an extended one and then ignoring the normalization parameter you're all set. If you already do an extended fit, you also don't have to worry at all about the multi-ranged fits,even with the RooSimultaneous.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:478,security,validat,validate,478,"In 6.26, just don't use the RooSimultaneous and build your NLL as a sum of per-channel NLLs instead, using RooAddition. This is what I also do in the updated cross-check for the simultaneous fit in this PR #11455 ( see the `testRooSimultaneous` file). In 6.24 or older, you would have to further all all these multi-range normalization correction integrals to the RooAddition, like I introduced it under the hood in #7719. But I would not advice doing this unless you carefully validate that you implemented the math correctly. Then, I also have a little hack for you that would work in all ROOT versions: the whole problem **does not affect extended fits**, as explained in this tutorial from ROOT 6.24: https://root.cern.ch/doc/v624/rf204b__extendedLikelihood__rangedFit_8C.html. So even if you don't care about doing an extended fit, by making your PDF an extended one and then ignoring the normalization parameter you're all set. If you already do an extended fit, you also don't have to worry at all about the multi-ranged fits,even with the RooSimultaneous.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:555,security,hack,hack,555,"In 6.26, just don't use the RooSimultaneous and build your NLL as a sum of per-channel NLLs instead, using RooAddition. This is what I also do in the updated cross-check for the simultaneous fit in this PR #11455 ( see the `testRooSimultaneous` file). In 6.24 or older, you would have to further all all these multi-range normalization correction integrals to the RooAddition, like I introduced it under the hood in #7719. But I would not advice doing this unless you carefully validate that you implemented the math correctly. Then, I also have a little hack for you that would work in all ROOT versions: the whole problem **does not affect extended fits**, as explained in this tutorial from ROOT 6.24: https://root.cern.ch/doc/v624/rf204b__extendedLikelihood__rangedFit_8C.html. So even if you don't care about doing an extended fit, by making your PDF an extended one and then ignoring the normalization parameter you're all set. If you already do an extended fit, you also don't have to worry at all about the multi-ranged fits,even with the RooSimultaneous.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:178,testability,simul,simultaneous,178,"In 6.26, just don't use the RooSimultaneous and build your NLL as a sum of per-channel NLLs instead, using RooAddition. This is what I also do in the updated cross-check for the simultaneous fit in this PR #11455 ( see the `testRooSimultaneous` file). In 6.24 or older, you would have to further all all these multi-range normalization correction integrals to the RooAddition, like I introduced it under the hood in #7719. But I would not advice doing this unless you carefully validate that you implemented the math correctly. Then, I also have a little hack for you that would work in all ROOT versions: the whole problem **does not affect extended fits**, as explained in this tutorial from ROOT 6.24: https://root.cern.ch/doc/v624/rf204b__extendedLikelihood__rangedFit_8C.html. So even if you don't care about doing an extended fit, by making your PDF an extended one and then ignoring the normalization parameter you're all set. If you already do an extended fit, you also don't have to worry at all about the multi-ranged fits,even with the RooSimultaneous.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:224,testability,test,testRooSimultaneous,224,"In 6.26, just don't use the RooSimultaneous and build your NLL as a sum of per-channel NLLs instead, using RooAddition. This is what I also do in the updated cross-check for the simultaneous fit in this PR #11455 ( see the `testRooSimultaneous` file). In 6.24 or older, you would have to further all all these multi-range normalization correction integrals to the RooAddition, like I introduced it under the hood in #7719. But I would not advice doing this unless you carefully validate that you implemented the math correctly. Then, I also have a little hack for you that would work in all ROOT versions: the whole problem **does not affect extended fits**, as explained in this tutorial from ROOT 6.24: https://root.cern.ch/doc/v624/rf204b__extendedLikelihood__rangedFit_8C.html. So even if you don't care about doing an extended fit, by making your PDF an extended one and then ignoring the normalization parameter you're all set. If you already do an extended fit, you also don't have to worry at all about the multi-ranged fits,even with the RooSimultaneous.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:347,testability,integr,integrals,347,"In 6.26, just don't use the RooSimultaneous and build your NLL as a sum of per-channel NLLs instead, using RooAddition. This is what I also do in the updated cross-check for the simultaneous fit in this PR #11455 ( see the `testRooSimultaneous` file). In 6.24 or older, you would have to further all all these multi-range normalization correction integrals to the RooAddition, like I introduced it under the hood in #7719. But I would not advice doing this unless you carefully validate that you implemented the math correctly. Then, I also have a little hack for you that would work in all ROOT versions: the whole problem **does not affect extended fits**, as explained in this tutorial from ROOT 6.24: https://root.cern.ch/doc/v624/rf204b__extendedLikelihood__rangedFit_8C.html. So even if you don't care about doing an extended fit, by making your PDF an extended one and then ignoring the normalization parameter you're all set. If you already do an extended fit, you also don't have to worry at all about the multi-ranged fits,even with the RooSimultaneous.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:134,deployability,build,build,134,"Thanks for the helpful information. May I ask what the recommendation is after the fix (e.g. in 6.28+)? Do you expect users to always build NLL as a sum of per-channel NLLs? I believe a lot of existing packages in the community rely on building a simultaneous pdf for multi-category models, so it may not be trivial to change this tradition.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:236,deployability,build,building,236,"Thanks for the helpful information. May I ask what the recommendation is after the fix (e.g. in 6.28+)? Do you expect users to always build NLL as a sum of per-channel NLLs? I believe a lot of existing packages in the community rely on building a simultaneous pdf for multi-category models, so it may not be trivial to change this tradition.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:283,energy efficiency,model,models,283,"Thanks for the helpful information. May I ask what the recommendation is after the fix (e.g. in 6.28+)? Do you expect users to always build NLL as a sum of per-channel NLLs? I believe a lot of existing packages in the community rely on building a simultaneous pdf for multi-category models, so it may not be trivial to change this tradition.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:202,modifiability,pac,packages,202,"Thanks for the helpful information. May I ask what the recommendation is after the fix (e.g. in 6.28+)? Do you expect users to always build NLL as a sum of per-channel NLLs? I believe a lot of existing packages in the community rely on building a simultaneous pdf for multi-category models, so it may not be trivial to change this tradition.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:283,security,model,models,283,"Thanks for the helpful information. May I ask what the recommendation is after the fix (e.g. in 6.28+)? Do you expect users to always build NLL as a sum of per-channel NLLs? I believe a lot of existing packages in the community rely on building a simultaneous pdf for multi-category models, so it may not be trivial to change this tradition.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:247,testability,simul,simultaneous,247,"Thanks for the helpful information. May I ask what the recommendation is after the fix (e.g. in 6.28+)? Do you expect users to always build NLL as a sum of per-channel NLLs? I believe a lot of existing packages in the community rely on building a simultaneous pdf for multi-category models, so it may not be trivial to change this tradition.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:15,usability,help,helpful,15,"Thanks for the helpful information. May I ask what the recommendation is after the fix (e.g. in 6.28+)? Do you expect users to always build NLL as a sum of per-channel NLLs? I believe a lot of existing packages in the community rely on building a simultaneous pdf for multi-category models, so it may not be trivial to change this tradition.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:118,usability,user,users,118,"Thanks for the helpful information. May I ask what the recommendation is after the fix (e.g. in 6.28+)? Do you expect users to always build NLL as a sum of per-channel NLLs? I believe a lot of existing packages in the community rely on building a simultaneous pdf for multi-category models, so it may not be trivial to change this tradition.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:263,deployability,version,versions,263,"No, the idea of the fix is that the RooSimultaneous will behave as expected without changing any user code. The advice with the sum of NLLs is only a workaround for 6.26 to make it work, and the trick with the extended fit is a trick to make it work for all ROOT versions before the upcoming 6.28.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:263,integrability,version,versions,263,"No, the idea of the fix is that the RooSimultaneous will behave as expected without changing any user code. The advice with the sum of NLLs is only a workaround for 6.26 to make it work, and the trick with the extended fit is a trick to make it work for all ROOT versions before the upcoming 6.28.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:210,modifiability,exten,extended,210,"No, the idea of the fix is that the RooSimultaneous will behave as expected without changing any user code. The advice with the sum of NLLs is only a workaround for 6.26 to make it work, and the trick with the extended fit is a trick to make it work for all ROOT versions before the upcoming 6.28.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:263,modifiability,version,versions,263,"No, the idea of the fix is that the RooSimultaneous will behave as expected without changing any user code. The advice with the sum of NLLs is only a workaround for 6.26 to make it work, and the trick with the extended fit is a trick to make it work for all ROOT versions before the upcoming 6.28.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/issues/11447:97,usability,user,user,97,"No, the idea of the fix is that the RooSimultaneous will behave as expected without changing any user code. The advice with the sum of NLLs is only a workaround for 6.26 to make it work, and the trick with the extended fit is a trick to make it work for all ROOT versions before the upcoming 6.28.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11447
https://github.com/root-project/root/pull/11451:15,interoperability,conflict,conflicts,15,Rebased to fix conflicts.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11451
https://github.com/root-project/root/pull/11458:11,deployability,build,build,11,@phsft-bot build just on ROOT-ubuntu22.04/default,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11458
https://github.com/root-project/root/pull/11458:11,deployability,build,build,11,@phsft-bot build just on ROOT-ubuntu2204/default,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11458
https://github.com/root-project/root/pull/11458:33,performance,time,time,33,"Totally, but I cannot go back in time: this mistake on mine will now be there forever...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11458
https://github.com/root-project/root/pull/11459:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2204/default, ROOT-ubuntu18.04/default with flags -Dtmva-sofie=On",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11459
https://github.com/root-project/root/pull/11459:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2204/cxx17, ROOT-ubuntu2004/default, ROOT-ubuntu18.04/nortcxxmod",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11459
https://github.com/root-project/root/pull/11461:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11461
https://github.com/root-project/root/pull/11462:0,availability,Failur,Failures,0,Failures are unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11462
https://github.com/root-project/root/pull/11462:0,deployability,Fail,Failures,0,Failures are unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11462
https://github.com/root-project/root/pull/11462:0,performance,Failur,Failures,0,Failures are unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11462
https://github.com/root-project/root/pull/11462:0,reliability,Fail,Failures,0,Failures are unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11462
https://github.com/root-project/root/pull/11464:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2204/default, ROOT-ubuntu18.04/default",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11464
https://github.com/root-project/root/pull/11465:92,deployability,build,building,92,"Sorry, I just stopped the jenkins job manually. I falsely remember that the jenkins was not building draft PRs. It looks very much like I am introducing lifetime issues, but even with gdb I could not spot them. I am investigating, but might be something in front of my eyes that I am missing - help is much appreciated!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11465
https://github.com/root-project/root/pull/11465:58,safety,reme,remember,58,"Sorry, I just stopped the jenkins job manually. I falsely remember that the jenkins was not building draft PRs. It looks very much like I am introducing lifetime issues, but even with gdb I could not spot them. I am investigating, but might be something in front of my eyes that I am missing - help is much appreciated!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11465
https://github.com/root-project/root/pull/11465:14,usability,stop,stopped,14,"Sorry, I just stopped the jenkins job manually. I falsely remember that the jenkins was not building draft PRs. It looks very much like I am introducing lifetime issues, but even with gdb I could not spot them. I am investigating, but might be something in front of my eyes that I am missing - help is much appreciated!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11465
https://github.com/root-project/root/pull/11465:294,usability,help,help,294,"Sorry, I just stopped the jenkins job manually. I falsely remember that the jenkins was not building draft PRs. It looks very much like I am introducing lifetime issues, but even with gdb I could not spot them. I am investigating, but might be something in front of my eyes that I am missing - help is much appreciated!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11465
https://github.com/root-project/root/pull/11465:161,availability,error,error,161,"> For lifetime issues, try `valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp .... `. Thanks @pcanal -- valgrind immediately spotted `./tst: symbol lookup error: ./tst: undefined symbol: _ZN4ROOT10RDataFrameC1ERKNS_3RDF12Experimental12RDatasetSpecE`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11465
https://github.com/root-project/root/pull/11465:161,performance,error,error,161,"> For lifetime issues, try `valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp .... `. Thanks @pcanal -- valgrind immediately spotted `./tst: symbol lookup error: ./tst: undefined symbol: _ZN4ROOT10RDataFrameC1ERKNS_3RDF12Experimental12RDatasetSpecE`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11465
https://github.com/root-project/root/pull/11465:161,safety,error,error,161,"> For lifetime issues, try `valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp .... `. Thanks @pcanal -- valgrind immediately spotted `./tst: symbol lookup error: ./tst: undefined symbol: _ZN4ROOT10RDataFrameC1ERKNS_3RDF12Experimental12RDatasetSpecE`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11465
https://github.com/root-project/root/pull/11465:161,usability,error,error,161,"> For lifetime issues, try `valgrind --suppressions=$ROOTSYS/etc/valgrind-root.supp .... `. Thanks @pcanal -- valgrind immediately spotted `./tst: symbol lookup error: ./tst: undefined symbol: _ZN4ROOT10RDataFrameC1ERKNS_3RDF12Experimental12RDatasetSpecE`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11465
https://github.com/root-project/root/pull/11465:450,safety,valid,valid,450,"> odd .. is your executable (`tst`) linked against `libRDataFrame` ? Thanksss @pcanal ! I forgot to include to include `ROOT/RDF/RDatasetSpec` ... as it used to come from `ROOT/RDataFrame`. Hmmm, now I included it ... valgrind is happy, but I have the same effect - in short I end up creating an empty dataframe, although all trees and files are there upon construction ... and the RDF only knows about its columns . On the other hand I can create a valid RDF with its other ctors (just created a df from tree, and also from an empty datasource). I am trying to follow the `includes` now, but I do not see surpises there.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11465
https://github.com/root-project/root/pull/11465:122,availability,error,error,122,> I forgot to include to include ROOT/RDF/RDatasetSpec ... . This is confusing. Adding an include should not solve a link error. How is your 'tst' made?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11465
https://github.com/root-project/root/pull/11465:122,performance,error,error,122,> I forgot to include to include ROOT/RDF/RDatasetSpec ... . This is confusing. Adding an include should not solve a link error. How is your 'tst' made?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11465
https://github.com/root-project/root/pull/11465:122,safety,error,error,122,> I forgot to include to include ROOT/RDF/RDatasetSpec ... . This is confusing. Adding an include should not solve a link error. How is your 'tst' made?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11465
https://github.com/root-project/root/pull/11465:122,usability,error,error,122,> I forgot to include to include ROOT/RDF/RDatasetSpec ... . This is confusing. Adding an include should not solve a link error. How is your 'tst' made?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11465
https://github.com/root-project/root/pull/11465:77,deployability,version,version,77,"Maybe I confused myself. I had a long file, but now with this is the minimal version of my program:. ```cpp. #include <ROOT/RDF/RDatasetSpec.hxx>. #include <ROOT/RDFHelpers.hxx>. #include <ROOT/RDataFrame.hxx>. #include <ROOT/RVec.hxx>. #include <TSystem.h>. #include <iostream>. using namespace ROOT;. using namespace ROOT::RDF::Experimental;. int main() {. auto dfWriter0 =. RDataFrame(5).Define(""z"", [](ULong64_t e) { return e; }, {""rdfentry_""}). .Snapshot<ULong64_t>(""tree"", ""specTestFile0.root"", {""z""});. // this is ok. const auto RDF =. *(RDataFrame(""tree"", ""specTestFile0.root"").Take<ULong64_t>(""z""));. for (const auto &el : RDF). std::cout << el << std::endl;. // there is nothing. const auto specRDF =. *(RDataFrame(RDatasetSpec(""tree"", ""specTestFile0.root"")).Take<ULong64_t>(""z""));. for (const auto &el : specRDF). std::cout << el << std::endl;. gSystem->Unlink(""specTestFile0.root"");. }. ```. In this version, if I use valgrind does not seem to have complains (ofc only the llvm one).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11465
https://github.com/root-project/root/pull/11465:912,deployability,version,version,912,"Maybe I confused myself. I had a long file, but now with this is the minimal version of my program:. ```cpp. #include <ROOT/RDF/RDatasetSpec.hxx>. #include <ROOT/RDFHelpers.hxx>. #include <ROOT/RDataFrame.hxx>. #include <ROOT/RVec.hxx>. #include <TSystem.h>. #include <iostream>. using namespace ROOT;. using namespace ROOT::RDF::Experimental;. int main() {. auto dfWriter0 =. RDataFrame(5).Define(""z"", [](ULong64_t e) { return e; }, {""rdfentry_""}). .Snapshot<ULong64_t>(""tree"", ""specTestFile0.root"", {""z""});. // this is ok. const auto RDF =. *(RDataFrame(""tree"", ""specTestFile0.root"").Take<ULong64_t>(""z""));. for (const auto &el : RDF). std::cout << el << std::endl;. // there is nothing. const auto specRDF =. *(RDataFrame(RDatasetSpec(""tree"", ""specTestFile0.root"")).Take<ULong64_t>(""z""));. for (const auto &el : specRDF). std::cout << el << std::endl;. gSystem->Unlink(""specTestFile0.root"");. }. ```. In this version, if I use valgrind does not seem to have complains (ofc only the llvm one).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11465
https://github.com/root-project/root/pull/11465:77,integrability,version,version,77,"Maybe I confused myself. I had a long file, but now with this is the minimal version of my program:. ```cpp. #include <ROOT/RDF/RDatasetSpec.hxx>. #include <ROOT/RDFHelpers.hxx>. #include <ROOT/RDataFrame.hxx>. #include <ROOT/RVec.hxx>. #include <TSystem.h>. #include <iostream>. using namespace ROOT;. using namespace ROOT::RDF::Experimental;. int main() {. auto dfWriter0 =. RDataFrame(5).Define(""z"", [](ULong64_t e) { return e; }, {""rdfentry_""}). .Snapshot<ULong64_t>(""tree"", ""specTestFile0.root"", {""z""});. // this is ok. const auto RDF =. *(RDataFrame(""tree"", ""specTestFile0.root"").Take<ULong64_t>(""z""));. for (const auto &el : RDF). std::cout << el << std::endl;. // there is nothing. const auto specRDF =. *(RDataFrame(RDatasetSpec(""tree"", ""specTestFile0.root"")).Take<ULong64_t>(""z""));. for (const auto &el : specRDF). std::cout << el << std::endl;. gSystem->Unlink(""specTestFile0.root"");. }. ```. In this version, if I use valgrind does not seem to have complains (ofc only the llvm one).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11465
https://github.com/root-project/root/pull/11465:912,integrability,version,version,912,"Maybe I confused myself. I had a long file, but now with this is the minimal version of my program:. ```cpp. #include <ROOT/RDF/RDatasetSpec.hxx>. #include <ROOT/RDFHelpers.hxx>. #include <ROOT/RDataFrame.hxx>. #include <ROOT/RVec.hxx>. #include <TSystem.h>. #include <iostream>. using namespace ROOT;. using namespace ROOT::RDF::Experimental;. int main() {. auto dfWriter0 =. RDataFrame(5).Define(""z"", [](ULong64_t e) { return e; }, {""rdfentry_""}). .Snapshot<ULong64_t>(""tree"", ""specTestFile0.root"", {""z""});. // this is ok. const auto RDF =. *(RDataFrame(""tree"", ""specTestFile0.root"").Take<ULong64_t>(""z""));. for (const auto &el : RDF). std::cout << el << std::endl;. // there is nothing. const auto specRDF =. *(RDataFrame(RDatasetSpec(""tree"", ""specTestFile0.root"")).Take<ULong64_t>(""z""));. for (const auto &el : specRDF). std::cout << el << std::endl;. gSystem->Unlink(""specTestFile0.root"");. }. ```. In this version, if I use valgrind does not seem to have complains (ofc only the llvm one).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11465
https://github.com/root-project/root/pull/11465:77,modifiability,version,version,77,"Maybe I confused myself. I had a long file, but now with this is the minimal version of my program:. ```cpp. #include <ROOT/RDF/RDatasetSpec.hxx>. #include <ROOT/RDFHelpers.hxx>. #include <ROOT/RDataFrame.hxx>. #include <ROOT/RVec.hxx>. #include <TSystem.h>. #include <iostream>. using namespace ROOT;. using namespace ROOT::RDF::Experimental;. int main() {. auto dfWriter0 =. RDataFrame(5).Define(""z"", [](ULong64_t e) { return e; }, {""rdfentry_""}). .Snapshot<ULong64_t>(""tree"", ""specTestFile0.root"", {""z""});. // this is ok. const auto RDF =. *(RDataFrame(""tree"", ""specTestFile0.root"").Take<ULong64_t>(""z""));. for (const auto &el : RDF). std::cout << el << std::endl;. // there is nothing. const auto specRDF =. *(RDataFrame(RDatasetSpec(""tree"", ""specTestFile0.root"")).Take<ULong64_t>(""z""));. for (const auto &el : specRDF). std::cout << el << std::endl;. gSystem->Unlink(""specTestFile0.root"");. }. ```. In this version, if I use valgrind does not seem to have complains (ofc only the llvm one).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11465
https://github.com/root-project/root/pull/11465:912,modifiability,version,version,912,"Maybe I confused myself. I had a long file, but now with this is the minimal version of my program:. ```cpp. #include <ROOT/RDF/RDatasetSpec.hxx>. #include <ROOT/RDFHelpers.hxx>. #include <ROOT/RDataFrame.hxx>. #include <ROOT/RVec.hxx>. #include <TSystem.h>. #include <iostream>. using namespace ROOT;. using namespace ROOT::RDF::Experimental;. int main() {. auto dfWriter0 =. RDataFrame(5).Define(""z"", [](ULong64_t e) { return e; }, {""rdfentry_""}). .Snapshot<ULong64_t>(""tree"", ""specTestFile0.root"", {""z""});. // this is ok. const auto RDF =. *(RDataFrame(""tree"", ""specTestFile0.root"").Take<ULong64_t>(""z""));. for (const auto &el : RDF). std::cout << el << std::endl;. // there is nothing. const auto specRDF =. *(RDataFrame(RDatasetSpec(""tree"", ""specTestFile0.root"")).Take<ULong64_t>(""z""));. for (const auto &el : specRDF). std::cout << el << std::endl;. gSystem->Unlink(""specTestFile0.root"");. }. ```. In this version, if I use valgrind does not seem to have complains (ofc only the llvm one).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11465
https://github.com/root-project/root/pull/11465:939,reliability,doe,does,939,"Maybe I confused myself. I had a long file, but now with this is the minimal version of my program:. ```cpp. #include <ROOT/RDF/RDatasetSpec.hxx>. #include <ROOT/RDFHelpers.hxx>. #include <ROOT/RDataFrame.hxx>. #include <ROOT/RVec.hxx>. #include <TSystem.h>. #include <iostream>. using namespace ROOT;. using namespace ROOT::RDF::Experimental;. int main() {. auto dfWriter0 =. RDataFrame(5).Define(""z"", [](ULong64_t e) { return e; }, {""rdfentry_""}). .Snapshot<ULong64_t>(""tree"", ""specTestFile0.root"", {""z""});. // this is ok. const auto RDF =. *(RDataFrame(""tree"", ""specTestFile0.root"").Take<ULong64_t>(""z""));. for (const auto &el : RDF). std::cout << el << std::endl;. // there is nothing. const auto specRDF =. *(RDataFrame(RDatasetSpec(""tree"", ""specTestFile0.root"")).Take<ULong64_t>(""z""));. for (const auto &el : specRDF). std::cout << el << std::endl;. gSystem->Unlink(""specTestFile0.root"");. }. ```. In this version, if I use valgrind does not seem to have complains (ofc only the llvm one).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11465
https://github.com/root-project/root/pull/11465:961,safety,compl,complains,961,"Maybe I confused myself. I had a long file, but now with this is the minimal version of my program:. ```cpp. #include <ROOT/RDF/RDatasetSpec.hxx>. #include <ROOT/RDFHelpers.hxx>. #include <ROOT/RDataFrame.hxx>. #include <ROOT/RVec.hxx>. #include <TSystem.h>. #include <iostream>. using namespace ROOT;. using namespace ROOT::RDF::Experimental;. int main() {. auto dfWriter0 =. RDataFrame(5).Define(""z"", [](ULong64_t e) { return e; }, {""rdfentry_""}). .Snapshot<ULong64_t>(""tree"", ""specTestFile0.root"", {""z""});. // this is ok. const auto RDF =. *(RDataFrame(""tree"", ""specTestFile0.root"").Take<ULong64_t>(""z""));. for (const auto &el : RDF). std::cout << el << std::endl;. // there is nothing. const auto specRDF =. *(RDataFrame(RDatasetSpec(""tree"", ""specTestFile0.root"")).Take<ULong64_t>(""z""));. for (const auto &el : specRDF). std::cout << el << std::endl;. gSystem->Unlink(""specTestFile0.root"");. }. ```. In this version, if I use valgrind does not seem to have complains (ofc only the llvm one).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11465
https://github.com/root-project/root/pull/11465:961,security,compl,complains,961,"Maybe I confused myself. I had a long file, but now with this is the minimal version of my program:. ```cpp. #include <ROOT/RDF/RDatasetSpec.hxx>. #include <ROOT/RDFHelpers.hxx>. #include <ROOT/RDataFrame.hxx>. #include <ROOT/RVec.hxx>. #include <TSystem.h>. #include <iostream>. using namespace ROOT;. using namespace ROOT::RDF::Experimental;. int main() {. auto dfWriter0 =. RDataFrame(5).Define(""z"", [](ULong64_t e) { return e; }, {""rdfentry_""}). .Snapshot<ULong64_t>(""tree"", ""specTestFile0.root"", {""z""});. // this is ok. const auto RDF =. *(RDataFrame(""tree"", ""specTestFile0.root"").Take<ULong64_t>(""z""));. for (const auto &el : RDF). std::cout << el << std::endl;. // there is nothing. const auto specRDF =. *(RDataFrame(RDatasetSpec(""tree"", ""specTestFile0.root"")).Take<ULong64_t>(""z""));. for (const auto &el : specRDF). std::cout << el << std::endl;. gSystem->Unlink(""specTestFile0.root"");. }. ```. In this version, if I use valgrind does not seem to have complains (ofc only the llvm one).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11465
https://github.com/root-project/root/pull/11465:69,usability,minim,minimal,69,"Maybe I confused myself. I had a long file, but now with this is the minimal version of my program:. ```cpp. #include <ROOT/RDF/RDatasetSpec.hxx>. #include <ROOT/RDFHelpers.hxx>. #include <ROOT/RDataFrame.hxx>. #include <ROOT/RVec.hxx>. #include <TSystem.h>. #include <iostream>. using namespace ROOT;. using namespace ROOT::RDF::Experimental;. int main() {. auto dfWriter0 =. RDataFrame(5).Define(""z"", [](ULong64_t e) { return e; }, {""rdfentry_""}). .Snapshot<ULong64_t>(""tree"", ""specTestFile0.root"", {""z""});. // this is ok. const auto RDF =. *(RDataFrame(""tree"", ""specTestFile0.root"").Take<ULong64_t>(""z""));. for (const auto &el : RDF). std::cout << el << std::endl;. // there is nothing. const auto specRDF =. *(RDataFrame(RDatasetSpec(""tree"", ""specTestFile0.root"")).Take<ULong64_t>(""z""));. for (const auto &el : specRDF). std::cout << el << std::endl;. gSystem->Unlink(""specTestFile0.root"");. }. ```. In this version, if I use valgrind does not seem to have complains (ofc only the llvm one).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11465
https://github.com/root-project/root/pull/11465:187,interoperability,format,formatting,187,My terrible bad:. ```diff. const Long64_t &RDatasetSpec::GetEntryRangeBegin() const. {. - return fEntryRange.fEnd;. + return fEntryRange.fBegin;. }. ```. Everything works now! Fixing the formatting and making a PR!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11465
https://github.com/root-project/root/pull/11465:3,deployability,build,build,3,"PR build will fail because of missing: https://github.com/root-project/root/pull/11490, so cancelling for now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11465
https://github.com/root-project/root/pull/11465:14,deployability,fail,fail,14,"PR build will fail because of missing: https://github.com/root-project/root/pull/11490, so cancelling for now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11465
https://github.com/root-project/root/pull/11465:14,reliability,fail,fail,14,"PR build will fail because of missing: https://github.com/root-project/root/pull/11490, so cancelling for now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11465
https://github.com/root-project/root/pull/11465:91,usability,cancel,cancelling,91,"PR build will fail because of missing: https://github.com/root-project/root/pull/11490, so cancelling for now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11465
https://github.com/root-project/root/pull/11465:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11465
https://github.com/root-project/root/pull/11465:11,deployability,build,build,11,@phsft-bot build just on windows10/cxx14,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11465
https://github.com/root-project/root/pull/11466:338,availability,sli,slightly,338,"Very cool! Some first comments:. - I like the word `cage`. Let's keep it. - Regarding the locator, we should adjust the specification.md together with the code changes. I think we should make use of the foreseen extension for non-disk locators (see Section ""Locators and Envelope Links"" in the specification.md). It will make the locator slightly larger than necessary for object stores but it keeps them minimal for on-disk data. - I don't see yet that it's necessary to store the cage size limit in the anchor. If we need it, can't we determine it from the page list?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11466
https://github.com/root-project/root/pull/11466:5,energy efficiency,cool,cool,5,"Very cool! Some first comments:. - I like the word `cage`. Let's keep it. - Regarding the locator, we should adjust the specification.md together with the code changes. I think we should make use of the foreseen extension for non-disk locators (see Section ""Locators and Envelope Links"" in the specification.md). It will make the locator slightly larger than necessary for object stores but it keeps them minimal for on-disk data. - I don't see yet that it's necessary to store the cage size limit in the anchor. If we need it, can't we determine it from the page list?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11466
https://github.com/root-project/root/pull/11466:120,interoperability,specif,specification,120,"Very cool! Some first comments:. - I like the word `cage`. Let's keep it. - Regarding the locator, we should adjust the specification.md together with the code changes. I think we should make use of the foreseen extension for non-disk locators (see Section ""Locators and Envelope Links"" in the specification.md). It will make the locator slightly larger than necessary for object stores but it keeps them minimal for on-disk data. - I don't see yet that it's necessary to store the cage size limit in the anchor. If we need it, can't we determine it from the page list?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11466
https://github.com/root-project/root/pull/11466:294,interoperability,specif,specification,294,"Very cool! Some first comments:. - I like the word `cage`. Let's keep it. - Regarding the locator, we should adjust the specification.md together with the code changes. I think we should make use of the foreseen extension for non-disk locators (see Section ""Locators and Envelope Links"" in the specification.md). It will make the locator slightly larger than necessary for object stores but it keeps them minimal for on-disk data. - I don't see yet that it's necessary to store the cage size limit in the anchor. If we need it, can't we determine it from the page list?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11466
https://github.com/root-project/root/pull/11466:212,modifiability,extens,extension,212,"Very cool! Some first comments:. - I like the word `cage`. Let's keep it. - Regarding the locator, we should adjust the specification.md together with the code changes. I think we should make use of the foreseen extension for non-disk locators (see Section ""Locators and Envelope Links"" in the specification.md). It will make the locator slightly larger than necessary for object stores but it keeps them minimal for on-disk data. - I don't see yet that it's necessary to store the cage size limit in the anchor. If we need it, can't we determine it from the page list?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11466
https://github.com/root-project/root/pull/11466:230,performance,disk,disk,230,"Very cool! Some first comments:. - I like the word `cage`. Let's keep it. - Regarding the locator, we should adjust the specification.md together with the code changes. I think we should make use of the foreseen extension for non-disk locators (see Section ""Locators and Envelope Links"" in the specification.md). It will make the locator slightly larger than necessary for object stores but it keeps them minimal for on-disk data. - I don't see yet that it's necessary to store the cage size limit in the anchor. If we need it, can't we determine it from the page list?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11466
https://github.com/root-project/root/pull/11466:420,performance,disk,disk,420,"Very cool! Some first comments:. - I like the word `cage`. Let's keep it. - Regarding the locator, we should adjust the specification.md together with the code changes. I think we should make use of the foreseen extension for non-disk locators (see Section ""Locators and Envelope Links"" in the specification.md). It will make the locator slightly larger than necessary for object stores but it keeps them minimal for on-disk data. - I don't see yet that it's necessary to store the cage size limit in the anchor. If we need it, can't we determine it from the page list?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11466
https://github.com/root-project/root/pull/11466:338,reliability,sli,slightly,338,"Very cool! Some first comments:. - I like the word `cage`. Let's keep it. - Regarding the locator, we should adjust the specification.md together with the code changes. I think we should make use of the foreseen extension for non-disk locators (see Section ""Locators and Envelope Links"" in the specification.md). It will make the locator slightly larger than necessary for object stores but it keeps them minimal for on-disk data. - I don't see yet that it's necessary to store the cage size limit in the anchor. If we need it, can't we determine it from the page list?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11466
https://github.com/root-project/root/pull/11466:405,usability,minim,minimal,405,"Very cool! Some first comments:. - I like the word `cage`. Let's keep it. - Regarding the locator, we should adjust the specification.md together with the code changes. I think we should make use of the foreseen extension for non-disk locators (see Section ""Locators and Envelope Links"" in the specification.md). It will make the locator slightly larger than necessary for object stores but it keeps them minimal for on-disk data. - I don't see yet that it's necessary to store the cage size limit in the anchor. If we need it, can't we determine it from the page list?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11466
https://github.com/root-project/root/pull/11466:256,deployability,updat,updated,256,"This PR has been rebased and simplified to leverage the changes introduced by #11828. Accessing single pages that are remotely caged is now unsupported unless page buffering is enabled as a source option (which is by default the case). More details in the updated PR description. The change precludes storing the cage sizes in metadata or upper-bounding it in `RPageSourceDaos`, though it constrains that the entire page-group is requested and fetched - as the allocated buffer size for a cage depends on the sum of all the compressed sizes stored in the individual locators of requested pages belonging to that cage.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11466
https://github.com/root-project/root/pull/11466:494,deployability,depend,depends,494,"This PR has been rebased and simplified to leverage the changes introduced by #11828. Accessing single pages that are remotely caged is now unsupported unless page buffering is enabled as a source option (which is by default the case). More details in the updated PR description. The change precludes storing the cage sizes in metadata or upper-bounding it in `RPageSourceDaos`, though it constrains that the entire page-group is requested and fetched - as the allocated buffer size for a cage depends on the sum of all the compressed sizes stored in the individual locators of requested pages belonging to that cage.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11466
https://github.com/root-project/root/pull/11466:461,energy efficiency,alloc,allocated,461,"This PR has been rebased and simplified to leverage the changes introduced by #11828. Accessing single pages that are remotely caged is now unsupported unless page buffering is enabled as a source option (which is by default the case). More details in the updated PR description. The change precludes storing the cage sizes in metadata or upper-bounding it in `RPageSourceDaos`, though it constrains that the entire page-group is requested and fetched - as the allocated buffer size for a cage depends on the sum of all the compressed sizes stored in the individual locators of requested pages belonging to that cage.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11466
https://github.com/root-project/root/pull/11466:164,integrability,buffer,buffering,164,"This PR has been rebased and simplified to leverage the changes introduced by #11828. Accessing single pages that are remotely caged is now unsupported unless page buffering is enabled as a source option (which is by default the case). More details in the updated PR description. The change precludes storing the cage sizes in metadata or upper-bounding it in `RPageSourceDaos`, though it constrains that the entire page-group is requested and fetched - as the allocated buffer size for a cage depends on the sum of all the compressed sizes stored in the individual locators of requested pages belonging to that cage.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11466
https://github.com/root-project/root/pull/11466:471,integrability,buffer,buffer,471,"This PR has been rebased and simplified to leverage the changes introduced by #11828. Accessing single pages that are remotely caged is now unsupported unless page buffering is enabled as a source option (which is by default the case). More details in the updated PR description. The change precludes storing the cage sizes in metadata or upper-bounding it in `RPageSourceDaos`, though it constrains that the entire page-group is requested and fetched - as the allocated buffer size for a cage depends on the sum of all the compressed sizes stored in the individual locators of requested pages belonging to that cage.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11466
https://github.com/root-project/root/pull/11466:494,integrability,depend,depends,494,"This PR has been rebased and simplified to leverage the changes introduced by #11828. Accessing single pages that are remotely caged is now unsupported unless page buffering is enabled as a source option (which is by default the case). More details in the updated PR description. The change precludes storing the cage sizes in metadata or upper-bounding it in `RPageSourceDaos`, though it constrains that the entire page-group is requested and fetched - as the allocated buffer size for a cage depends on the sum of all the compressed sizes stored in the individual locators of requested pages belonging to that cage.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11466
https://github.com/root-project/root/pull/11466:494,modifiability,depend,depends,494,"This PR has been rebased and simplified to leverage the changes introduced by #11828. Accessing single pages that are remotely caged is now unsupported unless page buffering is enabled as a source option (which is by default the case). More details in the updated PR description. The change precludes storing the cage sizes in metadata or upper-bounding it in `RPageSourceDaos`, though it constrains that the entire page-group is requested and fetched - as the allocated buffer size for a cage depends on the sum of all the compressed sizes stored in the individual locators of requested pages belonging to that cage.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11466
https://github.com/root-project/root/pull/11466:256,safety,updat,updated,256,"This PR has been rebased and simplified to leverage the changes introduced by #11828. Accessing single pages that are remotely caged is now unsupported unless page buffering is enabled as a source option (which is by default the case). More details in the updated PR description. The change precludes storing the cage sizes in metadata or upper-bounding it in `RPageSourceDaos`, though it constrains that the entire page-group is requested and fetched - as the allocated buffer size for a cage depends on the sum of all the compressed sizes stored in the individual locators of requested pages belonging to that cage.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11466
https://github.com/root-project/root/pull/11466:494,safety,depend,depends,494,"This PR has been rebased and simplified to leverage the changes introduced by #11828. Accessing single pages that are remotely caged is now unsupported unless page buffering is enabled as a source option (which is by default the case). More details in the updated PR description. The change precludes storing the cage sizes in metadata or upper-bounding it in `RPageSourceDaos`, though it constrains that the entire page-group is requested and fetched - as the allocated buffer size for a cage depends on the sum of all the compressed sizes stored in the individual locators of requested pages belonging to that cage.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11466
https://github.com/root-project/root/pull/11466:86,security,Access,Accessing,86,"This PR has been rebased and simplified to leverage the changes introduced by #11828. Accessing single pages that are remotely caged is now unsupported unless page buffering is enabled as a source option (which is by default the case). More details in the updated PR description. The change precludes storing the cage sizes in metadata or upper-bounding it in `RPageSourceDaos`, though it constrains that the entire page-group is requested and fetched - as the allocated buffer size for a cage depends on the sum of all the compressed sizes stored in the individual locators of requested pages belonging to that cage.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11466
https://github.com/root-project/root/pull/11466:256,security,updat,updated,256,"This PR has been rebased and simplified to leverage the changes introduced by #11828. Accessing single pages that are remotely caged is now unsupported unless page buffering is enabled as a source option (which is by default the case). More details in the updated PR description. The change precludes storing the cage sizes in metadata or upper-bounding it in `RPageSourceDaos`, though it constrains that the entire page-group is requested and fetched - as the allocated buffer size for a cage depends on the sum of all the compressed sizes stored in the individual locators of requested pages belonging to that cage.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11466
https://github.com/root-project/root/pull/11466:29,testability,simpl,simplified,29,"This PR has been rebased and simplified to leverage the changes introduced by #11828. Accessing single pages that are remotely caged is now unsupported unless page buffering is enabled as a source option (which is by default the case). More details in the updated PR description. The change precludes storing the cage sizes in metadata or upper-bounding it in `RPageSourceDaos`, though it constrains that the entire page-group is requested and fetched - as the allocated buffer size for a cage depends on the sum of all the compressed sizes stored in the individual locators of requested pages belonging to that cage.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11466
https://github.com/root-project/root/pull/11466:494,testability,depend,depends,494,"This PR has been rebased and simplified to leverage the changes introduced by #11828. Accessing single pages that are remotely caged is now unsupported unless page buffering is enabled as a source option (which is by default the case). More details in the updated PR description. The change precludes storing the cage sizes in metadata or upper-bounding it in `RPageSourceDaos`, though it constrains that the entire page-group is requested and fetched - as the allocated buffer size for a cage depends on the sum of all the compressed sizes stored in the individual locators of requested pages belonging to that cage.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11466
https://github.com/root-project/root/pull/11466:29,usability,simpl,simplified,29,"This PR has been rebased and simplified to leverage the changes introduced by #11828. Accessing single pages that are remotely caged is now unsupported unless page buffering is enabled as a source option (which is by default the case). More details in the updated PR description. The change precludes storing the cage sizes in metadata or upper-bounding it in `RPageSourceDaos`, though it constrains that the entire page-group is requested and fetched - as the allocated buffer size for a cage depends on the sum of all the compressed sizes stored in the individual locators of requested pages belonging to that cage.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11466
https://github.com/root-project/root/pull/11466:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11466
https://github.com/root-project/root/pull/11468:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11468
https://github.com/root-project/root/pull/11468:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11468
https://github.com/root-project/root/pull/11468:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu18.04/nortcxxmod. (as far as I can tell from inspecting the logs of the other platforms, they actually built and tested fine...)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11468
https://github.com/root-project/root/pull/11468:96,deployability,log,logs,96,"@phsft-bot build just on ROOT-ubuntu18.04/nortcxxmod. (as far as I can tell from inspecting the logs of the other platforms, they actually built and tested fine...)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11468
https://github.com/root-project/root/pull/11468:114,interoperability,platform,platforms,114,"@phsft-bot build just on ROOT-ubuntu18.04/nortcxxmod. (as far as I can tell from inspecting the logs of the other platforms, they actually built and tested fine...)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11468
https://github.com/root-project/root/pull/11468:96,safety,log,logs,96,"@phsft-bot build just on ROOT-ubuntu18.04/nortcxxmod. (as far as I can tell from inspecting the logs of the other platforms, they actually built and tested fine...)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11468
https://github.com/root-project/root/pull/11468:149,safety,test,tested,149,"@phsft-bot build just on ROOT-ubuntu18.04/nortcxxmod. (as far as I can tell from inspecting the logs of the other platforms, they actually built and tested fine...)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11468
https://github.com/root-project/root/pull/11468:96,security,log,logs,96,"@phsft-bot build just on ROOT-ubuntu18.04/nortcxxmod. (as far as I can tell from inspecting the logs of the other platforms, they actually built and tested fine...)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11468
https://github.com/root-project/root/pull/11468:96,testability,log,logs,96,"@phsft-bot build just on ROOT-ubuntu18.04/nortcxxmod. (as far as I can tell from inspecting the logs of the other platforms, they actually built and tested fine...)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11468
https://github.com/root-project/root/pull/11468:149,testability,test,tested,149,"@phsft-bot build just on ROOT-ubuntu18.04/nortcxxmod. (as far as I can tell from inspecting the logs of the other platforms, they actually built and tested fine...)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11468
https://github.com/root-project/root/pull/11468:11,deployability,build,build,11,@phsft-bot build just on ROOT-ubuntu18.04/nortcxxmod,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11468
https://github.com/root-project/root/pull/11469:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2204/default, ROOT-ubuntu18.04/default",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11469
https://github.com/root-project/root/issues/11473:149,usability,confirm,confirm,149,"Hi @giamas,. that's most likely caused by something in your environment (as opposed to ROOT proper). However, I'm assigning @bellenot so that he can confirm, just in case. Cheers,. Javier.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11473
https://github.com/root-project/root/pull/11474:14,availability,ping,ping,14,@Axel-Naumann ping.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11474
https://github.com/root-project/root/issues/11476:9,safety,test,test,9,The unit test that covers [ROOT-10483](https://sft.its.cern.ch/jira/browse/ROOT-10483) is implemented in https://github.com/root-project/root/pull/11485.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11476
https://github.com/root-project/root/issues/11476:4,testability,unit,unit,4,The unit test that covers [ROOT-10483](https://sft.its.cern.ch/jira/browse/ROOT-10483) is implemented in https://github.com/root-project/root/pull/11485.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11476
https://github.com/root-project/root/issues/11476:9,testability,test,test,9,The unit test that covers [ROOT-10483](https://sft.its.cern.ch/jira/browse/ROOT-10483) is implemented in https://github.com/root-project/root/pull/11485.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11476
https://github.com/root-project/root/pull/11479:0,availability,ping,ping,0,ping...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11479
https://github.com/root-project/root/pull/11480:172,availability,avail,available,172,"Thank you @jalopezg-r00t :partying_face: I'll rebase the commits shortly and a bit indiscriminately. > I would just suggest testing it again on `olsky-03` or similar, when available. All clear on our (thankfully operational) HPE cluster with daos / libdaos 2.2.0.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:212,availability,operat,operational,212,"Thank you @jalopezg-r00t :partying_face: I'll rebase the commits shortly and a bit indiscriminately. > I would just suggest testing it again on `olsky-03` or similar, when available. All clear on our (thankfully operational) HPE cluster with daos / libdaos 2.2.0.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:229,availability,cluster,cluster,229,"Thank you @jalopezg-r00t :partying_face: I'll rebase the commits shortly and a bit indiscriminately. > I would just suggest testing it again on `olsky-03` or similar, when available. All clear on our (thankfully operational) HPE cluster with daos / libdaos 2.2.0.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:229,deployability,cluster,cluster,229,"Thank you @jalopezg-r00t :partying_face: I'll rebase the commits shortly and a bit indiscriminately. > I would just suggest testing it again on `olsky-03` or similar, when available. All clear on our (thankfully operational) HPE cluster with daos / libdaos 2.2.0.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:172,reliability,availab,available,172,"Thank you @jalopezg-r00t :partying_face: I'll rebase the commits shortly and a bit indiscriminately. > I would just suggest testing it again on `olsky-03` or similar, when available. All clear on our (thankfully operational) HPE cluster with daos / libdaos 2.2.0.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:124,safety,test,testing,124,"Thank you @jalopezg-r00t :partying_face: I'll rebase the commits shortly and a bit indiscriminately. > I would just suggest testing it again on `olsky-03` or similar, when available. All clear on our (thankfully operational) HPE cluster with daos / libdaos 2.2.0.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:172,safety,avail,available,172,"Thank you @jalopezg-r00t :partying_face: I'll rebase the commits shortly and a bit indiscriminately. > I would just suggest testing it again on `olsky-03` or similar, when available. All clear on our (thankfully operational) HPE cluster with daos / libdaos 2.2.0.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:172,security,availab,available,172,"Thank you @jalopezg-r00t :partying_face: I'll rebase the commits shortly and a bit indiscriminately. > I would just suggest testing it again on `olsky-03` or similar, when available. All clear on our (thankfully operational) HPE cluster with daos / libdaos 2.2.0.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:124,testability,test,testing,124,"Thank you @jalopezg-r00t :partying_face: I'll rebase the commits shortly and a bit indiscriminately. > I would just suggest testing it again on `olsky-03` or similar, when available. All clear on our (thankfully operational) HPE cluster with daos / libdaos 2.2.0.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:187,usability,clear,clear,187,"Thank you @jalopezg-r00t :partying_face: I'll rebase the commits shortly and a bit indiscriminately. > I would just suggest testing it again on `olsky-03` or similar, when available. All clear on our (thankfully operational) HPE cluster with daos / libdaos 2.2.0.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:2,availability,Error,Errors,2,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:159,availability,error,error,159,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:452,availability,error,error,452,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:873,availability,error,error,873,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:1303,availability,error,error,1303,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:1609,availability,failur,failures,1609,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:45,deployability,build,build,45,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:79,deployability,build,build,79,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:206,deployability,build,build,206,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:240,deployability,build,build,240,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:246,deployability,build,build,246,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:521,deployability,build,build,521,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:555,deployability,build,build,555,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:623,deployability,build,build,623,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:657,deployability,build,build,657,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:663,deployability,build,build,663,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:942,deployability,build,build,942,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:976,deployability,build,build,976,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:1051,deployability,build,build,1051,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:1085,deployability,build,build,1085,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:1091,deployability,build,build,1091,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:1372,deployability,build,build,1372,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:1406,deployability,build,build,1406,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:1484,deployability,build,build,1484,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:1518,deployability,build,build,1518,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:1524,deployability,build,build,1524,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:1609,deployability,fail,failures,1609,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:591,integrability,Transform,Transforms,591,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:694,integrability,Transform,Transforms,694,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:1012,integrability,Transform,Transforms,1012,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:1122,integrability,Transform,Transforms,1122,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:591,interoperability,Transform,Transforms,591,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:694,interoperability,Transform,Transforms,694,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:1012,interoperability,Transform,Transforms,1012,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:1122,interoperability,Transform,Transforms,1122,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:2,performance,Error,Errors,2,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:159,performance,error,error,159,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:452,performance,error,error,452,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:873,performance,error,error,873,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:1303,performance,error,error,1303,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:1609,performance,failur,failures,1609,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:1609,reliability,fail,failures,1609,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:2,safety,Error,Errors,2,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:159,safety,error,error,159,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:452,safety,error,error,452,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:873,safety,error,error,873,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:1303,safety,error,error,1303,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:2,usability,Error,Errors,2,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:159,usability,error,error,159,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:369,usability,Visual,Visual,369,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:401,usability,Tool,Tools,401,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:452,usability,error,error,452,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:789,usability,Visual,Visual,789,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:821,usability,Tool,Tools,821,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:873,usability,error,error,873,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:1217,usability,Visual,Visual,1217,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:1249,usability,Tool,Tools,1249,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11480:1303,usability,error,error,1303,"> Errors:. > * [2022-11-14T15:50:44.494Z] C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\RegisterPressure.cpp(1378,1): fatal error C1060: compiler is out of heap space [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\LLVMCodeGen.vcxproj]. > . > * [2022-11-14T15:50:44.494Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\tuple(718,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\Inliner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:44.994Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\vector(821,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\Transforms\IPO\LowerTypeTests.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\Transforms\IPO\LLVMipo.vcxproj]. > . > * [2022-11-14T15:50:47.146Z] C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.32.31326\include\xmemory(1372,1): fatal error C1060: compiler is out of heap space (compiling source file C:\build\workspace\root-pullrequests-build\root\interpreter\llvm\src\lib\CodeGen\SelectionDAG\DAGCombiner.cpp) [C:\build\workspace\root-pullrequests-build\build\interpreter\llvm\src\lib\CodeGen\SelectionDAG\LLVMSelectionDAG.vcxproj]. These failures are totally unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11480
https://github.com/root-project/root/pull/11481:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2004/default, ROOT-ubuntu18.04/nortcxxmod with flags -Dtmva-sofie=On",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11481
https://github.com/root-project/root/pull/11481:11,deployability,build,build,11,@phsft-bot build just on ROOT-ubuntu2004/default,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11481
https://github.com/root-project/root/pull/11481:11,deployability,build,build,11,@phsft-bot build just on ROOT-ubuntu2204/default,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11481
https://github.com/root-project/root/pull/11481:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2204/default, ROOT-ubuntu18.04/nortcxxmod",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11481
https://github.com/root-project/root/issues/11483:234,reliability,doe,doesn,234,"Another workaround is using the old syntax with `/` as separator for treename: `c.Add(""specTestFile0*.root/tree"");`. Apparently [`ParseTreeFilename`](https://root.cern.ch/doc/master/classTChain.html#a8c5fdf39b6ccebdd4b1c6bf38ca805e5) doesn't support the newer syntax when wildcarding is involved.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11483
https://github.com/root-project/root/issues/11483:242,usability,support,support,242,"Another workaround is using the old syntax with `/` as separator for treename: `c.Add(""specTestFile0*.root/tree"");`. Apparently [`ParseTreeFilename`](https://root.cern.ch/doc/master/classTChain.html#a8c5fdf39b6ccebdd4b1c6bf38ca805e5) doesn't support the newer syntax when wildcarding is involved.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11483
https://github.com/root-project/root/issues/11483:23,availability,ping,ping,23,@gganis @pcanal gentle ping :),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11483
https://github.com/root-project/root/issues/11483:153,safety,reme,remembered,153,"> Another workaround is using the old syntax with / as separator for treename: c.Add(""specTestFile0*.root/tree"");. For future reference, I just realized/remembered why we stopped using the old syntax (and why we still shouldn't): it incurs in https://github.com/root-project/root/issues/8739 (a better explanation of the problem is at https://github.com/root-project/root/pull/8820 ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11483
https://github.com/root-project/root/issues/11483:171,usability,stop,stopped,171,"> Another workaround is using the old syntax with / as separator for treename: c.Add(""specTestFile0*.root/tree"");. For future reference, I just realized/remembered why we stopped using the old syntax (and why we still shouldn't): it incurs in https://github.com/root-project/root/issues/8739 (a better explanation of the problem is at https://github.com/root-project/root/pull/8820 ).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11483
https://github.com/root-project/root/issues/11486:49,availability,slo,slow-performance-in-limited-range-fit-with-roofit,49,Related forum post: https://root-forum.cern.ch/t/slow-performance-in-limited-range-fit-with-roofit/52834/2,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11486
https://github.com/root-project/root/issues/11486:54,performance,perform,performance-in-limited-range-fit-with-roofit,54,Related forum post: https://root-forum.cern.ch/t/slow-performance-in-limited-range-fit-with-roofit/52834/2,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11486
https://github.com/root-project/root/issues/11486:49,reliability,slo,slow-performance-in-limited-range-fit-with-roofit,49,Related forum post: https://root-forum.cern.ch/t/slow-performance-in-limited-range-fit-with-roofit/52834/2,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11486
https://github.com/root-project/root/issues/11486:54,usability,perform,performance-in-limited-range-fit-with-roofit,54,Related forum post: https://root-forum.cern.ch/t/slow-performance-in-limited-range-fit-with-roofit/52834/2,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11486
https://github.com/root-project/root/issues/11486:43,deployability,integr,integrals,43,"The underlying problem is that multi-range integrals in the RooProdPdf don't work:. ```c++. // Define observables x,y. RooRealVar x(""x"",""x"",-10,10) ;. RooRealVar y(""y"",""y"",-10,10) ;. // Construct the background pdf (flat in x,y). RooUniform px(""px"",""px"",x) ;. RooUniform py(""py"",""py"",y) ;. RooProdPdf bkg(""bkg"",""bkg"",px,py) ;. // Construct the SideBand1,SideBand2,Signal regions. //. // |. // +-------------+-----------+. // | | |. // | Side | Sig |. // | Band1 | nal |. // | | |. // --+-------------+-----------+--. // | |. // | Side |. // | Band2 |. // | |. // +-------------+-----------+. // |. x.setRange(""SB1"",-10,+10) ;. y.setRange(""SB1"",-10,0) ;. x.setRange(""SB2"",-10,0) ;. y.setRange(""SB2"",0,+10) ;. x.setRange(""SIG"",0,+10) ;. y.setRange(""SIG"",0,+10) ;. x.setRange(""FULL"",-10,+10) ;. y.setRange(""FULL"",-10,+10) ;. RooArgSet deps{x, y};. bkg.setNormRange(""SB1,SB2"");. RooArgSet normSet{x, y};. // Doesn't work. std::cout << bkg.getVal(normSet) << std::endl;. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11486
https://github.com/root-project/root/issues/11486:102,deployability,observ,observables,102,"The underlying problem is that multi-range integrals in the RooProdPdf don't work:. ```c++. // Define observables x,y. RooRealVar x(""x"",""x"",-10,10) ;. RooRealVar y(""y"",""y"",-10,10) ;. // Construct the background pdf (flat in x,y). RooUniform px(""px"",""px"",x) ;. RooUniform py(""py"",""py"",y) ;. RooProdPdf bkg(""bkg"",""bkg"",px,py) ;. // Construct the SideBand1,SideBand2,Signal regions. //. // |. // +-------------+-----------+. // | | |. // | Side | Sig |. // | Band1 | nal |. // | | |. // --+-------------+-----------+--. // | |. // | Side |. // | Band2 |. // | |. // +-------------+-----------+. // |. x.setRange(""SB1"",-10,+10) ;. y.setRange(""SB1"",-10,0) ;. x.setRange(""SB2"",-10,0) ;. y.setRange(""SB2"",0,+10) ;. x.setRange(""SIG"",0,+10) ;. y.setRange(""SIG"",0,+10) ;. x.setRange(""FULL"",-10,+10) ;. y.setRange(""FULL"",-10,+10) ;. RooArgSet deps{x, y};. bkg.setNormRange(""SB1,SB2"");. RooArgSet normSet{x, y};. // Doesn't work. std::cout << bkg.getVal(normSet) << std::endl;. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11486
https://github.com/root-project/root/issues/11486:43,integrability,integr,integrals,43,"The underlying problem is that multi-range integrals in the RooProdPdf don't work:. ```c++. // Define observables x,y. RooRealVar x(""x"",""x"",-10,10) ;. RooRealVar y(""y"",""y"",-10,10) ;. // Construct the background pdf (flat in x,y). RooUniform px(""px"",""px"",x) ;. RooUniform py(""py"",""py"",y) ;. RooProdPdf bkg(""bkg"",""bkg"",px,py) ;. // Construct the SideBand1,SideBand2,Signal regions. //. // |. // +-------------+-----------+. // | | |. // | Side | Sig |. // | Band1 | nal |. // | | |. // --+-------------+-----------+--. // | |. // | Side |. // | Band2 |. // | |. // +-------------+-----------+. // |. x.setRange(""SB1"",-10,+10) ;. y.setRange(""SB1"",-10,0) ;. x.setRange(""SB2"",-10,0) ;. y.setRange(""SB2"",0,+10) ;. x.setRange(""SIG"",0,+10) ;. y.setRange(""SIG"",0,+10) ;. x.setRange(""FULL"",-10,+10) ;. y.setRange(""FULL"",-10,+10) ;. RooArgSet deps{x, y};. bkg.setNormRange(""SB1,SB2"");. RooArgSet normSet{x, y};. // Doesn't work. std::cout << bkg.getVal(normSet) << std::endl;. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11486
https://github.com/root-project/root/issues/11486:43,interoperability,integr,integrals,43,"The underlying problem is that multi-range integrals in the RooProdPdf don't work:. ```c++. // Define observables x,y. RooRealVar x(""x"",""x"",-10,10) ;. RooRealVar y(""y"",""y"",-10,10) ;. // Construct the background pdf (flat in x,y). RooUniform px(""px"",""px"",x) ;. RooUniform py(""py"",""py"",y) ;. RooProdPdf bkg(""bkg"",""bkg"",px,py) ;. // Construct the SideBand1,SideBand2,Signal regions. //. // |. // +-------------+-----------+. // | | |. // | Side | Sig |. // | Band1 | nal |. // | | |. // --+-------------+-----------+--. // | |. // | Side |. // | Band2 |. // | |. // +-------------+-----------+. // |. x.setRange(""SB1"",-10,+10) ;. y.setRange(""SB1"",-10,0) ;. x.setRange(""SB2"",-10,0) ;. y.setRange(""SB2"",0,+10) ;. x.setRange(""SIG"",0,+10) ;. y.setRange(""SIG"",0,+10) ;. x.setRange(""FULL"",-10,+10) ;. y.setRange(""FULL"",-10,+10) ;. RooArgSet deps{x, y};. bkg.setNormRange(""SB1,SB2"");. RooArgSet normSet{x, y};. // Doesn't work. std::cout << bkg.getVal(normSet) << std::endl;. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11486
https://github.com/root-project/root/issues/11486:43,modifiability,integr,integrals,43,"The underlying problem is that multi-range integrals in the RooProdPdf don't work:. ```c++. // Define observables x,y. RooRealVar x(""x"",""x"",-10,10) ;. RooRealVar y(""y"",""y"",-10,10) ;. // Construct the background pdf (flat in x,y). RooUniform px(""px"",""px"",x) ;. RooUniform py(""py"",""py"",y) ;. RooProdPdf bkg(""bkg"",""bkg"",px,py) ;. // Construct the SideBand1,SideBand2,Signal regions. //. // |. // +-------------+-----------+. // | | |. // | Side | Sig |. // | Band1 | nal |. // | | |. // --+-------------+-----------+--. // | |. // | Side |. // | Band2 |. // | |. // +-------------+-----------+. // |. x.setRange(""SB1"",-10,+10) ;. y.setRange(""SB1"",-10,0) ;. x.setRange(""SB2"",-10,0) ;. y.setRange(""SB2"",0,+10) ;. x.setRange(""SIG"",0,+10) ;. y.setRange(""SIG"",0,+10) ;. x.setRange(""FULL"",-10,+10) ;. y.setRange(""FULL"",-10,+10) ;. RooArgSet deps{x, y};. bkg.setNormRange(""SB1,SB2"");. RooArgSet normSet{x, y};. // Doesn't work. std::cout << bkg.getVal(normSet) << std::endl;. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11486
https://github.com/root-project/root/issues/11486:43,reliability,integr,integrals,43,"The underlying problem is that multi-range integrals in the RooProdPdf don't work:. ```c++. // Define observables x,y. RooRealVar x(""x"",""x"",-10,10) ;. RooRealVar y(""y"",""y"",-10,10) ;. // Construct the background pdf (flat in x,y). RooUniform px(""px"",""px"",x) ;. RooUniform py(""py"",""py"",y) ;. RooProdPdf bkg(""bkg"",""bkg"",px,py) ;. // Construct the SideBand1,SideBand2,Signal regions. //. // |. // +-------------+-----------+. // | | |. // | Side | Sig |. // | Band1 | nal |. // | | |. // --+-------------+-----------+--. // | |. // | Side |. // | Band2 |. // | |. // +-------------+-----------+. // |. x.setRange(""SB1"",-10,+10) ;. y.setRange(""SB1"",-10,0) ;. x.setRange(""SB2"",-10,0) ;. y.setRange(""SB2"",0,+10) ;. x.setRange(""SIG"",0,+10) ;. y.setRange(""SIG"",0,+10) ;. x.setRange(""FULL"",-10,+10) ;. y.setRange(""FULL"",-10,+10) ;. RooArgSet deps{x, y};. bkg.setNormRange(""SB1,SB2"");. RooArgSet normSet{x, y};. // Doesn't work. std::cout << bkg.getVal(normSet) << std::endl;. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11486
https://github.com/root-project/root/issues/11486:904,reliability,Doe,Doesn,904,"The underlying problem is that multi-range integrals in the RooProdPdf don't work:. ```c++. // Define observables x,y. RooRealVar x(""x"",""x"",-10,10) ;. RooRealVar y(""y"",""y"",-10,10) ;. // Construct the background pdf (flat in x,y). RooUniform px(""px"",""px"",x) ;. RooUniform py(""py"",""py"",y) ;. RooProdPdf bkg(""bkg"",""bkg"",px,py) ;. // Construct the SideBand1,SideBand2,Signal regions. //. // |. // +-------------+-----------+. // | | |. // | Side | Sig |. // | Band1 | nal |. // | | |. // --+-------------+-----------+--. // | |. // | Side |. // | Band2 |. // | |. // +-------------+-----------+. // |. x.setRange(""SB1"",-10,+10) ;. y.setRange(""SB1"",-10,0) ;. x.setRange(""SB2"",-10,0) ;. y.setRange(""SB2"",0,+10) ;. x.setRange(""SIG"",0,+10) ;. y.setRange(""SIG"",0,+10) ;. x.setRange(""FULL"",-10,+10) ;. y.setRange(""FULL"",-10,+10) ;. RooArgSet deps{x, y};. bkg.setNormRange(""SB1,SB2"");. RooArgSet normSet{x, y};. // Doesn't work. std::cout << bkg.getVal(normSet) << std::endl;. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11486
https://github.com/root-project/root/issues/11486:43,security,integr,integrals,43,"The underlying problem is that multi-range integrals in the RooProdPdf don't work:. ```c++. // Define observables x,y. RooRealVar x(""x"",""x"",-10,10) ;. RooRealVar y(""y"",""y"",-10,10) ;. // Construct the background pdf (flat in x,y). RooUniform px(""px"",""px"",x) ;. RooUniform py(""py"",""py"",y) ;. RooProdPdf bkg(""bkg"",""bkg"",px,py) ;. // Construct the SideBand1,SideBand2,Signal regions. //. // |. // +-------------+-----------+. // | | |. // | Side | Sig |. // | Band1 | nal |. // | | |. // --+-------------+-----------+--. // | |. // | Side |. // | Band2 |. // | |. // +-------------+-----------+. // |. x.setRange(""SB1"",-10,+10) ;. y.setRange(""SB1"",-10,0) ;. x.setRange(""SB2"",-10,0) ;. y.setRange(""SB2"",0,+10) ;. x.setRange(""SIG"",0,+10) ;. y.setRange(""SIG"",0,+10) ;. x.setRange(""FULL"",-10,+10) ;. y.setRange(""FULL"",-10,+10) ;. RooArgSet deps{x, y};. bkg.setNormRange(""SB1,SB2"");. RooArgSet normSet{x, y};. // Doesn't work. std::cout << bkg.getVal(normSet) << std::endl;. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11486
https://github.com/root-project/root/issues/11486:364,security,Sign,Signal,364,"The underlying problem is that multi-range integrals in the RooProdPdf don't work:. ```c++. // Define observables x,y. RooRealVar x(""x"",""x"",-10,10) ;. RooRealVar y(""y"",""y"",-10,10) ;. // Construct the background pdf (flat in x,y). RooUniform px(""px"",""px"",x) ;. RooUniform py(""py"",""py"",y) ;. RooProdPdf bkg(""bkg"",""bkg"",px,py) ;. // Construct the SideBand1,SideBand2,Signal regions. //. // |. // +-------------+-----------+. // | | |. // | Side | Sig |. // | Band1 | nal |. // | | |. // --+-------------+-----------+--. // | |. // | Side |. // | Band2 |. // | |. // +-------------+-----------+. // |. x.setRange(""SB1"",-10,+10) ;. y.setRange(""SB1"",-10,0) ;. x.setRange(""SB2"",-10,0) ;. y.setRange(""SB2"",0,+10) ;. x.setRange(""SIG"",0,+10) ;. y.setRange(""SIG"",0,+10) ;. x.setRange(""FULL"",-10,+10) ;. y.setRange(""FULL"",-10,+10) ;. RooArgSet deps{x, y};. bkg.setNormRange(""SB1,SB2"");. RooArgSet normSet{x, y};. // Doesn't work. std::cout << bkg.getVal(normSet) << std::endl;. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11486
https://github.com/root-project/root/issues/11486:43,testability,integr,integrals,43,"The underlying problem is that multi-range integrals in the RooProdPdf don't work:. ```c++. // Define observables x,y. RooRealVar x(""x"",""x"",-10,10) ;. RooRealVar y(""y"",""y"",-10,10) ;. // Construct the background pdf (flat in x,y). RooUniform px(""px"",""px"",x) ;. RooUniform py(""py"",""py"",y) ;. RooProdPdf bkg(""bkg"",""bkg"",px,py) ;. // Construct the SideBand1,SideBand2,Signal regions. //. // |. // +-------------+-----------+. // | | |. // | Side | Sig |. // | Band1 | nal |. // | | |. // --+-------------+-----------+--. // | |. // | Side |. // | Band2 |. // | |. // +-------------+-----------+. // |. x.setRange(""SB1"",-10,+10) ;. y.setRange(""SB1"",-10,0) ;. x.setRange(""SB2"",-10,0) ;. y.setRange(""SB2"",0,+10) ;. x.setRange(""SIG"",0,+10) ;. y.setRange(""SIG"",0,+10) ;. x.setRange(""FULL"",-10,+10) ;. y.setRange(""FULL"",-10,+10) ;. RooArgSet deps{x, y};. bkg.setNormRange(""SB1,SB2"");. RooArgSet normSet{x, y};. // Doesn't work. std::cout << bkg.getVal(normSet) << std::endl;. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11486
https://github.com/root-project/root/issues/11486:102,testability,observ,observables,102,"The underlying problem is that multi-range integrals in the RooProdPdf don't work:. ```c++. // Define observables x,y. RooRealVar x(""x"",""x"",-10,10) ;. RooRealVar y(""y"",""y"",-10,10) ;. // Construct the background pdf (flat in x,y). RooUniform px(""px"",""px"",x) ;. RooUniform py(""py"",""py"",y) ;. RooProdPdf bkg(""bkg"",""bkg"",px,py) ;. // Construct the SideBand1,SideBand2,Signal regions. //. // |. // +-------------+-----------+. // | | |. // | Side | Sig |. // | Band1 | nal |. // | | |. // --+-------------+-----------+--. // | |. // | Side |. // | Band2 |. // | |. // +-------------+-----------+. // |. x.setRange(""SB1"",-10,+10) ;. y.setRange(""SB1"",-10,0) ;. x.setRange(""SB2"",-10,0) ;. y.setRange(""SB2"",0,+10) ;. x.setRange(""SIG"",0,+10) ;. y.setRange(""SIG"",0,+10) ;. x.setRange(""FULL"",-10,+10) ;. y.setRange(""FULL"",-10,+10) ;. RooArgSet deps{x, y};. bkg.setNormRange(""SB1,SB2"");. RooArgSet normSet{x, y};. // Doesn't work. std::cout << bkg.getVal(normSet) << std::endl;. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11486
https://github.com/root-project/root/pull/11489:0,availability,Error,Errors,0,Errors are unrelated. Merging,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11489
https://github.com/root-project/root/pull/11489:0,performance,Error,Errors,0,Errors are unrelated. Merging,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11489
https://github.com/root-project/root/pull/11489:0,safety,Error,Errors,0,Errors are unrelated. Merging,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11489
https://github.com/root-project/root/pull/11489:0,usability,Error,Errors,0,Errors are unrelated. Merging,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11489
https://github.com/root-project/root/pull/11490:5,deployability,build,builds,5,"Many builds are happier than before - let's merge and not waste any more time with completely broken PyROOT... Thank you for fixing this, @hahnjo . FYI, @lmoneta",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11490
https://github.com/root-project/root/pull/11490:73,performance,time,time,73,"Many builds are happier than before - let's merge and not waste any more time with completely broken PyROOT... Thank you for fixing this, @hahnjo . FYI, @lmoneta",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11490
https://github.com/root-project/root/pull/11490:83,safety,compl,completely,83,"Many builds are happier than before - let's merge and not waste any more time with completely broken PyROOT... Thank you for fixing this, @hahnjo . FYI, @lmoneta",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11490
https://github.com/root-project/root/pull/11490:83,security,compl,completely,83,"Many builds are happier than before - let's merge and not waste any more time with completely broken PyROOT... Thank you for fixing this, @hahnjo . FYI, @lmoneta",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11490
https://github.com/root-project/root/issues/11495:129,deployability,build,build,129,"Hi @cgleggett,. This kind of question is better asked in the forum. However, could you provide details on your environment, ROOT build options, and a minimal reproducer of the problem?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11495
https://github.com/root-project/root/issues/11495:150,usability,minim,minimal,150,"Hi @cgleggett,. This kind of question is better asked in the forum. However, could you provide details on your environment, ROOT build options, and a minimal reproducer of the problem?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11495
https://github.com/root-project/root/issues/11495:335,deployability,version,versions,335,"ROOT was built with. `cmake -DCMAKE_CXX_STANDARD=17 -DCMAKE_CXX_EXTENSIONS=Off -DCMAKE_INSTALL_PREFIX=/opt/root/v6-26-06_gcc112_c17 -Dx11=OFF -Dtbb=OFF -Dopengl=OFF -Dgviz=OFF -Dimt=OFF -Ddavix=OFF -Dvdt=OFF -Dxrootd=OFF ../src`. The host is running centos7 and using cmake 3.23.2. After playing around a bit with various root and gcc versions, this seems to be an interaction between ROOT and Kokkos 3.7. . A little complex to reproduce, as it appears when building the ATLAS standalone Fast Calorimeter Simulation package:. after installing root and kokkos 3.7 w/ gcc 11.2:. ```. git clone git@github.com:cgleggett/FCS-GPU.git src. mkdir bld; cd bld. cmake ../src/FastCaloSimAnalyzer/ -DENABLE_XROOTD=Off -DENABLE_GPU=on -DINPUT_PATH=/bld2/data/FastCaloSimInputs -DCMAKE_CXX_STANDARD=17 -DUSE_KOKKOS=ON. make -j. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11495
https://github.com/root-project/root/issues/11495:458,deployability,build,building,458,"ROOT was built with. `cmake -DCMAKE_CXX_STANDARD=17 -DCMAKE_CXX_EXTENSIONS=Off -DCMAKE_INSTALL_PREFIX=/opt/root/v6-26-06_gcc112_c17 -Dx11=OFF -Dtbb=OFF -Dopengl=OFF -Dgviz=OFF -Dimt=OFF -Ddavix=OFF -Dvdt=OFF -Dxrootd=OFF ../src`. The host is running centos7 and using cmake 3.23.2. After playing around a bit with various root and gcc versions, this seems to be an interaction between ROOT and Kokkos 3.7. . A little complex to reproduce, as it appears when building the ATLAS standalone Fast Calorimeter Simulation package:. after installing root and kokkos 3.7 w/ gcc 11.2:. ```. git clone git@github.com:cgleggett/FCS-GPU.git src. mkdir bld; cd bld. cmake ../src/FastCaloSimAnalyzer/ -DENABLE_XROOTD=Off -DENABLE_GPU=on -DINPUT_PATH=/bld2/data/FastCaloSimInputs -DCMAKE_CXX_STANDARD=17 -DUSE_KOKKOS=ON. make -j. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11495
https://github.com/root-project/root/issues/11495:532,deployability,instal,installing,532,"ROOT was built with. `cmake -DCMAKE_CXX_STANDARD=17 -DCMAKE_CXX_EXTENSIONS=Off -DCMAKE_INSTALL_PREFIX=/opt/root/v6-26-06_gcc112_c17 -Dx11=OFF -Dtbb=OFF -Dopengl=OFF -Dgviz=OFF -Dimt=OFF -Ddavix=OFF -Dvdt=OFF -Dxrootd=OFF ../src`. The host is running centos7 and using cmake 3.23.2. After playing around a bit with various root and gcc versions, this seems to be an interaction between ROOT and Kokkos 3.7. . A little complex to reproduce, as it appears when building the ATLAS standalone Fast Calorimeter Simulation package:. after installing root and kokkos 3.7 w/ gcc 11.2:. ```. git clone git@github.com:cgleggett/FCS-GPU.git src. mkdir bld; cd bld. cmake ../src/FastCaloSimAnalyzer/ -DENABLE_XROOTD=Off -DENABLE_GPU=on -DINPUT_PATH=/bld2/data/FastCaloSimInputs -DCMAKE_CXX_STANDARD=17 -DUSE_KOKKOS=ON. make -j. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11495
https://github.com/root-project/root/issues/11495:621,energy efficiency,GPU,GPU,621,"ROOT was built with. `cmake -DCMAKE_CXX_STANDARD=17 -DCMAKE_CXX_EXTENSIONS=Off -DCMAKE_INSTALL_PREFIX=/opt/root/v6-26-06_gcc112_c17 -Dx11=OFF -Dtbb=OFF -Dopengl=OFF -Dgviz=OFF -Dimt=OFF -Ddavix=OFF -Dvdt=OFF -Dxrootd=OFF ../src`. The host is running centos7 and using cmake 3.23.2. After playing around a bit with various root and gcc versions, this seems to be an interaction between ROOT and Kokkos 3.7. . A little complex to reproduce, as it appears when building the ATLAS standalone Fast Calorimeter Simulation package:. after installing root and kokkos 3.7 w/ gcc 11.2:. ```. git clone git@github.com:cgleggett/FCS-GPU.git src. mkdir bld; cd bld. cmake ../src/FastCaloSimAnalyzer/ -DENABLE_XROOTD=Off -DENABLE_GPU=on -DINPUT_PATH=/bld2/data/FastCaloSimInputs -DCMAKE_CXX_STANDARD=17 -DUSE_KOKKOS=ON. make -j. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11495
https://github.com/root-project/root/issues/11495:335,integrability,version,versions,335,"ROOT was built with. `cmake -DCMAKE_CXX_STANDARD=17 -DCMAKE_CXX_EXTENSIONS=Off -DCMAKE_INSTALL_PREFIX=/opt/root/v6-26-06_gcc112_c17 -Dx11=OFF -Dtbb=OFF -Dopengl=OFF -Dgviz=OFF -Dimt=OFF -Ddavix=OFF -Dvdt=OFF -Dxrootd=OFF ../src`. The host is running centos7 and using cmake 3.23.2. After playing around a bit with various root and gcc versions, this seems to be an interaction between ROOT and Kokkos 3.7. . A little complex to reproduce, as it appears when building the ATLAS standalone Fast Calorimeter Simulation package:. after installing root and kokkos 3.7 w/ gcc 11.2:. ```. git clone git@github.com:cgleggett/FCS-GPU.git src. mkdir bld; cd bld. cmake ../src/FastCaloSimAnalyzer/ -DENABLE_XROOTD=Off -DENABLE_GPU=on -DINPUT_PATH=/bld2/data/FastCaloSimInputs -DCMAKE_CXX_STANDARD=17 -DUSE_KOKKOS=ON. make -j. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11495
https://github.com/root-project/root/issues/11495:335,modifiability,version,versions,335,"ROOT was built with. `cmake -DCMAKE_CXX_STANDARD=17 -DCMAKE_CXX_EXTENSIONS=Off -DCMAKE_INSTALL_PREFIX=/opt/root/v6-26-06_gcc112_c17 -Dx11=OFF -Dtbb=OFF -Dopengl=OFF -Dgviz=OFF -Dimt=OFF -Ddavix=OFF -Dvdt=OFF -Dxrootd=OFF ../src`. The host is running centos7 and using cmake 3.23.2. After playing around a bit with various root and gcc versions, this seems to be an interaction between ROOT and Kokkos 3.7. . A little complex to reproduce, as it appears when building the ATLAS standalone Fast Calorimeter Simulation package:. after installing root and kokkos 3.7 w/ gcc 11.2:. ```. git clone git@github.com:cgleggett/FCS-GPU.git src. mkdir bld; cd bld. cmake ../src/FastCaloSimAnalyzer/ -DENABLE_XROOTD=Off -DENABLE_GPU=on -DINPUT_PATH=/bld2/data/FastCaloSimInputs -DCMAKE_CXX_STANDARD=17 -DUSE_KOKKOS=ON. make -j. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11495
https://github.com/root-project/root/issues/11495:516,modifiability,pac,package,516,"ROOT was built with. `cmake -DCMAKE_CXX_STANDARD=17 -DCMAKE_CXX_EXTENSIONS=Off -DCMAKE_INSTALL_PREFIX=/opt/root/v6-26-06_gcc112_c17 -Dx11=OFF -Dtbb=OFF -Dopengl=OFF -Dgviz=OFF -Dimt=OFF -Ddavix=OFF -Dvdt=OFF -Dxrootd=OFF ../src`. The host is running centos7 and using cmake 3.23.2. After playing around a bit with various root and gcc versions, this seems to be an interaction between ROOT and Kokkos 3.7. . A little complex to reproduce, as it appears when building the ATLAS standalone Fast Calorimeter Simulation package:. after installing root and kokkos 3.7 w/ gcc 11.2:. ```. git clone git@github.com:cgleggett/FCS-GPU.git src. mkdir bld; cd bld. cmake ../src/FastCaloSimAnalyzer/ -DENABLE_XROOTD=Off -DENABLE_GPU=on -DINPUT_PATH=/bld2/data/FastCaloSimInputs -DCMAKE_CXX_STANDARD=17 -DUSE_KOKKOS=ON. make -j. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11495
https://github.com/root-project/root/issues/11495:621,performance,GPU,GPU,621,"ROOT was built with. `cmake -DCMAKE_CXX_STANDARD=17 -DCMAKE_CXX_EXTENSIONS=Off -DCMAKE_INSTALL_PREFIX=/opt/root/v6-26-06_gcc112_c17 -Dx11=OFF -Dtbb=OFF -Dopengl=OFF -Dgviz=OFF -Dimt=OFF -Ddavix=OFF -Dvdt=OFF -Dxrootd=OFF ../src`. The host is running centos7 and using cmake 3.23.2. After playing around a bit with various root and gcc versions, this seems to be an interaction between ROOT and Kokkos 3.7. . A little complex to reproduce, as it appears when building the ATLAS standalone Fast Calorimeter Simulation package:. after installing root and kokkos 3.7 w/ gcc 11.2:. ```. git clone git@github.com:cgleggett/FCS-GPU.git src. mkdir bld; cd bld. cmake ../src/FastCaloSimAnalyzer/ -DENABLE_XROOTD=Off -DENABLE_GPU=on -DINPUT_PATH=/bld2/data/FastCaloSimInputs -DCMAKE_CXX_STANDARD=17 -DUSE_KOKKOS=ON. make -j. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11495
https://github.com/root-project/root/issues/11495:417,safety,compl,complex,417,"ROOT was built with. `cmake -DCMAKE_CXX_STANDARD=17 -DCMAKE_CXX_EXTENSIONS=Off -DCMAKE_INSTALL_PREFIX=/opt/root/v6-26-06_gcc112_c17 -Dx11=OFF -Dtbb=OFF -Dopengl=OFF -Dgviz=OFF -Dimt=OFF -Ddavix=OFF -Dvdt=OFF -Dxrootd=OFF ../src`. The host is running centos7 and using cmake 3.23.2. After playing around a bit with various root and gcc versions, this seems to be an interaction between ROOT and Kokkos 3.7. . A little complex to reproduce, as it appears when building the ATLAS standalone Fast Calorimeter Simulation package:. after installing root and kokkos 3.7 w/ gcc 11.2:. ```. git clone git@github.com:cgleggett/FCS-GPU.git src. mkdir bld; cd bld. cmake ../src/FastCaloSimAnalyzer/ -DENABLE_XROOTD=Off -DENABLE_GPU=on -DINPUT_PATH=/bld2/data/FastCaloSimInputs -DCMAKE_CXX_STANDARD=17 -DUSE_KOKKOS=ON. make -j. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11495
https://github.com/root-project/root/issues/11495:417,security,compl,complex,417,"ROOT was built with. `cmake -DCMAKE_CXX_STANDARD=17 -DCMAKE_CXX_EXTENSIONS=Off -DCMAKE_INSTALL_PREFIX=/opt/root/v6-26-06_gcc112_c17 -Dx11=OFF -Dtbb=OFF -Dopengl=OFF -Dgviz=OFF -Dimt=OFF -Ddavix=OFF -Dvdt=OFF -Dxrootd=OFF ../src`. The host is running centos7 and using cmake 3.23.2. After playing around a bit with various root and gcc versions, this seems to be an interaction between ROOT and Kokkos 3.7. . A little complex to reproduce, as it appears when building the ATLAS standalone Fast Calorimeter Simulation package:. after installing root and kokkos 3.7 w/ gcc 11.2:. ```. git clone git@github.com:cgleggett/FCS-GPU.git src. mkdir bld; cd bld. cmake ../src/FastCaloSimAnalyzer/ -DENABLE_XROOTD=Off -DENABLE_GPU=on -DINPUT_PATH=/bld2/data/FastCaloSimInputs -DCMAKE_CXX_STANDARD=17 -DUSE_KOKKOS=ON. make -j. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11495
https://github.com/root-project/root/issues/11495:505,testability,Simul,Simulation,505,"ROOT was built with. `cmake -DCMAKE_CXX_STANDARD=17 -DCMAKE_CXX_EXTENSIONS=Off -DCMAKE_INSTALL_PREFIX=/opt/root/v6-26-06_gcc112_c17 -Dx11=OFF -Dtbb=OFF -Dopengl=OFF -Dgviz=OFF -Dimt=OFF -Ddavix=OFF -Dvdt=OFF -Dxrootd=OFF ../src`. The host is running centos7 and using cmake 3.23.2. After playing around a bit with various root and gcc versions, this seems to be an interaction between ROOT and Kokkos 3.7. . A little complex to reproduce, as it appears when building the ATLAS standalone Fast Calorimeter Simulation package:. after installing root and kokkos 3.7 w/ gcc 11.2:. ```. git clone git@github.com:cgleggett/FCS-GPU.git src. mkdir bld; cd bld. cmake ../src/FastCaloSimAnalyzer/ -DENABLE_XROOTD=Off -DENABLE_GPU=on -DINPUT_PATH=/bld2/data/FastCaloSimInputs -DCMAKE_CXX_STANDARD=17 -DUSE_KOKKOS=ON. make -j. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11495
https://github.com/root-project/root/issues/11495:365,usability,interact,interaction,365,"ROOT was built with. `cmake -DCMAKE_CXX_STANDARD=17 -DCMAKE_CXX_EXTENSIONS=Off -DCMAKE_INSTALL_PREFIX=/opt/root/v6-26-06_gcc112_c17 -Dx11=OFF -Dtbb=OFF -Dopengl=OFF -Dgviz=OFF -Dimt=OFF -Ddavix=OFF -Dvdt=OFF -Dxrootd=OFF ../src`. The host is running centos7 and using cmake 3.23.2. After playing around a bit with various root and gcc versions, this seems to be an interaction between ROOT and Kokkos 3.7. . A little complex to reproduce, as it appears when building the ATLAS standalone Fast Calorimeter Simulation package:. after installing root and kokkos 3.7 w/ gcc 11.2:. ```. git clone git@github.com:cgleggett/FCS-GPU.git src. mkdir bld; cd bld. cmake ../src/FastCaloSimAnalyzer/ -DENABLE_XROOTD=Off -DENABLE_GPU=on -DINPUT_PATH=/bld2/data/FastCaloSimInputs -DCMAKE_CXX_STANDARD=17 -DUSE_KOKKOS=ON. make -j. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11495
https://github.com/root-project/root/issues/11495:24,deployability,version,version,24,"After trying a few more version permutations, this looks like something that appeared with Kokkos 3.5, but worked with Kokkos 3.4",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11495
https://github.com/root-project/root/issues/11495:24,integrability,version,version,24,"After trying a few more version permutations, this looks like something that appeared with Kokkos 3.5, but worked with Kokkos 3.4",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11495
https://github.com/root-project/root/issues/11495:24,modifiability,version,version,24,"After trying a few more version permutations, this looks like something that appeared with Kokkos 3.5, but worked with Kokkos 3.4",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11495
https://github.com/root-project/root/issues/11495:154,availability,error,error,154,"After even more permutations of gcc/Kokkos/CUDA, it seems to be related to the version of CUDA. If I use CUDA 11.2, all is ok. With CUDA 11.7, I see this error.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11495
https://github.com/root-project/root/issues/11495:79,deployability,version,version,79,"After even more permutations of gcc/Kokkos/CUDA, it seems to be related to the version of CUDA. If I use CUDA 11.2, all is ok. With CUDA 11.7, I see this error.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11495
https://github.com/root-project/root/issues/11495:79,integrability,version,version,79,"After even more permutations of gcc/Kokkos/CUDA, it seems to be related to the version of CUDA. If I use CUDA 11.2, all is ok. With CUDA 11.7, I see this error.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11495
https://github.com/root-project/root/issues/11495:79,modifiability,version,version,79,"After even more permutations of gcc/Kokkos/CUDA, it seems to be related to the version of CUDA. If I use CUDA 11.2, all is ok. With CUDA 11.7, I see this error.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11495
https://github.com/root-project/root/issues/11495:154,performance,error,error,154,"After even more permutations of gcc/Kokkos/CUDA, it seems to be related to the version of CUDA. If I use CUDA 11.2, all is ok. With CUDA 11.7, I see this error.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11495
https://github.com/root-project/root/issues/11495:154,safety,error,error,154,"After even more permutations of gcc/Kokkos/CUDA, it seems to be related to the version of CUDA. If I use CUDA 11.2, all is ok. With CUDA 11.7, I see this error.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11495
https://github.com/root-project/root/issues/11495:154,usability,error,error,154,"After even more permutations of gcc/Kokkos/CUDA, it seems to be related to the version of CUDA. If I use CUDA 11.2, all is ok. With CUDA 11.7, I see this error.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11495
https://github.com/root-project/root/issues/11495:82,reliability,doe,doesn,82,"This appears to have started somewhere between CUDA 11.5 (works) and CUDA 11.6.2 (doesn't work). Should I close this issue and open a new one, or edit the title of this one?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11495
https://github.com/root-project/root/issues/11495:106,usability,close,close,106,"This appears to have started somewhere between CUDA 11.5 (works) and CUDA 11.6.2 (doesn't work). Should I close this issue and open a new one, or edit the title of this one?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11495
https://github.com/root-project/root/issues/11495:176,usability,close,closed,176,"@cgleggett Many thanks for the investigation of the problem above; indeed, it seems to be an interference affecting something in a header file. Thanks for marking the issue as closed. If need be, feel free to open a new issue if ROOT is directly involved.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11495
https://github.com/root-project/root/pull/11498:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11498
https://github.com/root-project/root/pull/11498:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11498
https://github.com/root-project/root/pull/11500:29,safety,review,review,29,"Hi @etejedor, thanks for the review! I have implemented your suggestions. Can you please take a look again? Thanks",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11500
https://github.com/root-project/root/pull/11500:29,testability,review,review,29,"Hi @etejedor, thanks for the review! I have implemented your suggestions. Can you please take a look again? Thanks",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11500
https://github.com/root-project/root/pull/11503:16,safety,input,input,16,"Thanks for your input. In principle, the TPaleetteAxis is never stored alone. Always with a histogram. That's why I implemented this way as there was no real risk. But you are right I will check more closely.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11503
https://github.com/root-project/root/pull/11503:158,safety,risk,risk,158,"Thanks for your input. In principle, the TPaleetteAxis is never stored alone. Always with a histogram. That's why I implemented this way as there was no real risk. But you are right I will check more closely.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11503
https://github.com/root-project/root/pull/11503:158,security,risk,risk,158,"Thanks for your input. In principle, the TPaleetteAxis is never stored alone. Always with a histogram. That's why I implemented this way as there was no real risk. But you are right I will check more closely.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11503
https://github.com/root-project/root/pull/11503:16,usability,input,input,16,"Thanks for your input. In principle, the TPaleetteAxis is never stored alone. Always with a histogram. That's why I implemented this way as there was no real risk. But you are right I will check more closely.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11503
https://github.com/root-project/root/pull/11503:200,usability,close,closely,200,"Thanks for your input. In principle, the TPaleetteAxis is never stored alone. Always with a histogram. That's why I implemented this way as there was no real risk. But you are right I will check more closely.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11503
https://github.com/root-project/root/pull/11503:81,energy efficiency,load,load,81,"To reproduce problem - store canvas with histogram and palette in the file, then load such canvas back and try to change any attribute in the palette before painting canvas. .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11503
https://github.com/root-project/root/pull/11503:81,performance,load,load,81,"To reproduce problem - store canvas with histogram and palette in the file, then load such canvas back and try to change any attribute in the palette before painting canvas. .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11503
https://github.com/root-project/root/pull/11503:333,deployability,version,version,333,"yes:. ```. % root c1.root. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for macosx64 on Oct 04 2022, 14:46:01 |. | From heads/marker-doc@v6-25-02-2391-g013a059db1 |. | With Apple clang version 14.0.0 (clang-1400.0.29.102) |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] . Attaching file c1.root as _file0... (TFile *) 0x7fb5c3068fb0. root [1] TCanvas *c1 = (TCanvas*)_file0->Get(""c1""). (TCanvas *) 0x7fb5c3166720. root [2] TH2F *h2 = (TH2F *)c1->GetListOfPrimitives()->FindObject(""hpxpy"");. root [3] TPaletteAxis* pal =(TPaletteAxis*)h2->GetListOfFunctions()->FindObject(""palette"");. root [4] pal->SetMaxDigits(2);. *** Break *** segmentation violation. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11503
https://github.com/root-project/root/pull/11503:333,integrability,version,version,333,"yes:. ```. % root c1.root. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for macosx64 on Oct 04 2022, 14:46:01 |. | From heads/marker-doc@v6-25-02-2391-g013a059db1 |. | With Apple clang version 14.0.0 (clang-1400.0.29.102) |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] . Attaching file c1.root as _file0... (TFile *) 0x7fb5c3068fb0. root [1] TCanvas *c1 = (TCanvas*)_file0->Get(""c1""). (TCanvas *) 0x7fb5c3166720. root [2] TH2F *h2 = (TH2F *)c1->GetListOfPrimitives()->FindObject(""hpxpy"");. root [3] TPaletteAxis* pal =(TPaletteAxis*)h2->GetListOfFunctions()->FindObject(""palette"");. root [4] pal->SetMaxDigits(2);. *** Break *** segmentation violation. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11503
https://github.com/root-project/root/pull/11503:333,modifiability,version,version,333,"yes:. ```. % root c1.root. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for macosx64 on Oct 04 2022, 14:46:01 |. | From heads/marker-doc@v6-25-02-2391-g013a059db1 |. | With Apple clang version 14.0.0 (clang-1400.0.29.102) |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] . Attaching file c1.root as _file0... (TFile *) 0x7fb5c3068fb0. root [1] TCanvas *c1 = (TCanvas*)_file0->Get(""c1""). (TCanvas *) 0x7fb5c3166720. root [2] TH2F *h2 = (TH2F *)c1->GetListOfPrimitives()->FindObject(""hpxpy"");. root [3] TPaletteAxis* pal =(TPaletteAxis*)h2->GetListOfFunctions()->FindObject(""palette"");. root [4] pal->SetMaxDigits(2);. *** Break *** segmentation violation. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11503
https://github.com/root-project/root/pull/11503:168,security,Team,Team,168,"yes:. ```. % root c1.root. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for macosx64 on Oct 04 2022, 14:46:01 |. | From heads/marker-doc@v6-25-02-2391-g013a059db1 |. | With Apple clang version 14.0.0 (clang-1400.0.29.102) |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] . Attaching file c1.root as _file0... (TFile *) 0x7fb5c3068fb0. root [1] TCanvas *c1 = (TCanvas*)_file0->Get(""c1""). (TCanvas *) 0x7fb5c3166720. root [2] TH2F *h2 = (TH2F *)c1->GetListOfPrimitives()->FindObject(""hpxpy"");. root [3] TPaletteAxis* pal =(TPaletteAxis*)h2->GetListOfFunctions()->FindObject(""palette"");. root [4] pal->SetMaxDigits(2);. *** Break *** segmentation violation. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11503
https://github.com/root-project/root/pull/11503:381,usability,help,help,381,"yes:. ```. % root c1.root. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for macosx64 on Oct 04 2022, 14:46:01 |. | From heads/marker-doc@v6-25-02-2391-g013a059db1 |. | With Apple clang version 14.0.0 (clang-1400.0.29.102) |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0] . Attaching file c1.root as _file0... (TFile *) 0x7fb5c3068fb0. root [1] TCanvas *c1 = (TCanvas*)_file0->Get(""c1""). (TCanvas *) 0x7fb5c3166720. root [2] TH2F *h2 = (TH2F *)c1->GetListOfPrimitives()->FindObject(""hpxpy"");. root [3] TPaletteAxis* pal =(TPaletteAxis*)h2->GetListOfFunctions()->FindObject(""palette"");. root [4] pal->SetMaxDigits(2);. *** Break *** segmentation violation. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11503
https://github.com/root-project/root/pull/11503:299,deployability,updat,update,299,TGaxis::SetLineColor is overwritten by TAxis::SetAxisColor which is already in the setter. [The line width does not exist at the in TAttAxis](https://root.cern/doc/master/classTAttAxis.html). The line style is not a TGaxis attribute. I will complete the PR because TPaletteAxis::SavePrimitive needs update,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11503
https://github.com/root-project/root/pull/11503:107,reliability,doe,does,107,TGaxis::SetLineColor is overwritten by TAxis::SetAxisColor which is already in the setter. [The line width does not exist at the in TAttAxis](https://root.cern/doc/master/classTAttAxis.html). The line style is not a TGaxis attribute. I will complete the PR because TPaletteAxis::SavePrimitive needs update,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11503
https://github.com/root-project/root/pull/11503:241,safety,compl,complete,241,TGaxis::SetLineColor is overwritten by TAxis::SetAxisColor which is already in the setter. [The line width does not exist at the in TAttAxis](https://root.cern/doc/master/classTAttAxis.html). The line style is not a TGaxis attribute. I will complete the PR because TPaletteAxis::SavePrimitive needs update,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11503
https://github.com/root-project/root/pull/11503:299,safety,updat,update,299,TGaxis::SetLineColor is overwritten by TAxis::SetAxisColor which is already in the setter. [The line width does not exist at the in TAttAxis](https://root.cern/doc/master/classTAttAxis.html). The line style is not a TGaxis attribute. I will complete the PR because TPaletteAxis::SavePrimitive needs update,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11503
https://github.com/root-project/root/pull/11503:241,security,compl,complete,241,TGaxis::SetLineColor is overwritten by TAxis::SetAxisColor which is already in the setter. [The line width does not exist at the in TAttAxis](https://root.cern/doc/master/classTAttAxis.html). The line style is not a TGaxis attribute. I will complete the PR because TPaletteAxis::SavePrimitive needs update,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11503
https://github.com/root-project/root/pull/11503:299,security,updat,update,299,TGaxis::SetLineColor is overwritten by TAxis::SetAxisColor which is already in the setter. [The line width does not exist at the in TAttAxis](https://root.cern/doc/master/classTAttAxis.html). The line style is not a TGaxis attribute. I will complete the PR because TPaletteAxis::SavePrimitive needs update,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11503
https://github.com/root-project/root/pull/11503:179,energy efficiency,current,current,179,"> TGaxis::SetLineColor is overwritten by TAxis::SetAxisColor which is already in the setter. But still `fAxis.GetLineColor()` is used in `TPaletteAxis::Paint`, around line 449 in current master.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11503
https://github.com/root-project/root/pull/11503:56,energy efficiency,draw,draws,56,"Yes that's the CJUST option written by Otto Schaile. It draws the ticks with lines as tGaxis is not used in that case. it is in Paint. So at this level the Tgaxis color as been set by ImportAxisAttributes . So this ""after"" ImportAxisAttributes but the setters we are talking about are before ... so overwritten by ImportAxisAttributes",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11503
https://github.com/root-project/root/pull/11504:146,availability,error,error,146,"This looks real:. ```. [ RUN ] TRootTDS.FromARDFMT. C:\build\workspace\root-pullrequests-build\root\tree\dataframe\test\datasource_root.cxx(176): error: Expected equality of these values:. 0. Which is: 0. *min. Which is: 7. [ FAILED ] TRootTDS.FromARDFMT (11 ms). ```. where the test is:. ```cpp. std::unique_ptr<RDataSource> tds(new ROOT::Internal::RDF::RRootDS(treeName, fileGlob));. RDataFrame tdf(std::move(tds));. auto max = tdf.Max<int>(""i"");. auto min = tdf.Min<int>(""i"");. auto c = tdf.Count();. EXPECT_EQ(30U, *c);. EXPECT_DOUBLE_EQ(29., *max);. EXPECT_DOUBLE_EQ(0., *min);. ```. I just checked with `valgrind` locally (on my fedora) and it had no complaints. I will rerun the test on windows ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11504
https://github.com/root-project/root/pull/11504:55,deployability,build,build,55,"This looks real:. ```. [ RUN ] TRootTDS.FromARDFMT. C:\build\workspace\root-pullrequests-build\root\tree\dataframe\test\datasource_root.cxx(176): error: Expected equality of these values:. 0. Which is: 0. *min. Which is: 7. [ FAILED ] TRootTDS.FromARDFMT (11 ms). ```. where the test is:. ```cpp. std::unique_ptr<RDataSource> tds(new ROOT::Internal::RDF::RRootDS(treeName, fileGlob));. RDataFrame tdf(std::move(tds));. auto max = tdf.Max<int>(""i"");. auto min = tdf.Min<int>(""i"");. auto c = tdf.Count();. EXPECT_EQ(30U, *c);. EXPECT_DOUBLE_EQ(29., *max);. EXPECT_DOUBLE_EQ(0., *min);. ```. I just checked with `valgrind` locally (on my fedora) and it had no complaints. I will rerun the test on windows ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11504
https://github.com/root-project/root/pull/11504:89,deployability,build,build,89,"This looks real:. ```. [ RUN ] TRootTDS.FromARDFMT. C:\build\workspace\root-pullrequests-build\root\tree\dataframe\test\datasource_root.cxx(176): error: Expected equality of these values:. 0. Which is: 0. *min. Which is: 7. [ FAILED ] TRootTDS.FromARDFMT (11 ms). ```. where the test is:. ```cpp. std::unique_ptr<RDataSource> tds(new ROOT::Internal::RDF::RRootDS(treeName, fileGlob));. RDataFrame tdf(std::move(tds));. auto max = tdf.Max<int>(""i"");. auto min = tdf.Min<int>(""i"");. auto c = tdf.Count();. EXPECT_EQ(30U, *c);. EXPECT_DOUBLE_EQ(29., *max);. EXPECT_DOUBLE_EQ(0., *min);. ```. I just checked with `valgrind` locally (on my fedora) and it had no complaints. I will rerun the test on windows ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11504
https://github.com/root-project/root/pull/11504:226,deployability,FAIL,FAILED,226,"This looks real:. ```. [ RUN ] TRootTDS.FromARDFMT. C:\build\workspace\root-pullrequests-build\root\tree\dataframe\test\datasource_root.cxx(176): error: Expected equality of these values:. 0. Which is: 0. *min. Which is: 7. [ FAILED ] TRootTDS.FromARDFMT (11 ms). ```. where the test is:. ```cpp. std::unique_ptr<RDataSource> tds(new ROOT::Internal::RDF::RRootDS(treeName, fileGlob));. RDataFrame tdf(std::move(tds));. auto max = tdf.Max<int>(""i"");. auto min = tdf.Min<int>(""i"");. auto c = tdf.Count();. EXPECT_EQ(30U, *c);. EXPECT_DOUBLE_EQ(29., *max);. EXPECT_DOUBLE_EQ(0., *min);. ```. I just checked with `valgrind` locally (on my fedora) and it had no complaints. I will rerun the test on windows ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11504
https://github.com/root-project/root/pull/11504:146,performance,error,error,146,"This looks real:. ```. [ RUN ] TRootTDS.FromARDFMT. C:\build\workspace\root-pullrequests-build\root\tree\dataframe\test\datasource_root.cxx(176): error: Expected equality of these values:. 0. Which is: 0. *min. Which is: 7. [ FAILED ] TRootTDS.FromARDFMT (11 ms). ```. where the test is:. ```cpp. std::unique_ptr<RDataSource> tds(new ROOT::Internal::RDF::RRootDS(treeName, fileGlob));. RDataFrame tdf(std::move(tds));. auto max = tdf.Max<int>(""i"");. auto min = tdf.Min<int>(""i"");. auto c = tdf.Count();. EXPECT_EQ(30U, *c);. EXPECT_DOUBLE_EQ(29., *max);. EXPECT_DOUBLE_EQ(0., *min);. ```. I just checked with `valgrind` locally (on my fedora) and it had no complaints. I will rerun the test on windows ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11504
https://github.com/root-project/root/pull/11504:226,reliability,FAIL,FAILED,226,"This looks real:. ```. [ RUN ] TRootTDS.FromARDFMT. C:\build\workspace\root-pullrequests-build\root\tree\dataframe\test\datasource_root.cxx(176): error: Expected equality of these values:. 0. Which is: 0. *min. Which is: 7. [ FAILED ] TRootTDS.FromARDFMT (11 ms). ```. where the test is:. ```cpp. std::unique_ptr<RDataSource> tds(new ROOT::Internal::RDF::RRootDS(treeName, fileGlob));. RDataFrame tdf(std::move(tds));. auto max = tdf.Max<int>(""i"");. auto min = tdf.Min<int>(""i"");. auto c = tdf.Count();. EXPECT_EQ(30U, *c);. EXPECT_DOUBLE_EQ(29., *max);. EXPECT_DOUBLE_EQ(0., *min);. ```. I just checked with `valgrind` locally (on my fedora) and it had no complaints. I will rerun the test on windows ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11504
https://github.com/root-project/root/pull/11504:115,safety,test,test,115,"This looks real:. ```. [ RUN ] TRootTDS.FromARDFMT. C:\build\workspace\root-pullrequests-build\root\tree\dataframe\test\datasource_root.cxx(176): error: Expected equality of these values:. 0. Which is: 0. *min. Which is: 7. [ FAILED ] TRootTDS.FromARDFMT (11 ms). ```. where the test is:. ```cpp. std::unique_ptr<RDataSource> tds(new ROOT::Internal::RDF::RRootDS(treeName, fileGlob));. RDataFrame tdf(std::move(tds));. auto max = tdf.Max<int>(""i"");. auto min = tdf.Min<int>(""i"");. auto c = tdf.Count();. EXPECT_EQ(30U, *c);. EXPECT_DOUBLE_EQ(29., *max);. EXPECT_DOUBLE_EQ(0., *min);. ```. I just checked with `valgrind` locally (on my fedora) and it had no complaints. I will rerun the test on windows ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11504
https://github.com/root-project/root/pull/11504:146,safety,error,error,146,"This looks real:. ```. [ RUN ] TRootTDS.FromARDFMT. C:\build\workspace\root-pullrequests-build\root\tree\dataframe\test\datasource_root.cxx(176): error: Expected equality of these values:. 0. Which is: 0. *min. Which is: 7. [ FAILED ] TRootTDS.FromARDFMT (11 ms). ```. where the test is:. ```cpp. std::unique_ptr<RDataSource> tds(new ROOT::Internal::RDF::RRootDS(treeName, fileGlob));. RDataFrame tdf(std::move(tds));. auto max = tdf.Max<int>(""i"");. auto min = tdf.Min<int>(""i"");. auto c = tdf.Count();. EXPECT_EQ(30U, *c);. EXPECT_DOUBLE_EQ(29., *max);. EXPECT_DOUBLE_EQ(0., *min);. ```. I just checked with `valgrind` locally (on my fedora) and it had no complaints. I will rerun the test on windows ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11504
https://github.com/root-project/root/pull/11504:279,safety,test,test,279,"This looks real:. ```. [ RUN ] TRootTDS.FromARDFMT. C:\build\workspace\root-pullrequests-build\root\tree\dataframe\test\datasource_root.cxx(176): error: Expected equality of these values:. 0. Which is: 0. *min. Which is: 7. [ FAILED ] TRootTDS.FromARDFMT (11 ms). ```. where the test is:. ```cpp. std::unique_ptr<RDataSource> tds(new ROOT::Internal::RDF::RRootDS(treeName, fileGlob));. RDataFrame tdf(std::move(tds));. auto max = tdf.Max<int>(""i"");. auto min = tdf.Min<int>(""i"");. auto c = tdf.Count();. EXPECT_EQ(30U, *c);. EXPECT_DOUBLE_EQ(29., *max);. EXPECT_DOUBLE_EQ(0., *min);. ```. I just checked with `valgrind` locally (on my fedora) and it had no complaints. I will rerun the test on windows ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11504
https://github.com/root-project/root/pull/11504:657,safety,compl,complaints,657,"This looks real:. ```. [ RUN ] TRootTDS.FromARDFMT. C:\build\workspace\root-pullrequests-build\root\tree\dataframe\test\datasource_root.cxx(176): error: Expected equality of these values:. 0. Which is: 0. *min. Which is: 7. [ FAILED ] TRootTDS.FromARDFMT (11 ms). ```. where the test is:. ```cpp. std::unique_ptr<RDataSource> tds(new ROOT::Internal::RDF::RRootDS(treeName, fileGlob));. RDataFrame tdf(std::move(tds));. auto max = tdf.Max<int>(""i"");. auto min = tdf.Min<int>(""i"");. auto c = tdf.Count();. EXPECT_EQ(30U, *c);. EXPECT_DOUBLE_EQ(29., *max);. EXPECT_DOUBLE_EQ(0., *min);. ```. I just checked with `valgrind` locally (on my fedora) and it had no complaints. I will rerun the test on windows ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11504
https://github.com/root-project/root/pull/11504:686,safety,test,test,686,"This looks real:. ```. [ RUN ] TRootTDS.FromARDFMT. C:\build\workspace\root-pullrequests-build\root\tree\dataframe\test\datasource_root.cxx(176): error: Expected equality of these values:. 0. Which is: 0. *min. Which is: 7. [ FAILED ] TRootTDS.FromARDFMT (11 ms). ```. where the test is:. ```cpp. std::unique_ptr<RDataSource> tds(new ROOT::Internal::RDF::RRootDS(treeName, fileGlob));. RDataFrame tdf(std::move(tds));. auto max = tdf.Max<int>(""i"");. auto min = tdf.Min<int>(""i"");. auto c = tdf.Count();. EXPECT_EQ(30U, *c);. EXPECT_DOUBLE_EQ(29., *max);. EXPECT_DOUBLE_EQ(0., *min);. ```. I just checked with `valgrind` locally (on my fedora) and it had no complaints. I will rerun the test on windows ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11504
https://github.com/root-project/root/pull/11504:657,security,compl,complaints,657,"This looks real:. ```. [ RUN ] TRootTDS.FromARDFMT. C:\build\workspace\root-pullrequests-build\root\tree\dataframe\test\datasource_root.cxx(176): error: Expected equality of these values:. 0. Which is: 0. *min. Which is: 7. [ FAILED ] TRootTDS.FromARDFMT (11 ms). ```. where the test is:. ```cpp. std::unique_ptr<RDataSource> tds(new ROOT::Internal::RDF::RRootDS(treeName, fileGlob));. RDataFrame tdf(std::move(tds));. auto max = tdf.Max<int>(""i"");. auto min = tdf.Min<int>(""i"");. auto c = tdf.Count();. EXPECT_EQ(30U, *c);. EXPECT_DOUBLE_EQ(29., *max);. EXPECT_DOUBLE_EQ(0., *min);. ```. I just checked with `valgrind` locally (on my fedora) and it had no complaints. I will rerun the test on windows ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11504
https://github.com/root-project/root/pull/11504:115,testability,test,test,115,"This looks real:. ```. [ RUN ] TRootTDS.FromARDFMT. C:\build\workspace\root-pullrequests-build\root\tree\dataframe\test\datasource_root.cxx(176): error: Expected equality of these values:. 0. Which is: 0. *min. Which is: 7. [ FAILED ] TRootTDS.FromARDFMT (11 ms). ```. where the test is:. ```cpp. std::unique_ptr<RDataSource> tds(new ROOT::Internal::RDF::RRootDS(treeName, fileGlob));. RDataFrame tdf(std::move(tds));. auto max = tdf.Max<int>(""i"");. auto min = tdf.Min<int>(""i"");. auto c = tdf.Count();. EXPECT_EQ(30U, *c);. EXPECT_DOUBLE_EQ(29., *max);. EXPECT_DOUBLE_EQ(0., *min);. ```. I just checked with `valgrind` locally (on my fedora) and it had no complaints. I will rerun the test on windows ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11504
https://github.com/root-project/root/pull/11504:279,testability,test,test,279,"This looks real:. ```. [ RUN ] TRootTDS.FromARDFMT. C:\build\workspace\root-pullrequests-build\root\tree\dataframe\test\datasource_root.cxx(176): error: Expected equality of these values:. 0. Which is: 0. *min. Which is: 7. [ FAILED ] TRootTDS.FromARDFMT (11 ms). ```. where the test is:. ```cpp. std::unique_ptr<RDataSource> tds(new ROOT::Internal::RDF::RRootDS(treeName, fileGlob));. RDataFrame tdf(std::move(tds));. auto max = tdf.Max<int>(""i"");. auto min = tdf.Min<int>(""i"");. auto c = tdf.Count();. EXPECT_EQ(30U, *c);. EXPECT_DOUBLE_EQ(29., *max);. EXPECT_DOUBLE_EQ(0., *min);. ```. I just checked with `valgrind` locally (on my fedora) and it had no complaints. I will rerun the test on windows ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11504
https://github.com/root-project/root/pull/11504:686,testability,test,test,686,"This looks real:. ```. [ RUN ] TRootTDS.FromARDFMT. C:\build\workspace\root-pullrequests-build\root\tree\dataframe\test\datasource_root.cxx(176): error: Expected equality of these values:. 0. Which is: 0. *min. Which is: 7. [ FAILED ] TRootTDS.FromARDFMT (11 ms). ```. where the test is:. ```cpp. std::unique_ptr<RDataSource> tds(new ROOT::Internal::RDF::RRootDS(treeName, fileGlob));. RDataFrame tdf(std::move(tds));. auto max = tdf.Max<int>(""i"");. auto min = tdf.Min<int>(""i"");. auto c = tdf.Count();. EXPECT_EQ(30U, *c);. EXPECT_DOUBLE_EQ(29., *max);. EXPECT_DOUBLE_EQ(0., *min);. ```. I just checked with `valgrind` locally (on my fedora) and it had no complaints. I will rerun the test on windows ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11504
https://github.com/root-project/root/pull/11504:146,usability,error,error,146,"This looks real:. ```. [ RUN ] TRootTDS.FromARDFMT. C:\build\workspace\root-pullrequests-build\root\tree\dataframe\test\datasource_root.cxx(176): error: Expected equality of these values:. 0. Which is: 0. *min. Which is: 7. [ FAILED ] TRootTDS.FromARDFMT (11 ms). ```. where the test is:. ```cpp. std::unique_ptr<RDataSource> tds(new ROOT::Internal::RDF::RRootDS(treeName, fileGlob));. RDataFrame tdf(std::move(tds));. auto max = tdf.Max<int>(""i"");. auto min = tdf.Min<int>(""i"");. auto c = tdf.Count();. EXPECT_EQ(30U, *c);. EXPECT_DOUBLE_EQ(29., *max);. EXPECT_DOUBLE_EQ(0., *min);. ```. I just checked with `valgrind` locally (on my fedora) and it had no complaints. I will rerun the test on windows ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11504
https://github.com/root-project/root/pull/11504:11,deployability,build,build,11,@phsft-bot build just on windows10/cxx14,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11504
https://github.com/root-project/root/pull/11507:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11507
https://github.com/root-project/root/pull/11507:273,deployability,patch,patch,273,"Thank you very much for this PR! No, if you already have a fix, it's completely fine to create a PR without a corresponding issue. And It's also not necessary to write a test for that. I also added this PR to the list of bugfix PRs that I want to backport to the next 6.26 patch release:. https://github.com/root-project/root/issues/11059",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11507
https://github.com/root-project/root/pull/11507:279,deployability,releas,release,279,"Thank you very much for this PR! No, if you already have a fix, it's completely fine to create a PR without a corresponding issue. And It's also not necessary to write a test for that. I also added this PR to the list of bugfix PRs that I want to backport to the next 6.26 patch release:. https://github.com/root-project/root/issues/11059",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11507
https://github.com/root-project/root/pull/11507:69,safety,compl,completely,69,"Thank you very much for this PR! No, if you already have a fix, it's completely fine to create a PR without a corresponding issue. And It's also not necessary to write a test for that. I also added this PR to the list of bugfix PRs that I want to backport to the next 6.26 patch release:. https://github.com/root-project/root/issues/11059",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11507
https://github.com/root-project/root/pull/11507:170,safety,test,test,170,"Thank you very much for this PR! No, if you already have a fix, it's completely fine to create a PR without a corresponding issue. And It's also not necessary to write a test for that. I also added this PR to the list of bugfix PRs that I want to backport to the next 6.26 patch release:. https://github.com/root-project/root/issues/11059",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11507
https://github.com/root-project/root/pull/11507:273,safety,patch,patch,273,"Thank you very much for this PR! No, if you already have a fix, it's completely fine to create a PR without a corresponding issue. And It's also not necessary to write a test for that. I also added this PR to the list of bugfix PRs that I want to backport to the next 6.26 patch release:. https://github.com/root-project/root/issues/11059",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11507
https://github.com/root-project/root/pull/11507:69,security,compl,completely,69,"Thank you very much for this PR! No, if you already have a fix, it's completely fine to create a PR without a corresponding issue. And It's also not necessary to write a test for that. I also added this PR to the list of bugfix PRs that I want to backport to the next 6.26 patch release:. https://github.com/root-project/root/issues/11059",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11507
https://github.com/root-project/root/pull/11507:273,security,patch,patch,273,"Thank you very much for this PR! No, if you already have a fix, it's completely fine to create a PR without a corresponding issue. And It's also not necessary to write a test for that. I also added this PR to the list of bugfix PRs that I want to backport to the next 6.26 patch release:. https://github.com/root-project/root/issues/11059",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11507
https://github.com/root-project/root/pull/11507:170,testability,test,test,170,"Thank you very much for this PR! No, if you already have a fix, it's completely fine to create a PR without a corresponding issue. And It's also not necessary to write a test for that. I also added this PR to the list of bugfix PRs that I want to backport to the next 6.26 patch release:. https://github.com/root-project/root/issues/11059",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11507
https://github.com/root-project/root/pull/11507:59,availability,failur,failure,59,Thank you! Is the formatting fine? I do not understand the failure. Is it the space before the semicolon?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11507
https://github.com/root-project/root/pull/11507:59,deployability,fail,failure,59,Thank you! Is the formatting fine? I do not understand the failure. Is it the space before the semicolon?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11507
https://github.com/root-project/root/pull/11507:18,interoperability,format,formatting,18,Thank you! Is the formatting fine? I do not understand the failure. Is it the space before the semicolon?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11507
https://github.com/root-project/root/pull/11507:59,performance,failur,failure,59,Thank you! Is the formatting fine? I do not understand the failure. Is it the space before the semicolon?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11507
https://github.com/root-project/root/pull/11507:59,reliability,fail,failure,59,Thank you! Is the formatting fine? I do not understand the failure. Is it the space before the semicolon?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11507
https://github.com/root-project/root/pull/11507:44,testability,understand,understand,44,Thank you! Is the formatting fine? I do not understand the failure. Is it the space before the semicolon?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11507
https://github.com/root-project/root/pull/11507:10,availability,failur,failure,10,"Yeah, the failure about the formatting is because the code is not conform with the clang-format style of ROOT:. https://github.com/root-project/root/blob/master/.clang-format. But since RooFit never followed the style to begin with (at least for all files older than a year), we will just ignore the errors. It was decided to not do the reformatting of the whole RooFit code for now, because this would obfuscate the development history with formatting changes in every line (`git blame` would not be so useful anymore). So this PR is ready to go as it is! I'll merge it once the Jenkins tests are passing.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11507
https://github.com/root-project/root/pull/11507:300,availability,error,errors,300,"Yeah, the failure about the formatting is because the code is not conform with the clang-format style of ROOT:. https://github.com/root-project/root/blob/master/.clang-format. But since RooFit never followed the style to begin with (at least for all files older than a year), we will just ignore the errors. It was decided to not do the reformatting of the whole RooFit code for now, because this would obfuscate the development history with formatting changes in every line (`git blame` would not be so useful anymore). So this PR is ready to go as it is! I'll merge it once the Jenkins tests are passing.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11507
https://github.com/root-project/root/pull/11507:10,deployability,fail,failure,10,"Yeah, the failure about the formatting is because the code is not conform with the clang-format style of ROOT:. https://github.com/root-project/root/blob/master/.clang-format. But since RooFit never followed the style to begin with (at least for all files older than a year), we will just ignore the errors. It was decided to not do the reformatting of the whole RooFit code for now, because this would obfuscate the development history with formatting changes in every line (`git blame` would not be so useful anymore). So this PR is ready to go as it is! I'll merge it once the Jenkins tests are passing.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11507
https://github.com/root-project/root/pull/11507:28,interoperability,format,formatting,28,"Yeah, the failure about the formatting is because the code is not conform with the clang-format style of ROOT:. https://github.com/root-project/root/blob/master/.clang-format. But since RooFit never followed the style to begin with (at least for all files older than a year), we will just ignore the errors. It was decided to not do the reformatting of the whole RooFit code for now, because this would obfuscate the development history with formatting changes in every line (`git blame` would not be so useful anymore). So this PR is ready to go as it is! I'll merge it once the Jenkins tests are passing.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11507
https://github.com/root-project/root/pull/11507:89,interoperability,format,format,89,"Yeah, the failure about the formatting is because the code is not conform with the clang-format style of ROOT:. https://github.com/root-project/root/blob/master/.clang-format. But since RooFit never followed the style to begin with (at least for all files older than a year), we will just ignore the errors. It was decided to not do the reformatting of the whole RooFit code for now, because this would obfuscate the development history with formatting changes in every line (`git blame` would not be so useful anymore). So this PR is ready to go as it is! I'll merge it once the Jenkins tests are passing.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11507
https://github.com/root-project/root/pull/11507:168,interoperability,format,format,168,"Yeah, the failure about the formatting is because the code is not conform with the clang-format style of ROOT:. https://github.com/root-project/root/blob/master/.clang-format. But since RooFit never followed the style to begin with (at least for all files older than a year), we will just ignore the errors. It was decided to not do the reformatting of the whole RooFit code for now, because this would obfuscate the development history with formatting changes in every line (`git blame` would not be so useful anymore). So this PR is ready to go as it is! I'll merge it once the Jenkins tests are passing.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11507
https://github.com/root-project/root/pull/11507:442,interoperability,format,formatting,442,"Yeah, the failure about the formatting is because the code is not conform with the clang-format style of ROOT:. https://github.com/root-project/root/blob/master/.clang-format. But since RooFit never followed the style to begin with (at least for all files older than a year), we will just ignore the errors. It was decided to not do the reformatting of the whole RooFit code for now, because this would obfuscate the development history with formatting changes in every line (`git blame` would not be so useful anymore). So this PR is ready to go as it is! I'll merge it once the Jenkins tests are passing.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11507
https://github.com/root-project/root/pull/11507:10,performance,failur,failure,10,"Yeah, the failure about the formatting is because the code is not conform with the clang-format style of ROOT:. https://github.com/root-project/root/blob/master/.clang-format. But since RooFit never followed the style to begin with (at least for all files older than a year), we will just ignore the errors. It was decided to not do the reformatting of the whole RooFit code for now, because this would obfuscate the development history with formatting changes in every line (`git blame` would not be so useful anymore). So this PR is ready to go as it is! I'll merge it once the Jenkins tests are passing.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11507
https://github.com/root-project/root/pull/11507:300,performance,error,errors,300,"Yeah, the failure about the formatting is because the code is not conform with the clang-format style of ROOT:. https://github.com/root-project/root/blob/master/.clang-format. But since RooFit never followed the style to begin with (at least for all files older than a year), we will just ignore the errors. It was decided to not do the reformatting of the whole RooFit code for now, because this would obfuscate the development history with formatting changes in every line (`git blame` would not be so useful anymore). So this PR is ready to go as it is! I'll merge it once the Jenkins tests are passing.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11507
https://github.com/root-project/root/pull/11507:10,reliability,fail,failure,10,"Yeah, the failure about the formatting is because the code is not conform with the clang-format style of ROOT:. https://github.com/root-project/root/blob/master/.clang-format. But since RooFit never followed the style to begin with (at least for all files older than a year), we will just ignore the errors. It was decided to not do the reformatting of the whole RooFit code for now, because this would obfuscate the development history with formatting changes in every line (`git blame` would not be so useful anymore). So this PR is ready to go as it is! I'll merge it once the Jenkins tests are passing.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11507
https://github.com/root-project/root/pull/11507:300,safety,error,errors,300,"Yeah, the failure about the formatting is because the code is not conform with the clang-format style of ROOT:. https://github.com/root-project/root/blob/master/.clang-format. But since RooFit never followed the style to begin with (at least for all files older than a year), we will just ignore the errors. It was decided to not do the reformatting of the whole RooFit code for now, because this would obfuscate the development history with formatting changes in every line (`git blame` would not be so useful anymore). So this PR is ready to go as it is! I'll merge it once the Jenkins tests are passing.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11507
https://github.com/root-project/root/pull/11507:588,safety,test,tests,588,"Yeah, the failure about the formatting is because the code is not conform with the clang-format style of ROOT:. https://github.com/root-project/root/blob/master/.clang-format. But since RooFit never followed the style to begin with (at least for all files older than a year), we will just ignore the errors. It was decided to not do the reformatting of the whole RooFit code for now, because this would obfuscate the development history with formatting changes in every line (`git blame` would not be so useful anymore). So this PR is ready to go as it is! I'll merge it once the Jenkins tests are passing.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11507
https://github.com/root-project/root/pull/11507:403,security,obfusc,obfuscate,403,"Yeah, the failure about the formatting is because the code is not conform with the clang-format style of ROOT:. https://github.com/root-project/root/blob/master/.clang-format. But since RooFit never followed the style to begin with (at least for all files older than a year), we will just ignore the errors. It was decided to not do the reformatting of the whole RooFit code for now, because this would obfuscate the development history with formatting changes in every line (`git blame` would not be so useful anymore). So this PR is ready to go as it is! I'll merge it once the Jenkins tests are passing.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11507
https://github.com/root-project/root/pull/11507:588,testability,test,tests,588,"Yeah, the failure about the formatting is because the code is not conform with the clang-format style of ROOT:. https://github.com/root-project/root/blob/master/.clang-format. But since RooFit never followed the style to begin with (at least for all files older than a year), we will just ignore the errors. It was decided to not do the reformatting of the whole RooFit code for now, because this would obfuscate the development history with formatting changes in every line (`git blame` would not be so useful anymore). So this PR is ready to go as it is! I'll merge it once the Jenkins tests are passing.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11507
https://github.com/root-project/root/pull/11507:300,usability,error,errors,300,"Yeah, the failure about the formatting is because the code is not conform with the clang-format style of ROOT:. https://github.com/root-project/root/blob/master/.clang-format. But since RooFit never followed the style to begin with (at least for all files older than a year), we will just ignore the errors. It was decided to not do the reformatting of the whole RooFit code for now, because this would obfuscate the development history with formatting changes in every line (`git blame` would not be so useful anymore). So this PR is ready to go as it is! I'll merge it once the Jenkins tests are passing.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11507
https://github.com/root-project/root/pull/11509:165,energy efficiency,alloc,allocator,165,"Small experiment:. ```cpp. root [0] auto rdf = ROOT::RDataFrame(10);. root [1] *(rdf.Range(0,0).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 }. root [2] *(rdf.Range(1,1).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) {}. root [2] *(rdf.Range(3,3).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) {}. root [3] *(rdf.Range(1,1,3).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) {}. root [4] *(rdf.Range(0,0,3).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) { 0, 3, 6, 9 }. root [5] *(rdf.Range(0,0,6).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) { 0, 6 }. root [6] *(rdf.Range(2,2,6).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) {}. ```. Range (0,0) should be either always empty, or documented that acts as first--last.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11509
https://github.com/root-project/root/pull/11509:329,energy efficiency,alloc,allocator,329,"Small experiment:. ```cpp. root [0] auto rdf = ROOT::RDataFrame(10);. root [1] *(rdf.Range(0,0).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 }. root [2] *(rdf.Range(1,1).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) {}. root [2] *(rdf.Range(3,3).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) {}. root [3] *(rdf.Range(1,1,3).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) {}. root [4] *(rdf.Range(0,0,3).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) { 0, 3, 6, 9 }. root [5] *(rdf.Range(0,0,6).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) { 0, 6 }. root [6] *(rdf.Range(2,2,6).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) {}. ```. Range (0,0) should be either always empty, or documented that acts as first--last.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11509
https://github.com/root-project/root/pull/11509:463,energy efficiency,alloc,allocator,463,"Small experiment:. ```cpp. root [0] auto rdf = ROOT::RDataFrame(10);. root [1] *(rdf.Range(0,0).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 }. root [2] *(rdf.Range(1,1).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) {}. root [2] *(rdf.Range(3,3).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) {}. root [3] *(rdf.Range(1,1,3).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) {}. root [4] *(rdf.Range(0,0,3).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) { 0, 3, 6, 9 }. root [5] *(rdf.Range(0,0,6).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) { 0, 6 }. root [6] *(rdf.Range(2,2,6).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) {}. ```. Range (0,0) should be either always empty, or documented that acts as first--last.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11509
https://github.com/root-project/root/pull/11509:599,energy efficiency,alloc,allocator,599,"Small experiment:. ```cpp. root [0] auto rdf = ROOT::RDataFrame(10);. root [1] *(rdf.Range(0,0).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 }. root [2] *(rdf.Range(1,1).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) {}. root [2] *(rdf.Range(3,3).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) {}. root [3] *(rdf.Range(1,1,3).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) {}. root [4] *(rdf.Range(0,0,3).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) { 0, 3, 6, 9 }. root [5] *(rdf.Range(0,0,6).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) { 0, 6 }. root [6] *(rdf.Range(2,2,6).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) {}. ```. Range (0,0) should be either always empty, or documented that acts as first--last.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11509
https://github.com/root-project/root/pull/11509:735,energy efficiency,alloc,allocator,735,"Small experiment:. ```cpp. root [0] auto rdf = ROOT::RDataFrame(10);. root [1] *(rdf.Range(0,0).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 }. root [2] *(rdf.Range(1,1).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) {}. root [2] *(rdf.Range(3,3).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) {}. root [3] *(rdf.Range(1,1,3).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) {}. root [4] *(rdf.Range(0,0,3).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) { 0, 3, 6, 9 }. root [5] *(rdf.Range(0,0,6).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) { 0, 6 }. root [6] *(rdf.Range(2,2,6).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) {}. ```. Range (0,0) should be either always empty, or documented that acts as first--last.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11509
https://github.com/root-project/root/pull/11509:883,energy efficiency,alloc,allocator,883,"Small experiment:. ```cpp. root [0] auto rdf = ROOT::RDataFrame(10);. root [1] *(rdf.Range(0,0).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 }. root [2] *(rdf.Range(1,1).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) {}. root [2] *(rdf.Range(3,3).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) {}. root [3] *(rdf.Range(1,1,3).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) {}. root [4] *(rdf.Range(0,0,3).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) { 0, 3, 6, 9 }. root [5] *(rdf.Range(0,0,6).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) { 0, 6 }. root [6] *(rdf.Range(2,2,6).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) {}. ```. Range (0,0) should be either always empty, or documented that acts as first--last.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11509
https://github.com/root-project/root/pull/11509:1025,energy efficiency,alloc,allocator,1025,"Small experiment:. ```cpp. root [0] auto rdf = ROOT::RDataFrame(10);. root [1] *(rdf.Range(0,0).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 }. root [2] *(rdf.Range(1,1).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) {}. root [2] *(rdf.Range(3,3).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) {}. root [3] *(rdf.Range(1,1,3).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) {}. root [4] *(rdf.Range(0,0,3).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) { 0, 3, 6, 9 }. root [5] *(rdf.Range(0,0,6).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) { 0, 6 }. root [6] *(rdf.Range(2,2,6).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) {}. ```. Range (0,0) should be either always empty, or documented that acts as first--last.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11509
https://github.com/root-project/root/pull/11509:1115,usability,document,documented,1115,"Small experiment:. ```cpp. root [0] auto rdf = ROOT::RDataFrame(10);. root [1] *(rdf.Range(0,0).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 }. root [2] *(rdf.Range(1,1).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) {}. root [2] *(rdf.Range(3,3).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) {}. root [3] *(rdf.Range(1,1,3).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) {}. root [4] *(rdf.Range(0,0,3).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) { 0, 3, 6, 9 }. root [5] *(rdf.Range(0,0,6).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) { 0, 6 }. root [6] *(rdf.Range(2,2,6).Take<ULong64_t>(""tdfentry_"")). (std::vector<unsigned long long, std::allocator<unsigned long long> > &) {}. ```. Range (0,0) should be either always empty, or documented that acts as first--last.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11509
https://github.com/root-project/root/pull/11509:5,usability,document,documented,5,It's documented: https://root.cern/doc/master/classROOT_1_1RDF_1_1RInterface.html#aa20e0c679a90c1bf315825e3d57afcc9,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11509
https://github.com/root-project/root/pull/11512:106,deployability,instal,install,106,"> LGTM, makes complete sense to me! I guess you verified that the compiled pyc files also ended up in the install directory? Just to make sure. Yes, all the bytecodes are there when you install, the py2 and the py3 ones, now respecting the compatibility.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11512
https://github.com/root-project/root/pull/11512:186,deployability,instal,install,186,"> LGTM, makes complete sense to me! I guess you verified that the compiled pyc files also ended up in the install directory? Just to make sure. Yes, all the bytecodes are there when you install, the py2 and the py3 ones, now respecting the compatibility.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11512
https://github.com/root-project/root/pull/11512:240,interoperability,compatib,compatibility,240,"> LGTM, makes complete sense to me! I guess you verified that the compiled pyc files also ended up in the install directory? Just to make sure. Yes, all the bytecodes are there when you install, the py2 and the py3 ones, now respecting the compatibility.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11512
https://github.com/root-project/root/pull/11512:14,safety,compl,complete,14,"> LGTM, makes complete sense to me! I guess you verified that the compiled pyc files also ended up in the install directory? Just to make sure. Yes, all the bytecodes are there when you install, the py2 and the py3 ones, now respecting the compatibility.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11512
https://github.com/root-project/root/pull/11512:14,security,compl,complete,14,"> LGTM, makes complete sense to me! I guess you verified that the compiled pyc files also ended up in the install directory? Just to make sure. Yes, all the bytecodes are there when you install, the py2 and the py3 ones, now respecting the compatibility.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11512
https://github.com/root-project/root/pull/11512:48,testability,verif,verified,48,"> LGTM, makes complete sense to me! I guess you verified that the compiled pyc files also ended up in the install directory? Just to make sure. Yes, all the bytecodes are there when you install, the py2 and the py3 ones, now respecting the compatibility.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11512
https://github.com/root-project/root/pull/11514:18,safety,test,test,18,"@junaire, can you test if this solves also your problems?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:18,testability,test,test,18,"@junaire, can you test if this solves also your problems?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:643,deployability,fail,failed,643,"> @junaire, can you test if this solves also your problems? I haven't tested this, but @hahnjo said this almost fixes my issue in #10910, only `roottest-root-html-runMakeIndex` needs some tweaking for the generated header file. But I think this may not be a full ""workaround"" as it doesn't handle the root issue. In fact, Jonas did mention this doesn't help with the problems about `TSeq`, which means we still have to preload `ROOTDataFrame`. I also made my own fix (https://github.com/root-project/root/pull/10910/commits/4757b60656381a668b24a0ea0dbf6b77aff71e14) and I feel like it may be a better direction to work on (even though it also failed to fix `TSeq`...) .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:282,reliability,doe,doesn,282,"> @junaire, can you test if this solves also your problems? I haven't tested this, but @hahnjo said this almost fixes my issue in #10910, only `roottest-root-html-runMakeIndex` needs some tweaking for the generated header file. But I think this may not be a full ""workaround"" as it doesn't handle the root issue. In fact, Jonas did mention this doesn't help with the problems about `TSeq`, which means we still have to preload `ROOTDataFrame`. I also made my own fix (https://github.com/root-project/root/pull/10910/commits/4757b60656381a668b24a0ea0dbf6b77aff71e14) and I feel like it may be a better direction to work on (even though it also failed to fix `TSeq`...) .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:345,reliability,doe,doesn,345,"> @junaire, can you test if this solves also your problems? I haven't tested this, but @hahnjo said this almost fixes my issue in #10910, only `roottest-root-html-runMakeIndex` needs some tweaking for the generated header file. But I think this may not be a full ""workaround"" as it doesn't handle the root issue. In fact, Jonas did mention this doesn't help with the problems about `TSeq`, which means we still have to preload `ROOTDataFrame`. I also made my own fix (https://github.com/root-project/root/pull/10910/commits/4757b60656381a668b24a0ea0dbf6b77aff71e14) and I feel like it may be a better direction to work on (even though it also failed to fix `TSeq`...) .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:643,reliability,fail,failed,643,"> @junaire, can you test if this solves also your problems? I haven't tested this, but @hahnjo said this almost fixes my issue in #10910, only `roottest-root-html-runMakeIndex` needs some tweaking for the generated header file. But I think this may not be a full ""workaround"" as it doesn't handle the root issue. In fact, Jonas did mention this doesn't help with the problems about `TSeq`, which means we still have to preload `ROOTDataFrame`. I also made my own fix (https://github.com/root-project/root/pull/10910/commits/4757b60656381a668b24a0ea0dbf6b77aff71e14) and I feel like it may be a better direction to work on (even though it also failed to fix `TSeq`...) .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:20,safety,test,test,20,"> @junaire, can you test if this solves also your problems? I haven't tested this, but @hahnjo said this almost fixes my issue in #10910, only `roottest-root-html-runMakeIndex` needs some tweaking for the generated header file. But I think this may not be a full ""workaround"" as it doesn't handle the root issue. In fact, Jonas did mention this doesn't help with the problems about `TSeq`, which means we still have to preload `ROOTDataFrame`. I also made my own fix (https://github.com/root-project/root/pull/10910/commits/4757b60656381a668b24a0ea0dbf6b77aff71e14) and I feel like it may be a better direction to work on (even though it also failed to fix `TSeq`...) .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:70,safety,test,tested,70,"> @junaire, can you test if this solves also your problems? I haven't tested this, but @hahnjo said this almost fixes my issue in #10910, only `roottest-root-html-runMakeIndex` needs some tweaking for the generated header file. But I think this may not be a full ""workaround"" as it doesn't handle the root issue. In fact, Jonas did mention this doesn't help with the problems about `TSeq`, which means we still have to preload `ROOTDataFrame`. I also made my own fix (https://github.com/root-project/root/pull/10910/commits/4757b60656381a668b24a0ea0dbf6b77aff71e14) and I feel like it may be a better direction to work on (even though it also failed to fix `TSeq`...) .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:20,testability,test,test,20,"> @junaire, can you test if this solves also your problems? I haven't tested this, but @hahnjo said this almost fixes my issue in #10910, only `roottest-root-html-runMakeIndex` needs some tweaking for the generated header file. But I think this may not be a full ""workaround"" as it doesn't handle the root issue. In fact, Jonas did mention this doesn't help with the problems about `TSeq`, which means we still have to preload `ROOTDataFrame`. I also made my own fix (https://github.com/root-project/root/pull/10910/commits/4757b60656381a668b24a0ea0dbf6b77aff71e14) and I feel like it may be a better direction to work on (even though it also failed to fix `TSeq`...) .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:70,testability,test,tested,70,"> @junaire, can you test if this solves also your problems? I haven't tested this, but @hahnjo said this almost fixes my issue in #10910, only `roottest-root-html-runMakeIndex` needs some tweaking for the generated header file. But I think this may not be a full ""workaround"" as it doesn't handle the root issue. In fact, Jonas did mention this doesn't help with the problems about `TSeq`, which means we still have to preload `ROOTDataFrame`. I also made my own fix (https://github.com/root-project/root/pull/10910/commits/4757b60656381a668b24a0ea0dbf6b77aff71e14) and I feel like it may be a better direction to work on (even though it also failed to fix `TSeq`...) .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:353,usability,help,help,353,"> @junaire, can you test if this solves also your problems? I haven't tested this, but @hahnjo said this almost fixes my issue in #10910, only `roottest-root-html-runMakeIndex` needs some tweaking for the generated header file. But I think this may not be a full ""workaround"" as it doesn't handle the root issue. In fact, Jonas did mention this doesn't help with the problems about `TSeq`, which means we still have to preload `ROOTDataFrame`. I also made my own fix (https://github.com/root-project/root/pull/10910/commits/4757b60656381a668b24a0ea0dbf6b77aff71e14) and I feel like it may be a better direction to work on (even though it also failed to fix `TSeq`...) .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:656,deployability,fail,failed,656,"> > @junaire, can you test if this solves also your problems? > . > I haven't tested this, but @hahnjo said this almost fixes my issue in #10910, only `roottest-root-html-runMakeIndex` needs some tweaking for the generated header file. But I think this may not be a full ""workaround"" as it doesn't handle the root issue. In fact, Jonas did mention this doesn't help with the problems about `TSeq`, which means we still have to preload `ROOTDataFrame`. > . > I also made my own fix ([4757b60](https://github.com/root-project/root/commit/4757b60656381a668b24a0ea0dbf6b77aff71e14)) and I feel like it may be a better direction to work on (even though it also failed to fix `TSeq`...). FWIW I pushed a new commit to #10910 and it looks like surprisingly fixes all issues even without preloading `ROOTDataFrame`! But now let's see if Jenkins is happy or not. Fingers crossed :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:290,reliability,doe,doesn,290,"> > @junaire, can you test if this solves also your problems? > . > I haven't tested this, but @hahnjo said this almost fixes my issue in #10910, only `roottest-root-html-runMakeIndex` needs some tweaking for the generated header file. But I think this may not be a full ""workaround"" as it doesn't handle the root issue. In fact, Jonas did mention this doesn't help with the problems about `TSeq`, which means we still have to preload `ROOTDataFrame`. > . > I also made my own fix ([4757b60](https://github.com/root-project/root/commit/4757b60656381a668b24a0ea0dbf6b77aff71e14)) and I feel like it may be a better direction to work on (even though it also failed to fix `TSeq`...). FWIW I pushed a new commit to #10910 and it looks like surprisingly fixes all issues even without preloading `ROOTDataFrame`! But now let's see if Jenkins is happy or not. Fingers crossed :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:353,reliability,doe,doesn,353,"> > @junaire, can you test if this solves also your problems? > . > I haven't tested this, but @hahnjo said this almost fixes my issue in #10910, only `roottest-root-html-runMakeIndex` needs some tweaking for the generated header file. But I think this may not be a full ""workaround"" as it doesn't handle the root issue. In fact, Jonas did mention this doesn't help with the problems about `TSeq`, which means we still have to preload `ROOTDataFrame`. > . > I also made my own fix ([4757b60](https://github.com/root-project/root/commit/4757b60656381a668b24a0ea0dbf6b77aff71e14)) and I feel like it may be a better direction to work on (even though it also failed to fix `TSeq`...). FWIW I pushed a new commit to #10910 and it looks like surprisingly fixes all issues even without preloading `ROOTDataFrame`! But now let's see if Jenkins is happy or not. Fingers crossed :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:656,reliability,fail,failed,656,"> > @junaire, can you test if this solves also your problems? > . > I haven't tested this, but @hahnjo said this almost fixes my issue in #10910, only `roottest-root-html-runMakeIndex` needs some tweaking for the generated header file. But I think this may not be a full ""workaround"" as it doesn't handle the root issue. In fact, Jonas did mention this doesn't help with the problems about `TSeq`, which means we still have to preload `ROOTDataFrame`. > . > I also made my own fix ([4757b60](https://github.com/root-project/root/commit/4757b60656381a668b24a0ea0dbf6b77aff71e14)) and I feel like it may be a better direction to work on (even though it also failed to fix `TSeq`...). FWIW I pushed a new commit to #10910 and it looks like surprisingly fixes all issues even without preloading `ROOTDataFrame`! But now let's see if Jenkins is happy or not. Fingers crossed :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:22,safety,test,test,22,"> > @junaire, can you test if this solves also your problems? > . > I haven't tested this, but @hahnjo said this almost fixes my issue in #10910, only `roottest-root-html-runMakeIndex` needs some tweaking for the generated header file. But I think this may not be a full ""workaround"" as it doesn't handle the root issue. In fact, Jonas did mention this doesn't help with the problems about `TSeq`, which means we still have to preload `ROOTDataFrame`. > . > I also made my own fix ([4757b60](https://github.com/root-project/root/commit/4757b60656381a668b24a0ea0dbf6b77aff71e14)) and I feel like it may be a better direction to work on (even though it also failed to fix `TSeq`...). FWIW I pushed a new commit to #10910 and it looks like surprisingly fixes all issues even without preloading `ROOTDataFrame`! But now let's see if Jenkins is happy or not. Fingers crossed :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:78,safety,test,tested,78,"> > @junaire, can you test if this solves also your problems? > . > I haven't tested this, but @hahnjo said this almost fixes my issue in #10910, only `roottest-root-html-runMakeIndex` needs some tweaking for the generated header file. But I think this may not be a full ""workaround"" as it doesn't handle the root issue. In fact, Jonas did mention this doesn't help with the problems about `TSeq`, which means we still have to preload `ROOTDataFrame`. > . > I also made my own fix ([4757b60](https://github.com/root-project/root/commit/4757b60656381a668b24a0ea0dbf6b77aff71e14)) and I feel like it may be a better direction to work on (even though it also failed to fix `TSeq`...). FWIW I pushed a new commit to #10910 and it looks like surprisingly fixes all issues even without preloading `ROOTDataFrame`! But now let's see if Jenkins is happy or not. Fingers crossed :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:22,testability,test,test,22,"> > @junaire, can you test if this solves also your problems? > . > I haven't tested this, but @hahnjo said this almost fixes my issue in #10910, only `roottest-root-html-runMakeIndex` needs some tweaking for the generated header file. But I think this may not be a full ""workaround"" as it doesn't handle the root issue. In fact, Jonas did mention this doesn't help with the problems about `TSeq`, which means we still have to preload `ROOTDataFrame`. > . > I also made my own fix ([4757b60](https://github.com/root-project/root/commit/4757b60656381a668b24a0ea0dbf6b77aff71e14)) and I feel like it may be a better direction to work on (even though it also failed to fix `TSeq`...). FWIW I pushed a new commit to #10910 and it looks like surprisingly fixes all issues even without preloading `ROOTDataFrame`! But now let's see if Jenkins is happy or not. Fingers crossed :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:78,testability,test,tested,78,"> > @junaire, can you test if this solves also your problems? > . > I haven't tested this, but @hahnjo said this almost fixes my issue in #10910, only `roottest-root-html-runMakeIndex` needs some tweaking for the generated header file. But I think this may not be a full ""workaround"" as it doesn't handle the root issue. In fact, Jonas did mention this doesn't help with the problems about `TSeq`, which means we still have to preload `ROOTDataFrame`. > . > I also made my own fix ([4757b60](https://github.com/root-project/root/commit/4757b60656381a668b24a0ea0dbf6b77aff71e14)) and I feel like it may be a better direction to work on (even though it also failed to fix `TSeq`...). FWIW I pushed a new commit to #10910 and it looks like surprisingly fixes all issues even without preloading `ROOTDataFrame`! But now let's see if Jenkins is happy or not. Fingers crossed :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:361,usability,help,help,361,"> > @junaire, can you test if this solves also your problems? > . > I haven't tested this, but @hahnjo said this almost fixes my issue in #10910, only `roottest-root-html-runMakeIndex` needs some tweaking for the generated header file. But I think this may not be a full ""workaround"" as it doesn't handle the root issue. In fact, Jonas did mention this doesn't help with the problems about `TSeq`, which means we still have to preload `ROOTDataFrame`. > . > I also made my own fix ([4757b60](https://github.com/root-project/root/commit/4757b60656381a668b24a0ea0dbf6b77aff71e14)) and I feel like it may be a better direction to work on (even though it also failed to fix `TSeq`...). FWIW I pushed a new commit to #10910 and it looks like surprisingly fixes all issues even without preloading `ROOTDataFrame`! But now let's see if Jenkins is happy or not. Fingers crossed :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:915,availability,failur,failures,915,"> > > @junaire, can you test if this solves also your problems? > > . > > . > > I haven't tested this, but @hahnjo said this almost fixes my issue in #10910, only `roottest-root-html-runMakeIndex` needs some tweaking for the generated header file. But I think this may not be a full ""workaround"" as it doesn't handle the root issue. In fact, Jonas did mention this doesn't help with the problems about `TSeq`, which means we still have to preload `ROOTDataFrame`. > > I also made my own fix ([4757b60](https://github.com/root-project/root/commit/4757b60656381a668b24a0ea0dbf6b77aff71e14)) and I feel like it may be a better direction to work on (even though it also failed to fix `TSeq`...). > . > FWIW I pushed a new commit to #10910 and it looks like surprisingly fixes all issues even without preloading `ROOTDataFrame`! But now let's see if Jenkins is happy or not. Fingers crossed :). OK, so we still got some failures but I can't see it locally. I'll try to reproduce them, but I feel like that's the right direction. CC @hahnjo @vgvassilev",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:666,deployability,fail,failed,666,"> > > @junaire, can you test if this solves also your problems? > > . > > . > > I haven't tested this, but @hahnjo said this almost fixes my issue in #10910, only `roottest-root-html-runMakeIndex` needs some tweaking for the generated header file. But I think this may not be a full ""workaround"" as it doesn't handle the root issue. In fact, Jonas did mention this doesn't help with the problems about `TSeq`, which means we still have to preload `ROOTDataFrame`. > > I also made my own fix ([4757b60](https://github.com/root-project/root/commit/4757b60656381a668b24a0ea0dbf6b77aff71e14)) and I feel like it may be a better direction to work on (even though it also failed to fix `TSeq`...). > . > FWIW I pushed a new commit to #10910 and it looks like surprisingly fixes all issues even without preloading `ROOTDataFrame`! But now let's see if Jenkins is happy or not. Fingers crossed :). OK, so we still got some failures but I can't see it locally. I'll try to reproduce them, but I feel like that's the right direction. CC @hahnjo @vgvassilev",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:915,deployability,fail,failures,915,"> > > @junaire, can you test if this solves also your problems? > > . > > . > > I haven't tested this, but @hahnjo said this almost fixes my issue in #10910, only `roottest-root-html-runMakeIndex` needs some tweaking for the generated header file. But I think this may not be a full ""workaround"" as it doesn't handle the root issue. In fact, Jonas did mention this doesn't help with the problems about `TSeq`, which means we still have to preload `ROOTDataFrame`. > > I also made my own fix ([4757b60](https://github.com/root-project/root/commit/4757b60656381a668b24a0ea0dbf6b77aff71e14)) and I feel like it may be a better direction to work on (even though it also failed to fix `TSeq`...). > . > FWIW I pushed a new commit to #10910 and it looks like surprisingly fixes all issues even without preloading `ROOTDataFrame`! But now let's see if Jenkins is happy or not. Fingers crossed :). OK, so we still got some failures but I can't see it locally. I'll try to reproduce them, but I feel like that's the right direction. CC @hahnjo @vgvassilev",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:915,performance,failur,failures,915,"> > > @junaire, can you test if this solves also your problems? > > . > > . > > I haven't tested this, but @hahnjo said this almost fixes my issue in #10910, only `roottest-root-html-runMakeIndex` needs some tweaking for the generated header file. But I think this may not be a full ""workaround"" as it doesn't handle the root issue. In fact, Jonas did mention this doesn't help with the problems about `TSeq`, which means we still have to preload `ROOTDataFrame`. > > I also made my own fix ([4757b60](https://github.com/root-project/root/commit/4757b60656381a668b24a0ea0dbf6b77aff71e14)) and I feel like it may be a better direction to work on (even though it also failed to fix `TSeq`...). > . > FWIW I pushed a new commit to #10910 and it looks like surprisingly fixes all issues even without preloading `ROOTDataFrame`! But now let's see if Jenkins is happy or not. Fingers crossed :). OK, so we still got some failures but I can't see it locally. I'll try to reproduce them, but I feel like that's the right direction. CC @hahnjo @vgvassilev",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:302,reliability,doe,doesn,302,"> > > @junaire, can you test if this solves also your problems? > > . > > . > > I haven't tested this, but @hahnjo said this almost fixes my issue in #10910, only `roottest-root-html-runMakeIndex` needs some tweaking for the generated header file. But I think this may not be a full ""workaround"" as it doesn't handle the root issue. In fact, Jonas did mention this doesn't help with the problems about `TSeq`, which means we still have to preload `ROOTDataFrame`. > > I also made my own fix ([4757b60](https://github.com/root-project/root/commit/4757b60656381a668b24a0ea0dbf6b77aff71e14)) and I feel like it may be a better direction to work on (even though it also failed to fix `TSeq`...). > . > FWIW I pushed a new commit to #10910 and it looks like surprisingly fixes all issues even without preloading `ROOTDataFrame`! But now let's see if Jenkins is happy or not. Fingers crossed :). OK, so we still got some failures but I can't see it locally. I'll try to reproduce them, but I feel like that's the right direction. CC @hahnjo @vgvassilev",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:365,reliability,doe,doesn,365,"> > > @junaire, can you test if this solves also your problems? > > . > > . > > I haven't tested this, but @hahnjo said this almost fixes my issue in #10910, only `roottest-root-html-runMakeIndex` needs some tweaking for the generated header file. But I think this may not be a full ""workaround"" as it doesn't handle the root issue. In fact, Jonas did mention this doesn't help with the problems about `TSeq`, which means we still have to preload `ROOTDataFrame`. > > I also made my own fix ([4757b60](https://github.com/root-project/root/commit/4757b60656381a668b24a0ea0dbf6b77aff71e14)) and I feel like it may be a better direction to work on (even though it also failed to fix `TSeq`...). > . > FWIW I pushed a new commit to #10910 and it looks like surprisingly fixes all issues even without preloading `ROOTDataFrame`! But now let's see if Jenkins is happy or not. Fingers crossed :). OK, so we still got some failures but I can't see it locally. I'll try to reproduce them, but I feel like that's the right direction. CC @hahnjo @vgvassilev",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:666,reliability,fail,failed,666,"> > > @junaire, can you test if this solves also your problems? > > . > > . > > I haven't tested this, but @hahnjo said this almost fixes my issue in #10910, only `roottest-root-html-runMakeIndex` needs some tweaking for the generated header file. But I think this may not be a full ""workaround"" as it doesn't handle the root issue. In fact, Jonas did mention this doesn't help with the problems about `TSeq`, which means we still have to preload `ROOTDataFrame`. > > I also made my own fix ([4757b60](https://github.com/root-project/root/commit/4757b60656381a668b24a0ea0dbf6b77aff71e14)) and I feel like it may be a better direction to work on (even though it also failed to fix `TSeq`...). > . > FWIW I pushed a new commit to #10910 and it looks like surprisingly fixes all issues even without preloading `ROOTDataFrame`! But now let's see if Jenkins is happy or not. Fingers crossed :). OK, so we still got some failures but I can't see it locally. I'll try to reproduce them, but I feel like that's the right direction. CC @hahnjo @vgvassilev",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:915,reliability,fail,failures,915,"> > > @junaire, can you test if this solves also your problems? > > . > > . > > I haven't tested this, but @hahnjo said this almost fixes my issue in #10910, only `roottest-root-html-runMakeIndex` needs some tweaking for the generated header file. But I think this may not be a full ""workaround"" as it doesn't handle the root issue. In fact, Jonas did mention this doesn't help with the problems about `TSeq`, which means we still have to preload `ROOTDataFrame`. > > I also made my own fix ([4757b60](https://github.com/root-project/root/commit/4757b60656381a668b24a0ea0dbf6b77aff71e14)) and I feel like it may be a better direction to work on (even though it also failed to fix `TSeq`...). > . > FWIW I pushed a new commit to #10910 and it looks like surprisingly fixes all issues even without preloading `ROOTDataFrame`! But now let's see if Jenkins is happy or not. Fingers crossed :). OK, so we still got some failures but I can't see it locally. I'll try to reproduce them, but I feel like that's the right direction. CC @hahnjo @vgvassilev",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:24,safety,test,test,24,"> > > @junaire, can you test if this solves also your problems? > > . > > . > > I haven't tested this, but @hahnjo said this almost fixes my issue in #10910, only `roottest-root-html-runMakeIndex` needs some tweaking for the generated header file. But I think this may not be a full ""workaround"" as it doesn't handle the root issue. In fact, Jonas did mention this doesn't help with the problems about `TSeq`, which means we still have to preload `ROOTDataFrame`. > > I also made my own fix ([4757b60](https://github.com/root-project/root/commit/4757b60656381a668b24a0ea0dbf6b77aff71e14)) and I feel like it may be a better direction to work on (even though it also failed to fix `TSeq`...). > . > FWIW I pushed a new commit to #10910 and it looks like surprisingly fixes all issues even without preloading `ROOTDataFrame`! But now let's see if Jenkins is happy or not. Fingers crossed :). OK, so we still got some failures but I can't see it locally. I'll try to reproduce them, but I feel like that's the right direction. CC @hahnjo @vgvassilev",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:90,safety,test,tested,90,"> > > @junaire, can you test if this solves also your problems? > > . > > . > > I haven't tested this, but @hahnjo said this almost fixes my issue in #10910, only `roottest-root-html-runMakeIndex` needs some tweaking for the generated header file. But I think this may not be a full ""workaround"" as it doesn't handle the root issue. In fact, Jonas did mention this doesn't help with the problems about `TSeq`, which means we still have to preload `ROOTDataFrame`. > > I also made my own fix ([4757b60](https://github.com/root-project/root/commit/4757b60656381a668b24a0ea0dbf6b77aff71e14)) and I feel like it may be a better direction to work on (even though it also failed to fix `TSeq`...). > . > FWIW I pushed a new commit to #10910 and it looks like surprisingly fixes all issues even without preloading `ROOTDataFrame`! But now let's see if Jenkins is happy or not. Fingers crossed :). OK, so we still got some failures but I can't see it locally. I'll try to reproduce them, but I feel like that's the right direction. CC @hahnjo @vgvassilev",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:24,testability,test,test,24,"> > > @junaire, can you test if this solves also your problems? > > . > > . > > I haven't tested this, but @hahnjo said this almost fixes my issue in #10910, only `roottest-root-html-runMakeIndex` needs some tweaking for the generated header file. But I think this may not be a full ""workaround"" as it doesn't handle the root issue. In fact, Jonas did mention this doesn't help with the problems about `TSeq`, which means we still have to preload `ROOTDataFrame`. > > I also made my own fix ([4757b60](https://github.com/root-project/root/commit/4757b60656381a668b24a0ea0dbf6b77aff71e14)) and I feel like it may be a better direction to work on (even though it also failed to fix `TSeq`...). > . > FWIW I pushed a new commit to #10910 and it looks like surprisingly fixes all issues even without preloading `ROOTDataFrame`! But now let's see if Jenkins is happy or not. Fingers crossed :). OK, so we still got some failures but I can't see it locally. I'll try to reproduce them, but I feel like that's the right direction. CC @hahnjo @vgvassilev",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:90,testability,test,tested,90,"> > > @junaire, can you test if this solves also your problems? > > . > > . > > I haven't tested this, but @hahnjo said this almost fixes my issue in #10910, only `roottest-root-html-runMakeIndex` needs some tweaking for the generated header file. But I think this may not be a full ""workaround"" as it doesn't handle the root issue. In fact, Jonas did mention this doesn't help with the problems about `TSeq`, which means we still have to preload `ROOTDataFrame`. > > I also made my own fix ([4757b60](https://github.com/root-project/root/commit/4757b60656381a668b24a0ea0dbf6b77aff71e14)) and I feel like it may be a better direction to work on (even though it also failed to fix `TSeq`...). > . > FWIW I pushed a new commit to #10910 and it looks like surprisingly fixes all issues even without preloading `ROOTDataFrame`! But now let's see if Jenkins is happy or not. Fingers crossed :). OK, so we still got some failures but I can't see it locally. I'll try to reproduce them, but I feel like that's the right direction. CC @hahnjo @vgvassilev",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:373,usability,help,help,373,"> > > @junaire, can you test if this solves also your problems? > > . > > . > > I haven't tested this, but @hahnjo said this almost fixes my issue in #10910, only `roottest-root-html-runMakeIndex` needs some tweaking for the generated header file. But I think this may not be a full ""workaround"" as it doesn't handle the root issue. In fact, Jonas did mention this doesn't help with the problems about `TSeq`, which means we still have to preload `ROOTDataFrame`. > > I also made my own fix ([4757b60](https://github.com/root-project/root/commit/4757b60656381a668b24a0ea0dbf6b77aff71e14)) and I feel like it may be a better direction to work on (even though it also failed to fix `TSeq`...). > . > FWIW I pushed a new commit to #10910 and it looks like surprisingly fixes all issues even without preloading `ROOTDataFrame`! But now let's see if Jenkins is happy or not. Fingers crossed :). OK, so we still got some failures but I can't see it locally. I'll try to reproduce them, but I feel like that's the right direction. CC @hahnjo @vgvassilev",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:229,availability,failur,failures,229,"@vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. FWIW I don't agree that the workarounds (hacks) introduced in https://github.com/root-project/root/pull/10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:650,availability,state,states,650,"@vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. FWIW I don't agree that the workarounds (hacks) introduced in https://github.com/root-project/root/pull/10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:229,deployability,fail,failures,229,"@vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. FWIW I don't agree that the workarounds (hacks) introduced in https://github.com/root-project/root/pull/10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:401,deployability,fail,failing,401,"@vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. FWIW I don't agree that the workarounds (hacks) introduced in https://github.com/root-project/root/pull/10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:559,deployability,fail,failing,559,"@vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. FWIW I don't agree that the workarounds (hacks) introduced in https://github.com/root-project/root/pull/10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:509,energy efficiency,current,currently,509,"@vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. FWIW I don't agree that the workarounds (hacks) introduced in https://github.com/root-project/root/pull/10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:602,integrability,event,eventually,602,"@vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. FWIW I don't agree that the workarounds (hacks) introduced in https://github.com/root-project/root/pull/10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:650,integrability,state,states,650,"@vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. FWIW I don't agree that the workarounds (hacks) introduced in https://github.com/root-project/root/pull/10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:229,performance,failur,failures,229,"@vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. FWIW I don't agree that the workarounds (hacks) introduced in https://github.com/root-project/root/pull/10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:229,reliability,fail,failures,229,"@vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. FWIW I don't agree that the workarounds (hacks) introduced in https://github.com/root-project/root/pull/10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:401,reliability,fail,failing,401,"@vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. FWIW I don't agree that the workarounds (hacks) introduced in https://github.com/root-project/root/pull/10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:559,reliability,fail,failing,559,"@vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. FWIW I don't agree that the workarounds (hacks) introduced in https://github.com/root-project/root/pull/10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:409,safety,test,tests,409,"@vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. FWIW I don't agree that the workarounds (hacks) introduced in https://github.com/root-project/root/pull/10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:466,safety,valid,valid,466,"@vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. FWIW I don't agree that the workarounds (hacks) introduced in https://github.com/root-project/root/pull/10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:567,safety,test,tests,567,"@vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. FWIW I don't agree that the workarounds (hacks) introduced in https://github.com/root-project/root/pull/10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:289,security,hack,hacks,289,"@vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. FWIW I don't agree that the workarounds (hacks) introduced in https://github.com/root-project/root/pull/10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:409,testability,test,tests,409,"@vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. FWIW I don't agree that the workarounds (hacks) introduced in https://github.com/root-project/root/pull/10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:567,testability,test,tests,567,"@vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. FWIW I don't agree that the workarounds (hacks) introduced in https://github.com/root-project/root/pull/10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:231,availability,failur,failures,231,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:617,availability,state,states,617,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:960,availability,failur,failures,960,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:1108,availability,failur,failure,1108,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:1302,availability,failur,failures,1302,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:231,deployability,fail,failures,231,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:368,deployability,fail,failing,368,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:526,deployability,fail,failing,526,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:854,deployability,fail,failing,854,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:960,deployability,fail,failures,960,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:986,deployability,build,build,986,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:1027,deployability,build,builders,1027,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:1108,deployability,fail,failure,1108,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:1220,deployability,patch,patch,1220,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:1302,deployability,fail,failures,1302,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:476,energy efficiency,current,currently,476,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:925,energy efficiency,Current,Currently,925,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:569,integrability,event,eventually,569,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:617,integrability,state,states,617,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:1188,integrability,discover,discover,1188,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:977,interoperability,specif,specific,977,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:1188,interoperability,discover,discover,1188,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:231,performance,failur,failures,231,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:960,performance,failur,failures,960,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:1108,performance,failur,failure,1108,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:1180,performance,time,time,1180,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:1302,performance,failur,failures,1302,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:231,reliability,fail,failures,231,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:368,reliability,fail,failing,368,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:526,reliability,fail,failing,526,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:854,reliability,fail,failing,854,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:960,reliability,fail,failures,960,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:1108,reliability,fail,failure,1108,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:1302,reliability,fail,failures,1302,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:376,safety,test,tests,376,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:433,safety,valid,valid,433,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:534,safety,test,tests,534,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:862,safety,test,tests,862,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:1053,safety,test,tested,1053,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:1220,safety,patch,patch,1220,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:297,security,hack,hacks,297,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:1220,security,patch,patch,1220,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:376,testability,test,tests,376,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:534,testability,test,tests,534,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:862,testability,test,tests,862,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:1053,testability,test,tested,1053,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:1188,usability,discov,discover,1188,"> @vgvassilev as I wrote on Mattermost, this change was particularly written to address Jun's problem. `roottest-root-html-runMakeIndex` is a separate thing that needs addressing anyhow; it's only now visible because all the other failures are gone. > . > FWIW I don't agree that the workarounds (hacks) introduced in #10910 are a good way to go, as shown by the many failing tests. The scope of the changes is too big and there are valid reasons to do something with `Decl`s currently being defined, as evidenced by the many failing tests. Adding more conditions will eventually only lead to internally inconsistent states... The ""workaround"" introduced in #10910 is not only intended to address my problem but also serves as a more generic fix. It makes more sense right? disable the callback when we're instantiating templates. > as shown by the many failing tests. Ahh... yes and no, actually we're almost getting there. Currently, it is just some strange failures in some specific build bots (`ROOT-debian10-i386` and mac builders) We also haven't tested that separately so who knows what triggered the failure. I'm not really sure which way is the best to go, we still need time to discover, can you check if that patch fixes your issue? Also, I would appreciate it if you can take a look at the failures to see if you have a clue or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:79,availability,failur,failures,79,"@junaire tests *should* be clean in CI builds, as you can see for this PR. Any failures are introduced by the code changes, possibly due to exposing other issues (as was the case here, leading to this fix). And it's not only some obscure platforms, but both macOS and two of the three Linux platforms. But we should discuss this on the PR itself, not here...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:39,deployability,build,builds,39,"@junaire tests *should* be clean in CI builds, as you can see for this PR. Any failures are introduced by the code changes, possibly due to exposing other issues (as was the case here, leading to this fix). And it's not only some obscure platforms, but both macOS and two of the three Linux platforms. But we should discuss this on the PR itself, not here...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:79,deployability,fail,failures,79,"@junaire tests *should* be clean in CI builds, as you can see for this PR. Any failures are introduced by the code changes, possibly due to exposing other issues (as was the case here, leading to this fix). And it's not only some obscure platforms, but both macOS and two of the three Linux platforms. But we should discuss this on the PR itself, not here...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:238,interoperability,platform,platforms,238,"@junaire tests *should* be clean in CI builds, as you can see for this PR. Any failures are introduced by the code changes, possibly due to exposing other issues (as was the case here, leading to this fix). And it's not only some obscure platforms, but both macOS and two of the three Linux platforms. But we should discuss this on the PR itself, not here...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:291,interoperability,platform,platforms,291,"@junaire tests *should* be clean in CI builds, as you can see for this PR. Any failures are introduced by the code changes, possibly due to exposing other issues (as was the case here, leading to this fix). And it's not only some obscure platforms, but both macOS and two of the three Linux platforms. But we should discuss this on the PR itself, not here...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:79,performance,failur,failures,79,"@junaire tests *should* be clean in CI builds, as you can see for this PR. Any failures are introduced by the code changes, possibly due to exposing other issues (as was the case here, leading to this fix). And it's not only some obscure platforms, but both macOS and two of the three Linux platforms. But we should discuss this on the PR itself, not here...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:79,reliability,fail,failures,79,"@junaire tests *should* be clean in CI builds, as you can see for this PR. Any failures are introduced by the code changes, possibly due to exposing other issues (as was the case here, leading to this fix). And it's not only some obscure platforms, but both macOS and two of the three Linux platforms. But we should discuss this on the PR itself, not here...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:9,safety,test,tests,9,"@junaire tests *should* be clean in CI builds, as you can see for this PR. Any failures are introduced by the code changes, possibly due to exposing other issues (as was the case here, leading to this fix). And it's not only some obscure platforms, but both macOS and two of the three Linux platforms. But we should discuss this on the PR itself, not here...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:140,security,expos,exposing,140,"@junaire tests *should* be clean in CI builds, as you can see for this PR. Any failures are introduced by the code changes, possibly due to exposing other issues (as was the case here, leading to this fix). And it's not only some obscure platforms, but both macOS and two of the three Linux platforms. But we should discuss this on the PR itself, not here...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:9,testability,test,tests,9,"@junaire tests *should* be clean in CI builds, as you can see for this PR. Any failures are introduced by the code changes, possibly due to exposing other issues (as was the case here, leading to this fix). And it's not only some obscure platforms, but both macOS and two of the three Linux platforms. But we should discuss this on the PR itself, not here...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:81,availability,failur,failures,81,"> @junaire tests _should_ be clean in CI builds, as you can see for this PR. Any failures are introduced by the code changes, possibly due to exposing other issues (as was the case here, leading to this fix). And it's not only some obscure platforms, but both macOS and two of the three Linux platforms. But we should discuss this on the PR itself, not here... Sorry about discussing unrelated content here, I sent you a message in mattermost. Anyway, thanks for your help!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:41,deployability,build,builds,41,"> @junaire tests _should_ be clean in CI builds, as you can see for this PR. Any failures are introduced by the code changes, possibly due to exposing other issues (as was the case here, leading to this fix). And it's not only some obscure platforms, but both macOS and two of the three Linux platforms. But we should discuss this on the PR itself, not here... Sorry about discussing unrelated content here, I sent you a message in mattermost. Anyway, thanks for your help!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:81,deployability,fail,failures,81,"> @junaire tests _should_ be clean in CI builds, as you can see for this PR. Any failures are introduced by the code changes, possibly due to exposing other issues (as was the case here, leading to this fix). And it's not only some obscure platforms, but both macOS and two of the three Linux platforms. But we should discuss this on the PR itself, not here... Sorry about discussing unrelated content here, I sent you a message in mattermost. Anyway, thanks for your help!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:421,integrability,messag,message,421,"> @junaire tests _should_ be clean in CI builds, as you can see for this PR. Any failures are introduced by the code changes, possibly due to exposing other issues (as was the case here, leading to this fix). And it's not only some obscure platforms, but both macOS and two of the three Linux platforms. But we should discuss this on the PR itself, not here... Sorry about discussing unrelated content here, I sent you a message in mattermost. Anyway, thanks for your help!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:240,interoperability,platform,platforms,240,"> @junaire tests _should_ be clean in CI builds, as you can see for this PR. Any failures are introduced by the code changes, possibly due to exposing other issues (as was the case here, leading to this fix). And it's not only some obscure platforms, but both macOS and two of the three Linux platforms. But we should discuss this on the PR itself, not here... Sorry about discussing unrelated content here, I sent you a message in mattermost. Anyway, thanks for your help!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:293,interoperability,platform,platforms,293,"> @junaire tests _should_ be clean in CI builds, as you can see for this PR. Any failures are introduced by the code changes, possibly due to exposing other issues (as was the case here, leading to this fix). And it's not only some obscure platforms, but both macOS and two of the three Linux platforms. But we should discuss this on the PR itself, not here... Sorry about discussing unrelated content here, I sent you a message in mattermost. Anyway, thanks for your help!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:421,interoperability,messag,message,421,"> @junaire tests _should_ be clean in CI builds, as you can see for this PR. Any failures are introduced by the code changes, possibly due to exposing other issues (as was the case here, leading to this fix). And it's not only some obscure platforms, but both macOS and two of the three Linux platforms. But we should discuss this on the PR itself, not here... Sorry about discussing unrelated content here, I sent you a message in mattermost. Anyway, thanks for your help!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:81,performance,failur,failures,81,"> @junaire tests _should_ be clean in CI builds, as you can see for this PR. Any failures are introduced by the code changes, possibly due to exposing other issues (as was the case here, leading to this fix). And it's not only some obscure platforms, but both macOS and two of the three Linux platforms. But we should discuss this on the PR itself, not here... Sorry about discussing unrelated content here, I sent you a message in mattermost. Anyway, thanks for your help!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:394,performance,content,content,394,"> @junaire tests _should_ be clean in CI builds, as you can see for this PR. Any failures are introduced by the code changes, possibly due to exposing other issues (as was the case here, leading to this fix). And it's not only some obscure platforms, but both macOS and two of the three Linux platforms. But we should discuss this on the PR itself, not here... Sorry about discussing unrelated content here, I sent you a message in mattermost. Anyway, thanks for your help!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:81,reliability,fail,failures,81,"> @junaire tests _should_ be clean in CI builds, as you can see for this PR. Any failures are introduced by the code changes, possibly due to exposing other issues (as was the case here, leading to this fix). And it's not only some obscure platforms, but both macOS and two of the three Linux platforms. But we should discuss this on the PR itself, not here... Sorry about discussing unrelated content here, I sent you a message in mattermost. Anyway, thanks for your help!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:11,safety,test,tests,11,"> @junaire tests _should_ be clean in CI builds, as you can see for this PR. Any failures are introduced by the code changes, possibly due to exposing other issues (as was the case here, leading to this fix). And it's not only some obscure platforms, but both macOS and two of the three Linux platforms. But we should discuss this on the PR itself, not here... Sorry about discussing unrelated content here, I sent you a message in mattermost. Anyway, thanks for your help!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:142,security,expos,exposing,142,"> @junaire tests _should_ be clean in CI builds, as you can see for this PR. Any failures are introduced by the code changes, possibly due to exposing other issues (as was the case here, leading to this fix). And it's not only some obscure platforms, but both macOS and two of the three Linux platforms. But we should discuss this on the PR itself, not here... Sorry about discussing unrelated content here, I sent you a message in mattermost. Anyway, thanks for your help!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:11,testability,test,tests,11,"> @junaire tests _should_ be clean in CI builds, as you can see for this PR. Any failures are introduced by the code changes, possibly due to exposing other issues (as was the case here, leading to this fix). And it's not only some obscure platforms, but both macOS and two of the three Linux platforms. But we should discuss this on the PR itself, not here... Sorry about discussing unrelated content here, I sent you a message in mattermost. Anyway, thanks for your help!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:468,usability,help,help,468,"> @junaire tests _should_ be clean in CI builds, as you can see for this PR. Any failures are introduced by the code changes, possibly due to exposing other issues (as was the case here, leading to this fix). And it's not only some obscure platforms, but both macOS and two of the three Linux platforms. But we should discuss this on the PR itself, not here... Sorry about discussing unrelated content here, I sent you a message in mattermost. Anyway, thanks for your help!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:76,availability,failur,failures,76,"This change looks good to me, do we have a plan what to do with the current failures?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:76,deployability,fail,failures,76,"This change looks good to me, do we have a plan what to do with the current failures?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:68,energy efficiency,current,current,68,"This change looks good to me, do we have a plan what to do with the current failures?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:76,performance,failur,failures,76,"This change looks good to me, do we have a plan what to do with the current failures?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:76,reliability,fail,failures,76,"This change looks good to me, do we have a plan what to do with the current failures?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:43,testability,plan,plan,43,"This change looks good to me, do we have a plan what to do with the current failures?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:16,availability,failur,failure,16,"@vgvassilev the failure is in a `nortcxxmod`, that's why I wondered about this case. The previous implementation looking at the `SourceLocation`s worked, so there must be *some* differences...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:16,deployability,fail,failure,16,"@vgvassilev the failure is in a `nortcxxmod`, that's why I wondered about this case. The previous implementation looking at the `SourceLocation`s worked, so there must be *some* differences...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:16,performance,failur,failure,16,"@vgvassilev the failure is in a `nortcxxmod`, that's why I wondered about this case. The previous implementation looking at the `SourceLocation`s worked, so there must be *some* differences...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:16,reliability,fail,failure,16,"@vgvassilev the failure is in a `nortcxxmod`, that's why I wondered about this case. The previous implementation looking at the `SourceLocation`s worked, so there must be *some* differences...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:18,availability,failur,failure,18,"> @vgvassilev the failure is in a `nortcxxmod`, that's why I wondered about this case. The previous implementation looking at the `SourceLocation`s worked, so there must be _some_ differences... I suspect that `std::pair<edm::Value>` returned `true` which we can classify more accurately now. Template instantiations are a weird beast that can contain both content from a system header and non-system headers. I suspect that `hasOwningModule` is false. For the PCH usually it is enough to use `isFromASTFile`. . PS: On a second thought that would probably fail elsewhere..",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:18,deployability,fail,failure,18,"> @vgvassilev the failure is in a `nortcxxmod`, that's why I wondered about this case. The previous implementation looking at the `SourceLocation`s worked, so there must be _some_ differences... I suspect that `std::pair<edm::Value>` returned `true` which we can classify more accurately now. Template instantiations are a weird beast that can contain both content from a system header and non-system headers. I suspect that `hasOwningModule` is false. For the PCH usually it is enough to use `isFromASTFile`. . PS: On a second thought that would probably fail elsewhere..",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:344,deployability,contain,contain,344,"> @vgvassilev the failure is in a `nortcxxmod`, that's why I wondered about this case. The previous implementation looking at the `SourceLocation`s worked, so there must be _some_ differences... I suspect that `std::pair<edm::Value>` returned `true` which we can classify more accurately now. Template instantiations are a weird beast that can contain both content from a system header and non-system headers. I suspect that `hasOwningModule` is false. For the PCH usually it is enough to use `isFromASTFile`. . PS: On a second thought that would probably fail elsewhere..",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:556,deployability,fail,fail,556,"> @vgvassilev the failure is in a `nortcxxmod`, that's why I wondered about this case. The previous implementation looking at the `SourceLocation`s worked, so there must be _some_ differences... I suspect that `std::pair<edm::Value>` returned `true` which we can classify more accurately now. Template instantiations are a weird beast that can contain both content from a system header and non-system headers. I suspect that `hasOwningModule` is false. For the PCH usually it is enough to use `isFromASTFile`. . PS: On a second thought that would probably fail elsewhere..",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:18,performance,failur,failure,18,"> @vgvassilev the failure is in a `nortcxxmod`, that's why I wondered about this case. The previous implementation looking at the `SourceLocation`s worked, so there must be _some_ differences... I suspect that `std::pair<edm::Value>` returned `true` which we can classify more accurately now. Template instantiations are a weird beast that can contain both content from a system header and non-system headers. I suspect that `hasOwningModule` is false. For the PCH usually it is enough to use `isFromASTFile`. . PS: On a second thought that would probably fail elsewhere..",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:357,performance,content,content,357,"> @vgvassilev the failure is in a `nortcxxmod`, that's why I wondered about this case. The previous implementation looking at the `SourceLocation`s worked, so there must be _some_ differences... I suspect that `std::pair<edm::Value>` returned `true` which we can classify more accurately now. Template instantiations are a weird beast that can contain both content from a system header and non-system headers. I suspect that `hasOwningModule` is false. For the PCH usually it is enough to use `isFromASTFile`. . PS: On a second thought that would probably fail elsewhere..",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:18,reliability,fail,failure,18,"> @vgvassilev the failure is in a `nortcxxmod`, that's why I wondered about this case. The previous implementation looking at the `SourceLocation`s worked, so there must be _some_ differences... I suspect that `std::pair<edm::Value>` returned `true` which we can classify more accurately now. Template instantiations are a weird beast that can contain both content from a system header and non-system headers. I suspect that `hasOwningModule` is false. For the PCH usually it is enough to use `isFromASTFile`. . PS: On a second thought that would probably fail elsewhere..",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:556,reliability,fail,fail,556,"> @vgvassilev the failure is in a `nortcxxmod`, that's why I wondered about this case. The previous implementation looking at the `SourceLocation`s worked, so there must be _some_ differences... I suspect that `std::pair<edm::Value>` returned `true` which we can classify more accurately now. Template instantiations are a weird beast that can contain both content from a system header and non-system headers. I suspect that `hasOwningModule` is false. For the PCH usually it is enough to use `isFromASTFile`. . PS: On a second thought that would probably fail elsewhere..",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:0,availability,ping,ping,0,ping...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:161,deployability,modul,module,161,> disable the callback when we're instantiating templates. As long as we do before hand the side effects. ie seeing `templateclass<MyClass>` we need to load the module for `MyClass` first.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:152,energy efficiency,load,load,152,> disable the callback when we're instantiating templates. As long as we do before hand the side effects. ie seeing `templateclass<MyClass>` we need to load the module for `MyClass` first.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:161,modifiability,modul,module,161,> disable the callback when we're instantiating templates. As long as we do before hand the side effects. ie seeing `templateclass<MyClass>` we need to load the module for `MyClass` first.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:152,performance,load,load,152,> disable the callback when we're instantiating templates. As long as we do before hand the side effects. ie seeing `templateclass<MyClass>` we need to load the module for `MyClass` first.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/pull/11514:161,safety,modul,module,161,> disable the callback when we're instantiating templates. As long as we do before hand the side effects. ie seeing `templateclass<MyClass>` we need to load the module for `MyClass` first.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11514
https://github.com/root-project/root/issues/11515:15,testability,trace,trace,15,> Thread1. The trace of this thread looks quite similar to the one at https://github.com/root-project/root/issues/8365#issuecomment-878288640 but probably it's just an unrelated issue,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:40,deployability,stack,stack,40,"For completeness, what are the complete stack trace for thread 1 and 21?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:4,safety,compl,completeness,4,"For completeness, what are the complete stack trace for thread 1 and 21?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:31,safety,compl,complete,31,"For completeness, what are the complete stack trace for thread 1 and 21?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:4,security,compl,completeness,4,"For completeness, what are the complete stack trace for thread 1 and 21?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:31,security,compl,complete,31,"For completeness, what are the complete stack trace for thread 1 and 21?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:46,testability,trace,trace,46,"For completeness, what are the complete stack trace for thread 1 and 21?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:11,deployability,stack,stacktrace,11,# Complete stacktrace of thread 1. [stacktrace_thread1.txt](https://github.com/root-project/root/files/9735449/stacktrace_thread1.txt). # Complete stacktrace of thread 21. [stacktrace_thread21.txt](https://github.com/root-project/root/files/9735450/stacktrace_thread21.txt).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:147,deployability,stack,stacktrace,147,# Complete stacktrace of thread 1. [stacktrace_thread1.txt](https://github.com/root-project/root/files/9735449/stacktrace_thread1.txt). # Complete stacktrace of thread 21. [stacktrace_thread21.txt](https://github.com/root-project/root/files/9735450/stacktrace_thread21.txt).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2,safety,Compl,Complete,2,# Complete stacktrace of thread 1. [stacktrace_thread1.txt](https://github.com/root-project/root/files/9735449/stacktrace_thread1.txt). # Complete stacktrace of thread 21. [stacktrace_thread21.txt](https://github.com/root-project/root/files/9735450/stacktrace_thread21.txt).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:138,safety,Compl,Complete,138,# Complete stacktrace of thread 1. [stacktrace_thread1.txt](https://github.com/root-project/root/files/9735449/stacktrace_thread1.txt). # Complete stacktrace of thread 21. [stacktrace_thread21.txt](https://github.com/root-project/root/files/9735450/stacktrace_thread21.txt).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2,security,Compl,Complete,2,# Complete stacktrace of thread 1. [stacktrace_thread1.txt](https://github.com/root-project/root/files/9735449/stacktrace_thread1.txt). # Complete stacktrace of thread 21. [stacktrace_thread21.txt](https://github.com/root-project/root/files/9735450/stacktrace_thread21.txt).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:138,security,Compl,Complete,138,# Complete stacktrace of thread 1. [stacktrace_thread1.txt](https://github.com/root-project/root/files/9735449/stacktrace_thread1.txt). # Complete stacktrace of thread 21. [stacktrace_thread21.txt](https://github.com/root-project/root/files/9735450/stacktrace_thread21.txt).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:86,availability,error,error,86,Can you also instrument `IncrementalExecutor::diagnoseUnresolvedSymbols` to print its error to `std::cout` so we get more details?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:86,performance,error,error,86,Can you also instrument `IncrementalExecutor::diagnoseUnresolvedSymbols` to print its error to `std::cout` so we get more details?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:46,reliability,diagno,diagnoseUnresolvedSymbols,46,Can you also instrument `IncrementalExecutor::diagnoseUnresolvedSymbols` to print its error to `std::cout` so we get more details?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:86,safety,error,error,86,Can you also instrument `IncrementalExecutor::diagnoseUnresolvedSymbols` to print its error to `std::cout` so we get more details?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:13,testability,instrument,instrument,13,Can you also instrument `IncrementalExecutor::diagnoseUnresolvedSymbols` to print its error to `std::cout` so we get more details?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:46,testability,diagno,diagnoseUnresolvedSymbols,46,Can you also instrument `IncrementalExecutor::diagnoseUnresolvedSymbols` to print its error to `std::cout` so we get more details?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:86,usability,error,error,86,Can you also instrument `IncrementalExecutor::diagnoseUnresolvedSymbols` to print its error to `std::cout` so we get more details?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:133,deployability,stack,stack,133,Most likely the problem is that `TClingClassInfo::IsEnum` is missing a `R__LOCKGUARD(gInterpreterMutex);` before the creation of the stack `TClingClassInfo`.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:86,availability,error,error,86,"> Can you also instrument IncrementalExecutor::diagnoseUnresolvedSymbols to print its error to std::cout so we get more details? I converted instances of `cling::errs` to `cling::outs`, no output is shown from that function when the error appears. > Most likely the problem is that TClingClassInfo::IsEnum is missing a R__LOCKGUARD(gInterpreterMutex); before the creation of the stack TClingClassInfo. This did something actually, now I quite consistently always get a segfault, seemingly triggered by Python, with this stacktrace. ```. Thread 1 (Thread 0x7f4d67fcc740 (LWP 53296) ""python""):. #0 0x00007f4d68189bdf in wait4 () from /lib64/libc.so.6. #1 0x00007f4d680f8a1b in do_system () from /lib64/libc.so.6. #2 0x00007f4d2f521370 in TUnixSystem::Exec (this=0x55bd15241770, shellcmd=0x55bd2b060400 ""/home/vpadulan/programs/rootproject/rootbuild/master-distrdf-debug/etc/gdb-backtrace.sh 53296 1>&2"") at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2104. #3 0x00007f4d2f521c11 in TUnixSystem::StackTrace (this=0x55bd15241770) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2395. #4 0x00007f4d2f8665b4 in (anonymous namespace)::do_trace (sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:182. #5 0x00007f4d2f866644 in (anonymous namespace)::TExceptionHandlerImp::HandleException (this=0x55bd15d7d000, sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:201. #6 0x00007f4d2f5255f9 in TUnixSystem::DispatchSignals (this=0x55bd15241770, sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3610. #7 0x00007f4d2f51d544 in SigHandler (sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:395. #8 0x00007f4d2f52554f in sighandler (sig=6) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3586. #9",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:233,availability,error,error,233,"> Can you also instrument IncrementalExecutor::diagnoseUnresolvedSymbols to print its error to std::cout so we get more details? I converted instances of `cling::errs` to `cling::outs`, no output is shown from that function when the error appears. > Most likely the problem is that TClingClassInfo::IsEnum is missing a R__LOCKGUARD(gInterpreterMutex); before the creation of the stack TClingClassInfo. This did something actually, now I quite consistently always get a segfault, seemingly triggered by Python, with this stacktrace. ```. Thread 1 (Thread 0x7f4d67fcc740 (LWP 53296) ""python""):. #0 0x00007f4d68189bdf in wait4 () from /lib64/libc.so.6. #1 0x00007f4d680f8a1b in do_system () from /lib64/libc.so.6. #2 0x00007f4d2f521370 in TUnixSystem::Exec (this=0x55bd15241770, shellcmd=0x55bd2b060400 ""/home/vpadulan/programs/rootproject/rootbuild/master-distrdf-debug/etc/gdb-backtrace.sh 53296 1>&2"") at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2104. #3 0x00007f4d2f521c11 in TUnixSystem::StackTrace (this=0x55bd15241770) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2395. #4 0x00007f4d2f8665b4 in (anonymous namespace)::do_trace (sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:182. #5 0x00007f4d2f866644 in (anonymous namespace)::TExceptionHandlerImp::HandleException (this=0x55bd15d7d000, sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:201. #6 0x00007f4d2f5255f9 in TUnixSystem::DispatchSignals (this=0x55bd15241770, sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3610. #7 0x00007f4d2f51d544 in SigHandler (sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:395. #8 0x00007f4d2f52554f in sighandler (sig=6) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3586. #9",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:443,availability,consist,consistently,443,"> Can you also instrument IncrementalExecutor::diagnoseUnresolvedSymbols to print its error to std::cout so we get more details? I converted instances of `cling::errs` to `cling::outs`, no output is shown from that function when the error appears. > Most likely the problem is that TClingClassInfo::IsEnum is missing a R__LOCKGUARD(gInterpreterMutex); before the creation of the stack TClingClassInfo. This did something actually, now I quite consistently always get a segfault, seemingly triggered by Python, with this stacktrace. ```. Thread 1 (Thread 0x7f4d67fcc740 (LWP 53296) ""python""):. #0 0x00007f4d68189bdf in wait4 () from /lib64/libc.so.6. #1 0x00007f4d680f8a1b in do_system () from /lib64/libc.so.6. #2 0x00007f4d2f521370 in TUnixSystem::Exec (this=0x55bd15241770, shellcmd=0x55bd2b060400 ""/home/vpadulan/programs/rootproject/rootbuild/master-distrdf-debug/etc/gdb-backtrace.sh 53296 1>&2"") at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2104. #3 0x00007f4d2f521c11 in TUnixSystem::StackTrace (this=0x55bd15241770) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2395. #4 0x00007f4d2f8665b4 in (anonymous namespace)::do_trace (sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:182. #5 0x00007f4d2f866644 in (anonymous namespace)::TExceptionHandlerImp::HandleException (this=0x55bd15d7d000, sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:201. #6 0x00007f4d2f5255f9 in TUnixSystem::DispatchSignals (this=0x55bd15241770, sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3610. #7 0x00007f4d2f51d544 in SigHandler (sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:395. #8 0x00007f4d2f52554f in sighandler (sig=6) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3586. #9",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:379,deployability,stack,stack,379,"> Can you also instrument IncrementalExecutor::diagnoseUnresolvedSymbols to print its error to std::cout so we get more details? I converted instances of `cling::errs` to `cling::outs`, no output is shown from that function when the error appears. > Most likely the problem is that TClingClassInfo::IsEnum is missing a R__LOCKGUARD(gInterpreterMutex); before the creation of the stack TClingClassInfo. This did something actually, now I quite consistently always get a segfault, seemingly triggered by Python, with this stacktrace. ```. Thread 1 (Thread 0x7f4d67fcc740 (LWP 53296) ""python""):. #0 0x00007f4d68189bdf in wait4 () from /lib64/libc.so.6. #1 0x00007f4d680f8a1b in do_system () from /lib64/libc.so.6. #2 0x00007f4d2f521370 in TUnixSystem::Exec (this=0x55bd15241770, shellcmd=0x55bd2b060400 ""/home/vpadulan/programs/rootproject/rootbuild/master-distrdf-debug/etc/gdb-backtrace.sh 53296 1>&2"") at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2104. #3 0x00007f4d2f521c11 in TUnixSystem::StackTrace (this=0x55bd15241770) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2395. #4 0x00007f4d2f8665b4 in (anonymous namespace)::do_trace (sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:182. #5 0x00007f4d2f866644 in (anonymous namespace)::TExceptionHandlerImp::HandleException (this=0x55bd15d7d000, sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:201. #6 0x00007f4d2f5255f9 in TUnixSystem::DispatchSignals (this=0x55bd15241770, sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3610. #7 0x00007f4d2f51d544 in SigHandler (sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:395. #8 0x00007f4d2f52554f in sighandler (sig=6) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3586. #9",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:520,deployability,stack,stacktrace,520,"> Can you also instrument IncrementalExecutor::diagnoseUnresolvedSymbols to print its error to std::cout so we get more details? I converted instances of `cling::errs` to `cling::outs`, no output is shown from that function when the error appears. > Most likely the problem is that TClingClassInfo::IsEnum is missing a R__LOCKGUARD(gInterpreterMutex); before the creation of the stack TClingClassInfo. This did something actually, now I quite consistently always get a segfault, seemingly triggered by Python, with this stacktrace. ```. Thread 1 (Thread 0x7f4d67fcc740 (LWP 53296) ""python""):. #0 0x00007f4d68189bdf in wait4 () from /lib64/libc.so.6. #1 0x00007f4d680f8a1b in do_system () from /lib64/libc.so.6. #2 0x00007f4d2f521370 in TUnixSystem::Exec (this=0x55bd15241770, shellcmd=0x55bd2b060400 ""/home/vpadulan/programs/rootproject/rootbuild/master-distrdf-debug/etc/gdb-backtrace.sh 53296 1>&2"") at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2104. #3 0x00007f4d2f521c11 in TUnixSystem::StackTrace (this=0x55bd15241770) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2395. #4 0x00007f4d2f8665b4 in (anonymous namespace)::do_trace (sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:182. #5 0x00007f4d2f866644 in (anonymous namespace)::TExceptionHandlerImp::HandleException (this=0x55bd15d7d000, sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:201. #6 0x00007f4d2f5255f9 in TUnixSystem::DispatchSignals (this=0x55bd15241770, sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3610. #7 0x00007f4d2f51d544 in SigHandler (sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:395. #8 0x00007f4d2f52554f in sighandler (sig=6) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3586. #9",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1023,deployability,Stack,StackTrace,1023,"crementalExecutor::diagnoseUnresolvedSymbols to print its error to std::cout so we get more details? I converted instances of `cling::errs` to `cling::outs`, no output is shown from that function when the error appears. > Most likely the problem is that TClingClassInfo::IsEnum is missing a R__LOCKGUARD(gInterpreterMutex); before the creation of the stack TClingClassInfo. This did something actually, now I quite consistently always get a segfault, seemingly triggered by Python, with this stacktrace. ```. Thread 1 (Thread 0x7f4d67fcc740 (LWP 53296) ""python""):. #0 0x00007f4d68189bdf in wait4 () from /lib64/libc.so.6. #1 0x00007f4d680f8a1b in do_system () from /lib64/libc.so.6. #2 0x00007f4d2f521370 in TUnixSystem::Exec (this=0x55bd15241770, shellcmd=0x55bd2b060400 ""/home/vpadulan/programs/rootproject/rootbuild/master-distrdf-debug/etc/gdb-backtrace.sh 53296 1>&2"") at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2104. #3 0x00007f4d2f521c11 in TUnixSystem::StackTrace (this=0x55bd15241770) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2395. #4 0x00007f4d2f8665b4 in (anonymous namespace)::do_trace (sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:182. #5 0x00007f4d2f866644 in (anonymous namespace)::TExceptionHandlerImp::HandleException (this=0x55bd15d7d000, sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:201. #6 0x00007f4d2f5255f9 in TUnixSystem::DispatchSignals (this=0x55bd15241770, sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3610. #7 0x00007f4d2f51d544 in SigHandler (sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:395. #8 0x00007f4d2f52554f in sighandler (sig=6) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3586. #9 <signal handler called>. #1",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:949,energy efficiency,core,core,949,"> Can you also instrument IncrementalExecutor::diagnoseUnresolvedSymbols to print its error to std::cout so we get more details? I converted instances of `cling::errs` to `cling::outs`, no output is shown from that function when the error appears. > Most likely the problem is that TClingClassInfo::IsEnum is missing a R__LOCKGUARD(gInterpreterMutex); before the creation of the stack TClingClassInfo. This did something actually, now I quite consistently always get a segfault, seemingly triggered by Python, with this stacktrace. ```. Thread 1 (Thread 0x7f4d67fcc740 (LWP 53296) ""python""):. #0 0x00007f4d68189bdf in wait4 () from /lib64/libc.so.6. #1 0x00007f4d680f8a1b in do_system () from /lib64/libc.so.6. #2 0x00007f4d2f521370 in TUnixSystem::Exec (this=0x55bd15241770, shellcmd=0x55bd2b060400 ""/home/vpadulan/programs/rootproject/rootbuild/master-distrdf-debug/etc/gdb-backtrace.sh 53296 1>&2"") at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2104. #3 0x00007f4d2f521c11 in TUnixSystem::StackTrace (this=0x55bd15241770) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2395. #4 0x00007f4d2f8665b4 in (anonymous namespace)::do_trace (sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:182. #5 0x00007f4d2f866644 in (anonymous namespace)::TExceptionHandlerImp::HandleException (this=0x55bd15d7d000, sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:201. #6 0x00007f4d2f5255f9 in TUnixSystem::DispatchSignals (this=0x55bd15241770, sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3610. #7 0x00007f4d2f51d544 in SigHandler (sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:395. #8 0x00007f4d2f52554f in sighandler (sig=6) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3586. #9",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1103,energy efficiency,core,core,1103,"so we get more details? I converted instances of `cling::errs` to `cling::outs`, no output is shown from that function when the error appears. > Most likely the problem is that TClingClassInfo::IsEnum is missing a R__LOCKGUARD(gInterpreterMutex); before the creation of the stack TClingClassInfo. This did something actually, now I quite consistently always get a segfault, seemingly triggered by Python, with this stacktrace. ```. Thread 1 (Thread 0x7f4d67fcc740 (LWP 53296) ""python""):. #0 0x00007f4d68189bdf in wait4 () from /lib64/libc.so.6. #1 0x00007f4d680f8a1b in do_system () from /lib64/libc.so.6. #2 0x00007f4d2f521370 in TUnixSystem::Exec (this=0x55bd15241770, shellcmd=0x55bd2b060400 ""/home/vpadulan/programs/rootproject/rootbuild/master-distrdf-debug/etc/gdb-backtrace.sh 53296 1>&2"") at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2104. #3 0x00007f4d2f521c11 in TUnixSystem::StackTrace (this=0x55bd15241770) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2395. #4 0x00007f4d2f8665b4 in (anonymous namespace)::do_trace (sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:182. #5 0x00007f4d2f866644 in (anonymous namespace)::TExceptionHandlerImp::HandleException (this=0x55bd15d7d000, sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:201. #6 0x00007f4d2f5255f9 in TUnixSystem::DispatchSignals (this=0x55bd15241770, sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3610. #7 0x00007f4d2f51d544 in SigHandler (sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:395. #8 0x00007f4d2f52554f in sighandler (sig=6) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3586. #9 <signal handler called>. #10 0x00007f4d6813bc4c in __pthread_kill_implementation () from /lib64/libc.so.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1701,energy efficiency,core,core,1701,"c.so.6. #2 0x00007f4d2f521370 in TUnixSystem::Exec (this=0x55bd15241770, shellcmd=0x55bd2b060400 ""/home/vpadulan/programs/rootproject/rootbuild/master-distrdf-debug/etc/gdb-backtrace.sh 53296 1>&2"") at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2104. #3 0x00007f4d2f521c11 in TUnixSystem::StackTrace (this=0x55bd15241770) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2395. #4 0x00007f4d2f8665b4 in (anonymous namespace)::do_trace (sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:182. #5 0x00007f4d2f866644 in (anonymous namespace)::TExceptionHandlerImp::HandleException (this=0x55bd15d7d000, sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:201. #6 0x00007f4d2f5255f9 in TUnixSystem::DispatchSignals (this=0x55bd15241770, sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3610. #7 0x00007f4d2f51d544 in SigHandler (sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:395. #8 0x00007f4d2f52554f in sighandler (sig=6) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3586. #9 <signal handler called>. #10 0x00007f4d6813bc4c in __pthread_kill_implementation () from /lib64/libc.so.6. #11 0x00007f4d680eb9c6 in raise () from /lib64/libc.so.6. #12 0x00007f4d680d57f4 in abort () from /lib64/libc.so.6. #13 0x00007f4d683a3f3d in _Py_FatalErrorFormat () from /lib64/libpython3.10.so.1.0. #14 0x00007f4d683532d8 in _enter_buffered_busy.cold () from /lib64/libpython3.10.so.1.0. #15 0x00007f4d6846b95e in buffered_flush () from /lib64/libpython3.10.so.1.0. #16 0x00007f4d683d0c24 in method_vectorcall_NOARGS () from /lib64/libpython3.10.so.1.0. #17 0x00007f4d683dfdae in PyObject_VectorcallMethod () from /lib64/libpython3.10.so.1.0. #18 0x00007f4d6846b70e in _io_TextIOWrapper_flush (",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1836,energy efficiency,core,core,1836,"ootbuild/master-distrdf-debug/etc/gdb-backtrace.sh 53296 1>&2"") at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2104. #3 0x00007f4d2f521c11 in TUnixSystem::StackTrace (this=0x55bd15241770) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2395. #4 0x00007f4d2f8665b4 in (anonymous namespace)::do_trace (sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:182. #5 0x00007f4d2f866644 in (anonymous namespace)::TExceptionHandlerImp::HandleException (this=0x55bd15d7d000, sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:201. #6 0x00007f4d2f5255f9 in TUnixSystem::DispatchSignals (this=0x55bd15241770, sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3610. #7 0x00007f4d2f51d544 in SigHandler (sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:395. #8 0x00007f4d2f52554f in sighandler (sig=6) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3586. #9 <signal handler called>. #10 0x00007f4d6813bc4c in __pthread_kill_implementation () from /lib64/libc.so.6. #11 0x00007f4d680eb9c6 in raise () from /lib64/libc.so.6. #12 0x00007f4d680d57f4 in abort () from /lib64/libc.so.6. #13 0x00007f4d683a3f3d in _Py_FatalErrorFormat () from /lib64/libpython3.10.so.1.0. #14 0x00007f4d683532d8 in _enter_buffered_busy.cold () from /lib64/libpython3.10.so.1.0. #15 0x00007f4d6846b95e in buffered_flush () from /lib64/libpython3.10.so.1.0. #16 0x00007f4d683d0c24 in method_vectorcall_NOARGS () from /lib64/libpython3.10.so.1.0. #17 0x00007f4d683dfdae in PyObject_VectorcallMethod () from /lib64/libpython3.10.so.1.0. #18 0x00007f4d6846b70e in _io_TextIOWrapper_flush () from /lib64/libpython3.10.so.1.0. #19 0x00007f4d683d0c24 in method_vectorcall_NOARGS () from /lib64/libpython3.10.so.1.0. #20 0x00007",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1962,energy efficiency,core,core,1962,"UnixSystem.cxx:2104. #3 0x00007f4d2f521c11 in TUnixSystem::StackTrace (this=0x55bd15241770) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2395. #4 0x00007f4d2f8665b4 in (anonymous namespace)::do_trace (sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:182. #5 0x00007f4d2f866644 in (anonymous namespace)::TExceptionHandlerImp::HandleException (this=0x55bd15d7d000, sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:201. #6 0x00007f4d2f5255f9 in TUnixSystem::DispatchSignals (this=0x55bd15241770, sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3610. #7 0x00007f4d2f51d544 in SigHandler (sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:395. #8 0x00007f4d2f52554f in sighandler (sig=6) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3586. #9 <signal handler called>. #10 0x00007f4d6813bc4c in __pthread_kill_implementation () from /lib64/libc.so.6. #11 0x00007f4d680eb9c6 in raise () from /lib64/libc.so.6. #12 0x00007f4d680d57f4 in abort () from /lib64/libc.so.6. #13 0x00007f4d683a3f3d in _Py_FatalErrorFormat () from /lib64/libpython3.10.so.1.0. #14 0x00007f4d683532d8 in _enter_buffered_busy.cold () from /lib64/libpython3.10.so.1.0. #15 0x00007f4d6846b95e in buffered_flush () from /lib64/libpython3.10.so.1.0. #16 0x00007f4d683d0c24 in method_vectorcall_NOARGS () from /lib64/libpython3.10.so.1.0. #17 0x00007f4d683dfdae in PyObject_VectorcallMethod () from /lib64/libpython3.10.so.1.0. #18 0x00007f4d6846b70e in _io_TextIOWrapper_flush () from /lib64/libpython3.10.so.1.0. #19 0x00007f4d683d0c24 in method_vectorcall_NOARGS () from /lib64/libpython3.10.so.1.0. #20 0x00007f4d683dfdae in PyObject_VectorcallMethod () from /lib64/libpython3.10.so.1.0. #21 0x00007f4d6846e605 in flush_std_files () fro",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1251,interoperability,bind,bindings,1251,"likely the problem is that TClingClassInfo::IsEnum is missing a R__LOCKGUARD(gInterpreterMutex); before the creation of the stack TClingClassInfo. This did something actually, now I quite consistently always get a segfault, seemingly triggered by Python, with this stacktrace. ```. Thread 1 (Thread 0x7f4d67fcc740 (LWP 53296) ""python""):. #0 0x00007f4d68189bdf in wait4 () from /lib64/libc.so.6. #1 0x00007f4d680f8a1b in do_system () from /lib64/libc.so.6. #2 0x00007f4d2f521370 in TUnixSystem::Exec (this=0x55bd15241770, shellcmd=0x55bd2b060400 ""/home/vpadulan/programs/rootproject/rootbuild/master-distrdf-debug/etc/gdb-backtrace.sh 53296 1>&2"") at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2104. #3 0x00007f4d2f521c11 in TUnixSystem::StackTrace (this=0x55bd15241770) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2395. #4 0x00007f4d2f8665b4 in (anonymous namespace)::do_trace (sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:182. #5 0x00007f4d2f866644 in (anonymous namespace)::TExceptionHandlerImp::HandleException (this=0x55bd15d7d000, sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:201. #6 0x00007f4d2f5255f9 in TUnixSystem::DispatchSignals (this=0x55bd15241770, sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3610. #7 0x00007f4d2f51d544 in SigHandler (sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:395. #8 0x00007f4d2f52554f in sighandler (sig=6) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3586. #9 <signal handler called>. #10 0x00007f4d6813bc4c in __pthread_kill_implementation () from /lib64/libc.so.6. #11 0x00007f4d680eb9c6 in raise () from /lib64/libc.so.6. #12 0x00007f4d680d57f4 in abort () from /lib64/libc.so.6. #13 0x00007f4d683a3f3d in _Py_F",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1488,interoperability,bind,bindings,1488,"ggered by Python, with this stacktrace. ```. Thread 1 (Thread 0x7f4d67fcc740 (LWP 53296) ""python""):. #0 0x00007f4d68189bdf in wait4 () from /lib64/libc.so.6. #1 0x00007f4d680f8a1b in do_system () from /lib64/libc.so.6. #2 0x00007f4d2f521370 in TUnixSystem::Exec (this=0x55bd15241770, shellcmd=0x55bd2b060400 ""/home/vpadulan/programs/rootproject/rootbuild/master-distrdf-debug/etc/gdb-backtrace.sh 53296 1>&2"") at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2104. #3 0x00007f4d2f521c11 in TUnixSystem::StackTrace (this=0x55bd15241770) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2395. #4 0x00007f4d2f8665b4 in (anonymous namespace)::do_trace (sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:182. #5 0x00007f4d2f866644 in (anonymous namespace)::TExceptionHandlerImp::HandleException (this=0x55bd15d7d000, sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:201. #6 0x00007f4d2f5255f9 in TUnixSystem::DispatchSignals (this=0x55bd15241770, sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3610. #7 0x00007f4d2f51d544 in SigHandler (sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:395. #8 0x00007f4d2f52554f in sighandler (sig=6) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3586. #9 <signal handler called>. #10 0x00007f4d6813bc4c in __pthread_kill_implementation () from /lib64/libc.so.6. #11 0x00007f4d680eb9c6 in raise () from /lib64/libc.so.6. #12 0x00007f4d680d57f4 in abort () from /lib64/libc.so.6. #13 0x00007f4d683a3f3d in _Py_FatalErrorFormat () from /lib64/libpython3.10.so.1.0. #14 0x00007f4d683532d8 in _enter_buffered_busy.cold () from /lib64/libpython3.10.so.1.0. #15 0x00007f4d6846b95e in buffered_flush () from /lib64/libpython3.10.so.1.0. #16 0x00007f4d683",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1251,modifiability,bind,bindings,1251,"likely the problem is that TClingClassInfo::IsEnum is missing a R__LOCKGUARD(gInterpreterMutex); before the creation of the stack TClingClassInfo. This did something actually, now I quite consistently always get a segfault, seemingly triggered by Python, with this stacktrace. ```. Thread 1 (Thread 0x7f4d67fcc740 (LWP 53296) ""python""):. #0 0x00007f4d68189bdf in wait4 () from /lib64/libc.so.6. #1 0x00007f4d680f8a1b in do_system () from /lib64/libc.so.6. #2 0x00007f4d2f521370 in TUnixSystem::Exec (this=0x55bd15241770, shellcmd=0x55bd2b060400 ""/home/vpadulan/programs/rootproject/rootbuild/master-distrdf-debug/etc/gdb-backtrace.sh 53296 1>&2"") at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2104. #3 0x00007f4d2f521c11 in TUnixSystem::StackTrace (this=0x55bd15241770) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2395. #4 0x00007f4d2f8665b4 in (anonymous namespace)::do_trace (sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:182. #5 0x00007f4d2f866644 in (anonymous namespace)::TExceptionHandlerImp::HandleException (this=0x55bd15d7d000, sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:201. #6 0x00007f4d2f5255f9 in TUnixSystem::DispatchSignals (this=0x55bd15241770, sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3610. #7 0x00007f4d2f51d544 in SigHandler (sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:395. #8 0x00007f4d2f52554f in sighandler (sig=6) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3586. #9 <signal handler called>. #10 0x00007f4d6813bc4c in __pthread_kill_implementation () from /lib64/libc.so.6. #11 0x00007f4d680eb9c6 in raise () from /lib64/libc.so.6. #12 0x00007f4d680d57f4 in abort () from /lib64/libc.so.6. #13 0x00007f4d683a3f3d in _Py_F",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1488,modifiability,bind,bindings,1488,"ggered by Python, with this stacktrace. ```. Thread 1 (Thread 0x7f4d67fcc740 (LWP 53296) ""python""):. #0 0x00007f4d68189bdf in wait4 () from /lib64/libc.so.6. #1 0x00007f4d680f8a1b in do_system () from /lib64/libc.so.6. #2 0x00007f4d2f521370 in TUnixSystem::Exec (this=0x55bd15241770, shellcmd=0x55bd2b060400 ""/home/vpadulan/programs/rootproject/rootbuild/master-distrdf-debug/etc/gdb-backtrace.sh 53296 1>&2"") at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2104. #3 0x00007f4d2f521c11 in TUnixSystem::StackTrace (this=0x55bd15241770) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2395. #4 0x00007f4d2f8665b4 in (anonymous namespace)::do_trace (sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:182. #5 0x00007f4d2f866644 in (anonymous namespace)::TExceptionHandlerImp::HandleException (this=0x55bd15d7d000, sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:201. #6 0x00007f4d2f5255f9 in TUnixSystem::DispatchSignals (this=0x55bd15241770, sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3610. #7 0x00007f4d2f51d544 in SigHandler (sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:395. #8 0x00007f4d2f52554f in sighandler (sig=6) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3586. #9 <signal handler called>. #10 0x00007f4d6813bc4c in __pthread_kill_implementation () from /lib64/libc.so.6. #11 0x00007f4d680eb9c6 in raise () from /lib64/libc.so.6. #12 0x00007f4d680d57f4 in abort () from /lib64/libc.so.6. #13 0x00007f4d683a3f3d in _Py_FatalErrorFormat () from /lib64/libpython3.10.so.1.0. #14 0x00007f4d683532d8 in _enter_buffered_busy.cold () from /lib64/libpython3.10.so.1.0. #15 0x00007f4d6846b95e in buffered_flush () from /lib64/libpython3.10.so.1.0. #16 0x00007f4d683",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:86,performance,error,error,86,"> Can you also instrument IncrementalExecutor::diagnoseUnresolvedSymbols to print its error to std::cout so we get more details? I converted instances of `cling::errs` to `cling::outs`, no output is shown from that function when the error appears. > Most likely the problem is that TClingClassInfo::IsEnum is missing a R__LOCKGUARD(gInterpreterMutex); before the creation of the stack TClingClassInfo. This did something actually, now I quite consistently always get a segfault, seemingly triggered by Python, with this stacktrace. ```. Thread 1 (Thread 0x7f4d67fcc740 (LWP 53296) ""python""):. #0 0x00007f4d68189bdf in wait4 () from /lib64/libc.so.6. #1 0x00007f4d680f8a1b in do_system () from /lib64/libc.so.6. #2 0x00007f4d2f521370 in TUnixSystem::Exec (this=0x55bd15241770, shellcmd=0x55bd2b060400 ""/home/vpadulan/programs/rootproject/rootbuild/master-distrdf-debug/etc/gdb-backtrace.sh 53296 1>&2"") at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2104. #3 0x00007f4d2f521c11 in TUnixSystem::StackTrace (this=0x55bd15241770) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2395. #4 0x00007f4d2f8665b4 in (anonymous namespace)::do_trace (sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:182. #5 0x00007f4d2f866644 in (anonymous namespace)::TExceptionHandlerImp::HandleException (this=0x55bd15d7d000, sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:201. #6 0x00007f4d2f5255f9 in TUnixSystem::DispatchSignals (this=0x55bd15241770, sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3610. #7 0x00007f4d2f51d544 in SigHandler (sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:395. #8 0x00007f4d2f52554f in sighandler (sig=6) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3586. #9",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:233,performance,error,error,233,"> Can you also instrument IncrementalExecutor::diagnoseUnresolvedSymbols to print its error to std::cout so we get more details? I converted instances of `cling::errs` to `cling::outs`, no output is shown from that function when the error appears. > Most likely the problem is that TClingClassInfo::IsEnum is missing a R__LOCKGUARD(gInterpreterMutex); before the creation of the stack TClingClassInfo. This did something actually, now I quite consistently always get a segfault, seemingly triggered by Python, with this stacktrace. ```. Thread 1 (Thread 0x7f4d67fcc740 (LWP 53296) ""python""):. #0 0x00007f4d68189bdf in wait4 () from /lib64/libc.so.6. #1 0x00007f4d680f8a1b in do_system () from /lib64/libc.so.6. #2 0x00007f4d2f521370 in TUnixSystem::Exec (this=0x55bd15241770, shellcmd=0x55bd2b060400 ""/home/vpadulan/programs/rootproject/rootbuild/master-distrdf-debug/etc/gdb-backtrace.sh 53296 1>&2"") at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2104. #3 0x00007f4d2f521c11 in TUnixSystem::StackTrace (this=0x55bd15241770) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2395. #4 0x00007f4d2f8665b4 in (anonymous namespace)::do_trace (sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:182. #5 0x00007f4d2f866644 in (anonymous namespace)::TExceptionHandlerImp::HandleException (this=0x55bd15d7d000, sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:201. #6 0x00007f4d2f5255f9 in TUnixSystem::DispatchSignals (this=0x55bd15241770, sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3610. #7 0x00007f4d2f51d544 in SigHandler (sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:395. #8 0x00007f4d2f52554f in sighandler (sig=6) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3586. #9",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:47,reliability,diagno,diagnoseUnresolvedSymbols,47,"> Can you also instrument IncrementalExecutor::diagnoseUnresolvedSymbols to print its error to std::cout so we get more details? I converted instances of `cling::errs` to `cling::outs`, no output is shown from that function when the error appears. > Most likely the problem is that TClingClassInfo::IsEnum is missing a R__LOCKGUARD(gInterpreterMutex); before the creation of the stack TClingClassInfo. This did something actually, now I quite consistently always get a segfault, seemingly triggered by Python, with this stacktrace. ```. Thread 1 (Thread 0x7f4d67fcc740 (LWP 53296) ""python""):. #0 0x00007f4d68189bdf in wait4 () from /lib64/libc.so.6. #1 0x00007f4d680f8a1b in do_system () from /lib64/libc.so.6. #2 0x00007f4d2f521370 in TUnixSystem::Exec (this=0x55bd15241770, shellcmd=0x55bd2b060400 ""/home/vpadulan/programs/rootproject/rootbuild/master-distrdf-debug/etc/gdb-backtrace.sh 53296 1>&2"") at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2104. #3 0x00007f4d2f521c11 in TUnixSystem::StackTrace (this=0x55bd15241770) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2395. #4 0x00007f4d2f8665b4 in (anonymous namespace)::do_trace (sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:182. #5 0x00007f4d2f866644 in (anonymous namespace)::TExceptionHandlerImp::HandleException (this=0x55bd15d7d000, sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:201. #6 0x00007f4d2f5255f9 in TUnixSystem::DispatchSignals (this=0x55bd15241770, sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3610. #7 0x00007f4d2f51d544 in SigHandler (sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:395. #8 0x00007f4d2f52554f in sighandler (sig=6) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3586. #9",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:86,safety,error,error,86,"> Can you also instrument IncrementalExecutor::diagnoseUnresolvedSymbols to print its error to std::cout so we get more details? I converted instances of `cling::errs` to `cling::outs`, no output is shown from that function when the error appears. > Most likely the problem is that TClingClassInfo::IsEnum is missing a R__LOCKGUARD(gInterpreterMutex); before the creation of the stack TClingClassInfo. This did something actually, now I quite consistently always get a segfault, seemingly triggered by Python, with this stacktrace. ```. Thread 1 (Thread 0x7f4d67fcc740 (LWP 53296) ""python""):. #0 0x00007f4d68189bdf in wait4 () from /lib64/libc.so.6. #1 0x00007f4d680f8a1b in do_system () from /lib64/libc.so.6. #2 0x00007f4d2f521370 in TUnixSystem::Exec (this=0x55bd15241770, shellcmd=0x55bd2b060400 ""/home/vpadulan/programs/rootproject/rootbuild/master-distrdf-debug/etc/gdb-backtrace.sh 53296 1>&2"") at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2104. #3 0x00007f4d2f521c11 in TUnixSystem::StackTrace (this=0x55bd15241770) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2395. #4 0x00007f4d2f8665b4 in (anonymous namespace)::do_trace (sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:182. #5 0x00007f4d2f866644 in (anonymous namespace)::TExceptionHandlerImp::HandleException (this=0x55bd15d7d000, sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:201. #6 0x00007f4d2f5255f9 in TUnixSystem::DispatchSignals (this=0x55bd15241770, sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3610. #7 0x00007f4d2f51d544 in SigHandler (sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:395. #8 0x00007f4d2f52554f in sighandler (sig=6) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3586. #9",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:233,safety,error,error,233,"> Can you also instrument IncrementalExecutor::diagnoseUnresolvedSymbols to print its error to std::cout so we get more details? I converted instances of `cling::errs` to `cling::outs`, no output is shown from that function when the error appears. > Most likely the problem is that TClingClassInfo::IsEnum is missing a R__LOCKGUARD(gInterpreterMutex); before the creation of the stack TClingClassInfo. This did something actually, now I quite consistently always get a segfault, seemingly triggered by Python, with this stacktrace. ```. Thread 1 (Thread 0x7f4d67fcc740 (LWP 53296) ""python""):. #0 0x00007f4d68189bdf in wait4 () from /lib64/libc.so.6. #1 0x00007f4d680f8a1b in do_system () from /lib64/libc.so.6. #2 0x00007f4d2f521370 in TUnixSystem::Exec (this=0x55bd15241770, shellcmd=0x55bd2b060400 ""/home/vpadulan/programs/rootproject/rootbuild/master-distrdf-debug/etc/gdb-backtrace.sh 53296 1>&2"") at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2104. #3 0x00007f4d2f521c11 in TUnixSystem::StackTrace (this=0x55bd15241770) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2395. #4 0x00007f4d2f8665b4 in (anonymous namespace)::do_trace (sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:182. #5 0x00007f4d2f866644 in (anonymous namespace)::TExceptionHandlerImp::HandleException (this=0x55bd15d7d000, sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:201. #6 0x00007f4d2f5255f9 in TUnixSystem::DispatchSignals (this=0x55bd15241770, sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3610. #7 0x00007f4d2f51d544 in SigHandler (sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:395. #8 0x00007f4d2f52554f in sighandler (sig=6) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3586. #9",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2002,security,sign,signal,2002,"1 in TUnixSystem::StackTrace (this=0x55bd15241770) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2395. #4 0x00007f4d2f8665b4 in (anonymous namespace)::do_trace (sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:182. #5 0x00007f4d2f866644 in (anonymous namespace)::TExceptionHandlerImp::HandleException (this=0x55bd15d7d000, sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:201. #6 0x00007f4d2f5255f9 in TUnixSystem::DispatchSignals (this=0x55bd15241770, sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3610. #7 0x00007f4d2f51d544 in SigHandler (sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:395. #8 0x00007f4d2f52554f in sighandler (sig=6) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3586. #9 <signal handler called>. #10 0x00007f4d6813bc4c in __pthread_kill_implementation () from /lib64/libc.so.6. #11 0x00007f4d680eb9c6 in raise () from /lib64/libc.so.6. #12 0x00007f4d680d57f4 in abort () from /lib64/libc.so.6. #13 0x00007f4d683a3f3d in _Py_FatalErrorFormat () from /lib64/libpython3.10.so.1.0. #14 0x00007f4d683532d8 in _enter_buffered_busy.cold () from /lib64/libpython3.10.so.1.0. #15 0x00007f4d6846b95e in buffered_flush () from /lib64/libpython3.10.so.1.0. #16 0x00007f4d683d0c24 in method_vectorcall_NOARGS () from /lib64/libpython3.10.so.1.0. #17 0x00007f4d683dfdae in PyObject_VectorcallMethod () from /lib64/libpython3.10.so.1.0. #18 0x00007f4d6846b70e in _io_TextIOWrapper_flush () from /lib64/libpython3.10.so.1.0. #19 0x00007f4d683d0c24 in method_vectorcall_NOARGS () from /lib64/libpython3.10.so.1.0. #20 0x00007f4d683dfdae in PyObject_VectorcallMethod () from /lib64/libpython3.10.so.1.0. #21 0x00007f4d6846e605 in flush_std_files () from /lib64/libpython3.10.so.1.0. #22 0x0000",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:15,testability,instrument,instrument,15,"> Can you also instrument IncrementalExecutor::diagnoseUnresolvedSymbols to print its error to std::cout so we get more details? I converted instances of `cling::errs` to `cling::outs`, no output is shown from that function when the error appears. > Most likely the problem is that TClingClassInfo::IsEnum is missing a R__LOCKGUARD(gInterpreterMutex); before the creation of the stack TClingClassInfo. This did something actually, now I quite consistently always get a segfault, seemingly triggered by Python, with this stacktrace. ```. Thread 1 (Thread 0x7f4d67fcc740 (LWP 53296) ""python""):. #0 0x00007f4d68189bdf in wait4 () from /lib64/libc.so.6. #1 0x00007f4d680f8a1b in do_system () from /lib64/libc.so.6. #2 0x00007f4d2f521370 in TUnixSystem::Exec (this=0x55bd15241770, shellcmd=0x55bd2b060400 ""/home/vpadulan/programs/rootproject/rootbuild/master-distrdf-debug/etc/gdb-backtrace.sh 53296 1>&2"") at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2104. #3 0x00007f4d2f521c11 in TUnixSystem::StackTrace (this=0x55bd15241770) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2395. #4 0x00007f4d2f8665b4 in (anonymous namespace)::do_trace (sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:182. #5 0x00007f4d2f866644 in (anonymous namespace)::TExceptionHandlerImp::HandleException (this=0x55bd15d7d000, sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:201. #6 0x00007f4d2f5255f9 in TUnixSystem::DispatchSignals (this=0x55bd15241770, sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3610. #7 0x00007f4d2f51d544 in SigHandler (sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:395. #8 0x00007f4d2f52554f in sighandler (sig=6) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3586. #9",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:47,testability,diagno,diagnoseUnresolvedSymbols,47,"> Can you also instrument IncrementalExecutor::diagnoseUnresolvedSymbols to print its error to std::cout so we get more details? I converted instances of `cling::errs` to `cling::outs`, no output is shown from that function when the error appears. > Most likely the problem is that TClingClassInfo::IsEnum is missing a R__LOCKGUARD(gInterpreterMutex); before the creation of the stack TClingClassInfo. This did something actually, now I quite consistently always get a segfault, seemingly triggered by Python, with this stacktrace. ```. Thread 1 (Thread 0x7f4d67fcc740 (LWP 53296) ""python""):. #0 0x00007f4d68189bdf in wait4 () from /lib64/libc.so.6. #1 0x00007f4d680f8a1b in do_system () from /lib64/libc.so.6. #2 0x00007f4d2f521370 in TUnixSystem::Exec (this=0x55bd15241770, shellcmd=0x55bd2b060400 ""/home/vpadulan/programs/rootproject/rootbuild/master-distrdf-debug/etc/gdb-backtrace.sh 53296 1>&2"") at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2104. #3 0x00007f4d2f521c11 in TUnixSystem::StackTrace (this=0x55bd15241770) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2395. #4 0x00007f4d2f8665b4 in (anonymous namespace)::do_trace (sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:182. #5 0x00007f4d2f866644 in (anonymous namespace)::TExceptionHandlerImp::HandleException (this=0x55bd15d7d000, sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:201. #6 0x00007f4d2f5255f9 in TUnixSystem::DispatchSignals (this=0x55bd15241770, sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3610. #7 0x00007f4d2f51d544 in SigHandler (sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:395. #8 0x00007f4d2f52554f in sighandler (sig=6) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3586. #9",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:86,usability,error,error,86,"> Can you also instrument IncrementalExecutor::diagnoseUnresolvedSymbols to print its error to std::cout so we get more details? I converted instances of `cling::errs` to `cling::outs`, no output is shown from that function when the error appears. > Most likely the problem is that TClingClassInfo::IsEnum is missing a R__LOCKGUARD(gInterpreterMutex); before the creation of the stack TClingClassInfo. This did something actually, now I quite consistently always get a segfault, seemingly triggered by Python, with this stacktrace. ```. Thread 1 (Thread 0x7f4d67fcc740 (LWP 53296) ""python""):. #0 0x00007f4d68189bdf in wait4 () from /lib64/libc.so.6. #1 0x00007f4d680f8a1b in do_system () from /lib64/libc.so.6. #2 0x00007f4d2f521370 in TUnixSystem::Exec (this=0x55bd15241770, shellcmd=0x55bd2b060400 ""/home/vpadulan/programs/rootproject/rootbuild/master-distrdf-debug/etc/gdb-backtrace.sh 53296 1>&2"") at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2104. #3 0x00007f4d2f521c11 in TUnixSystem::StackTrace (this=0x55bd15241770) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2395. #4 0x00007f4d2f8665b4 in (anonymous namespace)::do_trace (sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:182. #5 0x00007f4d2f866644 in (anonymous namespace)::TExceptionHandlerImp::HandleException (this=0x55bd15d7d000, sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:201. #6 0x00007f4d2f5255f9 in TUnixSystem::DispatchSignals (this=0x55bd15241770, sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3610. #7 0x00007f4d2f51d544 in SigHandler (sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:395. #8 0x00007f4d2f52554f in sighandler (sig=6) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3586. #9",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:233,usability,error,error,233,"> Can you also instrument IncrementalExecutor::diagnoseUnresolvedSymbols to print its error to std::cout so we get more details? I converted instances of `cling::errs` to `cling::outs`, no output is shown from that function when the error appears. > Most likely the problem is that TClingClassInfo::IsEnum is missing a R__LOCKGUARD(gInterpreterMutex); before the creation of the stack TClingClassInfo. This did something actually, now I quite consistently always get a segfault, seemingly triggered by Python, with this stacktrace. ```. Thread 1 (Thread 0x7f4d67fcc740 (LWP 53296) ""python""):. #0 0x00007f4d68189bdf in wait4 () from /lib64/libc.so.6. #1 0x00007f4d680f8a1b in do_system () from /lib64/libc.so.6. #2 0x00007f4d2f521370 in TUnixSystem::Exec (this=0x55bd15241770, shellcmd=0x55bd2b060400 ""/home/vpadulan/programs/rootproject/rootbuild/master-distrdf-debug/etc/gdb-backtrace.sh 53296 1>&2"") at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2104. #3 0x00007f4d2f521c11 in TUnixSystem::StackTrace (this=0x55bd15241770) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2395. #4 0x00007f4d2f8665b4 in (anonymous namespace)::do_trace (sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:182. #5 0x00007f4d2f866644 in (anonymous namespace)::TExceptionHandlerImp::HandleException (this=0x55bd15d7d000, sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:201. #6 0x00007f4d2f5255f9 in TUnixSystem::DispatchSignals (this=0x55bd15241770, sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3610. #7 0x00007f4d2f51d544 in SigHandler (sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:395. #8 0x00007f4d2f52554f in sighandler (sig=6) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3586. #9",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:443,usability,consist,consistently,443,"> Can you also instrument IncrementalExecutor::diagnoseUnresolvedSymbols to print its error to std::cout so we get more details? I converted instances of `cling::errs` to `cling::outs`, no output is shown from that function when the error appears. > Most likely the problem is that TClingClassInfo::IsEnum is missing a R__LOCKGUARD(gInterpreterMutex); before the creation of the stack TClingClassInfo. This did something actually, now I quite consistently always get a segfault, seemingly triggered by Python, with this stacktrace. ```. Thread 1 (Thread 0x7f4d67fcc740 (LWP 53296) ""python""):. #0 0x00007f4d68189bdf in wait4 () from /lib64/libc.so.6. #1 0x00007f4d680f8a1b in do_system () from /lib64/libc.so.6. #2 0x00007f4d2f521370 in TUnixSystem::Exec (this=0x55bd15241770, shellcmd=0x55bd2b060400 ""/home/vpadulan/programs/rootproject/rootbuild/master-distrdf-debug/etc/gdb-backtrace.sh 53296 1>&2"") at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2104. #3 0x00007f4d2f521c11 in TUnixSystem::StackTrace (this=0x55bd15241770) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:2395. #4 0x00007f4d2f8665b4 in (anonymous namespace)::do_trace (sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:182. #5 0x00007f4d2f866644 in (anonymous namespace)::TExceptionHandlerImp::HandleException (this=0x55bd15d7d000, sig=5) at /home/vpadulan/programs/rootproject/rootsrc/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx:201. #6 0x00007f4d2f5255f9 in TUnixSystem::DispatchSignals (this=0x55bd15241770, sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3610. #7 0x00007f4d2f51d544 in SigHandler (sig=kSigAbort) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:395. #8 0x00007f4d2f52554f in sighandler (sig=6) at /home/vpadulan/programs/rootproject/rootsrc/core/unix/src/TUnixSystem.cxx:3586. #9",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:22,deployability,fail,failing,22,Any chance to run the failing process in valgrind?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:22,reliability,fail,failing,22,Any chance to run the failing process in valgrind?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:327,availability,state,stated,327,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:466,availability,error,error,466,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:564,availability,ERROR,ERROR,564,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1351,availability,error,errors,1351,".1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1388,availability,error,errors,1388," the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the s",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1465,availability,state,state,1465,"ror, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1858,availability,error,errors,1858,"ckages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. F",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2118,availability,error,errors,2118,"llback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2161,availability,error,errors,2161,"ython3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2261,availability,error,errors,2261,"ntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process joi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2307,availability,error,errors,2307,"shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File """,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2520,availability,error,errors,2520,"ated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2835,availability,error,errors,2835,"ributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert exitcode is not None` in `process.py` is exactly what is being changed by the linked PR above. For the more generic error `RuntimeError: cannot schedule new futures ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:3789,availability,error,error,3789,"r::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert exitcode is not None` in `process.py` is exactly what is being changed by the linked PR above. For the more generic error `RuntimeError: cannot schedule new futures after shutdown`, which practically happens every time the test ends, at shutdown time of the dask cluster object, it seems like the proper fix was given by https://github.com/dask/distributed/pull/6847 . This commit seems to fix (at least for the case of a dask `LocalCluster`) a long-standing issue https://github.com/dask/distributed/issues/6846",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:3936,availability,cluster,cluster,3936,"r::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert exitcode is not None` in `process.py` is exactly what is being changed by the linked PR above. For the more generic error `RuntimeError: cannot schedule new futures after shutdown`, which practically happens every time the test ends, at shutdown time of the dask cluster object, it seems like the proper fix was given by https://github.com/dask/distributed/pull/6847 . This commit seems to fix (at least for the case of a dask `LocalCluster`) a long-standing issue https://github.com/dask/distributed/issues/6846",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:24,deployability,fail,failing,24,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:96,deployability,fail,fail,96,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:249,deployability,version,version,249,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:279,deployability,modul,module,279,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:380,deployability,version,version,380,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:880,deployability,deploy,deploy,880,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1520,deployability,updat,updated,1520,"08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No erro",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1709,deployability,depend,depending,1709,"cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. #",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1766,deployability,version,version,1766,"ter._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1796,deployability,modul,module,1796," done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could i",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2417,deployability,stack,stacktrace,2417,"that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/thr",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2653,deployability,updat,updating,2653,". . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. T",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2753,deployability,version,versions,2753," and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert exitcode is not None` in `process.py` is exactly what is being changed by the linked",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2886,deployability,stack,stacktrace,2886,"th those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert exitcode is not None` in `process.py` is exactly what is being changed by the linked PR above. For the more generic error `RuntimeError: cannot schedule new futures after shutdown`, which practically happens every time",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:3081,deployability,stack,stacktrace,3081,"stributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert exitcode is not None` in `process.py` is exactly what is being changed by the linked PR above. For the more generic error `RuntimeError: cannot schedule new futures after shutdown`, which practically happens every time the test ends, at shutdown time of the dask cluster object, it seems like the proper fix was given by https://github.com/dask/distributed/pull/6847 . This commit seems to fix (at least for the c",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:3936,deployability,cluster,cluster,3936,"r::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert exitcode is not None` in `process.py` is exactly what is being changed by the linked PR above. For the more generic error `RuntimeError: cannot schedule new futures after shutdown`, which practically happens every time the test ends, at shutdown time of the dask cluster object, it seems like the proper fix was given by https://github.com/dask/distributed/pull/6847 . This commit seems to fix (at least for the case of a dask `LocalCluster`) a long-standing issue https://github.com/dask/distributed/issues/6846",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:70,energy efficiency,power,power,70,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:161,energy efficiency,schedul,scheduling,161,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:931,energy efficiency,schedul,schedule,931,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1283,energy efficiency,schedul,schedule,1283,"In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1493,energy efficiency,schedul,scheduler,1493,"and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distrib",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1812,energy efficiency,current,current,1812," /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more clos",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1984,energy efficiency,schedul,schedule,1984,"recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seem",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2062,energy efficiency,current,current,2062,"ornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2338,energy efficiency,schedul,schedule,2338,"ht these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:3144,energy efficiency,schedul,schedule,3144,"tdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert exitcode is not None` in `process.py` is exactly what is being changed by the linked PR above. For the more generic error `RuntimeError: cannot schedule new futures after shutdown`, which practically happens every time the test ends, at shutdown time of the dask cluster object, it seems like the proper fix was given by https://github.com/dask/distributed/pull/6847 . This commit seems to fix (at least for the case of a dask `LocalCluster`) a long-standing issue https://gi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:3817,energy efficiency,schedul,schedule,3817,"r::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert exitcode is not None` in `process.py` is exactly what is being changed by the linked PR above. For the more generic error `RuntimeError: cannot schedule new futures after shutdown`, which practically happens every time the test ends, at shutdown time of the dask cluster object, it seems like the proper fix was given by https://github.com/dask/distributed/pull/6847 . This commit seems to fix (at least for the case of a dask `LocalCluster`) a long-standing issue https://github.com/dask/distributed/issues/6846",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:249,integrability,version,version,249,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:327,integrability,state,stated,327,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:380,integrability,version,version,380,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1465,integrability,state,state,1465,"ror, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1709,integrability,depend,depending,1709,"cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. #",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1766,integrability,version,version,1766,"ter._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2753,integrability,version,versions,2753," and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert exitcode is not None` in `process.py` is exactly what is being changed by the linked",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:266,interoperability,distribut,distributed,266,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:335,interoperability,distribut,distributed,335,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:668,interoperability,platform,platform,668,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:868,interoperability,distribut,distributed,868,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1532,interoperability,distribut,distributed,1532,"4 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1783,interoperability,distribut,distributed,1783,"internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1834,interoperability,distribut,distributed,1834,"ib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of error",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2084,interoperability,distribut,distributed,2084,"741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrac",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2227,interoperability,distribut,distributed,2227,"ure_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2491,interoperability,distribut,distributed,2491,"duler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). Fi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2666,interoperability,distribut,distributed,2666,"to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2740,interoperability,distribut,distributed,2740,"tus of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert exitcode is not None` in `process.py` is exactly what is being changed by",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2962,interoperability,distribut,distributed,2962,"k about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert exitcode is not None` in `process.py` is exactly what is being changed by the linked PR above. For the more generic error `RuntimeError: cannot schedule new futures after shutdown`, which practically happens every time the test ends, at shutdown time of the dask cluster object, it seems like th",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:3552,interoperability,distribut,distributed,3552,"r::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert exitcode is not None` in `process.py` is exactly what is being changed by the linked PR above. For the more generic error `RuntimeError: cannot schedule new futures after shutdown`, which practically happens every time the test ends, at shutdown time of the dask cluster object, it seems like the proper fix was given by https://github.com/dask/distributed/pull/6847 . This commit seems to fix (at least for the case of a dask `LocalCluster`) a long-standing issue https://github.com/dask/distributed/issues/6846",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:4018,interoperability,distribut,distributed,4018,"r::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert exitcode is not None` in `process.py` is exactly what is being changed by the linked PR above. For the more generic error `RuntimeError: cannot schedule new futures after shutdown`, which practically happens every time the test ends, at shutdown time of the dask cluster object, it seems like the proper fix was given by https://github.com/dask/distributed/pull/6847 . This commit seems to fix (at least for the case of a dask `LocalCluster`) a long-standing issue https://github.com/dask/distributed/issues/6846",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:4162,interoperability,distribut,distributed,4162,"r::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert exitcode is not None` in `process.py` is exactly what is being changed by the linked PR above. For the more generic error `RuntimeError: cannot schedule new futures after shutdown`, which practically happens every time the test ends, at shutdown time of the dask cluster object, it seems like the proper fix was given by https://github.com/dask/distributed/pull/6847 . This commit seems to fix (at least for the case of a dask `LocalCluster`) a long-standing issue https://github.com/dask/distributed/issues/6846",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:249,modifiability,version,version,249,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:279,modifiability,modul,module,279,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:380,modifiability,version,version,380,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:859,modifiability,pac,packages,859,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1056,modifiability,pac,packages,1056," have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROO",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1179,modifiability,pac,packages,1179,"y control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpre",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1698,modifiability,scenario,scenarios,1698," at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1709,modifiability,depend,depending,1709,"cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. #",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1766,modifiability,version,version,1766,"ter._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1796,modifiability,modul,module,1796," done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could i",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2753,modifiability,version,versions,2753," and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert exitcode is not None` in `process.py` is exactly what is being changed by the linked",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:3543,modifiability,pac,packages,3543,"r::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert exitcode is not None` in `process.py` is exactly what is being changed by the linked PR above. For the more generic error `RuntimeError: cannot schedule new futures after shutdown`, which practically happens every time the test ends, at shutdown time of the dask cluster object, it seems like the proper fix was given by https://github.com/dask/distributed/pull/6847 . This commit seems to fix (at least for the case of a dask `LocalCluster`) a long-standing issue https://github.com/dask/distributed/issues/6846",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:161,performance,schedul,scheduling,161,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:466,performance,error,error,466,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:564,performance,ERROR,ERROR,564,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:931,performance,schedul,schedule,931,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1283,performance,schedul,schedule,1283,"In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1351,performance,error,errors,1351,".1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1388,performance,error,errors,1388," the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the s",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1493,performance,schedul,scheduler,1493,"and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distrib",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1858,performance,error,errors,1858,"ckages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. F",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1984,performance,schedul,schedule,1984,"recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seem",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2118,performance,error,errors,2118,"llback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2161,performance,error,errors,2161,"ython3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2261,performance,error,errors,2261,"ntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process joi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2307,performance,error,errors,2307,"shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File """,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2338,performance,schedul,schedule,2338,"ht these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2520,performance,error,errors,2520,"ated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2835,performance,error,errors,2835,"ributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert exitcode is not None` in `process.py` is exactly what is being changed by the linked PR above. For the more generic error `RuntimeError: cannot schedule new futures ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:3144,performance,schedul,schedule,3144,"tdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert exitcode is not None` in `process.py` is exactly what is being changed by the linked PR above. For the more generic error `RuntimeError: cannot schedule new futures after shutdown`, which practically happens every time the test ends, at shutdown time of the dask cluster object, it seems like the proper fix was given by https://github.com/dask/distributed/pull/6847 . This commit seems to fix (at least for the case of a dask `LocalCluster`) a long-standing issue https://gi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:3789,performance,error,error,3789,"r::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert exitcode is not None` in `process.py` is exactly what is being changed by the linked PR above. For the more generic error `RuntimeError: cannot schedule new futures after shutdown`, which practically happens every time the test ends, at shutdown time of the dask cluster object, it seems like the proper fix was given by https://github.com/dask/distributed/pull/6847 . This commit seems to fix (at least for the case of a dask `LocalCluster`) a long-standing issue https://github.com/dask/distributed/issues/6846",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:3817,performance,schedul,schedule,3817,"r::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert exitcode is not None` in `process.py` is exactly what is being changed by the linked PR above. For the more generic error `RuntimeError: cannot schedule new futures after shutdown`, which practically happens every time the test ends, at shutdown time of the dask cluster object, it seems like the proper fix was given by https://github.com/dask/distributed/pull/6847 . This commit seems to fix (at least for the case of a dask `LocalCluster`) a long-standing issue https://github.com/dask/distributed/issues/6846",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:3887,performance,time,time,3887,"r::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert exitcode is not None` in `process.py` is exactly what is being changed by the linked PR above. For the more generic error `RuntimeError: cannot schedule new futures after shutdown`, which practically happens every time the test ends, at shutdown time of the dask cluster object, it seems like the proper fix was given by https://github.com/dask/distributed/pull/6847 . This commit seems to fix (at least for the case of a dask `LocalCluster`) a long-standing issue https://github.com/dask/distributed/issues/6846",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:3919,performance,time,time,3919,"r::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert exitcode is not None` in `process.py` is exactly what is being changed by the linked PR above. For the more generic error `RuntimeError: cannot schedule new futures after shutdown`, which practically happens every time the test ends, at shutdown time of the dask cluster object, it seems like the proper fix was given by https://github.com/dask/distributed/pull/6847 . This commit seems to fix (at least for the case of a dask `LocalCluster`) a long-standing issue https://github.com/dask/distributed/issues/6846",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:24,reliability,fail,failing,24,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:96,reliability,fail,fail,96,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:3861,reliability,pra,practically,3861,"r::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert exitcode is not None` in `process.py` is exactly what is being changed by the linked PR above. For the more generic error `RuntimeError: cannot schedule new futures after shutdown`, which practically happens every time the test ends, at shutdown time of the dask cluster object, it seems like the proper fix was given by https://github.com/dask/distributed/pull/6847 . This commit seems to fix (at least for the case of a dask `LocalCluster`) a long-standing issue https://github.com/dask/distributed/issues/6846",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:227,safety,test,tests,227,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:279,safety,modul,module,279,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:396,safety,test,tests,396,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:466,safety,error,error,466,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:493,safety,test,test,493,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:564,safety,ERROR,ERROR,564,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:572,safety,Except,Exception,572,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:900,safety,except,exception,900,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1351,safety,error,errors,1351,".1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1388,safety,error,errors,1388," the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the s",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1520,safety,updat,updated,1520,"08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No erro",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1709,safety,depend,depending,1709,"cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. #",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1796,safety,modul,module,1796," done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could i",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1858,safety,error,errors,1858,"ckages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. F",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2118,safety,error,errors,2118,"llback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2161,safety,error,errors,2161,"ython3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2261,safety,error,errors,2261,"ntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process joi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2307,safety,error,errors,2307,"shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File """,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2520,safety,error,errors,2520,"ated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2653,safety,updat,updating,2653,". . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. T",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2835,safety,error,errors,2835,"ributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert exitcode is not None` in `process.py` is exactly what is being changed by the linked PR above. For the more generic error `RuntimeError: cannot schedule new futures ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:3004,safety,test,test,3004,"fter shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert exitcode is not None` in `process.py` is exactly what is being changed by the linked PR above. For the more generic error `RuntimeError: cannot schedule new futures after shutdown`, which practically happens every time the test ends, at shutdown time of the dask cluster object, it seems like the proper fix was given by https://gith",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:3181,safety,Except,Exception,3181,"r::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert exitcode is not None` in `process.py` is exactly what is being changed by the linked PR above. For the more generic error `RuntimeError: cannot schedule new futures after shutdown`, which practically happens every time the test ends, at shutdown time of the dask cluster object, it seems like the proper fix was given by https://github.com/dask/distributed/pull/6847 . This commit seems to fix (at least for the case of a dask `LocalCluster`) a long-standing issue https://github.com/dask/distributed/issues/6846",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:3789,safety,error,error,3789,"r::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert exitcode is not None` in `process.py` is exactly what is being changed by the linked PR above. For the more generic error `RuntimeError: cannot schedule new futures after shutdown`, which practically happens every time the test ends, at shutdown time of the dask cluster object, it seems like the proper fix was given by https://github.com/dask/distributed/pull/6847 . This commit seems to fix (at least for the case of a dask `LocalCluster`) a long-standing issue https://github.com/dask/distributed/issues/6846",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:3896,safety,test,test,3896,"r::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert exitcode is not None` in `process.py` is exactly what is being changed by the linked PR above. For the more generic error `RuntimeError: cannot schedule new futures after shutdown`, which practically happens every time the test ends, at shutdown time of the dask cluster object, it seems like the proper fix was given by https://github.com/dask/distributed/pull/6847 . This commit seems to fix (at least for the case of a dask `LocalCluster`) a long-standing issue https://github.com/dask/distributed/issues/6846",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:185,security,control,control,185,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1520,security,updat,updated,1520,"08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No erro",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1675,security,ident,identify,1675,"yncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2653,security,updat,updating,2653,". . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. T",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2798,security,ident,identify,2798,":. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert exitcode is not None` in `process.py` is exactly what is being changed by the linked PR above. For the more generic error `Runtim",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:185,testability,control,control,185,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:227,testability,test,tests,227,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:396,testability,test,tests,396,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:493,testability,test,test,493,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:972,testability,Trace,Traceback,972,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1709,testability,depend,depending,1709,"cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. #",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:3004,testability,test,test,3004,"fter shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert exitcode is not None` in `process.py` is exactly what is being changed by the linked PR above. For the more generic error `RuntimeError: cannot schedule new futures after shutdown`, which practically happens every time the test ends, at shutdown time of the dask cluster object, it seems like the proper fix was given by https://gith",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:3268,testability,Trace,Traceback,3268,"r::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert exitcode is not None` in `process.py` is exactly what is being changed by the linked PR above. For the more generic error `RuntimeError: cannot schedule new futures after shutdown`, which practically happens every time the test ends, at shutdown time of the dask cluster object, it seems like the proper fix was given by https://github.com/dask/distributed/pull/6847 . This commit seems to fix (at least for the case of a dask `LocalCluster`) a long-standing issue https://github.com/dask/distributed/issues/6846",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:3606,testability,assert,assert,3606,"r::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert exitcode is not None` in `process.py` is exactly what is being changed by the linked PR above. For the more generic error `RuntimeError: cannot schedule new futures after shutdown`, which practically happens every time the test ends, at shutdown time of the dask cluster object, it seems like the proper fix was given by https://github.com/dask/distributed/pull/6847 . This commit seems to fix (at least for the case of a dask `LocalCluster`) a long-standing issue https://github.com/dask/distributed/issues/6846",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:3635,testability,Assert,AssertionError,3635,"r::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert exitcode is not None` in `process.py` is exactly what is being changed by the linked PR above. For the more generic error `RuntimeError: cannot schedule new futures after shutdown`, which practically happens every time the test ends, at shutdown time of the dask cluster object, it seems like the proper fix was given by https://github.com/dask/distributed/pull/6847 . This commit seems to fix (at least for the case of a dask `LocalCluster`) a long-standing issue https://github.com/dask/distributed/issues/6846",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:3666,testability,assert,assert,3666,"r::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert exitcode is not None` in `process.py` is exactly what is being changed by the linked PR above. For the more generic error `RuntimeError: cannot schedule new futures after shutdown`, which practically happens every time the test ends, at shutdown time of the dask cluster object, it seems like the proper fix was given by https://github.com/dask/distributed/pull/6847 . This commit seems to fix (at least for the case of a dask `LocalCluster`) a long-standing issue https://github.com/dask/distributed/issues/6846",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:3896,testability,test,test,3896,"r::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert exitcode is not None` in `process.py` is exactly what is being changed by the linked PR above. For the more generic error `RuntimeError: cannot schedule new futures after shutdown`, which practically happens every time the test ends, at shutdown time of the dask cluster object, it seems like the proper fix was given by https://github.com/dask/distributed/pull/6847 . This commit seems to fix (at least for the case of a dask `LocalCluster`) a long-standing issue https://github.com/dask/distributed/issues/6846",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:466,usability,error,error,466,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:564,usability,ERROR,ERROR,564,"> Any chance to run the failing process in valgrind? I don't have any power on the process that fail itself, it's a task run inside of the `dask` worker and its scheduling is out of my control. On other news, I made a few more tests focusing on the version of dask `distributed` module. In the description of the issue above I stated `distributed==2022.7.1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1351,usability,error,errors,1351,".1`, this was my starting version for the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new fut",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1388,usability,error,errors,1388," the tests I will describe in the following. First, I noticed this type of error, happening between a test and another. ```. 2022-10-08 02:33:36,474 - tornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f946cbb8340>>, <Task finished name='Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the s",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1743,usability,statu,status,1743,"Task-245' coro=<SpecCluster._correct_state_internal() done, defined at /home/vpadulan/.local/lib/python3.10/site-packages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distri",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:1858,usability,error,errors,1858,"ckages/distributed/deploy/spec.py:330> exception=RuntimeError('cannot schedule new futures after shutdown')>). Traceback (most recent call last):. File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 741, in _run_callback. ret = callback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. F",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2118,usability,error,errors,2118,"llback(). File ""/home/vpadulan/.local/lib/python3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2161,usability,error,errors,2161,"ython3.10/site-packages/tornado/ioloop.py"", line 765, in _discard_future_result. future.result(). RuntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2261,usability,error,errors,2261,"ntimeError: cannot schedule new futures after shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process joi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2307,usability,error,errors,2307,"shutdown. ```. Initially I thought these errors were just a by-product of the errors coming from `TInterpreter` that were leaving the dask worker in a bad state and thus breaking the scheduler too. But then, I updated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File """,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2520,usability,error,errors,2520,"ated to `distributed==2022.8.1` and they were not present. So I went on and I used `git bisect` starting from `2022.8.0` going onwards. . I was able to identify the following scenarios, depending on a combination of the status of ROOT and the version of dask `distributed` module:. * ROOT current master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2812,usability,close,closely,2812,"ent master, with `distributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert exitcode is not None` in `process.py` is exactly what is being changed by the linked PR above. For the more generic error `RuntimeError: cannot",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:2835,usability,error,errors,2835,"ributed==2022.8.0`: errors like shown shown above, both those coming from `TInterepreter::Calc` from RDF and those coming from dask about `cannot schedule new futures after shutdown` that I mentioned in this comment. * ROOT current master, with `distributed==2022.8.1`: **No more errors about futures after shutdown**. The errors from `TInterpreter::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert exitcode is not None` in `process.py` is exactly what is being changed by the linked PR above. For the more generic error `RuntimeError: cannot schedule new futures ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:3789,usability,error,error,3789,"r::Calc` remain. * ROOT master+fix, with `distributed==2022.8.0`: **No more errors from `TInterpreter::Calc`**, but still errors from dask about `cannot schedule new futures after shutdown` **and also the segfaults with Python-only stacktrace** that I wrote in a previous comment. * ROOT master+fix, with `distributed==2022.8.1`: **No errors at all!**. So it seems that a mix of adding the fix suggested by Philippe (a `R_LOCKGUARD` in `TClingClassInfo::IsEnum`) plus updating to `distributed==2022.8.1` fixes all our problems. ## More details about the `distributed` versions. Thanks to the `git bisect` I could identify more closely the sources of errors on the dask side. For the very weird Python stacktrace leading to a full segfault, I found that https://github.com/dask/distributed/pull/6684 seems to fix it. In test runs where the segfault is triggered, before getting it (and the Python stacktrace), I can see these lines . ```. RuntimeError: cannot schedule new futures after shutdown. Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:. Traceback (most recent call last):. File ""/usr/lib64/python3.10/threading.py"", line 1016, in _bootstrap_inner. self.run(). File ""/usr/lib64/python3.10/threading.py"", line 953, in run. self._target(*self._args, **self._kwargs). File ""/home/vpadulan/.local/lib/python3.10/site-packages/distributed/process.py"", line 238, in _watch_process. assert exitcode is not None. AssertionError. ```. The line `assert exitcode is not None` in `process.py` is exactly what is being changed by the linked PR above. For the more generic error `RuntimeError: cannot schedule new futures after shutdown`, which practically happens every time the test ends, at shutdown time of the dask cluster object, it seems like the proper fix was given by https://github.com/dask/distributed/pull/6847 . This commit seems to fix (at least for the case of a dask `LocalCluster`) a long-standing issue https://github.com/dask/distributed/issues/6846",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:166,deployability,version,version,166,"There's a second part to fixing this issue for good, i.e. also making sure we don't see weird crashes/segfaults due to `dask`. That involves bumping the minimum dask version to 2022.8.1, which in turn requires minimum Python version to 3.8",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:225,deployability,version,version,225,"There's a second part to fixing this issue for good, i.e. also making sure we don't see weird crashes/segfaults due to `dask`. That involves bumping the minimum dask version to 2022.8.1, which in turn requires minimum Python version to 3.8",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:166,integrability,version,version,166,"There's a second part to fixing this issue for good, i.e. also making sure we don't see weird crashes/segfaults due to `dask`. That involves bumping the minimum dask version to 2022.8.1, which in turn requires minimum Python version to 3.8",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:225,integrability,version,version,225,"There's a second part to fixing this issue for good, i.e. also making sure we don't see weird crashes/segfaults due to `dask`. That involves bumping the minimum dask version to 2022.8.1, which in turn requires minimum Python version to 3.8",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:166,modifiability,version,version,166,"There's a second part to fixing this issue for good, i.e. also making sure we don't see weird crashes/segfaults due to `dask`. That involves bumping the minimum dask version to 2022.8.1, which in turn requires minimum Python version to 3.8",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:225,modifiability,version,version,225,"There's a second part to fixing this issue for good, i.e. also making sure we don't see weird crashes/segfaults due to `dask`. That involves bumping the minimum dask version to 2022.8.1, which in turn requires minimum Python version to 3.8",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:153,usability,minim,minimum,153,"There's a second part to fixing this issue for good, i.e. also making sure we don't see weird crashes/segfaults due to `dask`. That involves bumping the minimum dask version to 2022.8.1, which in turn requires minimum Python version to 3.8",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/issues/11515:210,usability,minim,minimum,210,"There's a second part to fixing this issue for good, i.e. also making sure we don't see weird crashes/segfaults due to `dask`. That involves bumping the minimum dask version to 2022.8.1, which in turn requires minimum Python version to 3.8",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11515
https://github.com/root-project/root/pull/11516:19,availability,error,errors,19,The windows/python errors are unrelated (seems to be a mismatch installation of python 2/3),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11516
https://github.com/root-project/root/pull/11516:64,deployability,instal,installation,64,The windows/python errors are unrelated (seems to be a mismatch installation of python 2/3),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11516
https://github.com/root-project/root/pull/11516:55,interoperability,mismatch,mismatch,55,The windows/python errors are unrelated (seems to be a mismatch installation of python 2/3),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11516
https://github.com/root-project/root/pull/11516:19,performance,error,errors,19,The windows/python errors are unrelated (seems to be a mismatch installation of python 2/3),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11516
https://github.com/root-project/root/pull/11516:19,safety,error,errors,19,The windows/python errors are unrelated (seems to be a mismatch installation of python 2/3),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11516
https://github.com/root-project/root/pull/11516:19,usability,error,errors,19,The windows/python errors are unrelated (seems to be a mismatch installation of python 2/3),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11516
https://github.com/root-project/root/pull/11517:11,energy efficiency,current,current,11,Rebased on current master.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:28,deployability,version,version,28,The CI is picking up an old version of my roottest/df-bulk branch (which I forgot I had :sweat_smile: ). Will fix asap.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:28,integrability,version,version,28,The CI is picking up an old version of my roottest/df-bulk branch (which I forgot I had :sweat_smile: ). Will fix asap.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:28,modifiability,version,version,28,The CI is picking up an old version of my roottest/df-bulk branch (which I forgot I had :sweat_smile: ). Will fix asap.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:152,energy efficiency,reduc,reduce,152,"Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:188,integrability,batch,batch,188,"Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:109,interoperability,platform,platforms,109,"Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:163,performance,perform,performance,163,"Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:188,performance,batch,batch,188,"Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:138,security,sign,significantly,138,"Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:163,usability,perform,performance,163,"Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:166,availability,state,state,166,"> Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Yes I agree, this PR was just to check the state of the feature on all platforms from time to time and to provide a preview of the changes to you (the early commits are fixed, it's just that they cannot be merged on their own as they degrade performance). > Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward? I don't know of a way to fix the performance degradation with batch/bulk size of 1, so the idea would be to use a larger bulk size by default when this is merged, but:. - performance is not always better at the moment: as TTree I/O does not provide bulks, I have to perform extra copies to w.r.t. the non-bulk case that sometimes are more expensive than the bulk processing gains. - since I have to copy values into contiguous buffers, a number of use cases break (polymorphic use of TBranches, branch types with no default constructor, move-only branch types, TClonesArrays, ...). The plan is to try to fix the use cases that break as well as the performance issues so we can always turn bulk processing (with bulk size >> 1) on. It's going to be difficult, fingers crossed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:357,availability,degrad,degrade,357,"> Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Yes I agree, this PR was just to check the state of the feature on all platforms from time to time and to provide a preview of the changes to you (the early commits are fixed, it's just that they cannot be merged on their own as they degrade performance). > Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward? I don't know of a way to fix the performance degradation with batch/bulk size of 1, so the idea would be to use a larger bulk size by default when this is merged, but:. - performance is not always better at the moment: as TTree I/O does not provide bulks, I have to perform extra copies to w.r.t. the non-bulk case that sometimes are more expensive than the bulk processing gains. - since I have to copy values into contiguous buffers, a number of use cases break (polymorphic use of TBranches, branch types with no default constructor, move-only branch types, TClonesArrays, ...). The plan is to try to fix the use cases that break as well as the performance issues so we can always turn bulk processing (with bulk size >> 1) on. It's going to be difficult, fingers crossed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:538,availability,degrad,degradation,538,"> Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Yes I agree, this PR was just to check the state of the feature on all platforms from time to time and to provide a preview of the changes to you (the early commits are fixed, it's just that they cannot be merged on their own as they degrade performance). > Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward? I don't know of a way to fix the performance degradation with batch/bulk size of 1, so the idea would be to use a larger bulk size by default when this is merged, but:. - performance is not always better at the moment: as TTree I/O does not provide bulks, I have to perform extra copies to w.r.t. the non-bulk case that sometimes are more expensive than the bulk processing gains. - since I have to copy values into contiguous buffers, a number of use cases break (polymorphic use of TBranches, branch types with no default constructor, move-only branch types, TClonesArrays, ...). The plan is to try to fix the use cases that break as well as the performance issues so we can always turn bulk processing (with bulk size >> 1) on. It's going to be difficult, fingers crossed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:412,energy efficiency,reduc,reduce,412,"> Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Yes I agree, this PR was just to check the state of the feature on all platforms from time to time and to provide a preview of the changes to you (the early commits are fixed, it's just that they cannot be merged on their own as they degrade performance). > Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward? I don't know of a way to fix the performance degradation with batch/bulk size of 1, so the idea would be to use a larger bulk size by default when this is merged, but:. - performance is not always better at the moment: as TTree I/O does not provide bulks, I have to perform extra copies to w.r.t. the non-bulk case that sometimes are more expensive than the bulk processing gains. - since I have to copy values into contiguous buffers, a number of use cases break (polymorphic use of TBranches, branch types with no default constructor, move-only branch types, TClonesArrays, ...). The plan is to try to fix the use cases that break as well as the performance issues so we can always turn bulk processing (with bulk size >> 1) on. It's going to be difficult, fingers crossed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:166,integrability,state,state,166,"> Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Yes I agree, this PR was just to check the state of the feature on all platforms from time to time and to provide a preview of the changes to you (the early commits are fixed, it's just that they cannot be merged on their own as they degrade performance). > Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward? I don't know of a way to fix the performance degradation with batch/bulk size of 1, so the idea would be to use a larger bulk size by default when this is merged, but:. - performance is not always better at the moment: as TTree I/O does not provide bulks, I have to perform extra copies to w.r.t. the non-bulk case that sometimes are more expensive than the bulk processing gains. - since I have to copy values into contiguous buffers, a number of use cases break (polymorphic use of TBranches, branch types with no default constructor, move-only branch types, TClonesArrays, ...). The plan is to try to fix the use cases that break as well as the performance issues so we can always turn bulk processing (with bulk size >> 1) on. It's going to be difficult, fingers crossed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:448,integrability,batch,batch,448,"> Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Yes I agree, this PR was just to check the state of the feature on all platforms from time to time and to provide a preview of the changes to you (the early commits are fixed, it's just that they cannot be merged on their own as they degrade performance). > Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward? I don't know of a way to fix the performance degradation with batch/bulk size of 1, so the idea would be to use a larger bulk size by default when this is merged, but:. - performance is not always better at the moment: as TTree I/O does not provide bulks, I have to perform extra copies to w.r.t. the non-bulk case that sometimes are more expensive than the bulk processing gains. - since I have to copy values into contiguous buffers, a number of use cases break (polymorphic use of TBranches, branch types with no default constructor, move-only branch types, TClonesArrays, ...). The plan is to try to fix the use cases that break as well as the performance issues so we can always turn bulk processing (with bulk size >> 1) on. It's going to be difficult, fingers crossed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:555,integrability,batch,batch,555,"> Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Yes I agree, this PR was just to check the state of the feature on all platforms from time to time and to provide a preview of the changes to you (the early commits are fixed, it's just that they cannot be merged on their own as they degrade performance). > Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward? I don't know of a way to fix the performance degradation with batch/bulk size of 1, so the idea would be to use a larger bulk size by default when this is merged, but:. - performance is not always better at the moment: as TTree I/O does not provide bulks, I have to perform extra copies to w.r.t. the non-bulk case that sometimes are more expensive than the bulk processing gains. - since I have to copy values into contiguous buffers, a number of use cases break (polymorphic use of TBranches, branch types with no default constructor, move-only branch types, TClonesArrays, ...). The plan is to try to fix the use cases that break as well as the performance issues so we can always turn bulk processing (with bulk size >> 1) on. It's going to be difficult, fingers crossed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:920,integrability,buffer,buffers,920,"> Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Yes I agree, this PR was just to check the state of the feature on all platforms from time to time and to provide a preview of the changes to you (the early commits are fixed, it's just that they cannot be merged on their own as they degrade performance). > Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward? I don't know of a way to fix the performance degradation with batch/bulk size of 1, so the idea would be to use a larger bulk size by default when this is merged, but:. - performance is not always better at the moment: as TTree I/O does not provide bulks, I have to perform extra copies to w.r.t. the non-bulk case that sometimes are more expensive than the bulk processing gains. - since I have to copy values into contiguous buffers, a number of use cases break (polymorphic use of TBranches, branch types with no default constructor, move-only branch types, TClonesArrays, ...). The plan is to try to fix the use cases that break as well as the performance issues so we can always turn bulk processing (with bulk size >> 1) on. It's going to be difficult, fingers crossed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:111,interoperability,platform,platforms,111,"> Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Yes I agree, this PR was just to check the state of the feature on all platforms from time to time and to provide a preview of the changes to you (the early commits are fixed, it's just that they cannot be merged on their own as they degrade performance). > Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward? I don't know of a way to fix the performance degradation with batch/bulk size of 1, so the idea would be to use a larger bulk size by default when this is merged, but:. - performance is not always better at the moment: as TTree I/O does not provide bulks, I have to perform extra copies to w.r.t. the non-bulk case that sometimes are more expensive than the bulk processing gains. - since I have to copy values into contiguous buffers, a number of use cases break (polymorphic use of TBranches, branch types with no default constructor, move-only branch types, TClonesArrays, ...). The plan is to try to fix the use cases that break as well as the performance issues so we can always turn bulk processing (with bulk size >> 1) on. It's going to be difficult, fingers crossed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:194,interoperability,platform,platforms,194,"> Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Yes I agree, this PR was just to check the state of the feature on all platforms from time to time and to provide a preview of the changes to you (the early commits are fixed, it's just that they cannot be merged on their own as they degrade performance). > Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward? I don't know of a way to fix the performance degradation with batch/bulk size of 1, so the idea would be to use a larger bulk size by default when this is merged, but:. - performance is not always better at the moment: as TTree I/O does not provide bulks, I have to perform extra copies to w.r.t. the non-bulk case that sometimes are more expensive than the bulk processing gains. - since I have to copy values into contiguous buffers, a number of use cases break (polymorphic use of TBranches, branch types with no default constructor, move-only branch types, TClonesArrays, ...). The plan is to try to fix the use cases that break as well as the performance issues so we can always turn bulk processing (with bulk size >> 1) on. It's going to be difficult, fingers crossed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:958,modifiability,polymorph,polymorphic,958,"> Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Yes I agree, this PR was just to check the state of the feature on all platforms from time to time and to provide a preview of the changes to you (the early commits are fixed, it's just that they cannot be merged on their own as they degrade performance). > Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward? I don't know of a way to fix the performance degradation with batch/bulk size of 1, so the idea would be to use a larger bulk size by default when this is merged, but:. - performance is not always better at the moment: as TTree I/O does not provide bulks, I have to perform extra copies to w.r.t. the non-bulk case that sometimes are more expensive than the bulk processing gains. - since I have to copy values into contiguous buffers, a number of use cases break (polymorphic use of TBranches, branch types with no default constructor, move-only branch types, TClonesArrays, ...). The plan is to try to fix the use cases that break as well as the performance issues so we can always turn bulk processing (with bulk size >> 1) on. It's going to be difficult, fingers crossed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:209,performance,time,time,209,"> Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Yes I agree, this PR was just to check the state of the feature on all platforms from time to time and to provide a preview of the changes to you (the early commits are fixed, it's just that they cannot be merged on their own as they degrade performance). > Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward? I don't know of a way to fix the performance degradation with batch/bulk size of 1, so the idea would be to use a larger bulk size by default when this is merged, but:. - performance is not always better at the moment: as TTree I/O does not provide bulks, I have to perform extra copies to w.r.t. the non-bulk case that sometimes are more expensive than the bulk processing gains. - since I have to copy values into contiguous buffers, a number of use cases break (polymorphic use of TBranches, branch types with no default constructor, move-only branch types, TClonesArrays, ...). The plan is to try to fix the use cases that break as well as the performance issues so we can always turn bulk processing (with bulk size >> 1) on. It's going to be difficult, fingers crossed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:217,performance,time,time,217,"> Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Yes I agree, this PR was just to check the state of the feature on all platforms from time to time and to provide a preview of the changes to you (the early commits are fixed, it's just that they cannot be merged on their own as they degrade performance). > Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward? I don't know of a way to fix the performance degradation with batch/bulk size of 1, so the idea would be to use a larger bulk size by default when this is merged, but:. - performance is not always better at the moment: as TTree I/O does not provide bulks, I have to perform extra copies to w.r.t. the non-bulk case that sometimes are more expensive than the bulk processing gains. - since I have to copy values into contiguous buffers, a number of use cases break (polymorphic use of TBranches, branch types with no default constructor, move-only branch types, TClonesArrays, ...). The plan is to try to fix the use cases that break as well as the performance issues so we can always turn bulk processing (with bulk size >> 1) on. It's going to be difficult, fingers crossed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:365,performance,perform,performance,365,"> Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Yes I agree, this PR was just to check the state of the feature on all platforms from time to time and to provide a preview of the changes to you (the early commits are fixed, it's just that they cannot be merged on their own as they degrade performance). > Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward? I don't know of a way to fix the performance degradation with batch/bulk size of 1, so the idea would be to use a larger bulk size by default when this is merged, but:. - performance is not always better at the moment: as TTree I/O does not provide bulks, I have to perform extra copies to w.r.t. the non-bulk case that sometimes are more expensive than the bulk processing gains. - since I have to copy values into contiguous buffers, a number of use cases break (polymorphic use of TBranches, branch types with no default constructor, move-only branch types, TClonesArrays, ...). The plan is to try to fix the use cases that break as well as the performance issues so we can always turn bulk processing (with bulk size >> 1) on. It's going to be difficult, fingers crossed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:423,performance,perform,performance,423,"> Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Yes I agree, this PR was just to check the state of the feature on all platforms from time to time and to provide a preview of the changes to you (the early commits are fixed, it's just that they cannot be merged on their own as they degrade performance). > Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward? I don't know of a way to fix the performance degradation with batch/bulk size of 1, so the idea would be to use a larger bulk size by default when this is merged, but:. - performance is not always better at the moment: as TTree I/O does not provide bulks, I have to perform extra copies to w.r.t. the non-bulk case that sometimes are more expensive than the bulk processing gains. - since I have to copy values into contiguous buffers, a number of use cases break (polymorphic use of TBranches, branch types with no default constructor, move-only branch types, TClonesArrays, ...). The plan is to try to fix the use cases that break as well as the performance issues so we can always turn bulk processing (with bulk size >> 1) on. It's going to be difficult, fingers crossed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:448,performance,batch,batch,448,"> Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Yes I agree, this PR was just to check the state of the feature on all platforms from time to time and to provide a preview of the changes to you (the early commits are fixed, it's just that they cannot be merged on their own as they degrade performance). > Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward? I don't know of a way to fix the performance degradation with batch/bulk size of 1, so the idea would be to use a larger bulk size by default when this is merged, but:. - performance is not always better at the moment: as TTree I/O does not provide bulks, I have to perform extra copies to w.r.t. the non-bulk case that sometimes are more expensive than the bulk processing gains. - since I have to copy values into contiguous buffers, a number of use cases break (polymorphic use of TBranches, branch types with no default constructor, move-only branch types, TClonesArrays, ...). The plan is to try to fix the use cases that break as well as the performance issues so we can always turn bulk processing (with bulk size >> 1) on. It's going to be difficult, fingers crossed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:526,performance,perform,performance,526,"> Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Yes I agree, this PR was just to check the state of the feature on all platforms from time to time and to provide a preview of the changes to you (the early commits are fixed, it's just that they cannot be merged on their own as they degrade performance). > Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward? I don't know of a way to fix the performance degradation with batch/bulk size of 1, so the idea would be to use a larger bulk size by default when this is merged, but:. - performance is not always better at the moment: as TTree I/O does not provide bulks, I have to perform extra copies to w.r.t. the non-bulk case that sometimes are more expensive than the bulk processing gains. - since I have to copy values into contiguous buffers, a number of use cases break (polymorphic use of TBranches, branch types with no default constructor, move-only branch types, TClonesArrays, ...). The plan is to try to fix the use cases that break as well as the performance issues so we can always turn bulk processing (with bulk size >> 1) on. It's going to be difficult, fingers crossed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:555,performance,batch,batch,555,"> Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Yes I agree, this PR was just to check the state of the feature on all platforms from time to time and to provide a preview of the changes to you (the early commits are fixed, it's just that they cannot be merged on their own as they degrade performance). > Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward? I don't know of a way to fix the performance degradation with batch/bulk size of 1, so the idea would be to use a larger bulk size by default when this is merged, but:. - performance is not always better at the moment: as TTree I/O does not provide bulks, I have to perform extra copies to w.r.t. the non-bulk case that sometimes are more expensive than the bulk processing gains. - since I have to copy values into contiguous buffers, a number of use cases break (polymorphic use of TBranches, branch types with no default constructor, move-only branch types, TClonesArrays, ...). The plan is to try to fix the use cases that break as well as the performance issues so we can always turn bulk processing (with bulk size >> 1) on. It's going to be difficult, fingers crossed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:664,performance,perform,performance,664,"> Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Yes I agree, this PR was just to check the state of the feature on all platforms from time to time and to provide a preview of the changes to you (the early commits are fixed, it's just that they cannot be merged on their own as they degrade performance). > Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward? I don't know of a way to fix the performance degradation with batch/bulk size of 1, so the idea would be to use a larger bulk size by default when this is merged, but:. - performance is not always better at the moment: as TTree I/O does not provide bulks, I have to perform extra copies to w.r.t. the non-bulk case that sometimes are more expensive than the bulk processing gains. - since I have to copy values into contiguous buffers, a number of use cases break (polymorphic use of TBranches, branch types with no default constructor, move-only branch types, TClonesArrays, ...). The plan is to try to fix the use cases that break as well as the performance issues so we can always turn bulk processing (with bulk size >> 1) on. It's going to be difficult, fingers crossed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:721,performance,I/O,I/O,721,"> Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Yes I agree, this PR was just to check the state of the feature on all platforms from time to time and to provide a preview of the changes to you (the early commits are fixed, it's just that they cannot be merged on their own as they degrade performance). > Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward? I don't know of a way to fix the performance degradation with batch/bulk size of 1, so the idea would be to use a larger bulk size by default when this is merged, but:. - performance is not always better at the moment: as TTree I/O does not provide bulks, I have to perform extra copies to w.r.t. the non-bulk case that sometimes are more expensive than the bulk processing gains. - since I have to copy values into contiguous buffers, a number of use cases break (polymorphic use of TBranches, branch types with no default constructor, move-only branch types, TClonesArrays, ...). The plan is to try to fix the use cases that break as well as the performance issues so we can always turn bulk processing (with bulk size >> 1) on. It's going to be difficult, fingers crossed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:759,performance,perform,perform,759,"> Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Yes I agree, this PR was just to check the state of the feature on all platforms from time to time and to provide a preview of the changes to you (the early commits are fixed, it's just that they cannot be merged on their own as they degrade performance). > Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward? I don't know of a way to fix the performance degradation with batch/bulk size of 1, so the idea would be to use a larger bulk size by default when this is merged, but:. - performance is not always better at the moment: as TTree I/O does not provide bulks, I have to perform extra copies to w.r.t. the non-bulk case that sometimes are more expensive than the bulk processing gains. - since I have to copy values into contiguous buffers, a number of use cases break (polymorphic use of TBranches, branch types with no default constructor, move-only branch types, TClonesArrays, ...). The plan is to try to fix the use cases that break as well as the performance issues so we can always turn bulk processing (with bulk size >> 1) on. It's going to be difficult, fingers crossed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:1141,performance,performance issu,performance issues,1141,"> Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Yes I agree, this PR was just to check the state of the feature on all platforms from time to time and to provide a preview of the changes to you (the early commits are fixed, it's just that they cannot be merged on their own as they degrade performance). > Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward? I don't know of a way to fix the performance degradation with batch/bulk size of 1, so the idea would be to use a larger bulk size by default when this is merged, but:. - performance is not always better at the moment: as TTree I/O does not provide bulks, I have to perform extra copies to w.r.t. the non-bulk case that sometimes are more expensive than the bulk processing gains. - since I have to copy values into contiguous buffers, a number of use cases break (polymorphic use of TBranches, branch types with no default constructor, move-only branch types, TClonesArrays, ...). The plan is to try to fix the use cases that break as well as the performance issues so we can always turn bulk processing (with bulk size >> 1) on. It's going to be difficult, fingers crossed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:357,reliability,degrad,degrade,357,"> Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Yes I agree, this PR was just to check the state of the feature on all platforms from time to time and to provide a preview of the changes to you (the early commits are fixed, it's just that they cannot be merged on their own as they degrade performance). > Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward? I don't know of a way to fix the performance degradation with batch/bulk size of 1, so the idea would be to use a larger bulk size by default when this is merged, but:. - performance is not always better at the moment: as TTree I/O does not provide bulks, I have to perform extra copies to w.r.t. the non-bulk case that sometimes are more expensive than the bulk processing gains. - since I have to copy values into contiguous buffers, a number of use cases break (polymorphic use of TBranches, branch types with no default constructor, move-only branch types, TClonesArrays, ...). The plan is to try to fix the use cases that break as well as the performance issues so we can always turn bulk processing (with bulk size >> 1) on. It's going to be difficult, fingers crossed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:538,reliability,degrad,degradation,538,"> Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Yes I agree, this PR was just to check the state of the feature on all platforms from time to time and to provide a preview of the changes to you (the early commits are fixed, it's just that they cannot be merged on their own as they degrade performance). > Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward? I don't know of a way to fix the performance degradation with batch/bulk size of 1, so the idea would be to use a larger bulk size by default when this is merged, but:. - performance is not always better at the moment: as TTree I/O does not provide bulks, I have to perform extra copies to w.r.t. the non-bulk case that sometimes are more expensive than the bulk processing gains. - since I have to copy values into contiguous buffers, a number of use cases break (polymorphic use of TBranches, branch types with no default constructor, move-only branch types, TClonesArrays, ...). The plan is to try to fix the use cases that break as well as the performance issues so we can always turn bulk processing (with bulk size >> 1) on. It's going to be difficult, fingers crossed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:725,reliability,doe,does,725,"> Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Yes I agree, this PR was just to check the state of the feature on all platforms from time to time and to provide a preview of the changes to you (the early commits are fixed, it's just that they cannot be merged on their own as they degrade performance). > Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward? I don't know of a way to fix the performance degradation with batch/bulk size of 1, so the idea would be to use a larger bulk size by default when this is merged, but:. - performance is not always better at the moment: as TTree I/O does not provide bulks, I have to perform extra copies to w.r.t. the non-bulk case that sometimes are more expensive than the bulk processing gains. - since I have to copy values into contiguous buffers, a number of use cases break (polymorphic use of TBranches, branch types with no default constructor, move-only branch types, TClonesArrays, ...). The plan is to try to fix the use cases that break as well as the performance issues so we can always turn bulk processing (with bulk size >> 1) on. It's going to be difficult, fingers crossed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:398,security,sign,significantly,398,"> Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Yes I agree, this PR was just to check the state of the feature on all platforms from time to time and to provide a preview of the changes to you (the early commits are fixed, it's just that they cannot be merged on their own as they degrade performance). > Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward? I don't know of a way to fix the performance degradation with batch/bulk size of 1, so the idea would be to use a larger bulk size by default when this is merged, but:. - performance is not always better at the moment: as TTree I/O does not provide bulks, I have to perform extra copies to w.r.t. the non-bulk case that sometimes are more expensive than the bulk processing gains. - since I have to copy values into contiguous buffers, a number of use cases break (polymorphic use of TBranches, branch types with no default constructor, move-only branch types, TClonesArrays, ...). The plan is to try to fix the use cases that break as well as the performance issues so we can always turn bulk processing (with bulk size >> 1) on. It's going to be difficult, fingers crossed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:1079,testability,plan,plan,1079,"> Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Yes I agree, this PR was just to check the state of the feature on all platforms from time to time and to provide a preview of the changes to you (the early commits are fixed, it's just that they cannot be merged on their own as they degrade performance). > Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward? I don't know of a way to fix the performance degradation with batch/bulk size of 1, so the idea would be to use a larger bulk size by default when this is merged, but:. - performance is not always better at the moment: as TTree I/O does not provide bulks, I have to perform extra copies to w.r.t. the non-bulk case that sometimes are more expensive than the bulk processing gains. - since I have to copy values into contiguous buffers, a number of use cases break (polymorphic use of TBranches, branch types with no default constructor, move-only branch types, TClonesArrays, ...). The plan is to try to fix the use cases that break as well as the performance issues so we can always turn bulk processing (with bulk size >> 1) on. It's going to be difficult, fingers crossed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:365,usability,perform,performance,365,"> Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Yes I agree, this PR was just to check the state of the feature on all platforms from time to time and to provide a preview of the changes to you (the early commits are fixed, it's just that they cannot be merged on their own as they degrade performance). > Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward? I don't know of a way to fix the performance degradation with batch/bulk size of 1, so the idea would be to use a larger bulk size by default when this is merged, but:. - performance is not always better at the moment: as TTree I/O does not provide bulks, I have to perform extra copies to w.r.t. the non-bulk case that sometimes are more expensive than the bulk processing gains. - since I have to copy values into contiguous buffers, a number of use cases break (polymorphic use of TBranches, branch types with no default constructor, move-only branch types, TClonesArrays, ...). The plan is to try to fix the use cases that break as well as the performance issues so we can always turn bulk processing (with bulk size >> 1) on. It's going to be difficult, fingers crossed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:423,usability,perform,performance,423,"> Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Yes I agree, this PR was just to check the state of the feature on all platforms from time to time and to provide a preview of the changes to you (the early commits are fixed, it's just that they cannot be merged on their own as they degrade performance). > Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward? I don't know of a way to fix the performance degradation with batch/bulk size of 1, so the idea would be to use a larger bulk size by default when this is merged, but:. - performance is not always better at the moment: as TTree I/O does not provide bulks, I have to perform extra copies to w.r.t. the non-bulk case that sometimes are more expensive than the bulk processing gains. - since I have to copy values into contiguous buffers, a number of use cases break (polymorphic use of TBranches, branch types with no default constructor, move-only branch types, TClonesArrays, ...). The plan is to try to fix the use cases that break as well as the performance issues so we can always turn bulk processing (with bulk size >> 1) on. It's going to be difficult, fingers crossed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:526,usability,perform,performance,526,"> Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Yes I agree, this PR was just to check the state of the feature on all platforms from time to time and to provide a preview of the changes to you (the early commits are fixed, it's just that they cannot be merged on their own as they degrade performance). > Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward? I don't know of a way to fix the performance degradation with batch/bulk size of 1, so the idea would be to use a larger bulk size by default when this is merged, but:. - performance is not always better at the moment: as TTree I/O does not provide bulks, I have to perform extra copies to w.r.t. the non-bulk case that sometimes are more expensive than the bulk processing gains. - since I have to copy values into contiguous buffers, a number of use cases break (polymorphic use of TBranches, branch types with no default constructor, move-only branch types, TClonesArrays, ...). The plan is to try to fix the use cases that break as well as the performance issues so we can always turn bulk processing (with bulk size >> 1) on. It's going to be difficult, fingers crossed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:664,usability,perform,performance,664,"> Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Yes I agree, this PR was just to check the state of the feature on all platforms from time to time and to provide a preview of the changes to you (the early commits are fixed, it's just that they cannot be merged on their own as they degrade performance). > Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward? I don't know of a way to fix the performance degradation with batch/bulk size of 1, so the idea would be to use a larger bulk size by default when this is merged, but:. - performance is not always better at the moment: as TTree I/O does not provide bulks, I have to perform extra copies to w.r.t. the non-bulk case that sometimes are more expensive than the bulk processing gains. - since I have to copy values into contiguous buffers, a number of use cases break (polymorphic use of TBranches, branch types with no default constructor, move-only branch types, TClonesArrays, ...). The plan is to try to fix the use cases that break as well as the performance issues so we can always turn bulk processing (with bulk size >> 1) on. It's going to be difficult, fingers crossed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:759,usability,perform,perform,759,"> Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Yes I agree, this PR was just to check the state of the feature on all platforms from time to time and to provide a preview of the changes to you (the early commits are fixed, it's just that they cannot be merged on their own as they degrade performance). > Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward? I don't know of a way to fix the performance degradation with batch/bulk size of 1, so the idea would be to use a larger bulk size by default when this is merged, but:. - performance is not always better at the moment: as TTree I/O does not provide bulks, I have to perform extra copies to w.r.t. the non-bulk case that sometimes are more expensive than the bulk processing gains. - since I have to copy values into contiguous buffers, a number of use cases break (polymorphic use of TBranches, branch types with no default constructor, move-only branch types, TClonesArrays, ...). The plan is to try to fix the use cases that break as well as the performance issues so we can always turn bulk processing (with bulk size >> 1) on. It's going to be difficult, fingers crossed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:1141,usability,perform,performance,1141,"> Maybe it makes sense to open a new PR once this works, such that we get rid of the part ""make it work on all platforms""? Yes I agree, this PR was just to check the state of the feature on all platforms from time to time and to provide a preview of the changes to you (the early commits are fixed, it's just that they cannot be merged on their own as they degrade performance). > Do you expect to significantly reduce the performance impact for a batch size of 1, or what's the path forward? I don't know of a way to fix the performance degradation with batch/bulk size of 1, so the idea would be to use a larger bulk size by default when this is merged, but:. - performance is not always better at the moment: as TTree I/O does not provide bulks, I have to perform extra copies to w.r.t. the non-bulk case that sometimes are more expensive than the bulk processing gains. - since I have to copy values into contiguous buffers, a number of use cases break (polymorphic use of TBranches, branch types with no default constructor, move-only branch types, TClonesArrays, ...). The plan is to try to fix the use cases that break as well as the performance issues so we can always turn bulk processing (with bulk size >> 1) on. It's going to be difficult, fingers crossed.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:109,integrability,interfac,interface,109,"> as TTree I/O does not provide bulks, . What do you mean? There is a (non-zero copy but still low) bulk i/o interface in TTree already.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:109,interoperability,interfac,interface,109,"> as TTree I/O does not provide bulks, . What do you mean? There is a (non-zero copy but still low) bulk i/o interface in TTree already.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:109,modifiability,interfac,interface,109,"> as TTree I/O does not provide bulks, . What do you mean? There is a (non-zero copy but still low) bulk i/o interface in TTree already.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:11,performance,I/O,I/O,11,"> as TTree I/O does not provide bulks, . What do you mean? There is a (non-zero copy but still low) bulk i/o interface in TTree already.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:105,performance,i/o,i/o,105,"> as TTree I/O does not provide bulks, . What do you mean? There is a (non-zero copy but still low) bulk i/o interface in TTree already.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:15,reliability,doe,does,15,"> as TTree I/O does not provide bulks, . What do you mean? There is a (non-zero copy but still low) bulk i/o interface in TTree already.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:114,integrability,interfac,interface,114,">> as TTree I/O does not provide bulks,. >. > What do you mean? There is a (non-zero copy but still low) bulk i/o interface in TTree already. Only for certain types and it's not exposed by TTreeReader.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:114,interoperability,interfac,interface,114,">> as TTree I/O does not provide bulks,. >. > What do you mean? There is a (non-zero copy but still low) bulk i/o interface in TTree already. Only for certain types and it's not exposed by TTreeReader.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:114,modifiability,interfac,interface,114,">> as TTree I/O does not provide bulks,. >. > What do you mean? There is a (non-zero copy but still low) bulk i/o interface in TTree already. Only for certain types and it's not exposed by TTreeReader.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:12,performance,I/O,I/O,12,">> as TTree I/O does not provide bulks,. >. > What do you mean? There is a (non-zero copy but still low) bulk i/o interface in TTree already. Only for certain types and it's not exposed by TTreeReader.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:110,performance,i/o,i/o,110,">> as TTree I/O does not provide bulks,. >. > What do you mean? There is a (non-zero copy but still low) bulk i/o interface in TTree already. Only for certain types and it's not exposed by TTreeReader.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:16,reliability,doe,does,16,">> as TTree I/O does not provide bulks,. >. > What do you mean? There is a (non-zero copy but still low) bulk i/o interface in TTree already. Only for certain types and it's not exposed by TTreeReader.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:178,security,expos,exposed,178,">> as TTree I/O does not provide bulks,. >. > What do you mean? There is a (non-zero copy but still low) bulk i/o interface in TTree already. Only for certain types and it's not exposed by TTreeReader.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:188,safety,test,test,188,> Only for certain types and it's not exposed by TTreeReader. humm .. isn't it also the case for RNtuple (I guess maybe less so but still). Anyway there is an attempt of it see `tree/tree/test/BulkApi*`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:38,security,expos,exposed,38,> Only for certain types and it's not exposed by TTreeReader. humm .. isn't it also the case for RNtuple (I guess maybe less so but still). Anyway there is an attempt of it see `tree/tree/test/BulkApi*`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11517:188,testability,test,test,188,> Only for certain types and it's not exposed by TTreeReader. humm .. isn't it also the case for RNtuple (I guess maybe less so but still). Anyway there is an attempt of it see `tree/tree/test/BulkApi*`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11517
https://github.com/root-project/root/pull/11518:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2204/cxx17, ROOT-ubuntu2004/default, ROOT-ubuntu18.04/nortcxxmod",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11518
https://github.com/root-project/root/pull/11518:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2204/cxx17, ROOT-ubuntu2004/default, ROOT-ubuntu18.04/nortcxxmod",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11518
https://github.com/root-project/root/pull/11518:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2204/default, ROOT-ubuntu2004/cxx17, ROOT-ubuntu18.04/nortcxxmod",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11518
https://github.com/root-project/root/pull/11518:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2204/default, ROOT-ubuntu2004/cxx17, ROOT-ubuntu18.04/nortcxxmod",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11518
https://github.com/root-project/root/pull/11518:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2004/default, ROOT-ubuntu18.04/nortcxxmod",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11518
https://github.com/root-project/root/issues/11519:63,usability,hint,hint,63,Fixed in master by commit a5cbb5d7796846c Thanks again for the hint!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11519
https://github.com/root-project/root/pull/11522:153,modifiability,variab,variable,153,"> we might have broken old analysis, no? I hope no real RDF code reads in-memory trees that have been just been written and that use the same underlying variable for multiple branches :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11522
https://github.com/root-project/root/pull/11522:74,performance,memor,memory,74,"> we might have broken old analysis, no? I hope no real RDF code reads in-memory trees that have been just been written and that use the same underlying variable for multiple branches :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11522
https://github.com/root-project/root/pull/11522:74,usability,memor,memory,74,"> we might have broken old analysis, no? I hope no real RDF code reads in-memory trees that have been just been written and that use the same underlying variable for multiple branches :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11522
https://github.com/root-project/root/pull/11526:4,availability,error,errors,4,The errors seen in the CI such as . ```. Error in <TFile::TFile>: file /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/roottest/python/distrdf/dask/distrdf_check_friend_trees_alignment_dask_file_1.root/distrdf_check_friend_trees_alignment_dask_tree_1.root does not exist. ```. Show that something is wrong with the file names. Notice the double file name above. Probably in the creation of the spec passed to the task-local RDF something is wrong,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:41,availability,Error,Error,41,The errors seen in the CI such as . ```. Error in <TFile::TFile>: file /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/roottest/python/distrdf/dask/distrdf_check_friend_trees_alignment_dask_file_1.root/distrdf_check_friend_trees_alignment_dask_tree_1.root does not exist. ```. Show that something is wrong with the file names. Notice the double file name above. Probably in the creation of the spec passed to the task-local RDF something is wrong,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:87,deployability,build,build,87,The errors seen in the CI such as . ```. Error in <TFile::TFile>: file /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/roottest/python/distrdf/dask/distrdf_check_friend_trees_alignment_dask_file_1.root/distrdf_check_friend_trees_alignment_dask_tree_1.root does not exist. ```. Show that something is wrong with the file names. Notice the double file name above. Probably in the creation of the spec passed to the task-local RDF something is wrong,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:129,deployability,build,build,129,The errors seen in the CI such as . ```. Error in <TFile::TFile>: file /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/roottest/python/distrdf/dask/distrdf_check_friend_trees_alignment_dask_file_1.root/distrdf_check_friend_trees_alignment_dask_tree_1.root does not exist. ```. Show that something is wrong with the file names. Notice the double file name above. Probably in the creation of the spec passed to the task-local RDF something is wrong,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:135,deployability,build,build,135,The errors seen in the CI such as . ```. Error in <TFile::TFile>: file /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/roottest/python/distrdf/dask/distrdf_check_friend_trees_alignment_dask_file_1.root/distrdf_check_friend_trees_alignment_dask_tree_1.root does not exist. ```. Show that something is wrong with the file names. Notice the double file name above. Probably in the creation of the spec passed to the task-local RDF something is wrong,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:4,performance,error,errors,4,The errors seen in the CI such as . ```. Error in <TFile::TFile>: file /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/roottest/python/distrdf/dask/distrdf_check_friend_trees_alignment_dask_file_1.root/distrdf_check_friend_trees_alignment_dask_tree_1.root does not exist. ```. Show that something is wrong with the file names. Notice the double file name above. Probably in the creation of the spec passed to the task-local RDF something is wrong,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:41,performance,Error,Error,41,The errors seen in the CI such as . ```. Error in <TFile::TFile>: file /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/roottest/python/distrdf/dask/distrdf_check_friend_trees_alignment_dask_file_1.root/distrdf_check_friend_trees_alignment_dask_tree_1.root does not exist. ```. Show that something is wrong with the file names. Notice the double file name above. Probably in the creation of the spec passed to the task-local RDF something is wrong,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:278,reliability,doe,does,278,The errors seen in the CI such as . ```. Error in <TFile::TFile>: file /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/roottest/python/distrdf/dask/distrdf_check_friend_trees_alignment_dask_file_1.root/distrdf_check_friend_trees_alignment_dask_tree_1.root does not exist. ```. Show that something is wrong with the file names. Notice the double file name above. Probably in the creation of the spec passed to the task-local RDF something is wrong,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:4,safety,error,errors,4,The errors seen in the CI such as . ```. Error in <TFile::TFile>: file /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/roottest/python/distrdf/dask/distrdf_check_friend_trees_alignment_dask_file_1.root/distrdf_check_friend_trees_alignment_dask_tree_1.root does not exist. ```. Show that something is wrong with the file names. Notice the double file name above. Probably in the creation of the spec passed to the task-local RDF something is wrong,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:41,safety,Error,Error,41,The errors seen in the CI such as . ```. Error in <TFile::TFile>: file /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/roottest/python/distrdf/dask/distrdf_check_friend_trees_alignment_dask_file_1.root/distrdf_check_friend_trees_alignment_dask_tree_1.root does not exist. ```. Show that something is wrong with the file names. Notice the double file name above. Probably in the creation of the spec passed to the task-local RDF something is wrong,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:4,usability,error,errors,4,The errors seen in the CI such as . ```. Error in <TFile::TFile>: file /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/roottest/python/distrdf/dask/distrdf_check_friend_trees_alignment_dask_file_1.root/distrdf_check_friend_trees_alignment_dask_tree_1.root does not exist. ```. Show that something is wrong with the file names. Notice the double file name above. Probably in the creation of the spec passed to the task-local RDF something is wrong,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:41,usability,Error,Error,41,The errors seen in the CI such as . ```. Error in <TFile::TFile>: file /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/roottest/python/distrdf/dask/distrdf_check_friend_trees_alignment_dask_file_1.root/distrdf_check_friend_trees_alignment_dask_tree_1.root does not exist. ```. Show that something is wrong with the file names. Notice the double file name above. Probably in the creation of the spec passed to the task-local RDF something is wrong,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:72,usability,User,Users,72,The errors seen in the CI such as . ```. Error in <TFile::TFile>: file /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/roottest/python/distrdf/dask/distrdf_check_friend_trees_alignment_dask_file_1.root/distrdf_check_friend_trees_alignment_dask_tree_1.root does not exist. ```. Show that something is wrong with the file names. Notice the double file name above. Probably in the creation of the spec passed to the task-local RDF something is wrong,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:6,availability,error,errors,6,"> The errors seen in the CI such as. > . > ```. > Error in <TFile::TFile>: file /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/roottest/python/distrdf/dask/distrdf_check_friend_trees_alignment_dask_file_1.root/distrdf_check_friend_trees_alignment_dask_tree_1.root does not exist. > ```. > . > Show that something is wrong with the file names. Notice the double file name above. Probably in the creation of the spec passed to the task-local RDF something is wrong. Hmm that is very strange. I grepped for `distrdf_check_friend_trees_alignment_dask_tree`. It is present only in `python/distrdf/dask/check_friend_trees_alignment.py`. I see that there the chain is created like:. ```py. def create_chain():. main = ROOT.TChain(). for i in range(3):. main.Add(f""{FILENAMES[i]}?#{TREENAMES[i]}""). friend = ROOT.TChain(). for i in range(3, 6):. friend.Add(f""{FILENAMES[i]}?#{TREENAMES[i]}""). main.AddFriend(friend, ""friend""). # import pdb; pdb.set_trace() --> a breakpoint I added. return main. ```. Then calling `df = Dask.RDataFrame(chain, daskclient=connection, npartitions=nparts)`. 1. Is it intentional not to use a spec instead? 2. From the breakpoint I printed the contents of file and tree names and they looked all file:. ```py. (Pdb) p FILENAMES. ['distrdf_check_friend_trees_alignment_dask_file_1.root', 'distrdf_check_friend_trees_alignment_dask_file_2.root', 'distrdf_check_friend_trees_alignment_dask_file_3.root', 'distrdf_check_friend_trees_alignment_dask_file_4.root', 'distrdf_check_friend_trees_alignment_dask_file_5.root', 'distrdf_check_friend_trees_alignment_dask_file_6.root']. (Pdb) p TREENAMES. ['distrdf_check_friend_trees_alignment_dask_tree_1.root', 'distrdf_check_friend_trees_alignment_dask_tree_2.root', 'distrdf_check_friend_trees_alignment_dask_tree_3.root', 'distrdf_check_friend_trees_alignment_dask_tree_4.root', 'distrdf_check_friend_trees_alignment_dask_tree_5.root', 'distrdf_check_friend_trees_alignment_dask_tree_6.root']. ```. 3. Locally this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:50,availability,Error,Error,50,"> The errors seen in the CI such as. > . > ```. > Error in <TFile::TFile>: file /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/roottest/python/distrdf/dask/distrdf_check_friend_trees_alignment_dask_file_1.root/distrdf_check_friend_trees_alignment_dask_tree_1.root does not exist. > ```. > . > Show that something is wrong with the file names. Notice the double file name above. Probably in the creation of the spec passed to the task-local RDF something is wrong. Hmm that is very strange. I grepped for `distrdf_check_friend_trees_alignment_dask_tree`. It is present only in `python/distrdf/dask/check_friend_trees_alignment.py`. I see that there the chain is created like:. ```py. def create_chain():. main = ROOT.TChain(). for i in range(3):. main.Add(f""{FILENAMES[i]}?#{TREENAMES[i]}""). friend = ROOT.TChain(). for i in range(3, 6):. friend.Add(f""{FILENAMES[i]}?#{TREENAMES[i]}""). main.AddFriend(friend, ""friend""). # import pdb; pdb.set_trace() --> a breakpoint I added. return main. ```. Then calling `df = Dask.RDataFrame(chain, daskclient=connection, npartitions=nparts)`. 1. Is it intentional not to use a spec instead? 2. From the breakpoint I printed the contents of file and tree names and they looked all file:. ```py. (Pdb) p FILENAMES. ['distrdf_check_friend_trees_alignment_dask_file_1.root', 'distrdf_check_friend_trees_alignment_dask_file_2.root', 'distrdf_check_friend_trees_alignment_dask_file_3.root', 'distrdf_check_friend_trees_alignment_dask_file_4.root', 'distrdf_check_friend_trees_alignment_dask_file_5.root', 'distrdf_check_friend_trees_alignment_dask_file_6.root']. (Pdb) p TREENAMES. ['distrdf_check_friend_trees_alignment_dask_tree_1.root', 'distrdf_check_friend_trees_alignment_dask_tree_2.root', 'distrdf_check_friend_trees_alignment_dask_tree_3.root', 'distrdf_check_friend_trees_alignment_dask_tree_4.root', 'distrdf_check_friend_trees_alignment_dask_tree_5.root', 'distrdf_check_friend_trees_alignment_dask_tree_6.root']. ```. 3. Locally this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:2506,availability,state,state,2506,"turn main. ```. Then calling `df = Dask.RDataFrame(chain, daskclient=connection, npartitions=nparts)`. 1. Is it intentional not to use a spec instead? 2. From the breakpoint I printed the contents of file and tree names and they looked all file:. ```py. (Pdb) p FILENAMES. ['distrdf_check_friend_trees_alignment_dask_file_1.root', 'distrdf_check_friend_trees_alignment_dask_file_2.root', 'distrdf_check_friend_trees_alignment_dask_file_3.root', 'distrdf_check_friend_trees_alignment_dask_file_4.root', 'distrdf_check_friend_trees_alignment_dask_file_5.root', 'distrdf_check_friend_trees_alignment_dask_file_6.root']. (Pdb) p TREENAMES. ['distrdf_check_friend_trees_alignment_dask_tree_1.root', 'distrdf_check_friend_trees_alignment_dask_tree_2.root', 'distrdf_check_friend_trees_alignment_dask_tree_3.root', 'distrdf_check_friend_trees_alignment_dask_tree_4.root', 'distrdf_check_friend_trees_alignment_dask_tree_5.root', 'distrdf_check_friend_trees_alignment_dask_tree_6.root']. ```. 3. Locally this test fails for me on `s1val = s1.GetValue()`. From pdb I get this stack strace:. ```py. ... > rdf_node = rdf_operation(*in_task_op.args, **in_task_op.kwargs). E cppyy.ll.SegmentationViolation: Template method resolution failed:. E ROOT::RDF::RResultPtr<double> ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void>::Sum(basic_string_view<char,char_traits<char> > columnName = """", double& initValue = RDFDetail::SumReturnType_t<RInferredType>{}) =>. E SegmentationViolation: segfault in C++; program state was reset. E ROOT::RDF::RResultPtr<double> ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void>::Sum(basic_string_view<char,char_traits<char> > columnName = """", double& initValue = RDFDetail::SumReturnType_t<RInferredType>{}) =>. E SegmentationViolation: segfault in C++; program state was reset. ../../../../rb/lib/DistRDF/ComputationGraphGenerator.py:134: SegmentationViolation. ```. This is also what jenkins complains about. I don't clearly see what is wrong. Investigating ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:2799,availability,state,state,2799,"turn main. ```. Then calling `df = Dask.RDataFrame(chain, daskclient=connection, npartitions=nparts)`. 1. Is it intentional not to use a spec instead? 2. From the breakpoint I printed the contents of file and tree names and they looked all file:. ```py. (Pdb) p FILENAMES. ['distrdf_check_friend_trees_alignment_dask_file_1.root', 'distrdf_check_friend_trees_alignment_dask_file_2.root', 'distrdf_check_friend_trees_alignment_dask_file_3.root', 'distrdf_check_friend_trees_alignment_dask_file_4.root', 'distrdf_check_friend_trees_alignment_dask_file_5.root', 'distrdf_check_friend_trees_alignment_dask_file_6.root']. (Pdb) p TREENAMES. ['distrdf_check_friend_trees_alignment_dask_tree_1.root', 'distrdf_check_friend_trees_alignment_dask_tree_2.root', 'distrdf_check_friend_trees_alignment_dask_tree_3.root', 'distrdf_check_friend_trees_alignment_dask_tree_4.root', 'distrdf_check_friend_trees_alignment_dask_tree_5.root', 'distrdf_check_friend_trees_alignment_dask_tree_6.root']. ```. 3. Locally this test fails for me on `s1val = s1.GetValue()`. From pdb I get this stack strace:. ```py. ... > rdf_node = rdf_operation(*in_task_op.args, **in_task_op.kwargs). E cppyy.ll.SegmentationViolation: Template method resolution failed:. E ROOT::RDF::RResultPtr<double> ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void>::Sum(basic_string_view<char,char_traits<char> > columnName = """", double& initValue = RDFDetail::SumReturnType_t<RInferredType>{}) =>. E SegmentationViolation: segfault in C++; program state was reset. E ROOT::RDF::RResultPtr<double> ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void>::Sum(basic_string_view<char,char_traits<char> > columnName = """", double& initValue = RDFDetail::SumReturnType_t<RInferredType>{}) =>. E SegmentationViolation: segfault in C++; program state was reset. ../../../../rb/lib/DistRDF/ComputationGraphGenerator.py:134: SegmentationViolation. ```. This is also what jenkins complains about. I don't clearly see what is wrong. Investigating ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:96,deployability,build,build,96,"> The errors seen in the CI such as. > . > ```. > Error in <TFile::TFile>: file /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/roottest/python/distrdf/dask/distrdf_check_friend_trees_alignment_dask_file_1.root/distrdf_check_friend_trees_alignment_dask_tree_1.root does not exist. > ```. > . > Show that something is wrong with the file names. Notice the double file name above. Probably in the creation of the spec passed to the task-local RDF something is wrong. Hmm that is very strange. I grepped for `distrdf_check_friend_trees_alignment_dask_tree`. It is present only in `python/distrdf/dask/check_friend_trees_alignment.py`. I see that there the chain is created like:. ```py. def create_chain():. main = ROOT.TChain(). for i in range(3):. main.Add(f""{FILENAMES[i]}?#{TREENAMES[i]}""). friend = ROOT.TChain(). for i in range(3, 6):. friend.Add(f""{FILENAMES[i]}?#{TREENAMES[i]}""). main.AddFriend(friend, ""friend""). # import pdb; pdb.set_trace() --> a breakpoint I added. return main. ```. Then calling `df = Dask.RDataFrame(chain, daskclient=connection, npartitions=nparts)`. 1. Is it intentional not to use a spec instead? 2. From the breakpoint I printed the contents of file and tree names and they looked all file:. ```py. (Pdb) p FILENAMES. ['distrdf_check_friend_trees_alignment_dask_file_1.root', 'distrdf_check_friend_trees_alignment_dask_file_2.root', 'distrdf_check_friend_trees_alignment_dask_file_3.root', 'distrdf_check_friend_trees_alignment_dask_file_4.root', 'distrdf_check_friend_trees_alignment_dask_file_5.root', 'distrdf_check_friend_trees_alignment_dask_file_6.root']. (Pdb) p TREENAMES. ['distrdf_check_friend_trees_alignment_dask_tree_1.root', 'distrdf_check_friend_trees_alignment_dask_tree_2.root', 'distrdf_check_friend_trees_alignment_dask_tree_3.root', 'distrdf_check_friend_trees_alignment_dask_tree_4.root', 'distrdf_check_friend_trees_alignment_dask_tree_5.root', 'distrdf_check_friend_trees_alignment_dask_tree_6.root']. ```. 3. Locally this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:138,deployability,build,build,138,"> The errors seen in the CI such as. > . > ```. > Error in <TFile::TFile>: file /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/roottest/python/distrdf/dask/distrdf_check_friend_trees_alignment_dask_file_1.root/distrdf_check_friend_trees_alignment_dask_tree_1.root does not exist. > ```. > . > Show that something is wrong with the file names. Notice the double file name above. Probably in the creation of the spec passed to the task-local RDF something is wrong. Hmm that is very strange. I grepped for `distrdf_check_friend_trees_alignment_dask_tree`. It is present only in `python/distrdf/dask/check_friend_trees_alignment.py`. I see that there the chain is created like:. ```py. def create_chain():. main = ROOT.TChain(). for i in range(3):. main.Add(f""{FILENAMES[i]}?#{TREENAMES[i]}""). friend = ROOT.TChain(). for i in range(3, 6):. friend.Add(f""{FILENAMES[i]}?#{TREENAMES[i]}""). main.AddFriend(friend, ""friend""). # import pdb; pdb.set_trace() --> a breakpoint I added. return main. ```. Then calling `df = Dask.RDataFrame(chain, daskclient=connection, npartitions=nparts)`. 1. Is it intentional not to use a spec instead? 2. From the breakpoint I printed the contents of file and tree names and they looked all file:. ```py. (Pdb) p FILENAMES. ['distrdf_check_friend_trees_alignment_dask_file_1.root', 'distrdf_check_friend_trees_alignment_dask_file_2.root', 'distrdf_check_friend_trees_alignment_dask_file_3.root', 'distrdf_check_friend_trees_alignment_dask_file_4.root', 'distrdf_check_friend_trees_alignment_dask_file_5.root', 'distrdf_check_friend_trees_alignment_dask_file_6.root']. (Pdb) p TREENAMES. ['distrdf_check_friend_trees_alignment_dask_tree_1.root', 'distrdf_check_friend_trees_alignment_dask_tree_2.root', 'distrdf_check_friend_trees_alignment_dask_tree_3.root', 'distrdf_check_friend_trees_alignment_dask_tree_4.root', 'distrdf_check_friend_trees_alignment_dask_tree_5.root', 'distrdf_check_friend_trees_alignment_dask_tree_6.root']. ```. 3. Locally this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:144,deployability,build,build,144,"> The errors seen in the CI such as. > . > ```. > Error in <TFile::TFile>: file /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/roottest/python/distrdf/dask/distrdf_check_friend_trees_alignment_dask_file_1.root/distrdf_check_friend_trees_alignment_dask_tree_1.root does not exist. > ```. > . > Show that something is wrong with the file names. Notice the double file name above. Probably in the creation of the spec passed to the task-local RDF something is wrong. Hmm that is very strange. I grepped for `distrdf_check_friend_trees_alignment_dask_tree`. It is present only in `python/distrdf/dask/check_friend_trees_alignment.py`. I see that there the chain is created like:. ```py. def create_chain():. main = ROOT.TChain(). for i in range(3):. main.Add(f""{FILENAMES[i]}?#{TREENAMES[i]}""). friend = ROOT.TChain(). for i in range(3, 6):. friend.Add(f""{FILENAMES[i]}?#{TREENAMES[i]}""). main.AddFriend(friend, ""friend""). # import pdb; pdb.set_trace() --> a breakpoint I added. return main. ```. Then calling `df = Dask.RDataFrame(chain, daskclient=connection, npartitions=nparts)`. 1. Is it intentional not to use a spec instead? 2. From the breakpoint I printed the contents of file and tree names and they looked all file:. ```py. (Pdb) p FILENAMES. ['distrdf_check_friend_trees_alignment_dask_file_1.root', 'distrdf_check_friend_trees_alignment_dask_file_2.root', 'distrdf_check_friend_trees_alignment_dask_file_3.root', 'distrdf_check_friend_trees_alignment_dask_file_4.root', 'distrdf_check_friend_trees_alignment_dask_file_5.root', 'distrdf_check_friend_trees_alignment_dask_file_6.root']. (Pdb) p TREENAMES. ['distrdf_check_friend_trees_alignment_dask_tree_1.root', 'distrdf_check_friend_trees_alignment_dask_tree_2.root', 'distrdf_check_friend_trees_alignment_dask_tree_3.root', 'distrdf_check_friend_trees_alignment_dask_tree_4.root', 'distrdf_check_friend_trees_alignment_dask_tree_5.root', 'distrdf_check_friend_trees_alignment_dask_tree_6.root']. ```. 3. Locally this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:2006,deployability,fail,fails,2006,"turn main. ```. Then calling `df = Dask.RDataFrame(chain, daskclient=connection, npartitions=nparts)`. 1. Is it intentional not to use a spec instead? 2. From the breakpoint I printed the contents of file and tree names and they looked all file:. ```py. (Pdb) p FILENAMES. ['distrdf_check_friend_trees_alignment_dask_file_1.root', 'distrdf_check_friend_trees_alignment_dask_file_2.root', 'distrdf_check_friend_trees_alignment_dask_file_3.root', 'distrdf_check_friend_trees_alignment_dask_file_4.root', 'distrdf_check_friend_trees_alignment_dask_file_5.root', 'distrdf_check_friend_trees_alignment_dask_file_6.root']. (Pdb) p TREENAMES. ['distrdf_check_friend_trees_alignment_dask_tree_1.root', 'distrdf_check_friend_trees_alignment_dask_tree_2.root', 'distrdf_check_friend_trees_alignment_dask_tree_3.root', 'distrdf_check_friend_trees_alignment_dask_tree_4.root', 'distrdf_check_friend_trees_alignment_dask_tree_5.root', 'distrdf_check_friend_trees_alignment_dask_tree_6.root']. ```. 3. Locally this test fails for me on `s1val = s1.GetValue()`. From pdb I get this stack strace:. ```py. ... > rdf_node = rdf_operation(*in_task_op.args, **in_task_op.kwargs). E cppyy.ll.SegmentationViolation: Template method resolution failed:. E ROOT::RDF::RResultPtr<double> ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void>::Sum(basic_string_view<char,char_traits<char> > columnName = """", double& initValue = RDFDetail::SumReturnType_t<RInferredType>{}) =>. E SegmentationViolation: segfault in C++; program state was reset. E ROOT::RDF::RResultPtr<double> ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void>::Sum(basic_string_view<char,char_traits<char> > columnName = """", double& initValue = RDFDetail::SumReturnType_t<RInferredType>{}) =>. E SegmentationViolation: segfault in C++; program state was reset. ../../../../rb/lib/DistRDF/ComputationGraphGenerator.py:134: SegmentationViolation. ```. This is also what jenkins complains about. I don't clearly see what is wrong. Investigating ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:2067,deployability,stack,stack,2067,"turn main. ```. Then calling `df = Dask.RDataFrame(chain, daskclient=connection, npartitions=nparts)`. 1. Is it intentional not to use a spec instead? 2. From the breakpoint I printed the contents of file and tree names and they looked all file:. ```py. (Pdb) p FILENAMES. ['distrdf_check_friend_trees_alignment_dask_file_1.root', 'distrdf_check_friend_trees_alignment_dask_file_2.root', 'distrdf_check_friend_trees_alignment_dask_file_3.root', 'distrdf_check_friend_trees_alignment_dask_file_4.root', 'distrdf_check_friend_trees_alignment_dask_file_5.root', 'distrdf_check_friend_trees_alignment_dask_file_6.root']. (Pdb) p TREENAMES. ['distrdf_check_friend_trees_alignment_dask_tree_1.root', 'distrdf_check_friend_trees_alignment_dask_tree_2.root', 'distrdf_check_friend_trees_alignment_dask_tree_3.root', 'distrdf_check_friend_trees_alignment_dask_tree_4.root', 'distrdf_check_friend_trees_alignment_dask_tree_5.root', 'distrdf_check_friend_trees_alignment_dask_tree_6.root']. ```. 3. Locally this test fails for me on `s1val = s1.GetValue()`. From pdb I get this stack strace:. ```py. ... > rdf_node = rdf_operation(*in_task_op.args, **in_task_op.kwargs). E cppyy.ll.SegmentationViolation: Template method resolution failed:. E ROOT::RDF::RResultPtr<double> ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void>::Sum(basic_string_view<char,char_traits<char> > columnName = """", double& initValue = RDFDetail::SumReturnType_t<RInferredType>{}) =>. E SegmentationViolation: segfault in C++; program state was reset. E ROOT::RDF::RResultPtr<double> ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void>::Sum(basic_string_view<char,char_traits<char> > columnName = """", double& initValue = RDFDetail::SumReturnType_t<RInferredType>{}) =>. E SegmentationViolation: segfault in C++; program state was reset. ../../../../rb/lib/DistRDF/ComputationGraphGenerator.py:134: SegmentationViolation. ```. This is also what jenkins complains about. I don't clearly see what is wrong. Investigating ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:2221,deployability,fail,failed,2221,"turn main. ```. Then calling `df = Dask.RDataFrame(chain, daskclient=connection, npartitions=nparts)`. 1. Is it intentional not to use a spec instead? 2. From the breakpoint I printed the contents of file and tree names and they looked all file:. ```py. (Pdb) p FILENAMES. ['distrdf_check_friend_trees_alignment_dask_file_1.root', 'distrdf_check_friend_trees_alignment_dask_file_2.root', 'distrdf_check_friend_trees_alignment_dask_file_3.root', 'distrdf_check_friend_trees_alignment_dask_file_4.root', 'distrdf_check_friend_trees_alignment_dask_file_5.root', 'distrdf_check_friend_trees_alignment_dask_file_6.root']. (Pdb) p TREENAMES. ['distrdf_check_friend_trees_alignment_dask_tree_1.root', 'distrdf_check_friend_trees_alignment_dask_tree_2.root', 'distrdf_check_friend_trees_alignment_dask_tree_3.root', 'distrdf_check_friend_trees_alignment_dask_tree_4.root', 'distrdf_check_friend_trees_alignment_dask_tree_5.root', 'distrdf_check_friend_trees_alignment_dask_tree_6.root']. ```. 3. Locally this test fails for me on `s1val = s1.GetValue()`. From pdb I get this stack strace:. ```py. ... > rdf_node = rdf_operation(*in_task_op.args, **in_task_op.kwargs). E cppyy.ll.SegmentationViolation: Template method resolution failed:. E ROOT::RDF::RResultPtr<double> ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void>::Sum(basic_string_view<char,char_traits<char> > columnName = """", double& initValue = RDFDetail::SumReturnType_t<RInferredType>{}) =>. E SegmentationViolation: segfault in C++; program state was reset. E ROOT::RDF::RResultPtr<double> ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void>::Sum(basic_string_view<char,char_traits<char> > columnName = """", double& initValue = RDFDetail::SumReturnType_t<RInferredType>{}) =>. E SegmentationViolation: segfault in C++; program state was reset. ../../../../rb/lib/DistRDF/ComputationGraphGenerator.py:134: SegmentationViolation. ```. This is also what jenkins complains about. I don't clearly see what is wrong. Investigating ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:2506,integrability,state,state,2506,"turn main. ```. Then calling `df = Dask.RDataFrame(chain, daskclient=connection, npartitions=nparts)`. 1. Is it intentional not to use a spec instead? 2. From the breakpoint I printed the contents of file and tree names and they looked all file:. ```py. (Pdb) p FILENAMES. ['distrdf_check_friend_trees_alignment_dask_file_1.root', 'distrdf_check_friend_trees_alignment_dask_file_2.root', 'distrdf_check_friend_trees_alignment_dask_file_3.root', 'distrdf_check_friend_trees_alignment_dask_file_4.root', 'distrdf_check_friend_trees_alignment_dask_file_5.root', 'distrdf_check_friend_trees_alignment_dask_file_6.root']. (Pdb) p TREENAMES. ['distrdf_check_friend_trees_alignment_dask_tree_1.root', 'distrdf_check_friend_trees_alignment_dask_tree_2.root', 'distrdf_check_friend_trees_alignment_dask_tree_3.root', 'distrdf_check_friend_trees_alignment_dask_tree_4.root', 'distrdf_check_friend_trees_alignment_dask_tree_5.root', 'distrdf_check_friend_trees_alignment_dask_tree_6.root']. ```. 3. Locally this test fails for me on `s1val = s1.GetValue()`. From pdb I get this stack strace:. ```py. ... > rdf_node = rdf_operation(*in_task_op.args, **in_task_op.kwargs). E cppyy.ll.SegmentationViolation: Template method resolution failed:. E ROOT::RDF::RResultPtr<double> ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void>::Sum(basic_string_view<char,char_traits<char> > columnName = """", double& initValue = RDFDetail::SumReturnType_t<RInferredType>{}) =>. E SegmentationViolation: segfault in C++; program state was reset. E ROOT::RDF::RResultPtr<double> ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void>::Sum(basic_string_view<char,char_traits<char> > columnName = """", double& initValue = RDFDetail::SumReturnType_t<RInferredType>{}) =>. E SegmentationViolation: segfault in C++; program state was reset. ../../../../rb/lib/DistRDF/ComputationGraphGenerator.py:134: SegmentationViolation. ```. This is also what jenkins complains about. I don't clearly see what is wrong. Investigating ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:2799,integrability,state,state,2799,"turn main. ```. Then calling `df = Dask.RDataFrame(chain, daskclient=connection, npartitions=nparts)`. 1. Is it intentional not to use a spec instead? 2. From the breakpoint I printed the contents of file and tree names and they looked all file:. ```py. (Pdb) p FILENAMES. ['distrdf_check_friend_trees_alignment_dask_file_1.root', 'distrdf_check_friend_trees_alignment_dask_file_2.root', 'distrdf_check_friend_trees_alignment_dask_file_3.root', 'distrdf_check_friend_trees_alignment_dask_file_4.root', 'distrdf_check_friend_trees_alignment_dask_file_5.root', 'distrdf_check_friend_trees_alignment_dask_file_6.root']. (Pdb) p TREENAMES. ['distrdf_check_friend_trees_alignment_dask_tree_1.root', 'distrdf_check_friend_trees_alignment_dask_tree_2.root', 'distrdf_check_friend_trees_alignment_dask_tree_3.root', 'distrdf_check_friend_trees_alignment_dask_tree_4.root', 'distrdf_check_friend_trees_alignment_dask_tree_5.root', 'distrdf_check_friend_trees_alignment_dask_tree_6.root']. ```. 3. Locally this test fails for me on `s1val = s1.GetValue()`. From pdb I get this stack strace:. ```py. ... > rdf_node = rdf_operation(*in_task_op.args, **in_task_op.kwargs). E cppyy.ll.SegmentationViolation: Template method resolution failed:. E ROOT::RDF::RResultPtr<double> ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void>::Sum(basic_string_view<char,char_traits<char> > columnName = """", double& initValue = RDFDetail::SumReturnType_t<RInferredType>{}) =>. E SegmentationViolation: segfault in C++; program state was reset. E ROOT::RDF::RResultPtr<double> ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void>::Sum(basic_string_view<char,char_traits<char> > columnName = """", double& initValue = RDFDetail::SumReturnType_t<RInferredType>{}) =>. E SegmentationViolation: segfault in C++; program state was reset. ../../../../rb/lib/DistRDF/ComputationGraphGenerator.py:134: SegmentationViolation. ```. This is also what jenkins complains about. I don't clearly see what is wrong. Investigating ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:6,performance,error,errors,6,"> The errors seen in the CI such as. > . > ```. > Error in <TFile::TFile>: file /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/roottest/python/distrdf/dask/distrdf_check_friend_trees_alignment_dask_file_1.root/distrdf_check_friend_trees_alignment_dask_tree_1.root does not exist. > ```. > . > Show that something is wrong with the file names. Notice the double file name above. Probably in the creation of the spec passed to the task-local RDF something is wrong. Hmm that is very strange. I grepped for `distrdf_check_friend_trees_alignment_dask_tree`. It is present only in `python/distrdf/dask/check_friend_trees_alignment.py`. I see that there the chain is created like:. ```py. def create_chain():. main = ROOT.TChain(). for i in range(3):. main.Add(f""{FILENAMES[i]}?#{TREENAMES[i]}""). friend = ROOT.TChain(). for i in range(3, 6):. friend.Add(f""{FILENAMES[i]}?#{TREENAMES[i]}""). main.AddFriend(friend, ""friend""). # import pdb; pdb.set_trace() --> a breakpoint I added. return main. ```. Then calling `df = Dask.RDataFrame(chain, daskclient=connection, npartitions=nparts)`. 1. Is it intentional not to use a spec instead? 2. From the breakpoint I printed the contents of file and tree names and they looked all file:. ```py. (Pdb) p FILENAMES. ['distrdf_check_friend_trees_alignment_dask_file_1.root', 'distrdf_check_friend_trees_alignment_dask_file_2.root', 'distrdf_check_friend_trees_alignment_dask_file_3.root', 'distrdf_check_friend_trees_alignment_dask_file_4.root', 'distrdf_check_friend_trees_alignment_dask_file_5.root', 'distrdf_check_friend_trees_alignment_dask_file_6.root']. (Pdb) p TREENAMES. ['distrdf_check_friend_trees_alignment_dask_tree_1.root', 'distrdf_check_friend_trees_alignment_dask_tree_2.root', 'distrdf_check_friend_trees_alignment_dask_tree_3.root', 'distrdf_check_friend_trees_alignment_dask_tree_4.root', 'distrdf_check_friend_trees_alignment_dask_tree_5.root', 'distrdf_check_friend_trees_alignment_dask_tree_6.root']. ```. 3. Locally this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:50,performance,Error,Error,50,"> The errors seen in the CI such as. > . > ```. > Error in <TFile::TFile>: file /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/roottest/python/distrdf/dask/distrdf_check_friend_trees_alignment_dask_file_1.root/distrdf_check_friend_trees_alignment_dask_tree_1.root does not exist. > ```. > . > Show that something is wrong with the file names. Notice the double file name above. Probably in the creation of the spec passed to the task-local RDF something is wrong. Hmm that is very strange. I grepped for `distrdf_check_friend_trees_alignment_dask_tree`. It is present only in `python/distrdf/dask/check_friend_trees_alignment.py`. I see that there the chain is created like:. ```py. def create_chain():. main = ROOT.TChain(). for i in range(3):. main.Add(f""{FILENAMES[i]}?#{TREENAMES[i]}""). friend = ROOT.TChain(). for i in range(3, 6):. friend.Add(f""{FILENAMES[i]}?#{TREENAMES[i]}""). main.AddFriend(friend, ""friend""). # import pdb; pdb.set_trace() --> a breakpoint I added. return main. ```. Then calling `df = Dask.RDataFrame(chain, daskclient=connection, npartitions=nparts)`. 1. Is it intentional not to use a spec instead? 2. From the breakpoint I printed the contents of file and tree names and they looked all file:. ```py. (Pdb) p FILENAMES. ['distrdf_check_friend_trees_alignment_dask_file_1.root', 'distrdf_check_friend_trees_alignment_dask_file_2.root', 'distrdf_check_friend_trees_alignment_dask_file_3.root', 'distrdf_check_friend_trees_alignment_dask_file_4.root', 'distrdf_check_friend_trees_alignment_dask_file_5.root', 'distrdf_check_friend_trees_alignment_dask_file_6.root']. (Pdb) p TREENAMES. ['distrdf_check_friend_trees_alignment_dask_tree_1.root', 'distrdf_check_friend_trees_alignment_dask_tree_2.root', 'distrdf_check_friend_trees_alignment_dask_tree_3.root', 'distrdf_check_friend_trees_alignment_dask_tree_4.root', 'distrdf_check_friend_trees_alignment_dask_tree_5.root', 'distrdf_check_friend_trees_alignment_dask_tree_6.root']. ```. 3. Locally this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:1188,performance,content,contents,1188,"_friend_trees_alignment_dask_file_1.root/distrdf_check_friend_trees_alignment_dask_tree_1.root does not exist. > ```. > . > Show that something is wrong with the file names. Notice the double file name above. Probably in the creation of the spec passed to the task-local RDF something is wrong. Hmm that is very strange. I grepped for `distrdf_check_friend_trees_alignment_dask_tree`. It is present only in `python/distrdf/dask/check_friend_trees_alignment.py`. I see that there the chain is created like:. ```py. def create_chain():. main = ROOT.TChain(). for i in range(3):. main.Add(f""{FILENAMES[i]}?#{TREENAMES[i]}""). friend = ROOT.TChain(). for i in range(3, 6):. friend.Add(f""{FILENAMES[i]}?#{TREENAMES[i]}""). main.AddFriend(friend, ""friend""). # import pdb; pdb.set_trace() --> a breakpoint I added. return main. ```. Then calling `df = Dask.RDataFrame(chain, daskclient=connection, npartitions=nparts)`. 1. Is it intentional not to use a spec instead? 2. From the breakpoint I printed the contents of file and tree names and they looked all file:. ```py. (Pdb) p FILENAMES. ['distrdf_check_friend_trees_alignment_dask_file_1.root', 'distrdf_check_friend_trees_alignment_dask_file_2.root', 'distrdf_check_friend_trees_alignment_dask_file_3.root', 'distrdf_check_friend_trees_alignment_dask_file_4.root', 'distrdf_check_friend_trees_alignment_dask_file_5.root', 'distrdf_check_friend_trees_alignment_dask_file_6.root']. (Pdb) p TREENAMES. ['distrdf_check_friend_trees_alignment_dask_tree_1.root', 'distrdf_check_friend_trees_alignment_dask_tree_2.root', 'distrdf_check_friend_trees_alignment_dask_tree_3.root', 'distrdf_check_friend_trees_alignment_dask_tree_4.root', 'distrdf_check_friend_trees_alignment_dask_tree_5.root', 'distrdf_check_friend_trees_alignment_dask_tree_6.root']. ```. 3. Locally this test fails for me on `s1val = s1.GetValue()`. From pdb I get this stack strace:. ```py. ... > rdf_node = rdf_operation(*in_task_op.args, **in_task_op.kwargs). E cppyy.ll.SegmentationViolation",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:287,reliability,doe,does,287,"> The errors seen in the CI such as. > . > ```. > Error in <TFile::TFile>: file /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/roottest/python/distrdf/dask/distrdf_check_friend_trees_alignment_dask_file_1.root/distrdf_check_friend_trees_alignment_dask_tree_1.root does not exist. > ```. > . > Show that something is wrong with the file names. Notice the double file name above. Probably in the creation of the spec passed to the task-local RDF something is wrong. Hmm that is very strange. I grepped for `distrdf_check_friend_trees_alignment_dask_tree`. It is present only in `python/distrdf/dask/check_friend_trees_alignment.py`. I see that there the chain is created like:. ```py. def create_chain():. main = ROOT.TChain(). for i in range(3):. main.Add(f""{FILENAMES[i]}?#{TREENAMES[i]}""). friend = ROOT.TChain(). for i in range(3, 6):. friend.Add(f""{FILENAMES[i]}?#{TREENAMES[i]}""). main.AddFriend(friend, ""friend""). # import pdb; pdb.set_trace() --> a breakpoint I added. return main. ```. Then calling `df = Dask.RDataFrame(chain, daskclient=connection, npartitions=nparts)`. 1. Is it intentional not to use a spec instead? 2. From the breakpoint I printed the contents of file and tree names and they looked all file:. ```py. (Pdb) p FILENAMES. ['distrdf_check_friend_trees_alignment_dask_file_1.root', 'distrdf_check_friend_trees_alignment_dask_file_2.root', 'distrdf_check_friend_trees_alignment_dask_file_3.root', 'distrdf_check_friend_trees_alignment_dask_file_4.root', 'distrdf_check_friend_trees_alignment_dask_file_5.root', 'distrdf_check_friend_trees_alignment_dask_file_6.root']. (Pdb) p TREENAMES. ['distrdf_check_friend_trees_alignment_dask_tree_1.root', 'distrdf_check_friend_trees_alignment_dask_tree_2.root', 'distrdf_check_friend_trees_alignment_dask_tree_3.root', 'distrdf_check_friend_trees_alignment_dask_tree_4.root', 'distrdf_check_friend_trees_alignment_dask_tree_5.root', 'distrdf_check_friend_trees_alignment_dask_tree_6.root']. ```. 3. Locally this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:2006,reliability,fail,fails,2006,"turn main. ```. Then calling `df = Dask.RDataFrame(chain, daskclient=connection, npartitions=nparts)`. 1. Is it intentional not to use a spec instead? 2. From the breakpoint I printed the contents of file and tree names and they looked all file:. ```py. (Pdb) p FILENAMES. ['distrdf_check_friend_trees_alignment_dask_file_1.root', 'distrdf_check_friend_trees_alignment_dask_file_2.root', 'distrdf_check_friend_trees_alignment_dask_file_3.root', 'distrdf_check_friend_trees_alignment_dask_file_4.root', 'distrdf_check_friend_trees_alignment_dask_file_5.root', 'distrdf_check_friend_trees_alignment_dask_file_6.root']. (Pdb) p TREENAMES. ['distrdf_check_friend_trees_alignment_dask_tree_1.root', 'distrdf_check_friend_trees_alignment_dask_tree_2.root', 'distrdf_check_friend_trees_alignment_dask_tree_3.root', 'distrdf_check_friend_trees_alignment_dask_tree_4.root', 'distrdf_check_friend_trees_alignment_dask_tree_5.root', 'distrdf_check_friend_trees_alignment_dask_tree_6.root']. ```. 3. Locally this test fails for me on `s1val = s1.GetValue()`. From pdb I get this stack strace:. ```py. ... > rdf_node = rdf_operation(*in_task_op.args, **in_task_op.kwargs). E cppyy.ll.SegmentationViolation: Template method resolution failed:. E ROOT::RDF::RResultPtr<double> ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void>::Sum(basic_string_view<char,char_traits<char> > columnName = """", double& initValue = RDFDetail::SumReturnType_t<RInferredType>{}) =>. E SegmentationViolation: segfault in C++; program state was reset. E ROOT::RDF::RResultPtr<double> ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void>::Sum(basic_string_view<char,char_traits<char> > columnName = """", double& initValue = RDFDetail::SumReturnType_t<RInferredType>{}) =>. E SegmentationViolation: segfault in C++; program state was reset. ../../../../rb/lib/DistRDF/ComputationGraphGenerator.py:134: SegmentationViolation. ```. This is also what jenkins complains about. I don't clearly see what is wrong. Investigating ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:2221,reliability,fail,failed,2221,"turn main. ```. Then calling `df = Dask.RDataFrame(chain, daskclient=connection, npartitions=nparts)`. 1. Is it intentional not to use a spec instead? 2. From the breakpoint I printed the contents of file and tree names and they looked all file:. ```py. (Pdb) p FILENAMES. ['distrdf_check_friend_trees_alignment_dask_file_1.root', 'distrdf_check_friend_trees_alignment_dask_file_2.root', 'distrdf_check_friend_trees_alignment_dask_file_3.root', 'distrdf_check_friend_trees_alignment_dask_file_4.root', 'distrdf_check_friend_trees_alignment_dask_file_5.root', 'distrdf_check_friend_trees_alignment_dask_file_6.root']. (Pdb) p TREENAMES. ['distrdf_check_friend_trees_alignment_dask_tree_1.root', 'distrdf_check_friend_trees_alignment_dask_tree_2.root', 'distrdf_check_friend_trees_alignment_dask_tree_3.root', 'distrdf_check_friend_trees_alignment_dask_tree_4.root', 'distrdf_check_friend_trees_alignment_dask_tree_5.root', 'distrdf_check_friend_trees_alignment_dask_tree_6.root']. ```. 3. Locally this test fails for me on `s1val = s1.GetValue()`. From pdb I get this stack strace:. ```py. ... > rdf_node = rdf_operation(*in_task_op.args, **in_task_op.kwargs). E cppyy.ll.SegmentationViolation: Template method resolution failed:. E ROOT::RDF::RResultPtr<double> ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void>::Sum(basic_string_view<char,char_traits<char> > columnName = """", double& initValue = RDFDetail::SumReturnType_t<RInferredType>{}) =>. E SegmentationViolation: segfault in C++; program state was reset. E ROOT::RDF::RResultPtr<double> ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void>::Sum(basic_string_view<char,char_traits<char> > columnName = """", double& initValue = RDFDetail::SumReturnType_t<RInferredType>{}) =>. E SegmentationViolation: segfault in C++; program state was reset. ../../../../rb/lib/DistRDF/ComputationGraphGenerator.py:134: SegmentationViolation. ```. This is also what jenkins complains about. I don't clearly see what is wrong. Investigating ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:6,safety,error,errors,6,"> The errors seen in the CI such as. > . > ```. > Error in <TFile::TFile>: file /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/roottest/python/distrdf/dask/distrdf_check_friend_trees_alignment_dask_file_1.root/distrdf_check_friend_trees_alignment_dask_tree_1.root does not exist. > ```. > . > Show that something is wrong with the file names. Notice the double file name above. Probably in the creation of the spec passed to the task-local RDF something is wrong. Hmm that is very strange. I grepped for `distrdf_check_friend_trees_alignment_dask_tree`. It is present only in `python/distrdf/dask/check_friend_trees_alignment.py`. I see that there the chain is created like:. ```py. def create_chain():. main = ROOT.TChain(). for i in range(3):. main.Add(f""{FILENAMES[i]}?#{TREENAMES[i]}""). friend = ROOT.TChain(). for i in range(3, 6):. friend.Add(f""{FILENAMES[i]}?#{TREENAMES[i]}""). main.AddFriend(friend, ""friend""). # import pdb; pdb.set_trace() --> a breakpoint I added. return main. ```. Then calling `df = Dask.RDataFrame(chain, daskclient=connection, npartitions=nparts)`. 1. Is it intentional not to use a spec instead? 2. From the breakpoint I printed the contents of file and tree names and they looked all file:. ```py. (Pdb) p FILENAMES. ['distrdf_check_friend_trees_alignment_dask_file_1.root', 'distrdf_check_friend_trees_alignment_dask_file_2.root', 'distrdf_check_friend_trees_alignment_dask_file_3.root', 'distrdf_check_friend_trees_alignment_dask_file_4.root', 'distrdf_check_friend_trees_alignment_dask_file_5.root', 'distrdf_check_friend_trees_alignment_dask_file_6.root']. (Pdb) p TREENAMES. ['distrdf_check_friend_trees_alignment_dask_tree_1.root', 'distrdf_check_friend_trees_alignment_dask_tree_2.root', 'distrdf_check_friend_trees_alignment_dask_tree_3.root', 'distrdf_check_friend_trees_alignment_dask_tree_4.root', 'distrdf_check_friend_trees_alignment_dask_tree_5.root', 'distrdf_check_friend_trees_alignment_dask_tree_6.root']. ```. 3. Locally this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:50,safety,Error,Error,50,"> The errors seen in the CI such as. > . > ```. > Error in <TFile::TFile>: file /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/roottest/python/distrdf/dask/distrdf_check_friend_trees_alignment_dask_file_1.root/distrdf_check_friend_trees_alignment_dask_tree_1.root does not exist. > ```. > . > Show that something is wrong with the file names. Notice the double file name above. Probably in the creation of the spec passed to the task-local RDF something is wrong. Hmm that is very strange. I grepped for `distrdf_check_friend_trees_alignment_dask_tree`. It is present only in `python/distrdf/dask/check_friend_trees_alignment.py`. I see that there the chain is created like:. ```py. def create_chain():. main = ROOT.TChain(). for i in range(3):. main.Add(f""{FILENAMES[i]}?#{TREENAMES[i]}""). friend = ROOT.TChain(). for i in range(3, 6):. friend.Add(f""{FILENAMES[i]}?#{TREENAMES[i]}""). main.AddFriend(friend, ""friend""). # import pdb; pdb.set_trace() --> a breakpoint I added. return main. ```. Then calling `df = Dask.RDataFrame(chain, daskclient=connection, npartitions=nparts)`. 1. Is it intentional not to use a spec instead? 2. From the breakpoint I printed the contents of file and tree names and they looked all file:. ```py. (Pdb) p FILENAMES. ['distrdf_check_friend_trees_alignment_dask_file_1.root', 'distrdf_check_friend_trees_alignment_dask_file_2.root', 'distrdf_check_friend_trees_alignment_dask_file_3.root', 'distrdf_check_friend_trees_alignment_dask_file_4.root', 'distrdf_check_friend_trees_alignment_dask_file_5.root', 'distrdf_check_friend_trees_alignment_dask_file_6.root']. (Pdb) p TREENAMES. ['distrdf_check_friend_trees_alignment_dask_tree_1.root', 'distrdf_check_friend_trees_alignment_dask_tree_2.root', 'distrdf_check_friend_trees_alignment_dask_tree_3.root', 'distrdf_check_friend_trees_alignment_dask_tree_4.root', 'distrdf_check_friend_trees_alignment_dask_tree_5.root', 'distrdf_check_friend_trees_alignment_dask_tree_6.root']. ```. 3. Locally this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:2001,safety,test,test,2001,"turn main. ```. Then calling `df = Dask.RDataFrame(chain, daskclient=connection, npartitions=nparts)`. 1. Is it intentional not to use a spec instead? 2. From the breakpoint I printed the contents of file and tree names and they looked all file:. ```py. (Pdb) p FILENAMES. ['distrdf_check_friend_trees_alignment_dask_file_1.root', 'distrdf_check_friend_trees_alignment_dask_file_2.root', 'distrdf_check_friend_trees_alignment_dask_file_3.root', 'distrdf_check_friend_trees_alignment_dask_file_4.root', 'distrdf_check_friend_trees_alignment_dask_file_5.root', 'distrdf_check_friend_trees_alignment_dask_file_6.root']. (Pdb) p TREENAMES. ['distrdf_check_friend_trees_alignment_dask_tree_1.root', 'distrdf_check_friend_trees_alignment_dask_tree_2.root', 'distrdf_check_friend_trees_alignment_dask_tree_3.root', 'distrdf_check_friend_trees_alignment_dask_tree_4.root', 'distrdf_check_friend_trees_alignment_dask_tree_5.root', 'distrdf_check_friend_trees_alignment_dask_tree_6.root']. ```. 3. Locally this test fails for me on `s1val = s1.GetValue()`. From pdb I get this stack strace:. ```py. ... > rdf_node = rdf_operation(*in_task_op.args, **in_task_op.kwargs). E cppyy.ll.SegmentationViolation: Template method resolution failed:. E ROOT::RDF::RResultPtr<double> ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void>::Sum(basic_string_view<char,char_traits<char> > columnName = """", double& initValue = RDFDetail::SumReturnType_t<RInferredType>{}) =>. E SegmentationViolation: segfault in C++; program state was reset. E ROOT::RDF::RResultPtr<double> ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void>::Sum(basic_string_view<char,char_traits<char> > columnName = """", double& initValue = RDFDetail::SumReturnType_t<RInferredType>{}) =>. E SegmentationViolation: segfault in C++; program state was reset. ../../../../rb/lib/DistRDF/ComputationGraphGenerator.py:134: SegmentationViolation. ```. This is also what jenkins complains about. I don't clearly see what is wrong. Investigating ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:2931,safety,compl,complains,2931,"turn main. ```. Then calling `df = Dask.RDataFrame(chain, daskclient=connection, npartitions=nparts)`. 1. Is it intentional not to use a spec instead? 2. From the breakpoint I printed the contents of file and tree names and they looked all file:. ```py. (Pdb) p FILENAMES. ['distrdf_check_friend_trees_alignment_dask_file_1.root', 'distrdf_check_friend_trees_alignment_dask_file_2.root', 'distrdf_check_friend_trees_alignment_dask_file_3.root', 'distrdf_check_friend_trees_alignment_dask_file_4.root', 'distrdf_check_friend_trees_alignment_dask_file_5.root', 'distrdf_check_friend_trees_alignment_dask_file_6.root']. (Pdb) p TREENAMES. ['distrdf_check_friend_trees_alignment_dask_tree_1.root', 'distrdf_check_friend_trees_alignment_dask_tree_2.root', 'distrdf_check_friend_trees_alignment_dask_tree_3.root', 'distrdf_check_friend_trees_alignment_dask_tree_4.root', 'distrdf_check_friend_trees_alignment_dask_tree_5.root', 'distrdf_check_friend_trees_alignment_dask_tree_6.root']. ```. 3. Locally this test fails for me on `s1val = s1.GetValue()`. From pdb I get this stack strace:. ```py. ... > rdf_node = rdf_operation(*in_task_op.args, **in_task_op.kwargs). E cppyy.ll.SegmentationViolation: Template method resolution failed:. E ROOT::RDF::RResultPtr<double> ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void>::Sum(basic_string_view<char,char_traits<char> > columnName = """", double& initValue = RDFDetail::SumReturnType_t<RInferredType>{}) =>. E SegmentationViolation: segfault in C++; program state was reset. E ROOT::RDF::RResultPtr<double> ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void>::Sum(basic_string_view<char,char_traits<char> > columnName = """", double& initValue = RDFDetail::SumReturnType_t<RInferredType>{}) =>. E SegmentationViolation: segfault in C++; program state was reset. ../../../../rb/lib/DistRDF/ComputationGraphGenerator.py:134: SegmentationViolation. ```. This is also what jenkins complains about. I don't clearly see what is wrong. Investigating ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:2931,security,compl,complains,2931,"turn main. ```. Then calling `df = Dask.RDataFrame(chain, daskclient=connection, npartitions=nparts)`. 1. Is it intentional not to use a spec instead? 2. From the breakpoint I printed the contents of file and tree names and they looked all file:. ```py. (Pdb) p FILENAMES. ['distrdf_check_friend_trees_alignment_dask_file_1.root', 'distrdf_check_friend_trees_alignment_dask_file_2.root', 'distrdf_check_friend_trees_alignment_dask_file_3.root', 'distrdf_check_friend_trees_alignment_dask_file_4.root', 'distrdf_check_friend_trees_alignment_dask_file_5.root', 'distrdf_check_friend_trees_alignment_dask_file_6.root']. (Pdb) p TREENAMES. ['distrdf_check_friend_trees_alignment_dask_tree_1.root', 'distrdf_check_friend_trees_alignment_dask_tree_2.root', 'distrdf_check_friend_trees_alignment_dask_tree_3.root', 'distrdf_check_friend_trees_alignment_dask_tree_4.root', 'distrdf_check_friend_trees_alignment_dask_tree_5.root', 'distrdf_check_friend_trees_alignment_dask_tree_6.root']. ```. 3. Locally this test fails for me on `s1val = s1.GetValue()`. From pdb I get this stack strace:. ```py. ... > rdf_node = rdf_operation(*in_task_op.args, **in_task_op.kwargs). E cppyy.ll.SegmentationViolation: Template method resolution failed:. E ROOT::RDF::RResultPtr<double> ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void>::Sum(basic_string_view<char,char_traits<char> > columnName = """", double& initValue = RDFDetail::SumReturnType_t<RInferredType>{}) =>. E SegmentationViolation: segfault in C++; program state was reset. E ROOT::RDF::RResultPtr<double> ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void>::Sum(basic_string_view<char,char_traits<char> > columnName = """", double& initValue = RDFDetail::SumReturnType_t<RInferredType>{}) =>. E SegmentationViolation: segfault in C++; program state was reset. ../../../../rb/lib/DistRDF/ComputationGraphGenerator.py:134: SegmentationViolation. ```. This is also what jenkins complains about. I don't clearly see what is wrong. Investigating ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:2001,testability,test,test,2001,"turn main. ```. Then calling `df = Dask.RDataFrame(chain, daskclient=connection, npartitions=nparts)`. 1. Is it intentional not to use a spec instead? 2. From the breakpoint I printed the contents of file and tree names and they looked all file:. ```py. (Pdb) p FILENAMES. ['distrdf_check_friend_trees_alignment_dask_file_1.root', 'distrdf_check_friend_trees_alignment_dask_file_2.root', 'distrdf_check_friend_trees_alignment_dask_file_3.root', 'distrdf_check_friend_trees_alignment_dask_file_4.root', 'distrdf_check_friend_trees_alignment_dask_file_5.root', 'distrdf_check_friend_trees_alignment_dask_file_6.root']. (Pdb) p TREENAMES. ['distrdf_check_friend_trees_alignment_dask_tree_1.root', 'distrdf_check_friend_trees_alignment_dask_tree_2.root', 'distrdf_check_friend_trees_alignment_dask_tree_3.root', 'distrdf_check_friend_trees_alignment_dask_tree_4.root', 'distrdf_check_friend_trees_alignment_dask_tree_5.root', 'distrdf_check_friend_trees_alignment_dask_tree_6.root']. ```. 3. Locally this test fails for me on `s1val = s1.GetValue()`. From pdb I get this stack strace:. ```py. ... > rdf_node = rdf_operation(*in_task_op.args, **in_task_op.kwargs). E cppyy.ll.SegmentationViolation: Template method resolution failed:. E ROOT::RDF::RResultPtr<double> ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void>::Sum(basic_string_view<char,char_traits<char> > columnName = """", double& initValue = RDFDetail::SumReturnType_t<RInferredType>{}) =>. E SegmentationViolation: segfault in C++; program state was reset. E ROOT::RDF::RResultPtr<double> ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void>::Sum(basic_string_view<char,char_traits<char> > columnName = """", double& initValue = RDFDetail::SumReturnType_t<RInferredType>{}) =>. E SegmentationViolation: segfault in C++; program state was reset. ../../../../rb/lib/DistRDF/ComputationGraphGenerator.py:134: SegmentationViolation. ```. This is also what jenkins complains about. I don't clearly see what is wrong. Investigating ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:6,usability,error,errors,6,"> The errors seen in the CI such as. > . > ```. > Error in <TFile::TFile>: file /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/roottest/python/distrdf/dask/distrdf_check_friend_trees_alignment_dask_file_1.root/distrdf_check_friend_trees_alignment_dask_tree_1.root does not exist. > ```. > . > Show that something is wrong with the file names. Notice the double file name above. Probably in the creation of the spec passed to the task-local RDF something is wrong. Hmm that is very strange. I grepped for `distrdf_check_friend_trees_alignment_dask_tree`. It is present only in `python/distrdf/dask/check_friend_trees_alignment.py`. I see that there the chain is created like:. ```py. def create_chain():. main = ROOT.TChain(). for i in range(3):. main.Add(f""{FILENAMES[i]}?#{TREENAMES[i]}""). friend = ROOT.TChain(). for i in range(3, 6):. friend.Add(f""{FILENAMES[i]}?#{TREENAMES[i]}""). main.AddFriend(friend, ""friend""). # import pdb; pdb.set_trace() --> a breakpoint I added. return main. ```. Then calling `df = Dask.RDataFrame(chain, daskclient=connection, npartitions=nparts)`. 1. Is it intentional not to use a spec instead? 2. From the breakpoint I printed the contents of file and tree names and they looked all file:. ```py. (Pdb) p FILENAMES. ['distrdf_check_friend_trees_alignment_dask_file_1.root', 'distrdf_check_friend_trees_alignment_dask_file_2.root', 'distrdf_check_friend_trees_alignment_dask_file_3.root', 'distrdf_check_friend_trees_alignment_dask_file_4.root', 'distrdf_check_friend_trees_alignment_dask_file_5.root', 'distrdf_check_friend_trees_alignment_dask_file_6.root']. (Pdb) p TREENAMES. ['distrdf_check_friend_trees_alignment_dask_tree_1.root', 'distrdf_check_friend_trees_alignment_dask_tree_2.root', 'distrdf_check_friend_trees_alignment_dask_tree_3.root', 'distrdf_check_friend_trees_alignment_dask_tree_4.root', 'distrdf_check_friend_trees_alignment_dask_tree_5.root', 'distrdf_check_friend_trees_alignment_dask_tree_6.root']. ```. 3. Locally this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:50,usability,Error,Error,50,"> The errors seen in the CI such as. > . > ```. > Error in <TFile::TFile>: file /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/roottest/python/distrdf/dask/distrdf_check_friend_trees_alignment_dask_file_1.root/distrdf_check_friend_trees_alignment_dask_tree_1.root does not exist. > ```. > . > Show that something is wrong with the file names. Notice the double file name above. Probably in the creation of the spec passed to the task-local RDF something is wrong. Hmm that is very strange. I grepped for `distrdf_check_friend_trees_alignment_dask_tree`. It is present only in `python/distrdf/dask/check_friend_trees_alignment.py`. I see that there the chain is created like:. ```py. def create_chain():. main = ROOT.TChain(). for i in range(3):. main.Add(f""{FILENAMES[i]}?#{TREENAMES[i]}""). friend = ROOT.TChain(). for i in range(3, 6):. friend.Add(f""{FILENAMES[i]}?#{TREENAMES[i]}""). main.AddFriend(friend, ""friend""). # import pdb; pdb.set_trace() --> a breakpoint I added. return main. ```. Then calling `df = Dask.RDataFrame(chain, daskclient=connection, npartitions=nparts)`. 1. Is it intentional not to use a spec instead? 2. From the breakpoint I printed the contents of file and tree names and they looked all file:. ```py. (Pdb) p FILENAMES. ['distrdf_check_friend_trees_alignment_dask_file_1.root', 'distrdf_check_friend_trees_alignment_dask_file_2.root', 'distrdf_check_friend_trees_alignment_dask_file_3.root', 'distrdf_check_friend_trees_alignment_dask_file_4.root', 'distrdf_check_friend_trees_alignment_dask_file_5.root', 'distrdf_check_friend_trees_alignment_dask_file_6.root']. (Pdb) p TREENAMES. ['distrdf_check_friend_trees_alignment_dask_tree_1.root', 'distrdf_check_friend_trees_alignment_dask_tree_2.root', 'distrdf_check_friend_trees_alignment_dask_tree_3.root', 'distrdf_check_friend_trees_alignment_dask_tree_4.root', 'distrdf_check_friend_trees_alignment_dask_tree_5.root', 'distrdf_check_friend_trees_alignment_dask_tree_6.root']. ```. 3. Locally this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:81,usability,User,Users,81,"> The errors seen in the CI such as. > . > ```. > Error in <TFile::TFile>: file /Users/sftnight/build/jenkins/workspace/root-pullrequests-build/build/roottest/python/distrdf/dask/distrdf_check_friend_trees_alignment_dask_file_1.root/distrdf_check_friend_trees_alignment_dask_tree_1.root does not exist. > ```. > . > Show that something is wrong with the file names. Notice the double file name above. Probably in the creation of the spec passed to the task-local RDF something is wrong. Hmm that is very strange. I grepped for `distrdf_check_friend_trees_alignment_dask_tree`. It is present only in `python/distrdf/dask/check_friend_trees_alignment.py`. I see that there the chain is created like:. ```py. def create_chain():. main = ROOT.TChain(). for i in range(3):. main.Add(f""{FILENAMES[i]}?#{TREENAMES[i]}""). friend = ROOT.TChain(). for i in range(3, 6):. friend.Add(f""{FILENAMES[i]}?#{TREENAMES[i]}""). main.AddFriend(friend, ""friend""). # import pdb; pdb.set_trace() --> a breakpoint I added. return main. ```. Then calling `df = Dask.RDataFrame(chain, daskclient=connection, npartitions=nparts)`. 1. Is it intentional not to use a spec instead? 2. From the breakpoint I printed the contents of file and tree names and they looked all file:. ```py. (Pdb) p FILENAMES. ['distrdf_check_friend_trees_alignment_dask_file_1.root', 'distrdf_check_friend_trees_alignment_dask_file_2.root', 'distrdf_check_friend_trees_alignment_dask_file_3.root', 'distrdf_check_friend_trees_alignment_dask_file_4.root', 'distrdf_check_friend_trees_alignment_dask_file_5.root', 'distrdf_check_friend_trees_alignment_dask_file_6.root']. (Pdb) p TREENAMES. ['distrdf_check_friend_trees_alignment_dask_tree_1.root', 'distrdf_check_friend_trees_alignment_dask_tree_2.root', 'distrdf_check_friend_trees_alignment_dask_tree_3.root', 'distrdf_check_friend_trees_alignment_dask_tree_4.root', 'distrdf_check_friend_trees_alignment_dask_tree_5.root', 'distrdf_check_friend_trees_alignment_dask_tree_6.root']. ```. 3. Locally this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:2956,usability,clear,clearly,2956,"turn main. ```. Then calling `df = Dask.RDataFrame(chain, daskclient=connection, npartitions=nparts)`. 1. Is it intentional not to use a spec instead? 2. From the breakpoint I printed the contents of file and tree names and they looked all file:. ```py. (Pdb) p FILENAMES. ['distrdf_check_friend_trees_alignment_dask_file_1.root', 'distrdf_check_friend_trees_alignment_dask_file_2.root', 'distrdf_check_friend_trees_alignment_dask_file_3.root', 'distrdf_check_friend_trees_alignment_dask_file_4.root', 'distrdf_check_friend_trees_alignment_dask_file_5.root', 'distrdf_check_friend_trees_alignment_dask_file_6.root']. (Pdb) p TREENAMES. ['distrdf_check_friend_trees_alignment_dask_tree_1.root', 'distrdf_check_friend_trees_alignment_dask_tree_2.root', 'distrdf_check_friend_trees_alignment_dask_tree_3.root', 'distrdf_check_friend_trees_alignment_dask_tree_4.root', 'distrdf_check_friend_trees_alignment_dask_tree_5.root', 'distrdf_check_friend_trees_alignment_dask_tree_6.root']. ```. 3. Locally this test fails for me on `s1val = s1.GetValue()`. From pdb I get this stack strace:. ```py. ... > rdf_node = rdf_operation(*in_task_op.args, **in_task_op.kwargs). E cppyy.ll.SegmentationViolation: Template method resolution failed:. E ROOT::RDF::RResultPtr<double> ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void>::Sum(basic_string_view<char,char_traits<char> > columnName = """", double& initValue = RDFDetail::SumReturnType_t<RInferredType>{}) =>. E SegmentationViolation: segfault in C++; program state was reset. E ROOT::RDF::RResultPtr<double> ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void>::Sum(basic_string_view<char,char_traits<char> > columnName = """", double& initValue = RDFDetail::SumReturnType_t<RInferredType>{}) =>. E SegmentationViolation: segfault in C++; program state was reset. ../../../../rb/lib/DistRDF/ComputationGraphGenerator.py:134: SegmentationViolation. ```. This is also what jenkins complains about. I don't clearly see what is wrong. Investigating ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:511,reliability,doe,does,511,"What I'm saying is that probably the wrong metadata is passed to the RDataFrame in the `_generate_rdf_creator` function. Maybe here (it's just a hunch, I didn't make a thorough check):. ```python. ds = ROOT.RDF.Experimental.RSpecBuilder(). # add a group with no name to represent the whole dataset. ds.AddGroup(("""", clustered_range.treenames, clustered_range.filenames)). ds.WithRange((clustered_range.globalstart, clustered_range.globalend)). ```. The way the dataset is created in the test (i.e. by the user) does not interfere at all",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:487,safety,test,test,487,"What I'm saying is that probably the wrong metadata is passed to the RDataFrame in the `_generate_rdf_creator` function. Maybe here (it's just a hunch, I didn't make a thorough check):. ```python. ds = ROOT.RDF.Experimental.RSpecBuilder(). # add a group with no name to represent the whole dataset. ds.AddGroup(("""", clustered_range.treenames, clustered_range.filenames)). ds.WithRange((clustered_range.globalstart, clustered_range.globalend)). ```. The way the dataset is created in the test (i.e. by the user) does not interfere at all",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:487,testability,test,test,487,"What I'm saying is that probably the wrong metadata is passed to the RDataFrame in the `_generate_rdf_creator` function. Maybe here (it's just a hunch, I didn't make a thorough check):. ```python. ds = ROOT.RDF.Experimental.RSpecBuilder(). # add a group with no name to represent the whole dataset. ds.AddGroup(("""", clustered_range.treenames, clustered_range.filenames)). ds.WithRange((clustered_range.globalstart, clustered_range.globalend)). ```. The way the dataset is created in the test (i.e. by the user) does not interfere at all",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:505,usability,user,user,505,"What I'm saying is that probably the wrong metadata is passed to the RDataFrame in the `_generate_rdf_creator` function. Maybe here (it's just a hunch, I didn't make a thorough check):. ```python. ds = ROOT.RDF.Experimental.RSpecBuilder(). # add a group with no name to represent the whole dataset. ds.AddGroup(("""", clustered_range.treenames, clustered_range.filenames)). ds.WithRange((clustered_range.globalstart, clustered_range.globalend)). ```. The way the dataset is created in the test (i.e. by the user) does not interfere at all",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11526:11,deployability,build,build,11,@phsft-bot build just on windows10/cxx14,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11526
https://github.com/root-project/root/pull/11529:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2004/default, ROOT-ubuntu2204/default, ROOT-ubuntu18.04/default with flags -Dtmva-sofie=On",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11529
https://github.com/root-project/root/pull/11530:114,availability,error,error,114,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:247,availability,state,state,247,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:542,availability,error,error,542,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:615,availability,Error,Error,615,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:15,deployability,instal,install,15,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:90,deployability,instal,installed,90,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:150,deployability,instal,install,150,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:205,deployability,Build,Building,205,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:214,deployability,depend,dependency,214,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:492,deployability,build,build,492,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:703,deployability,build,build-Release,703,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:746,deployability,fail,failed,746,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:864,deployability,build,build,864,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:872,deployability,log,log,872,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:214,integrability,depend,dependency,214,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:247,integrability,state,state,247,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:514,integrability,configur,configuring,514,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:727,integrability,messag,message,727,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:727,interoperability,messag,message,727,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:64,modifiability,pac,packages,64,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:182,modifiability,pac,package,182,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:214,modifiability,depend,dependency,214,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:294,modifiability,pac,package,294,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:339,modifiability,pac,package,339,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:394,modifiability,pac,package,394,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:514,modifiability,configur,configuring,514,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:114,performance,error,error,114,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:542,performance,error,error,542,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:615,performance,Error,Error,615,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:746,reliability,fail,failed,746,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:114,safety,error,error,114,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:214,safety,depend,dependency,214,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:542,safety,error,error,542,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:615,safety,Error,Error,615,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:872,safety,log,log,872,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:142,security,apt,apt-get,142,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:514,security,configur,configuring,514,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:872,security,log,log,872,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:214,testability,depend,dependency,214,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:872,testability,log,log,872,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:114,usability,error,error,114,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:542,usability,error,error,542,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:600,usability,stop,stops,600,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:615,usability,Error,Error,615,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:738,usability,Command,Command,738,"I am trying to install root-v6.26.00 in ubuntu 22. The required packages are unable to be installed. I receive an error:. saras@saras:~$ sudo apt-get install libglew1.5-dev. Reading package lists... Done. Building dependency tree... Done. Reading state information... Done. E: Unable to locate package libglew1.5-dev. E: Couldn't find any package by glob 'libglew1.5-dev'. E: Couldn't find any package by regex 'libglew1.5-dev'. Another problem that I am getting is that, when I run ""cmake --build . -- -j8"" after configuring root, following error ocurrs in the middle of the process and the process stops. . CMake Error at /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-Release.cmake:49 (message):. Command failed: 2. '/usr/bin/gmake'. See also. /home/saras/product/root/builtins/xrootd/XROOTD-prefix/src/XROOTD-stamp/XROOTD-build-*.log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:111,deployability,instal,install,111,@saraswati-pandey this has nothing to do with this PR. Please post at https://root-forum.cern.ch (Hint: try to install ROOT through snap!),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11530:98,usability,Hint,Hint,98,@saraswati-pandey this has nothing to do with this PR. Please post at https://root-forum.cern.ch (Hint: try to install ROOT through snap!),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11530
https://github.com/root-project/root/pull/11531:294,energy efficiency,model,model,294,"Hi, thanks for the review! Yes, sure, that would have also been an option and I was thinking about that when originally implementing `RooDataSet.from_numpy()` last year. The reason why I didn't go for it because then the dataset range is not synchronized anymore with the variable range of the model, which brings you back to the clipping problem: when the NLL iterates over the dataset to evaluate the PDF, the data values will be clipped inside the variable range.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11531
https://github.com/root-project/root/pull/11531:272,modifiability,variab,variable,272,"Hi, thanks for the review! Yes, sure, that would have also been an option and I was thinking about that when originally implementing `RooDataSet.from_numpy()` last year. The reason why I didn't go for it because then the dataset range is not synchronized anymore with the variable range of the model, which brings you back to the clipping problem: when the NLL iterates over the dataset to evaluate the PDF, the data values will be clipped inside the variable range.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11531
https://github.com/root-project/root/pull/11531:451,modifiability,variab,variable,451,"Hi, thanks for the review! Yes, sure, that would have also been an option and I was thinking about that when originally implementing `RooDataSet.from_numpy()` last year. The reason why I didn't go for it because then the dataset range is not synchronized anymore with the variable range of the model, which brings you back to the clipping problem: when the NLL iterates over the dataset to evaluate the PDF, the data values will be clipped inside the variable range.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11531
https://github.com/root-project/root/pull/11531:242,performance,synch,synchronized,242,"Hi, thanks for the review! Yes, sure, that would have also been an option and I was thinking about that when originally implementing `RooDataSet.from_numpy()` last year. The reason why I didn't go for it because then the dataset range is not synchronized anymore with the variable range of the model, which brings you back to the clipping problem: when the NLL iterates over the dataset to evaluate the PDF, the data values will be clipped inside the variable range.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11531
https://github.com/root-project/root/pull/11531:19,safety,review,review,19,"Hi, thanks for the review! Yes, sure, that would have also been an option and I was thinking about that when originally implementing `RooDataSet.from_numpy()` last year. The reason why I didn't go for it because then the dataset range is not synchronized anymore with the variable range of the model, which brings you back to the clipping problem: when the NLL iterates over the dataset to evaluate the PDF, the data values will be clipped inside the variable range.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11531
https://github.com/root-project/root/pull/11531:294,security,model,model,294,"Hi, thanks for the review! Yes, sure, that would have also been an option and I was thinking about that when originally implementing `RooDataSet.from_numpy()` last year. The reason why I didn't go for it because then the dataset range is not synchronized anymore with the variable range of the model, which brings you back to the clipping problem: when the NLL iterates over the dataset to evaluate the PDF, the data values will be clipped inside the variable range.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11531
https://github.com/root-project/root/pull/11531:19,testability,review,review,19,"Hi, thanks for the review! Yes, sure, that would have also been an option and I was thinking about that when originally implementing `RooDataSet.from_numpy()` last year. The reason why I didn't go for it because then the dataset range is not synchronized anymore with the variable range of the model, which brings you back to the clipping problem: when the NLL iterates over the dataset to evaluate the PDF, the data values will be clipped inside the variable range.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11531
https://github.com/root-project/root/issues/11533:72,deployability,version,version,72,"BTW, if it's a blocker for you, you can replace `fprintf` by a more C++ version. For example:. ```. std::ofstream fid(""testfile.txt"");. fid << ""text\n"";. fid << 1 << ""\n"";. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11533
https://github.com/root-project/root/issues/11533:72,integrability,version,version,72,"BTW, if it's a blocker for you, you can replace `fprintf` by a more C++ version. For example:. ```. std::ofstream fid(""testfile.txt"");. fid << ""text\n"";. fid << 1 << ""\n"";. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11533
https://github.com/root-project/root/issues/11533:72,modifiability,version,version,72,"BTW, if it's a blocker for you, you can replace `fprintf` by a more C++ version. For example:. ```. std::ofstream fid(""testfile.txt"");. fid << ""text\n"";. fid << 1 << ""\n"";. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11533
https://github.com/root-project/root/issues/11533:119,safety,test,testfile,119,"BTW, if it's a blocker for you, you can replace `fprintf` by a more C++ version. For example:. ```. std::ofstream fid(""testfile.txt"");. fid << ""text\n"";. fid << 1 << ""\n"";. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11533
https://github.com/root-project/root/issues/11533:119,testability,test,testfile,119,"BTW, if it's a blocker for you, you can replace `fprintf` by a more C++ version. For example:. ```. std::ofstream fid(""testfile.txt"");. fid << ""text\n"";. fid << 1 << ""\n"";. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11533
https://github.com/root-project/root/issues/11534:23,energy efficiency,current,currently,23,Cosing since there are currently no open problems or PRs to be backported anymore.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11534
https://github.com/root-project/root/pull/11535:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11535
https://github.com/root-project/root/pull/11535:89,deployability,patch,patch,89,"@will-cern, @bellenot, I don't know how controversial this change is, but given that the patch release will be prepared tomorrow we should act quickly if we want to backport this!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11535
https://github.com/root-project/root/pull/11535:95,deployability,releas,release,95,"@will-cern, @bellenot, I don't know how controversial this change is, but given that the patch release will be prepared tomorrow we should act quickly if we want to backport this!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11535
https://github.com/root-project/root/pull/11535:89,safety,patch,patch,89,"@will-cern, @bellenot, I don't know how controversial this change is, but given that the patch release will be prepared tomorrow we should act quickly if we want to backport this!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11535
https://github.com/root-project/root/pull/11535:89,security,patch,patch,89,"@will-cern, @bellenot, I don't know how controversial this change is, but given that the patch release will be prepared tomorrow we should act quickly if we want to backport this!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11535
https://github.com/root-project/root/pull/11535:15,safety,test,test,15,"Well, I cannot test it on MacOS...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11535
https://github.com/root-project/root/pull/11535:15,testability,test,test,15,"Well, I cannot test it on MacOS...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11535
https://github.com/root-project/root/pull/11535:22,integrability,coupl,couple,22,"Best I can offer is a couple of screenshots of what I see on my mac before and after this change:. <img width=""255"" alt=""image"" src=""https://user-images.githubusercontent.com/18280829/195141600-5005ee61-2391-472b-9849-3cb1454d022e.png"">. <img width=""261"" alt=""image"" src=""https://user-images.githubusercontent.com/18280829/195141735-413c223f-fb05-4c01-86fc-929757c2ff39.png"">. I'd also comment that if you read the comment, it implies that ""ytext"" would have been set already but it's completely unclear where that would have happened in the code above ... so I wonder if this is just some stale protection here??",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11535
https://github.com/root-project/root/pull/11535:22,modifiability,coupl,couple,22,"Best I can offer is a couple of screenshots of what I see on my mac before and after this change:. <img width=""255"" alt=""image"" src=""https://user-images.githubusercontent.com/18280829/195141600-5005ee61-2391-472b-9849-3cb1454d022e.png"">. <img width=""261"" alt=""image"" src=""https://user-images.githubusercontent.com/18280829/195141735-413c223f-fb05-4c01-86fc-929757c2ff39.png"">. I'd also comment that if you read the comment, it implies that ""ytext"" would have been set already but it's completely unclear where that would have happened in the code above ... so I wonder if this is just some stale protection here??",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11535
https://github.com/root-project/root/pull/11535:485,safety,compl,completely,485,"Best I can offer is a couple of screenshots of what I see on my mac before and after this change:. <img width=""255"" alt=""image"" src=""https://user-images.githubusercontent.com/18280829/195141600-5005ee61-2391-472b-9849-3cb1454d022e.png"">. <img width=""261"" alt=""image"" src=""https://user-images.githubusercontent.com/18280829/195141735-413c223f-fb05-4c01-86fc-929757c2ff39.png"">. I'd also comment that if you read the comment, it implies that ""ytext"" would have been set already but it's completely unclear where that would have happened in the code above ... so I wonder if this is just some stale protection here??",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11535
https://github.com/root-project/root/pull/11535:485,security,compl,completely,485,"Best I can offer is a couple of screenshots of what I see on my mac before and after this change:. <img width=""255"" alt=""image"" src=""https://user-images.githubusercontent.com/18280829/195141600-5005ee61-2391-472b-9849-3cb1454d022e.png"">. <img width=""261"" alt=""image"" src=""https://user-images.githubusercontent.com/18280829/195141735-413c223f-fb05-4c01-86fc-929757c2ff39.png"">. I'd also comment that if you read the comment, it implies that ""ytext"" would have been set already but it's completely unclear where that would have happened in the code above ... so I wonder if this is just some stale protection here??",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11535
https://github.com/root-project/root/pull/11535:22,testability,coupl,couple,22,"Best I can offer is a couple of screenshots of what I see on my mac before and after this change:. <img width=""255"" alt=""image"" src=""https://user-images.githubusercontent.com/18280829/195141600-5005ee61-2391-472b-9849-3cb1454d022e.png"">. <img width=""261"" alt=""image"" src=""https://user-images.githubusercontent.com/18280829/195141735-413c223f-fb05-4c01-86fc-929757c2ff39.png"">. I'd also comment that if you read the comment, it implies that ""ytext"" would have been set already but it's completely unclear where that would have happened in the code above ... so I wonder if this is just some stale protection here??",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11535
https://github.com/root-project/root/pull/11535:141,usability,user,user-images,141,"Best I can offer is a couple of screenshots of what I see on my mac before and after this change:. <img width=""255"" alt=""image"" src=""https://user-images.githubusercontent.com/18280829/195141600-5005ee61-2391-472b-9849-3cb1454d022e.png"">. <img width=""261"" alt=""image"" src=""https://user-images.githubusercontent.com/18280829/195141735-413c223f-fb05-4c01-86fc-929757c2ff39.png"">. I'd also comment that if you read the comment, it implies that ""ytext"" would have been set already but it's completely unclear where that would have happened in the code above ... so I wonder if this is just some stale protection here??",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11535
https://github.com/root-project/root/pull/11535:280,usability,user,user-images,280,"Best I can offer is a couple of screenshots of what I see on my mac before and after this change:. <img width=""255"" alt=""image"" src=""https://user-images.githubusercontent.com/18280829/195141600-5005ee61-2391-472b-9849-3cb1454d022e.png"">. <img width=""261"" alt=""image"" src=""https://user-images.githubusercontent.com/18280829/195141735-413c223f-fb05-4c01-86fc-929757c2ff39.png"">. I'd also comment that if you read the comment, it implies that ""ytext"" would have been set already but it's completely unclear where that would have happened in the code above ... so I wonder if this is just some stale protection here??",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11535
https://github.com/root-project/root/pull/11535:66,deployability,patch,patches,66,"@will-cern thanks! FYI, this is now committed in master, v6-26-00-patches and v6-24-00-patches",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11535
https://github.com/root-project/root/pull/11535:87,deployability,patch,patches,87,"@will-cern thanks! FYI, this is now committed in master, v6-26-00-patches and v6-24-00-patches",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11535
https://github.com/root-project/root/pull/11535:66,safety,patch,patches,66,"@will-cern thanks! FYI, this is now committed in master, v6-26-00-patches and v6-24-00-patches",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11535
https://github.com/root-project/root/pull/11535:87,safety,patch,patches,87,"@will-cern thanks! FYI, this is now committed in master, v6-26-00-patches and v6-24-00-patches",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11535
https://github.com/root-project/root/pull/11535:66,security,patch,patches,66,"@will-cern thanks! FYI, this is now committed in master, v6-26-00-patches and v6-24-00-patches",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11535
https://github.com/root-project/root/pull/11535:87,security,patch,patches,87,"@will-cern thanks! FYI, this is now committed in master, v6-26-00-patches and v6-24-00-patches",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11535
https://github.com/root-project/root/pull/11541:11,deployability,build,build,11,"@phsft-bot build just on mac1015/cxx17, mac11/cxx14, ROOT-ubuntu2004/python3",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11541
https://github.com/root-project/root/pull/11544:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11544
https://github.com/root-project/root/pull/11544:80,deployability,build,builds,80,"@bellenot, it seems these warnings are not coming from this PR. The rest of the builds are green. Shall we move forward?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11544
https://github.com/root-project/root/pull/11544:91,energy efficiency,green,green,91,"@bellenot, it seems these warnings are not coming from this PR. The rest of the builds are green. Shall we move forward?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11544
https://github.com/root-project/root/pull/11544:82,deployability,build,builds,82,"> @bellenot, it seems these warnings are not coming from this PR. The rest of the builds are green. Shall we move forward? Yes, just go ahead ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11544
https://github.com/root-project/root/pull/11544:93,energy efficiency,green,green,93,"> @bellenot, it seems these warnings are not coming from this PR. The rest of the builds are green. Shall we move forward? Yes, just go ahead ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11544
https://github.com/root-project/root/pull/11545:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2004/default, ROOT-ubuntu18.04/nortcxxmod with flags -Dtmva-sofie=On",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11545
https://github.com/root-project/root/pull/11546:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2204/default, ROOT-windows10/default with flags -DCTEST_TEST_EXCLUDE_NONE=On",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11546
https://github.com/root-project/root/pull/11546:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2204/default, windows10/default with flags -DCTEST_TEST_EXCLUDE_NONE=On",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11546
https://github.com/root-project/root/pull/11546:11,deployability,build,build,11,@phsft-bot build just on ROOT-ubuntu2004/default -DCTEST_TEST_EXCLUDE_NONE=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11546
https://github.com/root-project/root/pull/11547:430,deployability,Modul,Module,430,> This pull request **fixes 2 alerts** when merging [e61c8e2](https://github.com/root-project/root/commit/e61c8e28c12e7be3499173582c3e276443a42e58) into [60e14f2](https://github.com/root-project/root/commit/60e14f283e4034ed7b85b58f3a26e4eb282983b8) - [view on LGTM.com](https://lgtm.com/projects/g/root-project/root/rev/pr-5e457dc1573e05d74adef855680dd865dab49179). > . > **fixed alerts:**. > . > * 1 for Unused import. > * 1 for Module is imported with 'import' and 'import from'. @etejedor that doesn't look right!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11547
https://github.com/root-project/root/pull/11547:430,modifiability,Modul,Module,430,> This pull request **fixes 2 alerts** when merging [e61c8e2](https://github.com/root-project/root/commit/e61c8e28c12e7be3499173582c3e276443a42e58) into [60e14f2](https://github.com/root-project/root/commit/60e14f283e4034ed7b85b58f3a26e4eb282983b8) - [view on LGTM.com](https://lgtm.com/projects/g/root-project/root/rev/pr-5e457dc1573e05d74adef855680dd865dab49179). > . > **fixed alerts:**. > . > * 1 for Unused import. > * 1 for Module is imported with 'import' and 'import from'. @etejedor that doesn't look right!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11547
https://github.com/root-project/root/pull/11547:30,reliability,alert,alerts,30,> This pull request **fixes 2 alerts** when merging [e61c8e2](https://github.com/root-project/root/commit/e61c8e28c12e7be3499173582c3e276443a42e58) into [60e14f2](https://github.com/root-project/root/commit/60e14f283e4034ed7b85b58f3a26e4eb282983b8) - [view on LGTM.com](https://lgtm.com/projects/g/root-project/root/rev/pr-5e457dc1573e05d74adef855680dd865dab49179). > . > **fixed alerts:**. > . > * 1 for Unused import. > * 1 for Module is imported with 'import' and 'import from'. @etejedor that doesn't look right!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11547
https://github.com/root-project/root/pull/11547:380,reliability,alert,alerts,380,> This pull request **fixes 2 alerts** when merging [e61c8e2](https://github.com/root-project/root/commit/e61c8e28c12e7be3499173582c3e276443a42e58) into [60e14f2](https://github.com/root-project/root/commit/60e14f283e4034ed7b85b58f3a26e4eb282983b8) - [view on LGTM.com](https://lgtm.com/projects/g/root-project/root/rev/pr-5e457dc1573e05d74adef855680dd865dab49179). > . > **fixed alerts:**. > . > * 1 for Unused import. > * 1 for Module is imported with 'import' and 'import from'. @etejedor that doesn't look right!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11547
https://github.com/root-project/root/pull/11547:497,reliability,doe,doesn,497,> This pull request **fixes 2 alerts** when merging [e61c8e2](https://github.com/root-project/root/commit/e61c8e28c12e7be3499173582c3e276443a42e58) into [60e14f2](https://github.com/root-project/root/commit/60e14f283e4034ed7b85b58f3a26e4eb282983b8) - [view on LGTM.com](https://lgtm.com/projects/g/root-project/root/rev/pr-5e457dc1573e05d74adef855680dd865dab49179). > . > **fixed alerts:**. > . > * 1 for Unused import. > * 1 for Module is imported with 'import' and 'import from'. @etejedor that doesn't look right!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11547
https://github.com/root-project/root/pull/11547:30,safety,aler,alerts,30,> This pull request **fixes 2 alerts** when merging [e61c8e2](https://github.com/root-project/root/commit/e61c8e28c12e7be3499173582c3e276443a42e58) into [60e14f2](https://github.com/root-project/root/commit/60e14f283e4034ed7b85b58f3a26e4eb282983b8) - [view on LGTM.com](https://lgtm.com/projects/g/root-project/root/rev/pr-5e457dc1573e05d74adef855680dd865dab49179). > . > **fixed alerts:**. > . > * 1 for Unused import. > * 1 for Module is imported with 'import' and 'import from'. @etejedor that doesn't look right!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11547
https://github.com/root-project/root/pull/11547:380,safety,aler,alerts,380,> This pull request **fixes 2 alerts** when merging [e61c8e2](https://github.com/root-project/root/commit/e61c8e28c12e7be3499173582c3e276443a42e58) into [60e14f2](https://github.com/root-project/root/commit/60e14f283e4034ed7b85b58f3a26e4eb282983b8) - [view on LGTM.com](https://lgtm.com/projects/g/root-project/root/rev/pr-5e457dc1573e05d74adef855680dd865dab49179). > . > **fixed alerts:**. > . > * 1 for Unused import. > * 1 for Module is imported with 'import' and 'import from'. @etejedor that doesn't look right!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11547
https://github.com/root-project/root/pull/11547:430,safety,Modul,Module,430,> This pull request **fixes 2 alerts** when merging [e61c8e2](https://github.com/root-project/root/commit/e61c8e28c12e7be3499173582c3e276443a42e58) into [60e14f2](https://github.com/root-project/root/commit/60e14f283e4034ed7b85b58f3a26e4eb282983b8) - [view on LGTM.com](https://lgtm.com/projects/g/root-project/root/rev/pr-5e457dc1573e05d74adef855680dd865dab49179). > . > **fixed alerts:**. > . > * 1 for Unused import. > * 1 for Module is imported with 'import' and 'import from'. @etejedor that doesn't look right!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11547
https://github.com/root-project/root/pull/11547:17,reliability,doe,does,17,@ikabadzhov what does not look right?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11547
https://github.com/root-project/root/pull/11547:19,reliability,doe,does,19,> @ikabadzhov what does not look right? 2 fixed alerts. It is all good. Sorry for the noise.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11547
https://github.com/root-project/root/pull/11547:48,reliability,alert,alerts,48,> @ikabadzhov what does not look right? 2 fixed alerts. It is all good. Sorry for the noise.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11547
https://github.com/root-project/root/pull/11547:48,safety,aler,alerts,48,> @ikabadzhov what does not look right? 2 fixed alerts. It is all good. Sorry for the noise.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11547
https://github.com/root-project/root/pull/11548:84,integrability,wrap,wrapped,84,"Yes, I agree. I need to check layout settings that labels are not truncated and not wrapped. Will be done with next PR.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11548
https://github.com/root-project/root/pull/11549:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11549
https://github.com/root-project/root/pull/11550:10,safety,test,test,10,"We cannot test without the branch in your repo, @vgvassilev :-) But we know how it behaves in master, I'm positive that it will work in v6-26, too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11550
https://github.com/root-project/root/pull/11550:10,testability,test,test,10,"We cannot test without the branch in your repo, @vgvassilev :-) But we know how it behaves in master, I'm positive that it will work in v6-26, too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11550
https://github.com/root-project/root/pull/11551:33,deployability,build,build,33,Do we have a node in the jenkins build that will test the (previously) failing case?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:71,deployability,fail,failing,71,Do we have a node in the jenkins build that will test the (previously) failing case?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:71,reliability,fail,failing,71,Do we have a node in the jenkins build that will test the (previously) failing case?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:49,safety,test,test,49,Do we have a node in the jenkins build that will test the (previously) failing case?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:49,testability,test,test,49,Do we have a node in the jenkins build that will test the (previously) failing case?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:17,availability,error,errors,17,The windows test errors seems unusual and the actual error are not obvious. We should re-run them before merging to check if it is just a transient issue.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:53,availability,error,error,53,The windows test errors seems unusual and the actual error are not obvious. We should re-run them before merging to check if it is just a transient issue.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:17,performance,error,errors,17,The windows test errors seems unusual and the actual error are not obvious. We should re-run them before merging to check if it is just a transient issue.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:53,performance,error,error,53,The windows test errors seems unusual and the actual error are not obvious. We should re-run them before merging to check if it is just a transient issue.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:12,safety,test,test,12,The windows test errors seems unusual and the actual error are not obvious. We should re-run them before merging to check if it is just a transient issue.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:17,safety,error,errors,17,The windows test errors seems unusual and the actual error are not obvious. We should re-run them before merging to check if it is just a transient issue.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:53,safety,error,error,53,The windows test errors seems unusual and the actual error are not obvious. We should re-run them before merging to check if it is just a transient issue.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:12,testability,test,test,12,The windows test errors seems unusual and the actual error are not obvious. We should re-run them before merging to check if it is just a transient issue.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:17,usability,error,errors,17,The windows test errors seems unusual and the actual error are not obvious. We should re-run them before merging to check if it is just a transient issue.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:53,usability,error,error,53,The windows test errors seems unusual and the actual error are not obvious. We should re-run them before merging to check if it is just a transient issue.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:76,availability,servic,services,76,@bellenot If you want to check the first windows run output: https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157152/console. I can not find the test output anywhere.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:76,deployability,servic,services,76,@bellenot If you want to check the first windows run output: https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157152/console. I can not find the test output anywhere.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:128,deployability,build,build,128,@bellenot If you want to check the first windows run output: https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157152/console. I can not find the test output anywhere.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:76,integrability,servic,services,76,@bellenot If you want to check the first windows run output: https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157152/console. I can not find the test output anywhere.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:76,modifiability,servic,services,76,@bellenot If you want to check the first windows run output: https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157152/console. I can not find the test output anywhere.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:169,safety,test,test,169,@bellenot If you want to check the first windows run output: https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157152/console. I can not find the test output anywhere.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:169,testability,test,test,169,@bellenot If you want to check the first windows run output: https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157152/console. I can not find the test output anywhere.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:11,deployability,build,build,11,"@phsft-bot build just on ROOT-centos9/default, ROOT-ubuntu2204/default, windows10/cxx14",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2204/default, windows10/cxx14",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:35,availability,error,errors,35,"In `aclicDataMemberSelection`, the errors:. ```. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C: In function int checkDict(const char*):. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C:31:48: warning: this pointer is null [-Wnonnull]. 31 | std::cerr << ""Class "" << c->GetName() << "" not found!\n"";. | ^~~~~~~~~~~~~~~. In file included from /home/sftnight/build/workspace/root-pullrequests-build/build/roottest/root/io/uniquePointer/aclic01_C_ACLiC_dict.cxx:41:. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C: In function int checkDict(const char*):. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C:31:48: warning: this pointer is null [-Wnonnull]. 31 | std::cerr << ""Class "" << c->GetName() << "" not found!\n"";. | ^~~~~~~~~~~~~~~. ```. are new to me. Was it already there in the nightly?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:64,deployability,build,build,64,"In `aclicDataMemberSelection`, the errors:. ```. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C: In function int checkDict(const char*):. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C:31:48: warning: this pointer is null [-Wnonnull]. 31 | std::cerr << ""Class "" << c->GetName() << "" not found!\n"";. | ^~~~~~~~~~~~~~~. In file included from /home/sftnight/build/workspace/root-pullrequests-build/build/roottest/root/io/uniquePointer/aclic01_C_ACLiC_dict.cxx:41:. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C: In function int checkDict(const char*):. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C:31:48: warning: this pointer is null [-Wnonnull]. 31 | std::cerr << ""Class "" << c->GetName() << "" not found!\n"";. | ^~~~~~~~~~~~~~~. ```. are new to me. Was it already there in the nightly?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:98,deployability,build,build,98,"In `aclicDataMemberSelection`, the errors:. ```. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C: In function int checkDict(const char*):. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C:31:48: warning: this pointer is null [-Wnonnull]. 31 | std::cerr << ""Class "" << c->GetName() << "" not found!\n"";. | ^~~~~~~~~~~~~~~. In file included from /home/sftnight/build/workspace/root-pullrequests-build/build/roottest/root/io/uniquePointer/aclic01_C_ACLiC_dict.cxx:41:. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C: In function int checkDict(const char*):. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C:31:48: warning: this pointer is null [-Wnonnull]. 31 | std::cerr << ""Class "" << c->GetName() << "" not found!\n"";. | ^~~~~~~~~~~~~~~. ```. are new to me. Was it already there in the nightly?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:204,deployability,build,build,204,"In `aclicDataMemberSelection`, the errors:. ```. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C: In function int checkDict(const char*):. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C:31:48: warning: this pointer is null [-Wnonnull]. 31 | std::cerr << ""Class "" << c->GetName() << "" not found!\n"";. | ^~~~~~~~~~~~~~~. In file included from /home/sftnight/build/workspace/root-pullrequests-build/build/roottest/root/io/uniquePointer/aclic01_C_ACLiC_dict.cxx:41:. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C: In function int checkDict(const char*):. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C:31:48: warning: this pointer is null [-Wnonnull]. 31 | std::cerr << ""Class "" << c->GetName() << "" not found!\n"";. | ^~~~~~~~~~~~~~~. ```. are new to me. Was it already there in the nightly?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:238,deployability,build,build,238,"In `aclicDataMemberSelection`, the errors:. ```. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C: In function int checkDict(const char*):. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C:31:48: warning: this pointer is null [-Wnonnull]. 31 | std::cerr << ""Class "" << c->GetName() << "" not found!\n"";. | ^~~~~~~~~~~~~~~. In file included from /home/sftnight/build/workspace/root-pullrequests-build/build/roottest/root/io/uniquePointer/aclic01_C_ACLiC_dict.cxx:41:. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C: In function int checkDict(const char*):. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C:31:48: warning: this pointer is null [-Wnonnull]. 31 | std::cerr << ""Class "" << c->GetName() << "" not found!\n"";. | ^~~~~~~~~~~~~~~. ```. are new to me. Was it already there in the nightly?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:457,deployability,build,build,457,"In `aclicDataMemberSelection`, the errors:. ```. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C: In function int checkDict(const char*):. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C:31:48: warning: this pointer is null [-Wnonnull]. 31 | std::cerr << ""Class "" << c->GetName() << "" not found!\n"";. | ^~~~~~~~~~~~~~~. In file included from /home/sftnight/build/workspace/root-pullrequests-build/build/roottest/root/io/uniquePointer/aclic01_C_ACLiC_dict.cxx:41:. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C: In function int checkDict(const char*):. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C:31:48: warning: this pointer is null [-Wnonnull]. 31 | std::cerr << ""Class "" << c->GetName() << "" not found!\n"";. | ^~~~~~~~~~~~~~~. ```. are new to me. Was it already there in the nightly?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:491,deployability,build,build,491,"In `aclicDataMemberSelection`, the errors:. ```. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C: In function int checkDict(const char*):. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C:31:48: warning: this pointer is null [-Wnonnull]. 31 | std::cerr << ""Class "" << c->GetName() << "" not found!\n"";. | ^~~~~~~~~~~~~~~. In file included from /home/sftnight/build/workspace/root-pullrequests-build/build/roottest/root/io/uniquePointer/aclic01_C_ACLiC_dict.cxx:41:. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C: In function int checkDict(const char*):. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C:31:48: warning: this pointer is null [-Wnonnull]. 31 | std::cerr << ""Class "" << c->GetName() << "" not found!\n"";. | ^~~~~~~~~~~~~~~. ```. are new to me. Was it already there in the nightly?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:497,deployability,build,build,497,"In `aclicDataMemberSelection`, the errors:. ```. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C: In function int checkDict(const char*):. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C:31:48: warning: this pointer is null [-Wnonnull]. 31 | std::cerr << ""Class "" << c->GetName() << "" not found!\n"";. | ^~~~~~~~~~~~~~~. In file included from /home/sftnight/build/workspace/root-pullrequests-build/build/roottest/root/io/uniquePointer/aclic01_C_ACLiC_dict.cxx:41:. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C: In function int checkDict(const char*):. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C:31:48: warning: this pointer is null [-Wnonnull]. 31 | std::cerr << ""Class "" << c->GetName() << "" not found!\n"";. | ^~~~~~~~~~~~~~~. ```. are new to me. Was it already there in the nightly?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:579,deployability,build,build,579,"In `aclicDataMemberSelection`, the errors:. ```. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C: In function int checkDict(const char*):. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C:31:48: warning: this pointer is null [-Wnonnull]. 31 | std::cerr << ""Class "" << c->GetName() << "" not found!\n"";. | ^~~~~~~~~~~~~~~. In file included from /home/sftnight/build/workspace/root-pullrequests-build/build/roottest/root/io/uniquePointer/aclic01_C_ACLiC_dict.cxx:41:. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C: In function int checkDict(const char*):. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C:31:48: warning: this pointer is null [-Wnonnull]. 31 | std::cerr << ""Class "" << c->GetName() << "" not found!\n"";. | ^~~~~~~~~~~~~~~. ```. are new to me. Was it already there in the nightly?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:613,deployability,build,build,613,"In `aclicDataMemberSelection`, the errors:. ```. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C: In function int checkDict(const char*):. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C:31:48: warning: this pointer is null [-Wnonnull]. 31 | std::cerr << ""Class "" << c->GetName() << "" not found!\n"";. | ^~~~~~~~~~~~~~~. In file included from /home/sftnight/build/workspace/root-pullrequests-build/build/roottest/root/io/uniquePointer/aclic01_C_ACLiC_dict.cxx:41:. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C: In function int checkDict(const char*):. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C:31:48: warning: this pointer is null [-Wnonnull]. 31 | std::cerr << ""Class "" << c->GetName() << "" not found!\n"";. | ^~~~~~~~~~~~~~~. ```. are new to me. Was it already there in the nightly?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:719,deployability,build,build,719,"In `aclicDataMemberSelection`, the errors:. ```. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C: In function int checkDict(const char*):. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C:31:48: warning: this pointer is null [-Wnonnull]. 31 | std::cerr << ""Class "" << c->GetName() << "" not found!\n"";. | ^~~~~~~~~~~~~~~. In file included from /home/sftnight/build/workspace/root-pullrequests-build/build/roottest/root/io/uniquePointer/aclic01_C_ACLiC_dict.cxx:41:. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C: In function int checkDict(const char*):. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C:31:48: warning: this pointer is null [-Wnonnull]. 31 | std::cerr << ""Class "" << c->GetName() << "" not found!\n"";. | ^~~~~~~~~~~~~~~. ```. are new to me. Was it already there in the nightly?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:753,deployability,build,build,753,"In `aclicDataMemberSelection`, the errors:. ```. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C: In function int checkDict(const char*):. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C:31:48: warning: this pointer is null [-Wnonnull]. 31 | std::cerr << ""Class "" << c->GetName() << "" not found!\n"";. | ^~~~~~~~~~~~~~~. In file included from /home/sftnight/build/workspace/root-pullrequests-build/build/roottest/root/io/uniquePointer/aclic01_C_ACLiC_dict.cxx:41:. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C: In function int checkDict(const char*):. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C:31:48: warning: this pointer is null [-Wnonnull]. 31 | std::cerr << ""Class "" << c->GetName() << "" not found!\n"";. | ^~~~~~~~~~~~~~~. ```. are new to me. Was it already there in the nightly?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:35,performance,error,errors,35,"In `aclicDataMemberSelection`, the errors:. ```. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C: In function int checkDict(const char*):. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C:31:48: warning: this pointer is null [-Wnonnull]. 31 | std::cerr << ""Class "" << c->GetName() << "" not found!\n"";. | ^~~~~~~~~~~~~~~. In file included from /home/sftnight/build/workspace/root-pullrequests-build/build/roottest/root/io/uniquePointer/aclic01_C_ACLiC_dict.cxx:41:. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C: In function int checkDict(const char*):. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C:31:48: warning: this pointer is null [-Wnonnull]. 31 | std::cerr << ""Class "" << c->GetName() << "" not found!\n"";. | ^~~~~~~~~~~~~~~. ```. are new to me. Was it already there in the nightly?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:35,safety,error,errors,35,"In `aclicDataMemberSelection`, the errors:. ```. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C: In function int checkDict(const char*):. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C:31:48: warning: this pointer is null [-Wnonnull]. 31 | std::cerr << ""Class "" << c->GetName() << "" not found!\n"";. | ^~~~~~~~~~~~~~~. In file included from /home/sftnight/build/workspace/root-pullrequests-build/build/roottest/root/io/uniquePointer/aclic01_C_ACLiC_dict.cxx:41:. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C: In function int checkDict(const char*):. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C:31:48: warning: this pointer is null [-Wnonnull]. 31 | std::cerr << ""Class "" << c->GetName() << "" not found!\n"";. | ^~~~~~~~~~~~~~~. ```. are new to me. Was it already there in the nightly?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:35,usability,error,errors,35,"In `aclicDataMemberSelection`, the errors:. ```. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C: In function int checkDict(const char*):. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C:31:48: warning: this pointer is null [-Wnonnull]. 31 | std::cerr << ""Class "" << c->GetName() << "" not found!\n"";. | ^~~~~~~~~~~~~~~. In file included from /home/sftnight/build/workspace/root-pullrequests-build/build/roottest/root/io/uniquePointer/aclic01_C_ACLiC_dict.cxx:41:. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C: In function int checkDict(const char*):. /home/sftnight/build/workspace/root-pullrequests-build/roottest/root/io/uniquePointer/aclic01.C:31:48: warning: this pointer is null [-Wnonnull]. 31 | std::cerr << ""Class "" << c->GetName() << "" not found!\n"";. | ^~~~~~~~~~~~~~~. ```. are new to me. Was it already there in the nightly?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:45,availability,servic,services,45,The 2nd windows build worked: https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157161/console,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:16,deployability,build,build,16,The 2nd windows build worked: https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157161/console,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:45,deployability,servic,services,45,The 2nd windows build worked: https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157161/console,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:97,deployability,build,build,97,The 2nd windows build worked: https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157161/console,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:45,integrability,servic,services,45,The 2nd windows build worked: https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157161/console,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:45,modifiability,servic,services,45,The 2nd windows build worked: https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157161/console,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:47,availability,servic,services,47,"> The 2nd windows build worked: https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157161/console. There was apparently a problem with the build node, 267 tests failed...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:18,deployability,build,build,18,"> The 2nd windows build worked: https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157161/console. There was apparently a problem with the build node, 267 tests failed...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:47,deployability,servic,services,47,"> The 2nd windows build worked: https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157161/console. There was apparently a problem with the build node, 267 tests failed...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:99,deployability,build,build,99,"> The 2nd windows build worked: https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157161/console. There was apparently a problem with the build node, 267 tests failed...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:161,deployability,build,build,161,"> The 2nd windows build worked: https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157161/console. There was apparently a problem with the build node, 267 tests failed...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:183,deployability,fail,failed,183,"> The 2nd windows build worked: https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157161/console. There was apparently a problem with the build node, 267 tests failed...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:47,integrability,servic,services,47,"> The 2nd windows build worked: https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157161/console. There was apparently a problem with the build node, 267 tests failed...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:47,modifiability,servic,services,47,"> The 2nd windows build worked: https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157161/console. There was apparently a problem with the build node, 267 tests failed...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:183,reliability,fail,failed,183,"> The 2nd windows build worked: https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157161/console. There was apparently a problem with the build node, 267 tests failed...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:177,safety,test,tests,177,"> The 2nd windows build worked: https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157161/console. There was apparently a problem with the build node, 267 tests failed...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:177,testability,test,tests,177,"> The 2nd windows build worked: https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157161/console. There was apparently a problem with the build node, 267 tests failed...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:4,availability,failur,failure,4,The failure in `aclicDataMemberSelection` is pre-existing (seemingly on the same platform as the issue this PR fixes). I double locally checked that this PR fix the intended issue on Ubuntu 22.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:4,deployability,fail,failure,4,The failure in `aclicDataMemberSelection` is pre-existing (seemingly on the same platform as the issue this PR fixes). I double locally checked that this PR fix the intended issue on Ubuntu 22.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:81,interoperability,platform,platform,81,The failure in `aclicDataMemberSelection` is pre-existing (seemingly on the same platform as the issue this PR fixes). I double locally checked that this PR fix the intended issue on Ubuntu 22.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:4,performance,failur,failure,4,The failure in `aclicDataMemberSelection` is pre-existing (seemingly on the same platform as the issue this PR fixes). I double locally checked that this PR fix the intended issue on Ubuntu 22.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:4,reliability,fail,failure,4,The failure in `aclicDataMemberSelection` is pre-existing (seemingly on the same platform as the issue this PR fixes). I double locally checked that this PR fix the intended issue on Ubuntu 22.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:9,deployability,patch,patch,9,Was that patch a backport of something?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:9,safety,patch,patch,9,Was that patch a backport of something?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:9,security,patch,patch,9,Was that patch a backport of something?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:34,safety,review,reviews,34,"Yes: Backport of [D86765](https://reviews.llvm.org/D86765), commit [bf890dcb0f](https://github.com/llvm/llvm-project/commit/bf890dcb0f5eb05b1a98cbd1cdd24c0c4ece8f8d).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:34,testability,review,reviews,34,"Yes: Backport of [D86765](https://reviews.llvm.org/D86765), commit [bf890dcb0f](https://github.com/llvm/llvm-project/commit/bf890dcb0f5eb05b1a98cbd1cdd24c0c4ece8f8d).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:28,deployability,upgrad,upgrade,28,I hope thats in our llvm13 upgrade branch too.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11551:28,modifiability,upgrad,upgrade,28,I hope thats in our llvm13 upgrade branch too.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11551
https://github.com/root-project/root/pull/11552:143,availability,error,error,143,"As a side note, it appears that `dataframe_simple` printouts:. ```. [ RUN ] MT/RDFSimpleTests.WritingToFundamentalType/0. input_line_164:2:41: error: cannot assign to variable 'var0' with const-qualified type 'const int'. auto func22(const int var0){return var0 = 42. ~~~~ ^. input_line_164:2:23: note: variable 'var0' declared const here. auto func22(const int var0){return var0 = 42. ~~~~~~~~~~^~~~. [ OK ] MT/RDFSimpleTests.WritingToFundamentalType/0 (1 ms). ```. but it does not make that sub-test fails. Is that intentional?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11552
https://github.com/root-project/root/pull/11552:502,deployability,fail,fails,502,"As a side note, it appears that `dataframe_simple` printouts:. ```. [ RUN ] MT/RDFSimpleTests.WritingToFundamentalType/0. input_line_164:2:41: error: cannot assign to variable 'var0' with const-qualified type 'const int'. auto func22(const int var0){return var0 = 42. ~~~~ ^. input_line_164:2:23: note: variable 'var0' declared const here. auto func22(const int var0){return var0 = 42. ~~~~~~~~~~^~~~. [ OK ] MT/RDFSimpleTests.WritingToFundamentalType/0 (1 ms). ```. but it does not make that sub-test fails. Is that intentional?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11552
https://github.com/root-project/root/pull/11552:493,integrability,sub,sub-test,493,"As a side note, it appears that `dataframe_simple` printouts:. ```. [ RUN ] MT/RDFSimpleTests.WritingToFundamentalType/0. input_line_164:2:41: error: cannot assign to variable 'var0' with const-qualified type 'const int'. auto func22(const int var0){return var0 = 42. ~~~~ ^. input_line_164:2:23: note: variable 'var0' declared const here. auto func22(const int var0){return var0 = 42. ~~~~~~~~~~^~~~. [ OK ] MT/RDFSimpleTests.WritingToFundamentalType/0 (1 ms). ```. but it does not make that sub-test fails. Is that intentional?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11552
https://github.com/root-project/root/pull/11552:167,modifiability,variab,variable,167,"As a side note, it appears that `dataframe_simple` printouts:. ```. [ RUN ] MT/RDFSimpleTests.WritingToFundamentalType/0. input_line_164:2:41: error: cannot assign to variable 'var0' with const-qualified type 'const int'. auto func22(const int var0){return var0 = 42. ~~~~ ^. input_line_164:2:23: note: variable 'var0' declared const here. auto func22(const int var0){return var0 = 42. ~~~~~~~~~~^~~~. [ OK ] MT/RDFSimpleTests.WritingToFundamentalType/0 (1 ms). ```. but it does not make that sub-test fails. Is that intentional?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11552
https://github.com/root-project/root/pull/11552:303,modifiability,variab,variable,303,"As a side note, it appears that `dataframe_simple` printouts:. ```. [ RUN ] MT/RDFSimpleTests.WritingToFundamentalType/0. input_line_164:2:41: error: cannot assign to variable 'var0' with const-qualified type 'const int'. auto func22(const int var0){return var0 = 42. ~~~~ ^. input_line_164:2:23: note: variable 'var0' declared const here. auto func22(const int var0){return var0 = 42. ~~~~~~~~~~^~~~. [ OK ] MT/RDFSimpleTests.WritingToFundamentalType/0 (1 ms). ```. but it does not make that sub-test fails. Is that intentional?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11552
https://github.com/root-project/root/pull/11552:143,performance,error,error,143,"As a side note, it appears that `dataframe_simple` printouts:. ```. [ RUN ] MT/RDFSimpleTests.WritingToFundamentalType/0. input_line_164:2:41: error: cannot assign to variable 'var0' with const-qualified type 'const int'. auto func22(const int var0){return var0 = 42. ~~~~ ^. input_line_164:2:23: note: variable 'var0' declared const here. auto func22(const int var0){return var0 = 42. ~~~~~~~~~~^~~~. [ OK ] MT/RDFSimpleTests.WritingToFundamentalType/0 (1 ms). ```. but it does not make that sub-test fails. Is that intentional?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11552
https://github.com/root-project/root/pull/11552:474,reliability,doe,does,474,"As a side note, it appears that `dataframe_simple` printouts:. ```. [ RUN ] MT/RDFSimpleTests.WritingToFundamentalType/0. input_line_164:2:41: error: cannot assign to variable 'var0' with const-qualified type 'const int'. auto func22(const int var0){return var0 = 42. ~~~~ ^. input_line_164:2:23: note: variable 'var0' declared const here. auto func22(const int var0){return var0 = 42. ~~~~~~~~~~^~~~. [ OK ] MT/RDFSimpleTests.WritingToFundamentalType/0 (1 ms). ```. but it does not make that sub-test fails. Is that intentional?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11552
https://github.com/root-project/root/pull/11552:502,reliability,fail,fails,502,"As a side note, it appears that `dataframe_simple` printouts:. ```. [ RUN ] MT/RDFSimpleTests.WritingToFundamentalType/0. input_line_164:2:41: error: cannot assign to variable 'var0' with const-qualified type 'const int'. auto func22(const int var0){return var0 = 42. ~~~~ ^. input_line_164:2:23: note: variable 'var0' declared const here. auto func22(const int var0){return var0 = 42. ~~~~~~~~~~^~~~. [ OK ] MT/RDFSimpleTests.WritingToFundamentalType/0 (1 ms). ```. but it does not make that sub-test fails. Is that intentional?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11552
https://github.com/root-project/root/pull/11552:143,safety,error,error,143,"As a side note, it appears that `dataframe_simple` printouts:. ```. [ RUN ] MT/RDFSimpleTests.WritingToFundamentalType/0. input_line_164:2:41: error: cannot assign to variable 'var0' with const-qualified type 'const int'. auto func22(const int var0){return var0 = 42. ~~~~ ^. input_line_164:2:23: note: variable 'var0' declared const here. auto func22(const int var0){return var0 = 42. ~~~~~~~~~~^~~~. [ OK ] MT/RDFSimpleTests.WritingToFundamentalType/0 (1 ms). ```. but it does not make that sub-test fails. Is that intentional?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11552
https://github.com/root-project/root/pull/11552:497,safety,test,test,497,"As a side note, it appears that `dataframe_simple` printouts:. ```. [ RUN ] MT/RDFSimpleTests.WritingToFundamentalType/0. input_line_164:2:41: error: cannot assign to variable 'var0' with const-qualified type 'const int'. auto func22(const int var0){return var0 = 42. ~~~~ ^. input_line_164:2:23: note: variable 'var0' declared const here. auto func22(const int var0){return var0 = 42. ~~~~~~~~~~^~~~. [ OK ] MT/RDFSimpleTests.WritingToFundamentalType/0 (1 ms). ```. but it does not make that sub-test fails. Is that intentional?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11552
https://github.com/root-project/root/pull/11552:497,testability,test,test,497,"As a side note, it appears that `dataframe_simple` printouts:. ```. [ RUN ] MT/RDFSimpleTests.WritingToFundamentalType/0. input_line_164:2:41: error: cannot assign to variable 'var0' with const-qualified type 'const int'. auto func22(const int var0){return var0 = 42. ~~~~ ^. input_line_164:2:23: note: variable 'var0' declared const here. auto func22(const int var0){return var0 = 42. ~~~~~~~~~~^~~~. [ OK ] MT/RDFSimpleTests.WritingToFundamentalType/0 (1 ms). ```. but it does not make that sub-test fails. Is that intentional?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11552
https://github.com/root-project/root/pull/11552:143,usability,error,error,143,"As a side note, it appears that `dataframe_simple` printouts:. ```. [ RUN ] MT/RDFSimpleTests.WritingToFundamentalType/0. input_line_164:2:41: error: cannot assign to variable 'var0' with const-qualified type 'const int'. auto func22(const int var0){return var0 = 42. ~~~~ ^. input_line_164:2:23: note: variable 'var0' declared const here. auto func22(const int var0){return var0 = 42. ~~~~~~~~~~^~~~. [ OK ] MT/RDFSimpleTests.WritingToFundamentalType/0 (1 ms). ```. but it does not make that sub-test fails. Is that intentional?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11552
https://github.com/root-project/root/pull/11552:68,safety,test,test,68,"> Is that intentional? @pcanal yes, that's an `EXPECT_THROW` in the test code",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11552
https://github.com/root-project/root/pull/11552:68,testability,test,test,68,"> Is that intentional? @pcanal yes, that's an `EXPECT_THROW` in the test code",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11552
https://github.com/root-project/root/pull/11552:10,deployability,fail,fail,10,"This will fail again (sorry for the mails @pcanal ). I need to double-check what RDF's behavior is with scalar values and vector weights for histogram fillings with/without histo models and with/without multi-threading. It looks like we have an inconsistency in how Histo1D with/without models treats that case (the former allows it, the latter does not).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11552
https://github.com/root-project/root/pull/11552:179,energy efficiency,model,models,179,"This will fail again (sorry for the mails @pcanal ). I need to double-check what RDF's behavior is with scalar values and vector weights for histogram fillings with/without histo models and with/without multi-threading. It looks like we have an inconsistency in how Histo1D with/without models treats that case (the former allows it, the latter does not).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11552
https://github.com/root-project/root/pull/11552:287,energy efficiency,model,models,287,"This will fail again (sorry for the mails @pcanal ). I need to double-check what RDF's behavior is with scalar values and vector weights for histogram fillings with/without histo models and with/without multi-threading. It looks like we have an inconsistency in how Histo1D with/without models treats that case (the former allows it, the latter does not).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11552
https://github.com/root-project/root/pull/11552:104,modifiability,scal,scalar,104,"This will fail again (sorry for the mails @pcanal ). I need to double-check what RDF's behavior is with scalar values and vector weights for histogram fillings with/without histo models and with/without multi-threading. It looks like we have an inconsistency in how Histo1D with/without models treats that case (the former allows it, the latter does not).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11552
https://github.com/root-project/root/pull/11552:203,performance,multi-thread,multi-threading,203,"This will fail again (sorry for the mails @pcanal ). I need to double-check what RDF's behavior is with scalar values and vector weights for histogram fillings with/without histo models and with/without multi-threading. It looks like we have an inconsistency in how Histo1D with/without models treats that case (the former allows it, the latter does not).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11552
https://github.com/root-project/root/pull/11552:10,reliability,fail,fail,10,"This will fail again (sorry for the mails @pcanal ). I need to double-check what RDF's behavior is with scalar values and vector weights for histogram fillings with/without histo models and with/without multi-threading. It looks like we have an inconsistency in how Histo1D with/without models treats that case (the former allows it, the latter does not).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11552
https://github.com/root-project/root/pull/11552:345,reliability,doe,does,345,"This will fail again (sorry for the mails @pcanal ). I need to double-check what RDF's behavior is with scalar values and vector weights for histogram fillings with/without histo models and with/without multi-threading. It looks like we have an inconsistency in how Histo1D with/without models treats that case (the former allows it, the latter does not).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11552
https://github.com/root-project/root/pull/11552:179,security,model,models,179,"This will fail again (sorry for the mails @pcanal ). I need to double-check what RDF's behavior is with scalar values and vector weights for histogram fillings with/without histo models and with/without multi-threading. It looks like we have an inconsistency in how Histo1D with/without models treats that case (the former allows it, the latter does not).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11552
https://github.com/root-project/root/pull/11552:287,security,model,models,287,"This will fail again (sorry for the mails @pcanal ). I need to double-check what RDF's behavior is with scalar values and vector weights for histogram fillings with/without histo models and with/without multi-threading. It looks like we have an inconsistency in how Histo1D with/without models treats that case (the former allows it, the latter does not).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11552
https://github.com/root-project/root/pull/11552:87,usability,behavi,behavior,87,"This will fail again (sorry for the mails @pcanal ). I need to double-check what RDF's behavior is with scalar values and vector weights for histogram fillings with/without histo models and with/without multi-threading. It looks like we have an inconsistency in how Histo1D with/without models treats that case (the former allows it, the latter does not).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11552
https://github.com/root-project/root/pull/11552:63,deployability,depend,depends,63,"The only relevant change is the one in the last commit, but it depends on the other changes from https://github.com/root-project/root/pull/12972 to work correctly, so it's rebased on top of those for now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11552
https://github.com/root-project/root/pull/11552:63,integrability,depend,depends,63,"The only relevant change is the one in the last commit, but it depends on the other changes from https://github.com/root-project/root/pull/12972 to work correctly, so it's rebased on top of those for now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11552
https://github.com/root-project/root/pull/11552:63,modifiability,depend,depends,63,"The only relevant change is the one in the last commit, but it depends on the other changes from https://github.com/root-project/root/pull/12972 to work correctly, so it's rebased on top of those for now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11552
https://github.com/root-project/root/pull/11552:63,safety,depend,depends,63,"The only relevant change is the one in the last commit, but it depends on the other changes from https://github.com/root-project/root/pull/12972 to work correctly, so it's rebased on top of those for now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11552
https://github.com/root-project/root/pull/11552:63,testability,depend,depends,63,"The only relevant change is the one in the last commit, but it depends on the other changes from https://github.com/root-project/root/pull/12972 to work correctly, so it's rebased on top of those for now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11552
https://github.com/root-project/root/pull/11552:51,safety,review,review,51,@vepadulano this small change is finally ready for review :grimacing:,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11552
https://github.com/root-project/root/pull/11552:51,testability,review,review,51,@vepadulano this small change is finally ready for review :grimacing:,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11552
https://github.com/root-project/root/pull/11553:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11553
https://github.com/root-project/root/pull/11556:11,deployability,build,build,11,@phsft-bot build just on windows10/cxx14,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11556
https://github.com/root-project/root/pull/11556:76,availability,error,error,76,"> In the currently generated code, I don't see a reinterpret_cast... Is the error message in the commit message maybe copied from an intermediate try? Indeed it was! I update the description and git log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11556
https://github.com/root-project/root/pull/11556:168,deployability,updat,update,168,"> In the currently generated code, I don't see a reinterpret_cast... Is the error message in the commit message maybe copied from an intermediate try? Indeed it was! I update the description and git log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11556
https://github.com/root-project/root/pull/11556:199,deployability,log,log,199,"> In the currently generated code, I don't see a reinterpret_cast... Is the error message in the commit message maybe copied from an intermediate try? Indeed it was! I update the description and git log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11556
https://github.com/root-project/root/pull/11556:9,energy efficiency,current,currently,9,"> In the currently generated code, I don't see a reinterpret_cast... Is the error message in the commit message maybe copied from an intermediate try? Indeed it was! I update the description and git log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11556
https://github.com/root-project/root/pull/11556:82,integrability,messag,message,82,"> In the currently generated code, I don't see a reinterpret_cast... Is the error message in the commit message maybe copied from an intermediate try? Indeed it was! I update the description and git log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11556
https://github.com/root-project/root/pull/11556:104,integrability,messag,message,104,"> In the currently generated code, I don't see a reinterpret_cast... Is the error message in the commit message maybe copied from an intermediate try? Indeed it was! I update the description and git log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11556
https://github.com/root-project/root/pull/11556:82,interoperability,messag,message,82,"> In the currently generated code, I don't see a reinterpret_cast... Is the error message in the commit message maybe copied from an intermediate try? Indeed it was! I update the description and git log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11556
https://github.com/root-project/root/pull/11556:104,interoperability,messag,message,104,"> In the currently generated code, I don't see a reinterpret_cast... Is the error message in the commit message maybe copied from an intermediate try? Indeed it was! I update the description and git log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11556
https://github.com/root-project/root/pull/11556:133,modifiability,interm,intermediate,133,"> In the currently generated code, I don't see a reinterpret_cast... Is the error message in the commit message maybe copied from an intermediate try? Indeed it was! I update the description and git log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11556
https://github.com/root-project/root/pull/11556:76,performance,error,error,76,"> In the currently generated code, I don't see a reinterpret_cast... Is the error message in the commit message maybe copied from an intermediate try? Indeed it was! I update the description and git log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11556
https://github.com/root-project/root/pull/11556:76,safety,error,error,76,"> In the currently generated code, I don't see a reinterpret_cast... Is the error message in the commit message maybe copied from an intermediate try? Indeed it was! I update the description and git log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11556
https://github.com/root-project/root/pull/11556:168,safety,updat,update,168,"> In the currently generated code, I don't see a reinterpret_cast... Is the error message in the commit message maybe copied from an intermediate try? Indeed it was! I update the description and git log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11556
https://github.com/root-project/root/pull/11556:199,safety,log,log,199,"> In the currently generated code, I don't see a reinterpret_cast... Is the error message in the commit message maybe copied from an intermediate try? Indeed it was! I update the description and git log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11556
https://github.com/root-project/root/pull/11556:168,security,updat,update,168,"> In the currently generated code, I don't see a reinterpret_cast... Is the error message in the commit message maybe copied from an intermediate try? Indeed it was! I update the description and git log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11556
https://github.com/root-project/root/pull/11556:199,security,log,log,199,"> In the currently generated code, I don't see a reinterpret_cast... Is the error message in the commit message maybe copied from an intermediate try? Indeed it was! I update the description and git log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11556
https://github.com/root-project/root/pull/11556:199,testability,log,log,199,"> In the currently generated code, I don't see a reinterpret_cast... Is the error message in the commit message maybe copied from an intermediate try? Indeed it was! I update the description and git log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11556
https://github.com/root-project/root/pull/11556:76,usability,error,error,76,"> In the currently generated code, I don't see a reinterpret_cast... Is the error message in the commit message maybe copied from an intermediate try? Indeed it was! I update the description and git log.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11556
https://github.com/root-project/root/pull/11556:123,interoperability,standard,standard,123,"> Are we actually guaranteed that the compiler has to put a multi-dimensional array into contiguous memory? Yes, this is a standard C/C++ guarantee.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11556
https://github.com/root-project/root/pull/11556:100,performance,memor,memory,100,"> Are we actually guaranteed that the compiler has to put a multi-dimensional array into contiguous memory? Yes, this is a standard C/C++ guarantee.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11556
https://github.com/root-project/root/pull/11556:100,usability,memor,memory,100,"> Are we actually guaranteed that the compiler has to put a multi-dimensional array into contiguous memory? Yes, this is a standard C/C++ guarantee.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11556
https://github.com/root-project/root/pull/11557:12,interoperability,conflict,conflicting,12,Potentially conflicting MR: https://github.com/root-project/root/pull/11530,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11557
https://github.com/root-project/root/pull/11557:99,energy efficiency,green,green,99,"> Potentially conflicting MR: #11530. I'll rebase after it merges, and ensure that `shellcheck` is green.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11557
https://github.com/root-project/root/pull/11557:14,interoperability,conflict,conflicting,14,"> Potentially conflicting MR: #11530. I'll rebase after it merges, and ensure that `shellcheck` is green.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11557
https://github.com/root-project/root/pull/11557:29,safety,test,test,29,"BTW, is there a place to add test cases for `thisroot.sh`?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11557
https://github.com/root-project/root/pull/11557:29,testability,test,test,29,"BTW, is there a place to add test cases for `thisroot.sh`?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11557
https://github.com/root-project/root/pull/11557:27,integrability,repositor,repository,27,"That would be the roottest repository, say in a new directory root/thisroot/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11557
https://github.com/root-project/root/pull/11557:27,interoperability,repositor,repository,27,"That would be the roottest repository, say in a new directory root/thisroot/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11557
https://github.com/root-project/root/pull/11557:153,deployability,instal,installed,153,"> That would be the roottest repository, say in a new directory root/thisroot/. That's a good idea! Does the test machine have bash dash ksh zsh ... all installed or could they be added? So that several terms can be tested.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11557
https://github.com/root-project/root/pull/11557:29,integrability,repositor,repository,29,"> That would be the roottest repository, say in a new directory root/thisroot/. That's a good idea! Does the test machine have bash dash ksh zsh ... all installed or could they be added? So that several terms can be tested.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11557
https://github.com/root-project/root/pull/11557:29,interoperability,repositor,repository,29,"> That would be the roottest repository, say in a new directory root/thisroot/. That's a good idea! Does the test machine have bash dash ksh zsh ... all installed or could they be added? So that several terms can be tested.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11557
https://github.com/root-project/root/pull/11557:100,reliability,Doe,Does,100,"> That would be the roottest repository, say in a new directory root/thisroot/. That's a good idea! Does the test machine have bash dash ksh zsh ... all installed or could they be added? So that several terms can be tested.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11557
https://github.com/root-project/root/pull/11557:109,safety,test,test,109,"> That would be the roottest repository, say in a new directory root/thisroot/. That's a good idea! Does the test machine have bash dash ksh zsh ... all installed or could they be added? So that several terms can be tested.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11557
https://github.com/root-project/root/pull/11557:216,safety,test,tested,216,"> That would be the roottest repository, say in a new directory root/thisroot/. That's a good idea! Does the test machine have bash dash ksh zsh ... all installed or could they be added? So that several terms can be tested.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11557
https://github.com/root-project/root/pull/11557:109,testability,test,test,109,"> That would be the roottest repository, say in a new directory root/thisroot/. That's a good idea! Does the test machine have bash dash ksh zsh ... all installed or could they be added? So that several terms can be tested.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11557
https://github.com/root-project/root/pull/11557:216,testability,test,tested,216,"> That would be the roottest repository, say in a new directory root/thisroot/. That's a good idea! Does the test machine have bash dash ksh zsh ... all installed or could they be added? So that several terms can be tested.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11557
https://github.com/root-project/root/pull/11557:55,deployability,instal,installed,55,"> Does the test machine have bash dash ksh zsh ... all installed or could they be added? So that several terms can be tested. It would be great to include `shellcheck`, too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11557
https://github.com/root-project/root/pull/11557:2,reliability,Doe,Does,2,"> Does the test machine have bash dash ksh zsh ... all installed or could they be added? So that several terms can be tested. It would be great to include `shellcheck`, too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11557
https://github.com/root-project/root/pull/11557:11,safety,test,test,11,"> Does the test machine have bash dash ksh zsh ... all installed or could they be added? So that several terms can be tested. It would be great to include `shellcheck`, too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11557
https://github.com/root-project/root/pull/11557:118,safety,test,tested,118,"> Does the test machine have bash dash ksh zsh ... all installed or could they be added? So that several terms can be tested. It would be great to include `shellcheck`, too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11557
https://github.com/root-project/root/pull/11557:11,testability,test,test,11,"> Does the test machine have bash dash ksh zsh ... all installed or could they be added? So that several terms can be tested. It would be great to include `shellcheck`, too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11557
https://github.com/root-project/root/pull/11557:118,testability,test,tested,118,"> Does the test machine have bash dash ksh zsh ... all installed or could they be added? So that several terms can be tested. It would be great to include `shellcheck`, too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11557
https://github.com/root-project/root/pull/11559:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11559
https://github.com/root-project/root/pull/11560:0,availability,Failur,Failures,0,"Failures on Ubuntu 18.04 are unrelated, likely need a backport by @lmoneta",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11560
https://github.com/root-project/root/pull/11560:0,deployability,Fail,Failures,0,"Failures on Ubuntu 18.04 are unrelated, likely need a backport by @lmoneta",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11560
https://github.com/root-project/root/pull/11560:0,performance,Failur,Failures,0,"Failures on Ubuntu 18.04 are unrelated, likely need a backport by @lmoneta",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11560
https://github.com/root-project/root/pull/11560:0,reliability,Fail,Failures,0,"Failures on Ubuntu 18.04 are unrelated, likely need a backport by @lmoneta",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11560
https://github.com/root-project/root/issues/11562:209,availability,state,statement,209,"Thanks for the report, @hahnjo! IIRC, this one was not trivial to fix, as in principle, we only want to ignore `diag::warn_unused_result` if _(i)_ value capture is enabled, and _(ii)_ only for the last parsed statement. However, as the diagnostic is emitted during parsing (see `SemaStmt.cpp`), I think the only way of conditionally emitting this warning -given the two conditions above-, would be to buffer all the diagnostics and then filter this one based on the `cling::CompilationOptions` and the source location. Otherwise, we can always fallback to the naive fix of just disable/filter this diagnostic in every case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11562
https://github.com/root-project/root/issues/11562:209,integrability,state,statement,209,"Thanks for the report, @hahnjo! IIRC, this one was not trivial to fix, as in principle, we only want to ignore `diag::warn_unused_result` if _(i)_ value capture is enabled, and _(ii)_ only for the last parsed statement. However, as the diagnostic is emitted during parsing (see `SemaStmt.cpp`), I think the only way of conditionally emitting this warning -given the two conditions above-, would be to buffer all the diagnostics and then filter this one based on the `cling::CompilationOptions` and the source location. Otherwise, we can always fallback to the naive fix of just disable/filter this diagnostic in every case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11562
https://github.com/root-project/root/issues/11562:401,integrability,buffer,buffer,401,"Thanks for the report, @hahnjo! IIRC, this one was not trivial to fix, as in principle, we only want to ignore `diag::warn_unused_result` if _(i)_ value capture is enabled, and _(ii)_ only for the last parsed statement. However, as the diagnostic is emitted during parsing (see `SemaStmt.cpp`), I think the only way of conditionally emitting this warning -given the two conditions above-, would be to buffer all the diagnostics and then filter this one based on the `cling::CompilationOptions` and the source location. Otherwise, we can always fallback to the naive fix of just disable/filter this diagnostic in every case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11562
https://github.com/root-project/root/issues/11562:437,integrability,filter,filter,437,"Thanks for the report, @hahnjo! IIRC, this one was not trivial to fix, as in principle, we only want to ignore `diag::warn_unused_result` if _(i)_ value capture is enabled, and _(ii)_ only for the last parsed statement. However, as the diagnostic is emitted during parsing (see `SemaStmt.cpp`), I think the only way of conditionally emitting this warning -given the two conditions above-, would be to buffer all the diagnostics and then filter this one based on the `cling::CompilationOptions` and the source location. Otherwise, we can always fallback to the naive fix of just disable/filter this diagnostic in every case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11562
https://github.com/root-project/root/issues/11562:586,integrability,filter,filter,586,"Thanks for the report, @hahnjo! IIRC, this one was not trivial to fix, as in principle, we only want to ignore `diag::warn_unused_result` if _(i)_ value capture is enabled, and _(ii)_ only for the last parsed statement. However, as the diagnostic is emitted during parsing (see `SemaStmt.cpp`), I think the only way of conditionally emitting this warning -given the two conditions above-, would be to buffer all the diagnostics and then filter this one based on the `cling::CompilationOptions` and the source location. Otherwise, we can always fallback to the naive fix of just disable/filter this diagnostic in every case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11562
https://github.com/root-project/root/issues/11562:236,reliability,diagno,diagnostic,236,"Thanks for the report, @hahnjo! IIRC, this one was not trivial to fix, as in principle, we only want to ignore `diag::warn_unused_result` if _(i)_ value capture is enabled, and _(ii)_ only for the last parsed statement. However, as the diagnostic is emitted during parsing (see `SemaStmt.cpp`), I think the only way of conditionally emitting this warning -given the two conditions above-, would be to buffer all the diagnostics and then filter this one based on the `cling::CompilationOptions` and the source location. Otherwise, we can always fallback to the naive fix of just disable/filter this diagnostic in every case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11562
https://github.com/root-project/root/issues/11562:416,reliability,diagno,diagnostics,416,"Thanks for the report, @hahnjo! IIRC, this one was not trivial to fix, as in principle, we only want to ignore `diag::warn_unused_result` if _(i)_ value capture is enabled, and _(ii)_ only for the last parsed statement. However, as the diagnostic is emitted during parsing (see `SemaStmt.cpp`), I think the only way of conditionally emitting this warning -given the two conditions above-, would be to buffer all the diagnostics and then filter this one based on the `cling::CompilationOptions` and the source location. Otherwise, we can always fallback to the naive fix of just disable/filter this diagnostic in every case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11562
https://github.com/root-project/root/issues/11562:598,reliability,diagno,diagnostic,598,"Thanks for the report, @hahnjo! IIRC, this one was not trivial to fix, as in principle, we only want to ignore `diag::warn_unused_result` if _(i)_ value capture is enabled, and _(ii)_ only for the last parsed statement. However, as the diagnostic is emitted during parsing (see `SemaStmt.cpp`), I think the only way of conditionally emitting this warning -given the two conditions above-, would be to buffer all the diagnostics and then filter this one based on the `cling::CompilationOptions` and the source location. Otherwise, we can always fallback to the naive fix of just disable/filter this diagnostic in every case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11562
https://github.com/root-project/root/issues/11562:236,testability,diagno,diagnostic,236,"Thanks for the report, @hahnjo! IIRC, this one was not trivial to fix, as in principle, we only want to ignore `diag::warn_unused_result` if _(i)_ value capture is enabled, and _(ii)_ only for the last parsed statement. However, as the diagnostic is emitted during parsing (see `SemaStmt.cpp`), I think the only way of conditionally emitting this warning -given the two conditions above-, would be to buffer all the diagnostics and then filter this one based on the `cling::CompilationOptions` and the source location. Otherwise, we can always fallback to the naive fix of just disable/filter this diagnostic in every case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11562
https://github.com/root-project/root/issues/11562:416,testability,diagno,diagnostics,416,"Thanks for the report, @hahnjo! IIRC, this one was not trivial to fix, as in principle, we only want to ignore `diag::warn_unused_result` if _(i)_ value capture is enabled, and _(ii)_ only for the last parsed statement. However, as the diagnostic is emitted during parsing (see `SemaStmt.cpp`), I think the only way of conditionally emitting this warning -given the two conditions above-, would be to buffer all the diagnostics and then filter this one based on the `cling::CompilationOptions` and the source location. Otherwise, we can always fallback to the naive fix of just disable/filter this diagnostic in every case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11562
https://github.com/root-project/root/issues/11562:598,testability,diagno,diagnostic,598,"Thanks for the report, @hahnjo! IIRC, this one was not trivial to fix, as in principle, we only want to ignore `diag::warn_unused_result` if _(i)_ value capture is enabled, and _(ii)_ only for the last parsed statement. However, as the diagnostic is emitted during parsing (see `SemaStmt.cpp`), I think the only way of conditionally emitting this warning -given the two conditions above-, would be to buffer all the diagnostics and then filter this one based on the `cling::CompilationOptions` and the source location. Otherwise, we can always fallback to the naive fix of just disable/filter this diagnostic in every case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11562
https://github.com/root-project/root/issues/11562:198,safety,test,test,198,"Yes, I agree this is non-trivial to fix after reading through https://github.com/root-project/root/issues/8622. But I decided to open an issue just to keep track of the problem because it affects a test with GCC 12; not sure if we can do anything for that one in particular in the test code...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11562
https://github.com/root-project/root/issues/11562:281,safety,test,test,281,"Yes, I agree this is non-trivial to fix after reading through https://github.com/root-project/root/issues/8622. But I decided to open an issue just to keep track of the problem because it affects a test with GCC 12; not sure if we can do anything for that one in particular in the test code...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11562
https://github.com/root-project/root/issues/11562:198,testability,test,test,198,"Yes, I agree this is non-trivial to fix after reading through https://github.com/root-project/root/issues/8622. But I decided to open an issue just to keep track of the problem because it affects a test with GCC 12; not sure if we can do anything for that one in particular in the test code...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11562
https://github.com/root-project/root/issues/11562:281,testability,test,test,281,"Yes, I agree this is non-trivial to fix after reading through https://github.com/root-project/root/issues/8622. But I decided to open an issue just to keep track of the problem because it affects a test with GCC 12; not sure if we can do anything for that one in particular in the test code...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11562
https://github.com/root-project/root/issues/11565:123,usability,user,user-attachments,123,Fix here: https://github.com/root-project/root/pull/15902. Compilable reproducer is attached. [MWE.zip](https://github.com/user-attachments/files/15944228/MWE.zip).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11565
https://github.com/root-project/root/pull/11568:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2004/default, ROOT-ubuntu18.04/nortcxxmod with flags -DCTEST_TEST_EXCLUDE_NONE=On",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11568
https://github.com/root-project/root/pull/11570:11,deployability,build,build,11,@phsft-bot build just on windows10/cxx14,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11570
https://github.com/root-project/root/pull/11571:12,usability,help,help,12,This should help with cms-sw/cmssw#39735,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:5,availability,failur,failure,5,This failure seems unrelated to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:5,deployability,fail,failure,5,This failure seems unrelated to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:5,performance,failur,failure,5,This failure seems unrelated to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:5,reliability,fail,failure,5,This failure seems unrelated to this PR.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:177,deployability,build,build,177,"I'm not sure about this: Commit 0d6d2ff902bee4b6485aae19dba9d346c2138f69 requiring C++14 only landed for 6.26. Before that (including 6.24), ROOT only required C++11 and should build fine with GCC 4.8.5 from CentOS 7. Breaking this in a patch release may not be a good idea... @Axel-Naumann",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:237,deployability,patch,patch,237,"I'm not sure about this: Commit 0d6d2ff902bee4b6485aae19dba9d346c2138f69 requiring C++14 only landed for 6.26. Before that (including 6.24), ROOT only required C++11 and should build fine with GCC 4.8.5 from CentOS 7. Breaking this in a patch release may not be a good idea... @Axel-Naumann",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:243,deployability,releas,release,243,"I'm not sure about this: Commit 0d6d2ff902bee4b6485aae19dba9d346c2138f69 requiring C++14 only landed for 6.26. Before that (including 6.24), ROOT only required C++11 and should build fine with GCC 4.8.5 from CentOS 7. Breaking this in a patch release may not be a good idea... @Axel-Naumann",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:237,safety,patch,patch,237,"I'm not sure about this: Commit 0d6d2ff902bee4b6485aae19dba9d346c2138f69 requiring C++14 only landed for 6.26. Before that (including 6.24), ROOT only required C++11 and should build fine with GCC 4.8.5 from CentOS 7. Breaking this in a patch release may not be a good idea... @Axel-Naumann",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:237,security,patch,patch,237,"I'm not sure about this: Commit 0d6d2ff902bee4b6485aae19dba9d346c2138f69 requiring C++14 only landed for 6.26. Before that (including 6.24), ROOT only required C++11 and should build fine with GCC 4.8.5 from CentOS 7. Breaking this in a patch release may not be a good idea... @Axel-Naumann",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:25,availability,servic,services,25,"Found it: https://lcgapp-services.cern.ch/root-jenkins/view/ROOT%20Nightly/job/root-nightly-v6-24-00-patches/LABEL=ROOT-ubuntu16,SPEC=cxx14,V=6-24/175/console is now failing (since this PR) with. ```. 00:22:07 /mnt/build/night/LABEL/ROOT-ubuntu16/SPEC/cxx14/V/6-24/build/etc/cling/std.modulemap:313:20: error: header 'string_view' not found. 00:22:07 textual header ""string_view"". 00:22:07 ^. 00:22:07 input_line_1:1:10: note: submodule of top-level module 'std' implicitly imported here. 00:22:07 #include <new>. 00:22:07 ^. ``` . @vgvassilev please consider reverting this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:303,availability,error,error,303,"Found it: https://lcgapp-services.cern.ch/root-jenkins/view/ROOT%20Nightly/job/root-nightly-v6-24-00-patches/LABEL=ROOT-ubuntu16,SPEC=cxx14,V=6-24/175/console is now failing (since this PR) with. ```. 00:22:07 /mnt/build/night/LABEL/ROOT-ubuntu16/SPEC/cxx14/V/6-24/build/etc/cling/std.modulemap:313:20: error: header 'string_view' not found. 00:22:07 textual header ""string_view"". 00:22:07 ^. 00:22:07 input_line_1:1:10: note: submodule of top-level module 'std' implicitly imported here. 00:22:07 #include <new>. 00:22:07 ^. ``` . @vgvassilev please consider reverting this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:25,deployability,servic,services,25,"Found it: https://lcgapp-services.cern.ch/root-jenkins/view/ROOT%20Nightly/job/root-nightly-v6-24-00-patches/LABEL=ROOT-ubuntu16,SPEC=cxx14,V=6-24/175/console is now failing (since this PR) with. ```. 00:22:07 /mnt/build/night/LABEL/ROOT-ubuntu16/SPEC/cxx14/V/6-24/build/etc/cling/std.modulemap:313:20: error: header 'string_view' not found. 00:22:07 textual header ""string_view"". 00:22:07 ^. 00:22:07 input_line_1:1:10: note: submodule of top-level module 'std' implicitly imported here. 00:22:07 #include <new>. 00:22:07 ^. ``` . @vgvassilev please consider reverting this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:101,deployability,patch,patches,101,"Found it: https://lcgapp-services.cern.ch/root-jenkins/view/ROOT%20Nightly/job/root-nightly-v6-24-00-patches/LABEL=ROOT-ubuntu16,SPEC=cxx14,V=6-24/175/console is now failing (since this PR) with. ```. 00:22:07 /mnt/build/night/LABEL/ROOT-ubuntu16/SPEC/cxx14/V/6-24/build/etc/cling/std.modulemap:313:20: error: header 'string_view' not found. 00:22:07 textual header ""string_view"". 00:22:07 ^. 00:22:07 input_line_1:1:10: note: submodule of top-level module 'std' implicitly imported here. 00:22:07 #include <new>. 00:22:07 ^. ``` . @vgvassilev please consider reverting this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:166,deployability,fail,failing,166,"Found it: https://lcgapp-services.cern.ch/root-jenkins/view/ROOT%20Nightly/job/root-nightly-v6-24-00-patches/LABEL=ROOT-ubuntu16,SPEC=cxx14,V=6-24/175/console is now failing (since this PR) with. ```. 00:22:07 /mnt/build/night/LABEL/ROOT-ubuntu16/SPEC/cxx14/V/6-24/build/etc/cling/std.modulemap:313:20: error: header 'string_view' not found. 00:22:07 textual header ""string_view"". 00:22:07 ^. 00:22:07 input_line_1:1:10: note: submodule of top-level module 'std' implicitly imported here. 00:22:07 #include <new>. 00:22:07 ^. ``` . @vgvassilev please consider reverting this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:215,deployability,build,build,215,"Found it: https://lcgapp-services.cern.ch/root-jenkins/view/ROOT%20Nightly/job/root-nightly-v6-24-00-patches/LABEL=ROOT-ubuntu16,SPEC=cxx14,V=6-24/175/console is now failing (since this PR) with. ```. 00:22:07 /mnt/build/night/LABEL/ROOT-ubuntu16/SPEC/cxx14/V/6-24/build/etc/cling/std.modulemap:313:20: error: header 'string_view' not found. 00:22:07 textual header ""string_view"". 00:22:07 ^. 00:22:07 input_line_1:1:10: note: submodule of top-level module 'std' implicitly imported here. 00:22:07 #include <new>. 00:22:07 ^. ``` . @vgvassilev please consider reverting this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:265,deployability,build,build,265,"Found it: https://lcgapp-services.cern.ch/root-jenkins/view/ROOT%20Nightly/job/root-nightly-v6-24-00-patches/LABEL=ROOT-ubuntu16,SPEC=cxx14,V=6-24/175/console is now failing (since this PR) with. ```. 00:22:07 /mnt/build/night/LABEL/ROOT-ubuntu16/SPEC/cxx14/V/6-24/build/etc/cling/std.modulemap:313:20: error: header 'string_view' not found. 00:22:07 textual header ""string_view"". 00:22:07 ^. 00:22:07 input_line_1:1:10: note: submodule of top-level module 'std' implicitly imported here. 00:22:07 #include <new>. 00:22:07 ^. ``` . @vgvassilev please consider reverting this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:285,deployability,modul,modulemap,285,"Found it: https://lcgapp-services.cern.ch/root-jenkins/view/ROOT%20Nightly/job/root-nightly-v6-24-00-patches/LABEL=ROOT-ubuntu16,SPEC=cxx14,V=6-24/175/console is now failing (since this PR) with. ```. 00:22:07 /mnt/build/night/LABEL/ROOT-ubuntu16/SPEC/cxx14/V/6-24/build/etc/cling/std.modulemap:313:20: error: header 'string_view' not found. 00:22:07 textual header ""string_view"". 00:22:07 ^. 00:22:07 input_line_1:1:10: note: submodule of top-level module 'std' implicitly imported here. 00:22:07 #include <new>. 00:22:07 ^. ``` . @vgvassilev please consider reverting this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:450,deployability,modul,module,450,"Found it: https://lcgapp-services.cern.ch/root-jenkins/view/ROOT%20Nightly/job/root-nightly-v6-24-00-patches/LABEL=ROOT-ubuntu16,SPEC=cxx14,V=6-24/175/console is now failing (since this PR) with. ```. 00:22:07 /mnt/build/night/LABEL/ROOT-ubuntu16/SPEC/cxx14/V/6-24/build/etc/cling/std.modulemap:313:20: error: header 'string_view' not found. 00:22:07 textual header ""string_view"". 00:22:07 ^. 00:22:07 input_line_1:1:10: note: submodule of top-level module 'std' implicitly imported here. 00:22:07 #include <new>. 00:22:07 ^. ``` . @vgvassilev please consider reverting this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:25,integrability,servic,services,25,"Found it: https://lcgapp-services.cern.ch/root-jenkins/view/ROOT%20Nightly/job/root-nightly-v6-24-00-patches/LABEL=ROOT-ubuntu16,SPEC=cxx14,V=6-24/175/console is now failing (since this PR) with. ```. 00:22:07 /mnt/build/night/LABEL/ROOT-ubuntu16/SPEC/cxx14/V/6-24/build/etc/cling/std.modulemap:313:20: error: header 'string_view' not found. 00:22:07 textual header ""string_view"". 00:22:07 ^. 00:22:07 input_line_1:1:10: note: submodule of top-level module 'std' implicitly imported here. 00:22:07 #include <new>. 00:22:07 ^. ``` . @vgvassilev please consider reverting this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:427,integrability,sub,submodule,427,"Found it: https://lcgapp-services.cern.ch/root-jenkins/view/ROOT%20Nightly/job/root-nightly-v6-24-00-patches/LABEL=ROOT-ubuntu16,SPEC=cxx14,V=6-24/175/console is now failing (since this PR) with. ```. 00:22:07 /mnt/build/night/LABEL/ROOT-ubuntu16/SPEC/cxx14/V/6-24/build/etc/cling/std.modulemap:313:20: error: header 'string_view' not found. 00:22:07 textual header ""string_view"". 00:22:07 ^. 00:22:07 input_line_1:1:10: note: submodule of top-level module 'std' implicitly imported here. 00:22:07 #include <new>. 00:22:07 ^. ``` . @vgvassilev please consider reverting this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:25,modifiability,servic,services,25,"Found it: https://lcgapp-services.cern.ch/root-jenkins/view/ROOT%20Nightly/job/root-nightly-v6-24-00-patches/LABEL=ROOT-ubuntu16,SPEC=cxx14,V=6-24/175/console is now failing (since this PR) with. ```. 00:22:07 /mnt/build/night/LABEL/ROOT-ubuntu16/SPEC/cxx14/V/6-24/build/etc/cling/std.modulemap:313:20: error: header 'string_view' not found. 00:22:07 textual header ""string_view"". 00:22:07 ^. 00:22:07 input_line_1:1:10: note: submodule of top-level module 'std' implicitly imported here. 00:22:07 #include <new>. 00:22:07 ^. ``` . @vgvassilev please consider reverting this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:285,modifiability,modul,modulemap,285,"Found it: https://lcgapp-services.cern.ch/root-jenkins/view/ROOT%20Nightly/job/root-nightly-v6-24-00-patches/LABEL=ROOT-ubuntu16,SPEC=cxx14,V=6-24/175/console is now failing (since this PR) with. ```. 00:22:07 /mnt/build/night/LABEL/ROOT-ubuntu16/SPEC/cxx14/V/6-24/build/etc/cling/std.modulemap:313:20: error: header 'string_view' not found. 00:22:07 textual header ""string_view"". 00:22:07 ^. 00:22:07 input_line_1:1:10: note: submodule of top-level module 'std' implicitly imported here. 00:22:07 #include <new>. 00:22:07 ^. ``` . @vgvassilev please consider reverting this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:450,modifiability,modul,module,450,"Found it: https://lcgapp-services.cern.ch/root-jenkins/view/ROOT%20Nightly/job/root-nightly-v6-24-00-patches/LABEL=ROOT-ubuntu16,SPEC=cxx14,V=6-24/175/console is now failing (since this PR) with. ```. 00:22:07 /mnt/build/night/LABEL/ROOT-ubuntu16/SPEC/cxx14/V/6-24/build/etc/cling/std.modulemap:313:20: error: header 'string_view' not found. 00:22:07 textual header ""string_view"". 00:22:07 ^. 00:22:07 input_line_1:1:10: note: submodule of top-level module 'std' implicitly imported here. 00:22:07 #include <new>. 00:22:07 ^. ``` . @vgvassilev please consider reverting this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:303,performance,error,error,303,"Found it: https://lcgapp-services.cern.ch/root-jenkins/view/ROOT%20Nightly/job/root-nightly-v6-24-00-patches/LABEL=ROOT-ubuntu16,SPEC=cxx14,V=6-24/175/console is now failing (since this PR) with. ```. 00:22:07 /mnt/build/night/LABEL/ROOT-ubuntu16/SPEC/cxx14/V/6-24/build/etc/cling/std.modulemap:313:20: error: header 'string_view' not found. 00:22:07 textual header ""string_view"". 00:22:07 ^. 00:22:07 input_line_1:1:10: note: submodule of top-level module 'std' implicitly imported here. 00:22:07 #include <new>. 00:22:07 ^. ``` . @vgvassilev please consider reverting this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:166,reliability,fail,failing,166,"Found it: https://lcgapp-services.cern.ch/root-jenkins/view/ROOT%20Nightly/job/root-nightly-v6-24-00-patches/LABEL=ROOT-ubuntu16,SPEC=cxx14,V=6-24/175/console is now failing (since this PR) with. ```. 00:22:07 /mnt/build/night/LABEL/ROOT-ubuntu16/SPEC/cxx14/V/6-24/build/etc/cling/std.modulemap:313:20: error: header 'string_view' not found. 00:22:07 textual header ""string_view"". 00:22:07 ^. 00:22:07 input_line_1:1:10: note: submodule of top-level module 'std' implicitly imported here. 00:22:07 #include <new>. 00:22:07 ^. ``` . @vgvassilev please consider reverting this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:101,safety,patch,patches,101,"Found it: https://lcgapp-services.cern.ch/root-jenkins/view/ROOT%20Nightly/job/root-nightly-v6-24-00-patches/LABEL=ROOT-ubuntu16,SPEC=cxx14,V=6-24/175/console is now failing (since this PR) with. ```. 00:22:07 /mnt/build/night/LABEL/ROOT-ubuntu16/SPEC/cxx14/V/6-24/build/etc/cling/std.modulemap:313:20: error: header 'string_view' not found. 00:22:07 textual header ""string_view"". 00:22:07 ^. 00:22:07 input_line_1:1:10: note: submodule of top-level module 'std' implicitly imported here. 00:22:07 #include <new>. 00:22:07 ^. ``` . @vgvassilev please consider reverting this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:285,safety,modul,modulemap,285,"Found it: https://lcgapp-services.cern.ch/root-jenkins/view/ROOT%20Nightly/job/root-nightly-v6-24-00-patches/LABEL=ROOT-ubuntu16,SPEC=cxx14,V=6-24/175/console is now failing (since this PR) with. ```. 00:22:07 /mnt/build/night/LABEL/ROOT-ubuntu16/SPEC/cxx14/V/6-24/build/etc/cling/std.modulemap:313:20: error: header 'string_view' not found. 00:22:07 textual header ""string_view"". 00:22:07 ^. 00:22:07 input_line_1:1:10: note: submodule of top-level module 'std' implicitly imported here. 00:22:07 #include <new>. 00:22:07 ^. ``` . @vgvassilev please consider reverting this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:303,safety,error,error,303,"Found it: https://lcgapp-services.cern.ch/root-jenkins/view/ROOT%20Nightly/job/root-nightly-v6-24-00-patches/LABEL=ROOT-ubuntu16,SPEC=cxx14,V=6-24/175/console is now failing (since this PR) with. ```. 00:22:07 /mnt/build/night/LABEL/ROOT-ubuntu16/SPEC/cxx14/V/6-24/build/etc/cling/std.modulemap:313:20: error: header 'string_view' not found. 00:22:07 textual header ""string_view"". 00:22:07 ^. 00:22:07 input_line_1:1:10: note: submodule of top-level module 'std' implicitly imported here. 00:22:07 #include <new>. 00:22:07 ^. ``` . @vgvassilev please consider reverting this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:450,safety,modul,module,450,"Found it: https://lcgapp-services.cern.ch/root-jenkins/view/ROOT%20Nightly/job/root-nightly-v6-24-00-patches/LABEL=ROOT-ubuntu16,SPEC=cxx14,V=6-24/175/console is now failing (since this PR) with. ```. 00:22:07 /mnt/build/night/LABEL/ROOT-ubuntu16/SPEC/cxx14/V/6-24/build/etc/cling/std.modulemap:313:20: error: header 'string_view' not found. 00:22:07 textual header ""string_view"". 00:22:07 ^. 00:22:07 input_line_1:1:10: note: submodule of top-level module 'std' implicitly imported here. 00:22:07 #include <new>. 00:22:07 ^. ``` . @vgvassilev please consider reverting this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:101,security,patch,patches,101,"Found it: https://lcgapp-services.cern.ch/root-jenkins/view/ROOT%20Nightly/job/root-nightly-v6-24-00-patches/LABEL=ROOT-ubuntu16,SPEC=cxx14,V=6-24/175/console is now failing (since this PR) with. ```. 00:22:07 /mnt/build/night/LABEL/ROOT-ubuntu16/SPEC/cxx14/V/6-24/build/etc/cling/std.modulemap:313:20: error: header 'string_view' not found. 00:22:07 textual header ""string_view"". 00:22:07 ^. 00:22:07 input_line_1:1:10: note: submodule of top-level module 'std' implicitly imported here. 00:22:07 #include <new>. 00:22:07 ^. ``` . @vgvassilev please consider reverting this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:303,usability,error,error,303,"Found it: https://lcgapp-services.cern.ch/root-jenkins/view/ROOT%20Nightly/job/root-nightly-v6-24-00-patches/LABEL=ROOT-ubuntu16,SPEC=cxx14,V=6-24/175/console is now failing (since this PR) with. ```. 00:22:07 /mnt/build/night/LABEL/ROOT-ubuntu16/SPEC/cxx14/V/6-24/build/etc/cling/std.modulemap:313:20: error: header 'string_view' not found. 00:22:07 textual header ""string_view"". 00:22:07 ^. 00:22:07 input_line_1:1:10: note: submodule of top-level module 'std' implicitly imported here. 00:22:07 #include <new>. 00:22:07 ^. ``` . @vgvassilev please consider reverting this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:123,deployability,build,build,123,"This change in itself doesn't require C++14, but I understand ""We do not need to support gcc 4.8 anymore."" that you cannot build with that version of GCC anymore, which should have worked fine before with 6.24...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:139,deployability,version,version,139,"This change in itself doesn't require C++14, but I understand ""We do not need to support gcc 4.8 anymore."" that you cannot build with that version of GCC anymore, which should have worked fine before with 6.24...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:139,integrability,version,version,139,"This change in itself doesn't require C++14, but I understand ""We do not need to support gcc 4.8 anymore."" that you cannot build with that version of GCC anymore, which should have worked fine before with 6.24...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:139,modifiability,version,version,139,"This change in itself doesn't require C++14, but I understand ""We do not need to support gcc 4.8 anymore."" that you cannot build with that version of GCC anymore, which should have worked fine before with 6.24...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:22,reliability,doe,doesn,22,"This change in itself doesn't require C++14, but I understand ""We do not need to support gcc 4.8 anymore."" that you cannot build with that version of GCC anymore, which should have worked fine before with 6.24...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:51,testability,understand,understand,51,"This change in itself doesn't require C++14, but I understand ""We do not need to support gcc 4.8 anymore."" that you cannot build with that version of GCC anymore, which should have worked fine before with 6.24...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:81,usability,support,support,81,"This change in itself doesn't require C++14, but I understand ""We do not need to support gcc 4.8 anymore."" that you cannot build with that version of GCC anymore, which should have worked fine before with 6.24...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:13,security,access,access,13,I dont have access to a laptop right now. @hahnjo can you revert?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11571:15,security,access,access,15,> I dont have access to a laptop right now. @hahnjo can you revert? https://github.com/root-project/root/pull/11582,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11571
https://github.com/root-project/root/pull/11573:0,availability,Failur,Failure,0,Failure is unrelated and fixed in the meantime,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11573
https://github.com/root-project/root/pull/11573:0,deployability,Fail,Failure,0,Failure is unrelated and fixed in the meantime,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11573
https://github.com/root-project/root/pull/11573:0,performance,Failur,Failure,0,Failure is unrelated and fixed in the meantime,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11573
https://github.com/root-project/root/pull/11573:0,reliability,Fail,Failure,0,Failure is unrelated and fixed in the meantime,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11573
https://github.com/root-project/root/pull/11574:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11574
https://github.com/root-project/root/pull/11574:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11574
https://github.com/root-project/root/pull/11574:41,availability,failur,failures,41,"@Axel-Naumann, what should we do - these failures seem unrelated...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11574
https://github.com/root-project/root/pull/11574:41,deployability,fail,failures,41,"@Axel-Naumann, what should we do - these failures seem unrelated...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11574
https://github.com/root-project/root/pull/11574:41,performance,failur,failures,41,"@Axel-Naumann, what should we do - these failures seem unrelated...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11574
https://github.com/root-project/root/pull/11574:41,reliability,fail,failures,41,"@Axel-Naumann, what should we do - these failures seem unrelated...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11574
https://github.com/root-project/root/pull/11574:51,deployability,releas,releases,51,I have not seen complaints and we are far ahead in releases. Lets not bother.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11574
https://github.com/root-project/root/pull/11574:16,safety,compl,complaints,16,I have not seen complaints and we are far ahead in releases. Lets not bother.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11574
https://github.com/root-project/root/pull/11574:16,security,compl,complaints,16,I have not seen complaints and we are far ahead in releases. Lets not bother.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11574
https://github.com/root-project/root/pull/11574:36,deployability,observ,observation,36,"I close it following @vgvassilev 's observation, feel free to re-open if this becomes a problem",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11574
https://github.com/root-project/root/pull/11574:36,testability,observ,observation,36,"I close it following @vgvassilev 's observation, feel free to re-open if this becomes a problem",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11574
https://github.com/root-project/root/pull/11574:2,usability,close,close,2,"I close it following @vgvassilev 's observation, feel free to re-open if this becomes a problem",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11574
https://github.com/root-project/root/pull/11576:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2204/cxx17, ROOT-ubuntu2004/default, ROOT-ubuntu18.04/nortcxxmod",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11576
https://github.com/root-project/root/pull/11576:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2204/cxx17, ROOT-ubuntu2004/default, ROOT-ubuntu18.04/nortcxxmod with flags -Dtmva-sofie=On",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11576
https://github.com/root-project/root/pull/11577:138,availability,error,error,138,"Hi @guitargeek, I've included your suggested changes. Note that I've kept the default dtor in the RooMinimizer.h. Deleting that gives the error:. `unique_ptr.h:50:19: error: invalid application of 'sizeof' to an incomplete type`. The issue is explained further in the following thread, and the easiest solution seems to be to just leave the default destructor in there explicitly: https://stackoverflow.com/questions/34072862/why-is-error-invalid-application-of-sizeof-to-an-incomplete-type-using-uniqu",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11577
https://github.com/root-project/root/pull/11577:167,availability,error,error,167,"Hi @guitargeek, I've included your suggested changes. Note that I've kept the default dtor in the RooMinimizer.h. Deleting that gives the error:. `unique_ptr.h:50:19: error: invalid application of 'sizeof' to an incomplete type`. The issue is explained further in the following thread, and the easiest solution seems to be to just leave the default destructor in there explicitly: https://stackoverflow.com/questions/34072862/why-is-error-invalid-application-of-sizeof-to-an-incomplete-type-using-uniqu",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11577
https://github.com/root-project/root/pull/11577:433,availability,error,error-invalid-application-of-sizeof-to-an-incomplete-type-using-uniqu,433,"Hi @guitargeek, I've included your suggested changes. Note that I've kept the default dtor in the RooMinimizer.h. Deleting that gives the error:. `unique_ptr.h:50:19: error: invalid application of 'sizeof' to an incomplete type`. The issue is explained further in the following thread, and the easiest solution seems to be to just leave the default destructor in there explicitly: https://stackoverflow.com/questions/34072862/why-is-error-invalid-application-of-sizeof-to-an-incomplete-type-using-uniqu",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11577
https://github.com/root-project/root/pull/11577:389,deployability,stack,stackoverflow,389,"Hi @guitargeek, I've included your suggested changes. Note that I've kept the default dtor in the RooMinimizer.h. Deleting that gives the error:. `unique_ptr.h:50:19: error: invalid application of 'sizeof' to an incomplete type`. The issue is explained further in the following thread, and the easiest solution seems to be to just leave the default destructor in there explicitly: https://stackoverflow.com/questions/34072862/why-is-error-invalid-application-of-sizeof-to-an-incomplete-type-using-uniqu",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11577
https://github.com/root-project/root/pull/11577:138,performance,error,error,138,"Hi @guitargeek, I've included your suggested changes. Note that I've kept the default dtor in the RooMinimizer.h. Deleting that gives the error:. `unique_ptr.h:50:19: error: invalid application of 'sizeof' to an incomplete type`. The issue is explained further in the following thread, and the easiest solution seems to be to just leave the default destructor in there explicitly: https://stackoverflow.com/questions/34072862/why-is-error-invalid-application-of-sizeof-to-an-incomplete-type-using-uniqu",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11577
https://github.com/root-project/root/pull/11577:167,performance,error,error,167,"Hi @guitargeek, I've included your suggested changes. Note that I've kept the default dtor in the RooMinimizer.h. Deleting that gives the error:. `unique_ptr.h:50:19: error: invalid application of 'sizeof' to an incomplete type`. The issue is explained further in the following thread, and the easiest solution seems to be to just leave the default destructor in there explicitly: https://stackoverflow.com/questions/34072862/why-is-error-invalid-application-of-sizeof-to-an-incomplete-type-using-uniqu",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11577
https://github.com/root-project/root/pull/11577:433,performance,error,error-invalid-application-of-sizeof-to-an-incomplete-type-using-uniqu,433,"Hi @guitargeek, I've included your suggested changes. Note that I've kept the default dtor in the RooMinimizer.h. Deleting that gives the error:. `unique_ptr.h:50:19: error: invalid application of 'sizeof' to an incomplete type`. The issue is explained further in the following thread, and the easiest solution seems to be to just leave the default destructor in there explicitly: https://stackoverflow.com/questions/34072862/why-is-error-invalid-application-of-sizeof-to-an-incomplete-type-using-uniqu",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11577
https://github.com/root-project/root/pull/11577:138,safety,error,error,138,"Hi @guitargeek, I've included your suggested changes. Note that I've kept the default dtor in the RooMinimizer.h. Deleting that gives the error:. `unique_ptr.h:50:19: error: invalid application of 'sizeof' to an incomplete type`. The issue is explained further in the following thread, and the easiest solution seems to be to just leave the default destructor in there explicitly: https://stackoverflow.com/questions/34072862/why-is-error-invalid-application-of-sizeof-to-an-incomplete-type-using-uniqu",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11577
https://github.com/root-project/root/pull/11577:167,safety,error,error,167,"Hi @guitargeek, I've included your suggested changes. Note that I've kept the default dtor in the RooMinimizer.h. Deleting that gives the error:. `unique_ptr.h:50:19: error: invalid application of 'sizeof' to an incomplete type`. The issue is explained further in the following thread, and the easiest solution seems to be to just leave the default destructor in there explicitly: https://stackoverflow.com/questions/34072862/why-is-error-invalid-application-of-sizeof-to-an-incomplete-type-using-uniqu",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11577
https://github.com/root-project/root/pull/11577:433,safety,error,error-invalid-application-of-sizeof-to-an-incomplete-type-using-uniqu,433,"Hi @guitargeek, I've included your suggested changes. Note that I've kept the default dtor in the RooMinimizer.h. Deleting that gives the error:. `unique_ptr.h:50:19: error: invalid application of 'sizeof' to an incomplete type`. The issue is explained further in the following thread, and the easiest solution seems to be to just leave the default destructor in there explicitly: https://stackoverflow.com/questions/34072862/why-is-error-invalid-application-of-sizeof-to-an-incomplete-type-using-uniqu",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11577
https://github.com/root-project/root/pull/11577:138,usability,error,error,138,"Hi @guitargeek, I've included your suggested changes. Note that I've kept the default dtor in the RooMinimizer.h. Deleting that gives the error:. `unique_ptr.h:50:19: error: invalid application of 'sizeof' to an incomplete type`. The issue is explained further in the following thread, and the easiest solution seems to be to just leave the default destructor in there explicitly: https://stackoverflow.com/questions/34072862/why-is-error-invalid-application-of-sizeof-to-an-incomplete-type-using-uniqu",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11577
https://github.com/root-project/root/pull/11577:167,usability,error,error,167,"Hi @guitargeek, I've included your suggested changes. Note that I've kept the default dtor in the RooMinimizer.h. Deleting that gives the error:. `unique_ptr.h:50:19: error: invalid application of 'sizeof' to an incomplete type`. The issue is explained further in the following thread, and the easiest solution seems to be to just leave the default destructor in there explicitly: https://stackoverflow.com/questions/34072862/why-is-error-invalid-application-of-sizeof-to-an-incomplete-type-using-uniqu",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11577
https://github.com/root-project/root/pull/11577:433,usability,error,error-invalid-application-of-sizeof-to-an-incomplete-type-using-uniqu,433,"Hi @guitargeek, I've included your suggested changes. Note that I've kept the default dtor in the RooMinimizer.h. Deleting that gives the error:. `unique_ptr.h:50:19: error: invalid application of 'sizeof' to an incomplete type`. The issue is explained further in the following thread, and the easiest solution seems to be to just leave the default destructor in there explicitly: https://stackoverflow.com/questions/34072862/why-is-error-invalid-application-of-sizeof-to-an-incomplete-type-using-uniqu",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11577
https://github.com/root-project/root/pull/11577:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11577
https://github.com/root-project/root/pull/11577:64,availability,redund,redundant,64,"Thank you! That's great you also addressed the comment with the redundant verbosity flag. Let's test this once with multiprocess off, and then afterwards once with multiprocess on.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11577
https://github.com/root-project/root/pull/11577:64,deployability,redundan,redundant,64,"Thank you! That's great you also addressed the comment with the redundant verbosity flag. Let's test this once with multiprocess off, and then afterwards once with multiprocess on.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11577
https://github.com/root-project/root/pull/11577:64,reliability,redundan,redundant,64,"Thank you! That's great you also addressed the comment with the redundant verbosity flag. Let's test this once with multiprocess off, and then afterwards once with multiprocess on.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11577
https://github.com/root-project/root/pull/11577:64,safety,redund,redundant,64,"Thank you! That's great you also addressed the comment with the redundant verbosity flag. Let's test this once with multiprocess off, and then afterwards once with multiprocess on.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11577
https://github.com/root-project/root/pull/11577:96,safety,test,test,96,"Thank you! That's great you also addressed the comment with the redundant verbosity flag. Let's test this once with multiprocess off, and then afterwards once with multiprocess on.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11577
https://github.com/root-project/root/pull/11577:96,testability,test,test,96,"Thank you! That's great you also addressed the comment with the redundant verbosity flag. Let's test this once with multiprocess off, and then afterwards once with multiprocess on.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11577
https://github.com/root-project/root/pull/11577:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11577
https://github.com/root-project/root/pull/11577:11,deployability,build,build,11,@phsft-bot build with flags -Droofit_multiprocess=ON -Dbuiltin_zeromq=ON -Dbuiltin_cppzmq=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11577
https://github.com/root-project/root/issues/11578:166,deployability,integr,integrals,166,"Hi @elusian, thank you so much as always for reporting this! I haven't solved the problem yet, but just to track my progress here: the underlying problem is that the integrals of a derived PDF (like the `RooRealSumPdf` in your case) somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [Roo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:874,deployability,integr,integral,874,"Hi @elusian, thank you so much as always for reporting this! I haven't solved the problem yet, but just to track my progress here: the underlying problem is that the integrals of a derived PDF (like the `RooRealSumPdf` in your case) somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [Roo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:1149,deployability,integr,integral,1149," is that the integrals of a derived PDF (like the `RooRealSumPdf` in your case) somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [RooRealIntegral.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooRealIntegral.cxx#L68). * Whatever the fix will be, it may be ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:1793,deployability,integr,integrals,1793,") somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [RooRealIntegral.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooRealIntegral.cxx#L68). * Whatever the fix will be, it may be a too big change to the central `RooRealIntegral` class for a patch release...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:2215,deployability,patch,patch,2215,") somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [RooRealIntegral.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooRealIntegral.cxx#L68). * Whatever the fix will be, it may be a too big change to the central `RooRealIntegral` class for a patch release...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:2221,deployability,releas,release,2221,") somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [RooRealIntegral.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooRealIntegral.cxx#L68). * Whatever the fix will be, it may be a too big change to the central `RooRealIntegral` class for a patch release...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:166,integrability,integr,integrals,166,"Hi @elusian, thank you so much as always for reporting this! I haven't solved the problem yet, but just to track my progress here: the underlying problem is that the integrals of a derived PDF (like the `RooRealSumPdf` in your case) somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [Roo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:266,integrability,interfac,interface,266,"Hi @elusian, thank you so much as always for reporting this! I haven't solved the problem yet, but just to track my progress here: the underlying problem is that the integrals of a derived PDF (like the `RooRealSumPdf` in your case) somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [Roo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:874,integrability,integr,integral,874,"Hi @elusian, thank you so much as always for reporting this! I haven't solved the problem yet, but just to track my progress here: the underlying problem is that the integrals of a derived PDF (like the `RooRealSumPdf` in your case) somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [Roo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:1149,integrability,integr,integral,1149," is that the integrals of a derived PDF (like the `RooRealSumPdf` in your case) somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [RooRealIntegral.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooRealIntegral.cxx#L68). * Whatever the fix will be, it may be ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:1584,integrability,Batch,BatchMode,1584,") somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [RooRealIntegral.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooRealIntegral.cxx#L68). * Whatever the fix will be, it may be a too big change to the central `RooRealIntegral` class for a patch release...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:1631,integrability,interfac,interface,1631,") somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [RooRealIntegral.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooRealIntegral.cxx#L68). * Whatever the fix will be, it may be a too big change to the central `RooRealIntegral` class for a patch release...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:1793,integrability,integr,integrals,1793,") somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [RooRealIntegral.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooRealIntegral.cxx#L68). * Whatever the fix will be, it may be a too big change to the central `RooRealIntegral` class for a patch release...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:1904,integrability,Batch,BatchMode,1904,") somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [RooRealIntegral.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooRealIntegral.cxx#L68). * Whatever the fix will be, it may be a too big change to the central `RooRealIntegral` class for a patch release...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:166,interoperability,integr,integrals,166,"Hi @elusian, thank you so much as always for reporting this! I haven't solved the problem yet, but just to track my progress here: the underlying problem is that the integrals of a derived PDF (like the `RooRealSumPdf` in your case) somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [Roo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:252,interoperability,client-serv,client-server,252,"Hi @elusian, thank you so much as always for reporting this! I haven't solved the problem yet, but just to track my progress here: the underlying problem is that the integrals of a derived PDF (like the `RooRealSumPdf` in your case) somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [Roo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:266,interoperability,interfac,interface,266,"Hi @elusian, thank you so much as always for reporting this! I haven't solved the problem yet, but just to track my progress here: the underlying problem is that the integrals of a derived PDF (like the `RooRealSumPdf` in your case) somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [Roo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:874,interoperability,integr,integral,874,"Hi @elusian, thank you so much as always for reporting this! I haven't solved the problem yet, but just to track my progress here: the underlying problem is that the integrals of a derived PDF (like the `RooRealSumPdf` in your case) somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [Roo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:1149,interoperability,integr,integral,1149," is that the integrals of a derived PDF (like the `RooRealSumPdf` in your case) somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [RooRealIntegral.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooRealIntegral.cxx#L68). * Whatever the fix will be, it may be ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:1548,interoperability,client-serv,client-server,1548,") somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [RooRealIntegral.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooRealIntegral.cxx#L68). * Whatever the fix will be, it may be a too big change to the central `RooRealIntegral` class for a patch release...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:1631,interoperability,interfac,interface,1631,") somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [RooRealIntegral.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooRealIntegral.cxx#L68). * Whatever the fix will be, it may be a too big change to the central `RooRealIntegral` class for a patch release...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:1793,interoperability,integr,integrals,1793,") somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [RooRealIntegral.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooRealIntegral.cxx#L68). * Whatever the fix will be, it may be a too big change to the central `RooRealIntegral` class for a patch release...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:166,modifiability,integr,integrals,166,"Hi @elusian, thank you so much as always for reporting this! I haven't solved the problem yet, but just to track my progress here: the underlying problem is that the integrals of a derived PDF (like the `RooRealSumPdf` in your case) somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [Roo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:266,modifiability,interfac,interface,266,"Hi @elusian, thank you so much as always for reporting this! I haven't solved the problem yet, but just to track my progress here: the underlying problem is that the integrals of a derived PDF (like the `RooRealSumPdf` in your case) somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [Roo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:874,modifiability,integr,integral,874,"Hi @elusian, thank you so much as always for reporting this! I haven't solved the problem yet, but just to track my progress here: the underlying problem is that the integrals of a derived PDF (like the `RooRealSumPdf` in your case) somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [Roo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:940,modifiability,paramet,parameters,940,"Hi @elusian, thank you so much as always for reporting this! I haven't solved the problem yet, but just to track my progress here: the underlying problem is that the integrals of a derived PDF (like the `RooRealSumPdf` in your case) somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [Roo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:1149,modifiability,integr,integral,1149," is that the integrals of a derived PDF (like the `RooRealSumPdf` in your case) somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [RooRealIntegral.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooRealIntegral.cxx#L68). * Whatever the fix will be, it may be ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:1631,modifiability,interfac,interface,1631,") somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [RooRealIntegral.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooRealIntegral.cxx#L68). * Whatever the fix will be, it may be a too big change to the central `RooRealIntegral` class for a patch release...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:1793,modifiability,integr,integrals,1793,") somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [RooRealIntegral.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooRealIntegral.cxx#L68). * Whatever the fix will be, it may be a too big change to the central `RooRealIntegral` class for a patch release...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:1584,performance,Batch,BatchMode,1584,") somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [RooRealIntegral.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooRealIntegral.cxx#L68). * Whatever the fix will be, it may be a too big change to the central `RooRealIntegral` class for a patch release...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:1904,performance,Batch,BatchMode,1904,") somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [RooRealIntegral.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooRealIntegral.cxx#L68). * Whatever the fix will be, it may be a too big change to the central `RooRealIntegral` class for a patch release...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:166,reliability,integr,integrals,166,"Hi @elusian, thank you so much as always for reporting this! I haven't solved the problem yet, but just to track my progress here: the underlying problem is that the integrals of a derived PDF (like the `RooRealSumPdf` in your case) somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [Roo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:874,reliability,integr,integral,874,"Hi @elusian, thank you so much as always for reporting this! I haven't solved the problem yet, but just to track my progress here: the underlying problem is that the integrals of a derived PDF (like the `RooRealSumPdf` in your case) somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [Roo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:1149,reliability,integr,integral,1149," is that the integrals of a derived PDF (like the `RooRealSumPdf` in your case) somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [RooRealIntegral.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooRealIntegral.cxx#L68). * Whatever the fix will be, it may be ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:1224,reliability,doe,doesn,1224,"case) somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [RooRealIntegral.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooRealIntegral.cxx#L68). * Whatever the fix will be, it may be a too big change to the central `RooRealIntegral` class for a patch releas",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:1793,reliability,integr,integrals,1793,") somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [RooRealIntegral.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooRealIntegral.cxx#L68). * Whatever the fix will be, it may be a too big change to the central `RooRealIntegral` class for a patch release...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:2215,safety,patch,patch,2215,") somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [RooRealIntegral.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooRealIntegral.cxx#L68). * Whatever the fix will be, it may be a too big change to the central `RooRealIntegral` class for a patch release...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:166,security,integr,integrals,166,"Hi @elusian, thank you so much as always for reporting this! I haven't solved the problem yet, but just to track my progress here: the underlying problem is that the integrals of a derived PDF (like the `RooRealSumPdf` in your case) somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [Roo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:874,security,integr,integral,874,"Hi @elusian, thank you so much as always for reporting this! I haven't solved the problem yet, but just to track my progress here: the underlying problem is that the integrals of a derived PDF (like the `RooRealSumPdf` in your case) somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [Roo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:1149,security,integr,integral,1149," is that the integrals of a derived PDF (like the `RooRealSumPdf` in your case) somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [RooRealIntegral.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooRealIntegral.cxx#L68). * Whatever the fix will be, it may be ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:1793,security,integr,integrals,1793,") somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [RooRealIntegral.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooRealIntegral.cxx#L68). * Whatever the fix will be, it may be a too big change to the central `RooRealIntegral` class for a patch release...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:2215,security,patch,patch,2215,") somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [RooRealIntegral.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooRealIntegral.cxx#L68). * Whatever the fix will be, it may be a too big change to the central `RooRealIntegral` class for a patch release...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:166,testability,integr,integrals,166,"Hi @elusian, thank you so much as always for reporting this! I haven't solved the problem yet, but just to track my progress here: the underlying problem is that the integrals of a derived PDF (like the `RooRealSumPdf` in your case) somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [Roo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:874,testability,integr,integral,874,"Hi @elusian, thank you so much as always for reporting this! I haven't solved the problem yet, but just to track my progress here: the underlying problem is that the integrals of a derived PDF (like the `RooRealSumPdf` in your case) somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [Roo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:1149,testability,integr,integral,1149," is that the integrals of a derived PDF (like the `RooRealSumPdf` in your case) somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [RooRealIntegral.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooRealIntegral.cxx#L68). * Whatever the fix will be, it may be ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:1793,testability,integr,integrals,1793,") somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [RooRealIntegral.cxx](https://github.com/root-project/root/blob/master/roofit/roofitcore/src/RooRealIntegral.cxx#L68). * Whatever the fix will be, it may be a too big change to the central `RooRealIntegral` class for a patch release...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:116,usability,progress,progress,116,"Hi @elusian, thank you so much as always for reporting this! I haven't solved the problem yet, but just to track my progress here: the underlying problem is that the integrals of a derived PDF (like the `RooRealSumPdf` in your case) somehow have their client-server interface messed up. Here is a reproducer:. ```C++. void repro() {. using namespace RooFit;. RooRealVar x(""x"", """", 0, 1);. RooRealVar par(""par"", """", -0.005, -5, 5);. RooProduct parMod(""par_mod"", """", RooArgSet(par, RooConst(10)));. RooGaussian gauss(""gauss"", """", x, parMod, RooConst(2.0));. RooGenericPdf pdf(""pdf"", ""gauss"", gauss);. std::unique_ptr<RooAbsReal> integ1{gauss.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ1->Print(""v"");. std::cout << std::endl;. std::unique_ptr<RooAbsReal> integ2{pdf.createIntegral(x, *pdf.getIntegratorConfig(), nullptr)};. integ2->Print(""v"");. }. ```. The integral of the Gaussian has the correct value (`V`) servers (the parameters of the Gaussian):. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bf240,--) RooGaussian::gauss """". (0x7ffc9b9bff68,V-) RooProduct::par_mod """". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. The integral of the `RooGenericPdf` should have the same value servers, but it doesn't:. ```. (0x7ffc9b9bf798,-S) RooRealVar::x """". (0x7ffc9b9bec88,--) RooRealSumPdf::pdf """". (0x7ffc9b9bfb80,V-) RooRealVar::par """". (0x55ac51984c50,V-) RooConstVar::10 ""10"". (0x55ac531cd470,V-) RooConstVar::2 ""2"". ```. For some reason, the direct value server, which is `par_mod` is **skipped** now, misrepresenting the client-server relationship. The new BatchMode makes strong use of the value-server interface for the `RooFitDriver`, so it's very sensitive to `RooRealIntegrals` getting it wrong. I need to fix this problem with the value servers registered for integrals on RooRealSumPdfs. Further notes:. * The problem has always been there in RooFit, it's just that the BatchMode uncovered it. * Naturally, the problem is somehow in `getValueAndShapeServers` in [Roo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:380,deployability,integr,integrated,380,"I have opened a PR to fix the problem in RooRealIntegral. It's a first step, but it will probably take more time before this gets merge, as the RooRealIntegral is not covered that well by unit tests yet, and I want to first write more tests for the part of the code that I changed. I already have added one test based on your example, but I still need to cover the case where the integrated function has shape clients.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:380,integrability,integr,integrated,380,"I have opened a PR to fix the problem in RooRealIntegral. It's a first step, but it will probably take more time before this gets merge, as the RooRealIntegral is not covered that well by unit tests yet, and I want to first write more tests for the part of the code that I changed. I already have added one test based on your example, but I still need to cover the case where the integrated function has shape clients.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:380,interoperability,integr,integrated,380,"I have opened a PR to fix the problem in RooRealIntegral. It's a first step, but it will probably take more time before this gets merge, as the RooRealIntegral is not covered that well by unit tests yet, and I want to first write more tests for the part of the code that I changed. I already have added one test based on your example, but I still need to cover the case where the integrated function has shape clients.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:380,modifiability,integr,integrated,380,"I have opened a PR to fix the problem in RooRealIntegral. It's a first step, but it will probably take more time before this gets merge, as the RooRealIntegral is not covered that well by unit tests yet, and I want to first write more tests for the part of the code that I changed. I already have added one test based on your example, but I still need to cover the case where the integrated function has shape clients.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:108,performance,time,time,108,"I have opened a PR to fix the problem in RooRealIntegral. It's a first step, but it will probably take more time before this gets merge, as the RooRealIntegral is not covered that well by unit tests yet, and I want to first write more tests for the part of the code that I changed. I already have added one test based on your example, but I still need to cover the case where the integrated function has shape clients.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:380,reliability,integr,integrated,380,"I have opened a PR to fix the problem in RooRealIntegral. It's a first step, but it will probably take more time before this gets merge, as the RooRealIntegral is not covered that well by unit tests yet, and I want to first write more tests for the part of the code that I changed. I already have added one test based on your example, but I still need to cover the case where the integrated function has shape clients.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:193,safety,test,tests,193,"I have opened a PR to fix the problem in RooRealIntegral. It's a first step, but it will probably take more time before this gets merge, as the RooRealIntegral is not covered that well by unit tests yet, and I want to first write more tests for the part of the code that I changed. I already have added one test based on your example, but I still need to cover the case where the integrated function has shape clients.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:235,safety,test,tests,235,"I have opened a PR to fix the problem in RooRealIntegral. It's a first step, but it will probably take more time before this gets merge, as the RooRealIntegral is not covered that well by unit tests yet, and I want to first write more tests for the part of the code that I changed. I already have added one test based on your example, but I still need to cover the case where the integrated function has shape clients.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:307,safety,test,test,307,"I have opened a PR to fix the problem in RooRealIntegral. It's a first step, but it will probably take more time before this gets merge, as the RooRealIntegral is not covered that well by unit tests yet, and I want to first write more tests for the part of the code that I changed. I already have added one test based on your example, but I still need to cover the case where the integrated function has shape clients.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:380,security,integr,integrated,380,"I have opened a PR to fix the problem in RooRealIntegral. It's a first step, but it will probably take more time before this gets merge, as the RooRealIntegral is not covered that well by unit tests yet, and I want to first write more tests for the part of the code that I changed. I already have added one test based on your example, but I still need to cover the case where the integrated function has shape clients.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:188,testability,unit,unit,188,"I have opened a PR to fix the problem in RooRealIntegral. It's a first step, but it will probably take more time before this gets merge, as the RooRealIntegral is not covered that well by unit tests yet, and I want to first write more tests for the part of the code that I changed. I already have added one test based on your example, but I still need to cover the case where the integrated function has shape clients.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:193,testability,test,tests,193,"I have opened a PR to fix the problem in RooRealIntegral. It's a first step, but it will probably take more time before this gets merge, as the RooRealIntegral is not covered that well by unit tests yet, and I want to first write more tests for the part of the code that I changed. I already have added one test based on your example, but I still need to cover the case where the integrated function has shape clients.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:235,testability,test,tests,235,"I have opened a PR to fix the problem in RooRealIntegral. It's a first step, but it will probably take more time before this gets merge, as the RooRealIntegral is not covered that well by unit tests yet, and I want to first write more tests for the part of the code that I changed. I already have added one test based on your example, but I still need to cover the case where the integrated function has shape clients.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:307,testability,test,test,307,"I have opened a PR to fix the problem in RooRealIntegral. It's a first step, but it will probably take more time before this gets merge, as the RooRealIntegral is not covered that well by unit tests yet, and I want to first write more tests for the part of the code that I changed. I already have added one test based on your example, but I still need to cover the case where the integrated function has shape clients.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:380,testability,integr,integrated,380,"I have opened a PR to fix the problem in RooRealIntegral. It's a first step, but it will probably take more time before this gets merge, as the RooRealIntegral is not covered that well by unit tests yet, and I want to first write more tests for the part of the code that I changed. I already have added one test based on your example, but I still need to cover the case where the integrated function has shape clients.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:90,safety,test,tests,90,Thank you for looking into this! . Are you saying this is a first step due to the missing tests or because more work is needed after the PR?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:90,testability,test,tests,90,Thank you for looking into this! . Are you saying this is a first step due to the missing tests or because more work is needed after the PR?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:144,deployability,patch,patch,144,"Yes, just because of the missing tests to cover the code changes of RooRealIntegral. If it's tested well enough I could even backport it to the patch release maybe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:150,deployability,releas,release,150,"Yes, just because of the missing tests to cover the code changes of RooRealIntegral. If it's tested well enough I could even backport it to the patch release maybe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:33,safety,test,tests,33,"Yes, just because of the missing tests to cover the code changes of RooRealIntegral. If it's tested well enough I could even backport it to the patch release maybe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:93,safety,test,tested,93,"Yes, just because of the missing tests to cover the code changes of RooRealIntegral. If it's tested well enough I could even backport it to the patch release maybe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:144,safety,patch,patch,144,"Yes, just because of the missing tests to cover the code changes of RooRealIntegral. If it's tested well enough I could even backport it to the patch release maybe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:144,security,patch,patch,144,"Yes, just because of the missing tests to cover the code changes of RooRealIntegral. If it's tested well enough I could even backport it to the patch release maybe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:33,testability,test,tests,33,"Yes, just because of the missing tests to cover the code changes of RooRealIntegral. If it's tested well enough I could even backport it to the patch release maybe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/issues/11578:93,testability,test,tested,93,"Yes, just because of the missing tests to cover the code changes of RooRealIntegral. If it's tested well enough I could even backport it to the patch release maybe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11578
https://github.com/root-project/root/pull/11582:36,usability,support,support,36,I don't see how this will get us to support GCC 4.8 again...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11582
https://github.com/root-project/root/pull/11582:25,availability,error,error,25,I think it would fix the error reported here https://github.com/root-project/root/pull/11571#issuecomment-1280484047,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11582
https://github.com/root-project/root/pull/11582:25,performance,error,error,25,I think it would fix the error reported here https://github.com/root-project/root/pull/11571#issuecomment-1280484047,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11582
https://github.com/root-project/root/pull/11582:25,safety,error,error,25,I think it would fix the error reported here https://github.com/root-project/root/pull/11571#issuecomment-1280484047,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11582
https://github.com/root-project/root/pull/11582:25,usability,error,error,25,I think it would fix the error reported here https://github.com/root-project/root/pull/11571#issuecomment-1280484047,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11582
https://github.com/root-project/root/pull/11582:71,availability,state,state,71,"Maybe... I'm still going to merge this now to get back to the previous state, and we should carefully evaluate changes for CentOS 7 and Ubuntu 16.04.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11582
https://github.com/root-project/root/pull/11582:71,integrability,state,state,71,"Maybe... I'm still going to merge this now to get back to the previous state, and we should carefully evaluate changes for CentOS 7 and Ubuntu 16.04.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11582
https://github.com/root-project/root/pull/11586:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2204/cxx17, ROOT-ubuntu2004/default, ROOT-ubuntu18.04/nortcxxmod",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11586
https://github.com/root-project/root/pull/11586:27,deployability,updat,updating,27,"Hi @axmat, . Thank you for updating the PR. Can you please fix the warnings ? Thank you !",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11586
https://github.com/root-project/root/pull/11586:27,safety,updat,updating,27,"Hi @axmat, . Thank you for updating the PR. Can you please fix the warnings ? Thank you !",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11586
https://github.com/root-project/root/pull/11586:27,security,updat,updating,27,"Hi @axmat, . Thank you for updating the PR. Can you please fix the warnings ? Thank you !",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11586
https://github.com/root-project/root/pull/11586:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2204/cxx17, ROOT-ubuntu2004/default, ROOT-ubuntu18.04/nortcxxmod",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11586
https://github.com/root-project/root/issues/11587:57,deployability,upgrad,upgrade,57,"> in C++20. Unfortunately until we complete the on-going upgrade of the LLVM/Clang version we use for Cling, ROOT is not yet supporting `C++20` (Related notes, you also need to build ROOT and your code with the same version of C++ standard. The `ROOT` cmake would then detect when not to use items already provided by the standard).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11587
https://github.com/root-project/root/issues/11587:83,deployability,version,version,83,"> in C++20. Unfortunately until we complete the on-going upgrade of the LLVM/Clang version we use for Cling, ROOT is not yet supporting `C++20` (Related notes, you also need to build ROOT and your code with the same version of C++ standard. The `ROOT` cmake would then detect when not to use items already provided by the standard).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11587
https://github.com/root-project/root/issues/11587:177,deployability,build,build,177,"> in C++20. Unfortunately until we complete the on-going upgrade of the LLVM/Clang version we use for Cling, ROOT is not yet supporting `C++20` (Related notes, you also need to build ROOT and your code with the same version of C++ standard. The `ROOT` cmake would then detect when not to use items already provided by the standard).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11587
https://github.com/root-project/root/issues/11587:216,deployability,version,version,216,"> in C++20. Unfortunately until we complete the on-going upgrade of the LLVM/Clang version we use for Cling, ROOT is not yet supporting `C++20` (Related notes, you also need to build ROOT and your code with the same version of C++ standard. The `ROOT` cmake would then detect when not to use items already provided by the standard).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11587
https://github.com/root-project/root/issues/11587:83,integrability,version,version,83,"> in C++20. Unfortunately until we complete the on-going upgrade of the LLVM/Clang version we use for Cling, ROOT is not yet supporting `C++20` (Related notes, you also need to build ROOT and your code with the same version of C++ standard. The `ROOT` cmake would then detect when not to use items already provided by the standard).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11587
https://github.com/root-project/root/issues/11587:216,integrability,version,version,216,"> in C++20. Unfortunately until we complete the on-going upgrade of the LLVM/Clang version we use for Cling, ROOT is not yet supporting `C++20` (Related notes, you also need to build ROOT and your code with the same version of C++ standard. The `ROOT` cmake would then detect when not to use items already provided by the standard).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11587
https://github.com/root-project/root/issues/11587:231,interoperability,standard,standard,231,"> in C++20. Unfortunately until we complete the on-going upgrade of the LLVM/Clang version we use for Cling, ROOT is not yet supporting `C++20` (Related notes, you also need to build ROOT and your code with the same version of C++ standard. The `ROOT` cmake would then detect when not to use items already provided by the standard).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11587
https://github.com/root-project/root/issues/11587:322,interoperability,standard,standard,322,"> in C++20. Unfortunately until we complete the on-going upgrade of the LLVM/Clang version we use for Cling, ROOT is not yet supporting `C++20` (Related notes, you also need to build ROOT and your code with the same version of C++ standard. The `ROOT` cmake would then detect when not to use items already provided by the standard).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11587
https://github.com/root-project/root/issues/11587:57,modifiability,upgrad,upgrade,57,"> in C++20. Unfortunately until we complete the on-going upgrade of the LLVM/Clang version we use for Cling, ROOT is not yet supporting `C++20` (Related notes, you also need to build ROOT and your code with the same version of C++ standard. The `ROOT` cmake would then detect when not to use items already provided by the standard).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11587
https://github.com/root-project/root/issues/11587:83,modifiability,version,version,83,"> in C++20. Unfortunately until we complete the on-going upgrade of the LLVM/Clang version we use for Cling, ROOT is not yet supporting `C++20` (Related notes, you also need to build ROOT and your code with the same version of C++ standard. The `ROOT` cmake would then detect when not to use items already provided by the standard).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11587
https://github.com/root-project/root/issues/11587:216,modifiability,version,version,216,"> in C++20. Unfortunately until we complete the on-going upgrade of the LLVM/Clang version we use for Cling, ROOT is not yet supporting `C++20` (Related notes, you also need to build ROOT and your code with the same version of C++ standard. The `ROOT` cmake would then detect when not to use items already provided by the standard).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11587
https://github.com/root-project/root/issues/11587:35,safety,compl,complete,35,"> in C++20. Unfortunately until we complete the on-going upgrade of the LLVM/Clang version we use for Cling, ROOT is not yet supporting `C++20` (Related notes, you also need to build ROOT and your code with the same version of C++ standard. The `ROOT` cmake would then detect when not to use items already provided by the standard).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11587
https://github.com/root-project/root/issues/11587:269,safety,detect,detect,269,"> in C++20. Unfortunately until we complete the on-going upgrade of the LLVM/Clang version we use for Cling, ROOT is not yet supporting `C++20` (Related notes, you also need to build ROOT and your code with the same version of C++ standard. The `ROOT` cmake would then detect when not to use items already provided by the standard).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11587
https://github.com/root-project/root/issues/11587:35,security,compl,complete,35,"> in C++20. Unfortunately until we complete the on-going upgrade of the LLVM/Clang version we use for Cling, ROOT is not yet supporting `C++20` (Related notes, you also need to build ROOT and your code with the same version of C++ standard. The `ROOT` cmake would then detect when not to use items already provided by the standard).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11587
https://github.com/root-project/root/issues/11587:269,security,detect,detect,269,"> in C++20. Unfortunately until we complete the on-going upgrade of the LLVM/Clang version we use for Cling, ROOT is not yet supporting `C++20` (Related notes, you also need to build ROOT and your code with the same version of C++ standard. The `ROOT` cmake would then detect when not to use items already provided by the standard).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11587
https://github.com/root-project/root/issues/11587:125,usability,support,supporting,125,"> in C++20. Unfortunately until we complete the on-going upgrade of the LLVM/Clang version we use for Cling, ROOT is not yet supporting `C++20` (Related notes, you also need to build ROOT and your code with the same version of C++ standard. The `ROOT` cmake would then detect when not to use items already provided by the standard).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11587
https://github.com/root-project/root/issues/11587:24,safety,input,input,24,"Got it, thanks for your input!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11587
https://github.com/root-project/root/issues/11587:24,usability,input,input,24,"Got it, thanks for your input!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11587
https://github.com/root-project/root/pull/11588:11,deployability,build,build,11,@phsft-bot build just on windows10/cxx14,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:132,security,sign,signature,132,> I still don't like the implementation of TSystem::DirName(). I don't think there is any much better solution without changing the signature (i.e. `const char*` to `std::string` would help).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:185,usability,help,help,185,> I still don't like the implementation of TSystem::DirName(). I don't think there is any much better solution without changing the signature (i.e. `const char*` to `std::string` would help).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:96,availability,error,error,96,It says: . `Jenkins CI build  Build failed `. but I cannot access the details concerning build error. Let me know if something else is needed from my side.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:23,deployability,build,build,23,It says: . `Jenkins CI build  Build failed `. but I cannot access the details concerning build error. Let me know if something else is needed from my side.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:31,deployability,Build,Build,31,It says: . `Jenkins CI build  Build failed `. but I cannot access the details concerning build error. Let me know if something else is needed from my side.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:37,deployability,fail,failed,37,It says: . `Jenkins CI build  Build failed `. but I cannot access the details concerning build error. Let me know if something else is needed from my side.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:90,deployability,build,build,90,It says: . `Jenkins CI build  Build failed `. but I cannot access the details concerning build error. Let me know if something else is needed from my side.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:79,modifiability,concern,concerning,79,It says: . `Jenkins CI build  Build failed `. but I cannot access the details concerning build error. Let me know if something else is needed from my side.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:96,performance,error,error,96,It says: . `Jenkins CI build  Build failed `. but I cannot access the details concerning build error. Let me know if something else is needed from my side.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:37,reliability,fail,failed,37,It says: . `Jenkins CI build  Build failed `. but I cannot access the details concerning build error. Let me know if something else is needed from my side.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:96,safety,error,error,96,It says: . `Jenkins CI build  Build failed `. but I cannot access the details concerning build error. Let me know if something else is needed from my side.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:60,security,access,access,60,It says: . `Jenkins CI build  Build failed `. but I cannot access the details concerning build error. Let me know if something else is needed from my side.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:79,testability,concern,concerning,79,It says: . `Jenkins CI build  Build failed `. but I cannot access the details concerning build error. Let me know if something else is needed from my side.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:96,usability,error,error,96,It says: . `Jenkins CI build  Build failed `. but I cannot access the details concerning build error. Let me know if something else is needed from my side.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:95,availability,error,error,95,"> It says: `Jenkins CI build  Build failed ` but I cannot access the details concerning build error. You can click on the link in the comment by @phsft-bot (see quoted below). > Build failed on windows10/cxx14. Running on null:C:\build\workspace\root-pullrequests-build [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157660/console). Otherwise, we could just start a new build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:307,availability,servic,services,307,"> It says: `Jenkins CI build  Build failed ` but I cannot access the details concerning build error. You can click on the link in the comment by @phsft-bot (see quoted below). > Build failed on windows10/cxx14. Running on null:C:\build\workspace\root-pullrequests-build [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157660/console). Otherwise, we could just start a new build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:23,deployability,build,build,23,"> It says: `Jenkins CI build  Build failed ` but I cannot access the details concerning build error. You can click on the link in the comment by @phsft-bot (see quoted below). > Build failed on windows10/cxx14. Running on null:C:\build\workspace\root-pullrequests-build [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157660/console). Otherwise, we could just start a new build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:31,deployability,Build,Build,31,"> It says: `Jenkins CI build  Build failed ` but I cannot access the details concerning build error. You can click on the link in the comment by @phsft-bot (see quoted below). > Build failed on windows10/cxx14. Running on null:C:\build\workspace\root-pullrequests-build [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157660/console). Otherwise, we could just start a new build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:37,deployability,fail,failed,37,"> It says: `Jenkins CI build  Build failed ` but I cannot access the details concerning build error. You can click on the link in the comment by @phsft-bot (see quoted below). > Build failed on windows10/cxx14. Running on null:C:\build\workspace\root-pullrequests-build [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157660/console). Otherwise, we could just start a new build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:89,deployability,build,build,89,"> It says: `Jenkins CI build  Build failed ` but I cannot access the details concerning build error. You can click on the link in the comment by @phsft-bot (see quoted below). > Build failed on windows10/cxx14. Running on null:C:\build\workspace\root-pullrequests-build [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157660/console). Otherwise, we could just start a new build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:179,deployability,Build,Build,179,"> It says: `Jenkins CI build  Build failed ` but I cannot access the details concerning build error. You can click on the link in the comment by @phsft-bot (see quoted below). > Build failed on windows10/cxx14. Running on null:C:\build\workspace\root-pullrequests-build [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157660/console). Otherwise, we could just start a new build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:185,deployability,fail,failed,185,"> It says: `Jenkins CI build  Build failed ` but I cannot access the details concerning build error. You can click on the link in the comment by @phsft-bot (see quoted below). > Build failed on windows10/cxx14. Running on null:C:\build\workspace\root-pullrequests-build [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157660/console). Otherwise, we could just start a new build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:231,deployability,build,build,231,"> It says: `Jenkins CI build  Build failed ` but I cannot access the details concerning build error. You can click on the link in the comment by @phsft-bot (see quoted below). > Build failed on windows10/cxx14. Running on null:C:\build\workspace\root-pullrequests-build [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157660/console). Otherwise, we could just start a new build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:265,deployability,build,build,265,"> It says: `Jenkins CI build  Build failed ` but I cannot access the details concerning build error. You can click on the link in the comment by @phsft-bot (see quoted below). > Build failed on windows10/cxx14. Running on null:C:\build\workspace\root-pullrequests-build [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157660/console). Otherwise, we could just start a new build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:307,deployability,servic,services,307,"> It says: `Jenkins CI build  Build failed ` but I cannot access the details concerning build error. You can click on the link in the comment by @phsft-bot (see quoted below). > Build failed on windows10/cxx14. Running on null:C:\build\workspace\root-pullrequests-build [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157660/console). Otherwise, we could just start a new build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:359,deployability,build,build,359,"> It says: `Jenkins CI build  Build failed ` but I cannot access the details concerning build error. You can click on the link in the comment by @phsft-bot (see quoted below). > Build failed on windows10/cxx14. Running on null:C:\build\workspace\root-pullrequests-build [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157660/console). Otherwise, we could just start a new build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:419,deployability,build,build,419,"> It says: `Jenkins CI build  Build failed ` but I cannot access the details concerning build error. You can click on the link in the comment by @phsft-bot (see quoted below). > Build failed on windows10/cxx14. Running on null:C:\build\workspace\root-pullrequests-build [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157660/console). Otherwise, we could just start a new build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:307,integrability,servic,services,307,"> It says: `Jenkins CI build  Build failed ` but I cannot access the details concerning build error. You can click on the link in the comment by @phsft-bot (see quoted below). > Build failed on windows10/cxx14. Running on null:C:\build\workspace\root-pullrequests-build [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157660/console). Otherwise, we could just start a new build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:78,modifiability,concern,concerning,78,"> It says: `Jenkins CI build  Build failed ` but I cannot access the details concerning build error. You can click on the link in the comment by @phsft-bot (see quoted below). > Build failed on windows10/cxx14. Running on null:C:\build\workspace\root-pullrequests-build [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157660/console). Otherwise, we could just start a new build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:307,modifiability,servic,services,307,"> It says: `Jenkins CI build  Build failed ` but I cannot access the details concerning build error. You can click on the link in the comment by @phsft-bot (see quoted below). > Build failed on windows10/cxx14. Running on null:C:\build\workspace\root-pullrequests-build [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157660/console). Otherwise, we could just start a new build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:95,performance,error,error,95,"> It says: `Jenkins CI build  Build failed ` but I cannot access the details concerning build error. You can click on the link in the comment by @phsft-bot (see quoted below). > Build failed on windows10/cxx14. Running on null:C:\build\workspace\root-pullrequests-build [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157660/console). Otherwise, we could just start a new build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:37,reliability,fail,failed,37,"> It says: `Jenkins CI build  Build failed ` but I cannot access the details concerning build error. You can click on the link in the comment by @phsft-bot (see quoted below). > Build failed on windows10/cxx14. Running on null:C:\build\workspace\root-pullrequests-build [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157660/console). Otherwise, we could just start a new build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:185,reliability,fail,failed,185,"> It says: `Jenkins CI build  Build failed ` but I cannot access the details concerning build error. You can click on the link in the comment by @phsft-bot (see quoted below). > Build failed on windows10/cxx14. Running on null:C:\build\workspace\root-pullrequests-build [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157660/console). Otherwise, we could just start a new build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:95,safety,error,error,95,"> It says: `Jenkins CI build  Build failed ` but I cannot access the details concerning build error. You can click on the link in the comment by @phsft-bot (see quoted below). > Build failed on windows10/cxx14. Running on null:C:\build\workspace\root-pullrequests-build [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157660/console). Otherwise, we could just start a new build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:59,security,access,access,59,"> It says: `Jenkins CI build  Build failed ` but I cannot access the details concerning build error. You can click on the link in the comment by @phsft-bot (see quoted below). > Build failed on windows10/cxx14. Running on null:C:\build\workspace\root-pullrequests-build [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157660/console). Otherwise, we could just start a new build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:78,testability,concern,concerning,78,"> It says: `Jenkins CI build  Build failed ` but I cannot access the details concerning build error. You can click on the link in the comment by @phsft-bot (see quoted below). > Build failed on windows10/cxx14. Running on null:C:\build\workspace\root-pullrequests-build [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157660/console). Otherwise, we could just start a new build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:95,usability,error,error,95,"> It says: `Jenkins CI build  Build failed ` but I cannot access the details concerning build error. You can click on the link in the comment by @phsft-bot (see quoted below). > Build failed on windows10/cxx14. Running on null:C:\build\workspace\root-pullrequests-build [See console output](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157660/console). Otherwise, we could just start a new build.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:52,availability,error,error,52,"Thanks, I see it now. @bellenot any idea where this error might be coming from in Windows? `[2022-10-18T15:48:41.690Z] hudson.AbortException: script returned exit code -1`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:52,performance,error,error,52,"Thanks, I see it now. @bellenot any idea where this error might be coming from in Windows? `[2022-10-18T15:48:41.690Z] hudson.AbortException: script returned exit code -1`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:52,safety,error,error,52,"Thanks, I see it now. @bellenot any idea where this error might be coming from in Windows? `[2022-10-18T15:48:41.690Z] hudson.AbortException: script returned exit code -1`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:52,usability,error,error,52,"Thanks, I see it now. @bellenot any idea where this error might be coming from in Windows? `[2022-10-18T15:48:41.690Z] hudson.AbortException: script returned exit code -1`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:12,availability,failur,failure,12,The windows failure are unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:12,deployability,fail,failure,12,The windows failure are unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:12,performance,failur,failure,12,The windows failure are unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11588:12,reliability,fail,failure,12,The windows failure are unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11588
https://github.com/root-project/root/pull/11590:4,availability,failur,failure,4,The failure looks unrelated,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11590
https://github.com/root-project/root/pull/11590:4,deployability,fail,failure,4,The failure looks unrelated,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11590
https://github.com/root-project/root/pull/11590:4,performance,failur,failure,4,The failure looks unrelated,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11590
https://github.com/root-project/root/pull/11590:4,reliability,fail,failure,4,The failure looks unrelated,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11590
https://github.com/root-project/root/pull/11590:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11590
https://github.com/root-project/root/pull/11591:0,availability,Failur,Failures,0,"Failures look unrelated, although there are quite many. [root_meta_evolution_runforeign](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157629/testReport/projectroot.roottest.root.meta/evolution/roottest_root_meta_evolution_runforeign/) in particular fails on all platforms",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11591
https://github.com/root-project/root/pull/11591:104,availability,servic,services,104,"Failures look unrelated, although there are quite many. [root_meta_evolution_runforeign](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157629/testReport/projectroot.roottest.root.meta/evolution/roottest_root_meta_evolution_runforeign/) in particular fails on all platforms",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11591
https://github.com/root-project/root/pull/11591:0,deployability,Fail,Failures,0,"Failures look unrelated, although there are quite many. [root_meta_evolution_runforeign](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157629/testReport/projectroot.roottest.root.meta/evolution/roottest_root_meta_evolution_runforeign/) in particular fails on all platforms",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11591
https://github.com/root-project/root/pull/11591:104,deployability,servic,services,104,"Failures look unrelated, although there are quite many. [root_meta_evolution_runforeign](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157629/testReport/projectroot.roottest.root.meta/evolution/roottest_root_meta_evolution_runforeign/) in particular fails on all platforms",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11591
https://github.com/root-project/root/pull/11591:156,deployability,build,build,156,"Failures look unrelated, although there are quite many. [root_meta_evolution_runforeign](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157629/testReport/projectroot.roottest.root.meta/evolution/roottest_root_meta_evolution_runforeign/) in particular fails on all platforms",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11591
https://github.com/root-project/root/pull/11591:277,deployability,fail,fails,277,"Failures look unrelated, although there are quite many. [root_meta_evolution_runforeign](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157629/testReport/projectroot.roottest.root.meta/evolution/roottest_root_meta_evolution_runforeign/) in particular fails on all platforms",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11591
https://github.com/root-project/root/pull/11591:104,integrability,servic,services,104,"Failures look unrelated, although there are quite many. [root_meta_evolution_runforeign](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157629/testReport/projectroot.roottest.root.meta/evolution/roottest_root_meta_evolution_runforeign/) in particular fails on all platforms",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11591
https://github.com/root-project/root/pull/11591:290,interoperability,platform,platforms,290,"Failures look unrelated, although there are quite many. [root_meta_evolution_runforeign](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157629/testReport/projectroot.roottest.root.meta/evolution/roottest_root_meta_evolution_runforeign/) in particular fails on all platforms",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11591
https://github.com/root-project/root/pull/11591:104,modifiability,servic,services,104,"Failures look unrelated, although there are quite many. [root_meta_evolution_runforeign](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157629/testReport/projectroot.roottest.root.meta/evolution/roottest_root_meta_evolution_runforeign/) in particular fails on all platforms",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11591
https://github.com/root-project/root/pull/11591:0,performance,Failur,Failures,0,"Failures look unrelated, although there are quite many. [root_meta_evolution_runforeign](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157629/testReport/projectroot.roottest.root.meta/evolution/roottest_root_meta_evolution_runforeign/) in particular fails on all platforms",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11591
https://github.com/root-project/root/pull/11591:0,reliability,Fail,Failures,0,"Failures look unrelated, although there are quite many. [root_meta_evolution_runforeign](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157629/testReport/projectroot.roottest.root.meta/evolution/roottest_root_meta_evolution_runforeign/) in particular fails on all platforms",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11591
https://github.com/root-project/root/pull/11591:277,reliability,fail,fails,277,"Failures look unrelated, although there are quite many. [root_meta_evolution_runforeign](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157629/testReport/projectroot.roottest.root.meta/evolution/roottest_root_meta_evolution_runforeign/) in particular fails on all platforms",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11591
https://github.com/root-project/root/pull/11591:169,safety,test,testReport,169,"Failures look unrelated, although there are quite many. [root_meta_evolution_runforeign](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157629/testReport/projectroot.roottest.root.meta/evolution/roottest_root_meta_evolution_runforeign/) in particular fails on all platforms",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11591
https://github.com/root-project/root/pull/11591:169,testability,test,testReport,169,"Failures look unrelated, although there are quite many. [root_meta_evolution_runforeign](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/157629/testReport/projectroot.roottest.root.meta/evolution/roottest_root_meta_evolution_runforeign/) in particular fails on all platforms",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11591
https://github.com/root-project/root/pull/11591:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11591
https://github.com/root-project/root/pull/11592:380,integrability,inject,injected,380,"@hahnjo for `vector<char>` it's all fine, there is actually a test for it [here](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/stl_vector.py#L18) and it succeeds, meaning that our pythonization for `std::vector` runs fine. The fact that `value_type` for `vector<char>` in Python is the Python string `""char""` is due to another pythonization injected by cppyy itself [here](https://github.com/root-project/root/blob/07932d78211d0ac5fdb198ac2260c35530cb9647/bindings/pyroot/cppyy/CPyCppyy/src/Pythonize.cxx#L1159). Simple test:. ```python. >>> import ROOT. >>> a = ROOT.std.vector['char'].value_type. >>> a. 'char'. >>> type(a). <class 'str'>. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11592
https://github.com/root-project/root/pull/11592:130,interoperability,bind,bindings,130,"@hahnjo for `vector<char>` it's all fine, there is actually a test for it [here](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/stl_vector.py#L18) and it succeeds, meaning that our pythonization for `std::vector` runs fine. The fact that `value_type` for `vector<char>` in Python is the Python string `""char""` is due to another pythonization injected by cppyy itself [here](https://github.com/root-project/root/blob/07932d78211d0ac5fdb198ac2260c35530cb9647/bindings/pyroot/cppyy/CPyCppyy/src/Pythonize.cxx#L1159). Simple test:. ```python. >>> import ROOT. >>> a = ROOT.std.vector['char'].value_type. >>> a. 'char'. >>> type(a). <class 'str'>. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11592
https://github.com/root-project/root/pull/11592:495,interoperability,bind,bindings,495,"@hahnjo for `vector<char>` it's all fine, there is actually a test for it [here](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/stl_vector.py#L18) and it succeeds, meaning that our pythonization for `std::vector` runs fine. The fact that `value_type` for `vector<char>` in Python is the Python string `""char""` is due to another pythonization injected by cppyy itself [here](https://github.com/root-project/root/blob/07932d78211d0ac5fdb198ac2260c35530cb9647/bindings/pyroot/cppyy/CPyCppyy/src/Pythonize.cxx#L1159). Simple test:. ```python. >>> import ROOT. >>> a = ROOT.std.vector['char'].value_type. >>> a. 'char'. >>> type(a). <class 'str'>. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11592
https://github.com/root-project/root/pull/11592:130,modifiability,bind,bindings,130,"@hahnjo for `vector<char>` it's all fine, there is actually a test for it [here](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/stl_vector.py#L18) and it succeeds, meaning that our pythonization for `std::vector` runs fine. The fact that `value_type` for `vector<char>` in Python is the Python string `""char""` is due to another pythonization injected by cppyy itself [here](https://github.com/root-project/root/blob/07932d78211d0ac5fdb198ac2260c35530cb9647/bindings/pyroot/cppyy/CPyCppyy/src/Pythonize.cxx#L1159). Simple test:. ```python. >>> import ROOT. >>> a = ROOT.std.vector['char'].value_type. >>> a. 'char'. >>> type(a). <class 'str'>. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11592
https://github.com/root-project/root/pull/11592:495,modifiability,bind,bindings,495,"@hahnjo for `vector<char>` it's all fine, there is actually a test for it [here](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/stl_vector.py#L18) and it succeeds, meaning that our pythonization for `std::vector` runs fine. The fact that `value_type` for `vector<char>` in Python is the Python string `""char""` is due to another pythonization injected by cppyy itself [here](https://github.com/root-project/root/blob/07932d78211d0ac5fdb198ac2260c35530cb9647/bindings/pyroot/cppyy/CPyCppyy/src/Pythonize.cxx#L1159). Simple test:. ```python. >>> import ROOT. >>> a = ROOT.std.vector['char'].value_type. >>> a. 'char'. >>> type(a). <class 'str'>. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11592
https://github.com/root-project/root/pull/11592:62,safety,test,test,62,"@hahnjo for `vector<char>` it's all fine, there is actually a test for it [here](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/stl_vector.py#L18) and it succeeds, meaning that our pythonization for `std::vector` runs fine. The fact that `value_type` for `vector<char>` in Python is the Python string `""char""` is due to another pythonization injected by cppyy itself [here](https://github.com/root-project/root/blob/07932d78211d0ac5fdb198ac2260c35530cb9647/bindings/pyroot/cppyy/CPyCppyy/src/Pythonize.cxx#L1159). Simple test:. ```python. >>> import ROOT. >>> a = ROOT.std.vector['char'].value_type. >>> a. 'char'. >>> type(a). <class 'str'>. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11592
https://github.com/root-project/root/pull/11592:161,safety,test,test,161,"@hahnjo for `vector<char>` it's all fine, there is actually a test for it [here](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/stl_vector.py#L18) and it succeeds, meaning that our pythonization for `std::vector` runs fine. The fact that `value_type` for `vector<char>` in Python is the Python string `""char""` is due to another pythonization injected by cppyy itself [here](https://github.com/root-project/root/blob/07932d78211d0ac5fdb198ac2260c35530cb9647/bindings/pyroot/cppyy/CPyCppyy/src/Pythonize.cxx#L1159). Simple test:. ```python. >>> import ROOT. >>> a = ROOT.std.vector['char'].value_type. >>> a. 'char'. >>> type(a). <class 'str'>. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11592
https://github.com/root-project/root/pull/11592:559,safety,test,test,559,"@hahnjo for `vector<char>` it's all fine, there is actually a test for it [here](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/stl_vector.py#L18) and it succeeds, meaning that our pythonization for `std::vector` runs fine. The fact that `value_type` for `vector<char>` in Python is the Python string `""char""` is due to another pythonization injected by cppyy itself [here](https://github.com/root-project/root/blob/07932d78211d0ac5fdb198ac2260c35530cb9647/bindings/pyroot/cppyy/CPyCppyy/src/Pythonize.cxx#L1159). Simple test:. ```python. >>> import ROOT. >>> a = ROOT.std.vector['char'].value_type. >>> a. 'char'. >>> type(a). <class 'str'>. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11592
https://github.com/root-project/root/pull/11592:380,security,inject,injected,380,"@hahnjo for `vector<char>` it's all fine, there is actually a test for it [here](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/stl_vector.py#L18) and it succeeds, meaning that our pythonization for `std::vector` runs fine. The fact that `value_type` for `vector<char>` in Python is the Python string `""char""` is due to another pythonization injected by cppyy itself [here](https://github.com/root-project/root/blob/07932d78211d0ac5fdb198ac2260c35530cb9647/bindings/pyroot/cppyy/CPyCppyy/src/Pythonize.cxx#L1159). Simple test:. ```python. >>> import ROOT. >>> a = ROOT.std.vector['char'].value_type. >>> a. 'char'. >>> type(a). <class 'str'>. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11592
https://github.com/root-project/root/pull/11592:62,testability,test,test,62,"@hahnjo for `vector<char>` it's all fine, there is actually a test for it [here](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/stl_vector.py#L18) and it succeeds, meaning that our pythonization for `std::vector` runs fine. The fact that `value_type` for `vector<char>` in Python is the Python string `""char""` is due to another pythonization injected by cppyy itself [here](https://github.com/root-project/root/blob/07932d78211d0ac5fdb198ac2260c35530cb9647/bindings/pyroot/cppyy/CPyCppyy/src/Pythonize.cxx#L1159). Simple test:. ```python. >>> import ROOT. >>> a = ROOT.std.vector['char'].value_type. >>> a. 'char'. >>> type(a). <class 'str'>. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11592
https://github.com/root-project/root/pull/11592:161,testability,test,test,161,"@hahnjo for `vector<char>` it's all fine, there is actually a test for it [here](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/stl_vector.py#L18) and it succeeds, meaning that our pythonization for `std::vector` runs fine. The fact that `value_type` for `vector<char>` in Python is the Python string `""char""` is due to another pythonization injected by cppyy itself [here](https://github.com/root-project/root/blob/07932d78211d0ac5fdb198ac2260c35530cb9647/bindings/pyroot/cppyy/CPyCppyy/src/Pythonize.cxx#L1159). Simple test:. ```python. >>> import ROOT. >>> a = ROOT.std.vector['char'].value_type. >>> a. 'char'. >>> type(a). <class 'str'>. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11592
https://github.com/root-project/root/pull/11592:552,testability,Simpl,Simple,552,"@hahnjo for `vector<char>` it's all fine, there is actually a test for it [here](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/stl_vector.py#L18) and it succeeds, meaning that our pythonization for `std::vector` runs fine. The fact that `value_type` for `vector<char>` in Python is the Python string `""char""` is due to another pythonization injected by cppyy itself [here](https://github.com/root-project/root/blob/07932d78211d0ac5fdb198ac2260c35530cb9647/bindings/pyroot/cppyy/CPyCppyy/src/Pythonize.cxx#L1159). Simple test:. ```python. >>> import ROOT. >>> a = ROOT.std.vector['char'].value_type. >>> a. 'char'. >>> type(a). <class 'str'>. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11592
https://github.com/root-project/root/pull/11592:559,testability,test,test,559,"@hahnjo for `vector<char>` it's all fine, there is actually a test for it [here](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/stl_vector.py#L18) and it succeeds, meaning that our pythonization for `std::vector` runs fine. The fact that `value_type` for `vector<char>` in Python is the Python string `""char""` is due to another pythonization injected by cppyy itself [here](https://github.com/root-project/root/blob/07932d78211d0ac5fdb198ac2260c35530cb9647/bindings/pyroot/cppyy/CPyCppyy/src/Pythonize.cxx#L1159). Simple test:. ```python. >>> import ROOT. >>> a = ROOT.std.vector['char'].value_type. >>> a. 'char'. >>> type(a). <class 'str'>. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11592
https://github.com/root-project/root/pull/11592:552,usability,Simpl,Simple,552,"@hahnjo for `vector<char>` it's all fine, there is actually a test for it [here](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/stl_vector.py#L18) and it succeeds, meaning that our pythonization for `std::vector` runs fine. The fact that `value_type` for `vector<char>` in Python is the Python string `""char""` is due to another pythonization injected by cppyy itself [here](https://github.com/root-project/root/blob/07932d78211d0ac5fdb198ac2260c35530cb9647/bindings/pyroot/cppyy/CPyCppyy/src/Pythonize.cxx#L1159). Simple test:. ```python. >>> import ROOT. >>> a = ROOT.std.vector['char'].value_type. >>> a. 'char'. >>> type(a). <class 'str'>. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11592
https://github.com/root-project/root/pull/11593:11,deployability,build,build,11,@phsft-bot build just on windows10/cxx14,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11593
https://github.com/root-project/root/pull/11595:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2204/cxx17, ROOT-ubuntu2004/default, ROOT-ubuntu18.04/nortcxxmod",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11595
https://github.com/root-project/root/pull/11595:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2204/cxx17, ROOT-ubuntu2004/default, ROOT-ubuntu18.04/nortcxxmod.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11595
https://github.com/root-project/root/issues/11596:24,integrability,sub,subtle,24,"Indeed, it's a bit more subtle. There is a pythonization happening [here](https://github.com/root-project/root/blob/07932d78211d0ac5fdb198ac2260c35530cb9647/bindings/pyroot/cppyy/CPyCppyy/src/Pythonize.cxx#L1158-L1160), which transforms the type given by `::value_type` to a string and sets the corresponding Python attribute. Probably for `const char *` the type is not properly parsed thus the attribute is not set.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11596
https://github.com/root-project/root/issues/11596:226,integrability,transform,transforms,226,"Indeed, it's a bit more subtle. There is a pythonization happening [here](https://github.com/root-project/root/blob/07932d78211d0ac5fdb198ac2260c35530cb9647/bindings/pyroot/cppyy/CPyCppyy/src/Pythonize.cxx#L1158-L1160), which transforms the type given by `::value_type` to a string and sets the corresponding Python attribute. Probably for `const char *` the type is not properly parsed thus the attribute is not set.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11596
https://github.com/root-project/root/issues/11596:157,interoperability,bind,bindings,157,"Indeed, it's a bit more subtle. There is a pythonization happening [here](https://github.com/root-project/root/blob/07932d78211d0ac5fdb198ac2260c35530cb9647/bindings/pyroot/cppyy/CPyCppyy/src/Pythonize.cxx#L1158-L1160), which transforms the type given by `::value_type` to a string and sets the corresponding Python attribute. Probably for `const char *` the type is not properly parsed thus the attribute is not set.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11596
https://github.com/root-project/root/issues/11596:226,interoperability,transform,transforms,226,"Indeed, it's a bit more subtle. There is a pythonization happening [here](https://github.com/root-project/root/blob/07932d78211d0ac5fdb198ac2260c35530cb9647/bindings/pyroot/cppyy/CPyCppyy/src/Pythonize.cxx#L1158-L1160), which transforms the type given by `::value_type` to a string and sets the corresponding Python attribute. Probably for `const char *` the type is not properly parsed thus the attribute is not set.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11596
https://github.com/root-project/root/issues/11596:157,modifiability,bind,bindings,157,"Indeed, it's a bit more subtle. There is a pythonization happening [here](https://github.com/root-project/root/blob/07932d78211d0ac5fdb198ac2260c35530cb9647/bindings/pyroot/cppyy/CPyCppyy/src/Pythonize.cxx#L1158-L1160), which transforms the type given by `::value_type` to a string and sets the corresponding Python attribute. Probably for `const char *` the type is not properly parsed thus the attribute is not set.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11596
https://github.com/root-project/root/issues/11596:675,deployability,fail,fails,675,"The issue seems to be with [this line in particular](https://github.com/root-project/root/blob/07932d78211d0ac5fdb198ac2260c35530cb9647/bindings/pyroot/cppyy/CPyCppyy/src/Pythonize.cxx#L1152):. ```cpp. const std::string& vtype = Cppyy::ResolveName(name+""::value_type"");. size_t typesz = Cppyy::SizeOf(vtype);. ```. In the reproducer case, this is equivalent to calling `Cppyy::SizeOf(""const char *"")`. This will call [`SizeOf(const std::string &)`](https://github.com/root-project/root/blob/e6fcad7d14d6a7ffa0b59e4557005d88b05ce948/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx#L626). In turn, this first calls `gROOT->GetType(""const char *"")`, which fails, then falls back to calling `SizeOf(GetScope(type_name))`. In `GetScope`, we reach [this part](https://github.com/root-project/root/blob/e6fcad7d14d6a7ffa0b59e4557005d88b05ce948/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx#L531-L536) that calls `TClass::GetClass`. As we can see, this returns nullptr:. ```cpp. root [0] auto cl = TClass::GetClass(""const char *"", true, true);. root [1] cl. (TClass *) nullptr. ```. Thus, the final result of the initial call to `Cppyy::SizeOf(vtype)` is `0`. This means that cppyy thinks that the size of these types (including `const char *`, `const int *` and so on) is zero, thus the attribute is never pythonized. In upstream cppyy, this is fixed by calling `SizeOf` with the original type, instead of the resolved one: https://github.com/wlav/CPyCppyy/blob/master/src/Pythonize.cxx#L1789-L1802. So this should be done in our cppyy too. Reassigning the issue to me, it's not related to cling but cppyy itself",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11596
https://github.com/root-project/root/issues/11596:136,interoperability,bind,bindings,136,"The issue seems to be with [this line in particular](https://github.com/root-project/root/blob/07932d78211d0ac5fdb198ac2260c35530cb9647/bindings/pyroot/cppyy/CPyCppyy/src/Pythonize.cxx#L1152):. ```cpp. const std::string& vtype = Cppyy::ResolveName(name+""::value_type"");. size_t typesz = Cppyy::SizeOf(vtype);. ```. In the reproducer case, this is equivalent to calling `Cppyy::SizeOf(""const char *"")`. This will call [`SizeOf(const std::string &)`](https://github.com/root-project/root/blob/e6fcad7d14d6a7ffa0b59e4557005d88b05ce948/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx#L626). In turn, this first calls `gROOT->GetType(""const char *"")`, which fails, then falls back to calling `SizeOf(GetScope(type_name))`. In `GetScope`, we reach [this part](https://github.com/root-project/root/blob/e6fcad7d14d6a7ffa0b59e4557005d88b05ce948/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx#L531-L536) that calls `TClass::GetClass`. As we can see, this returns nullptr:. ```cpp. root [0] auto cl = TClass::GetClass(""const char *"", true, true);. root [1] cl. (TClass *) nullptr. ```. Thus, the final result of the initial call to `Cppyy::SizeOf(vtype)` is `0`. This means that cppyy thinks that the size of these types (including `const char *`, `const int *` and so on) is zero, thus the attribute is never pythonized. In upstream cppyy, this is fixed by calling `SizeOf` with the original type, instead of the resolved one: https://github.com/wlav/CPyCppyy/blob/master/src/Pythonize.cxx#L1789-L1802. So this should be done in our cppyy too. Reassigning the issue to me, it's not related to cling but cppyy itself",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11596
https://github.com/root-project/root/issues/11596:532,interoperability,bind,bindings,532,"The issue seems to be with [this line in particular](https://github.com/root-project/root/blob/07932d78211d0ac5fdb198ac2260c35530cb9647/bindings/pyroot/cppyy/CPyCppyy/src/Pythonize.cxx#L1152):. ```cpp. const std::string& vtype = Cppyy::ResolveName(name+""::value_type"");. size_t typesz = Cppyy::SizeOf(vtype);. ```. In the reproducer case, this is equivalent to calling `Cppyy::SizeOf(""const char *"")`. This will call [`SizeOf(const std::string &)`](https://github.com/root-project/root/blob/e6fcad7d14d6a7ffa0b59e4557005d88b05ce948/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx#L626). In turn, this first calls `gROOT->GetType(""const char *"")`, which fails, then falls back to calling `SizeOf(GetScope(type_name))`. In `GetScope`, we reach [this part](https://github.com/root-project/root/blob/e6fcad7d14d6a7ffa0b59e4557005d88b05ce948/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx#L531-L536) that calls `TClass::GetClass`. As we can see, this returns nullptr:. ```cpp. root [0] auto cl = TClass::GetClass(""const char *"", true, true);. root [1] cl. (TClass *) nullptr. ```. Thus, the final result of the initial call to `Cppyy::SizeOf(vtype)` is `0`. This means that cppyy thinks that the size of these types (including `const char *`, `const int *` and so on) is zero, thus the attribute is never pythonized. In upstream cppyy, this is fixed by calling `SizeOf` with the original type, instead of the resolved one: https://github.com/wlav/CPyCppyy/blob/master/src/Pythonize.cxx#L1789-L1802. So this should be done in our cppyy too. Reassigning the issue to me, it's not related to cling but cppyy itself",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11596
https://github.com/root-project/root/issues/11596:859,interoperability,bind,bindings,859,"The issue seems to be with [this line in particular](https://github.com/root-project/root/blob/07932d78211d0ac5fdb198ac2260c35530cb9647/bindings/pyroot/cppyy/CPyCppyy/src/Pythonize.cxx#L1152):. ```cpp. const std::string& vtype = Cppyy::ResolveName(name+""::value_type"");. size_t typesz = Cppyy::SizeOf(vtype);. ```. In the reproducer case, this is equivalent to calling `Cppyy::SizeOf(""const char *"")`. This will call [`SizeOf(const std::string &)`](https://github.com/root-project/root/blob/e6fcad7d14d6a7ffa0b59e4557005d88b05ce948/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx#L626). In turn, this first calls `gROOT->GetType(""const char *"")`, which fails, then falls back to calling `SizeOf(GetScope(type_name))`. In `GetScope`, we reach [this part](https://github.com/root-project/root/blob/e6fcad7d14d6a7ffa0b59e4557005d88b05ce948/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx#L531-L536) that calls `TClass::GetClass`. As we can see, this returns nullptr:. ```cpp. root [0] auto cl = TClass::GetClass(""const char *"", true, true);. root [1] cl. (TClass *) nullptr. ```. Thus, the final result of the initial call to `Cppyy::SizeOf(vtype)` is `0`. This means that cppyy thinks that the size of these types (including `const char *`, `const int *` and so on) is zero, thus the attribute is never pythonized. In upstream cppyy, this is fixed by calling `SizeOf` with the original type, instead of the resolved one: https://github.com/wlav/CPyCppyy/blob/master/src/Pythonize.cxx#L1789-L1802. So this should be done in our cppyy too. Reassigning the issue to me, it's not related to cling but cppyy itself",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11596
https://github.com/root-project/root/issues/11596:136,modifiability,bind,bindings,136,"The issue seems to be with [this line in particular](https://github.com/root-project/root/blob/07932d78211d0ac5fdb198ac2260c35530cb9647/bindings/pyroot/cppyy/CPyCppyy/src/Pythonize.cxx#L1152):. ```cpp. const std::string& vtype = Cppyy::ResolveName(name+""::value_type"");. size_t typesz = Cppyy::SizeOf(vtype);. ```. In the reproducer case, this is equivalent to calling `Cppyy::SizeOf(""const char *"")`. This will call [`SizeOf(const std::string &)`](https://github.com/root-project/root/blob/e6fcad7d14d6a7ffa0b59e4557005d88b05ce948/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx#L626). In turn, this first calls `gROOT->GetType(""const char *"")`, which fails, then falls back to calling `SizeOf(GetScope(type_name))`. In `GetScope`, we reach [this part](https://github.com/root-project/root/blob/e6fcad7d14d6a7ffa0b59e4557005d88b05ce948/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx#L531-L536) that calls `TClass::GetClass`. As we can see, this returns nullptr:. ```cpp. root [0] auto cl = TClass::GetClass(""const char *"", true, true);. root [1] cl. (TClass *) nullptr. ```. Thus, the final result of the initial call to `Cppyy::SizeOf(vtype)` is `0`. This means that cppyy thinks that the size of these types (including `const char *`, `const int *` and so on) is zero, thus the attribute is never pythonized. In upstream cppyy, this is fixed by calling `SizeOf` with the original type, instead of the resolved one: https://github.com/wlav/CPyCppyy/blob/master/src/Pythonize.cxx#L1789-L1802. So this should be done in our cppyy too. Reassigning the issue to me, it's not related to cling but cppyy itself",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11596
https://github.com/root-project/root/issues/11596:532,modifiability,bind,bindings,532,"The issue seems to be with [this line in particular](https://github.com/root-project/root/blob/07932d78211d0ac5fdb198ac2260c35530cb9647/bindings/pyroot/cppyy/CPyCppyy/src/Pythonize.cxx#L1152):. ```cpp. const std::string& vtype = Cppyy::ResolveName(name+""::value_type"");. size_t typesz = Cppyy::SizeOf(vtype);. ```. In the reproducer case, this is equivalent to calling `Cppyy::SizeOf(""const char *"")`. This will call [`SizeOf(const std::string &)`](https://github.com/root-project/root/blob/e6fcad7d14d6a7ffa0b59e4557005d88b05ce948/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx#L626). In turn, this first calls `gROOT->GetType(""const char *"")`, which fails, then falls back to calling `SizeOf(GetScope(type_name))`. In `GetScope`, we reach [this part](https://github.com/root-project/root/blob/e6fcad7d14d6a7ffa0b59e4557005d88b05ce948/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx#L531-L536) that calls `TClass::GetClass`. As we can see, this returns nullptr:. ```cpp. root [0] auto cl = TClass::GetClass(""const char *"", true, true);. root [1] cl. (TClass *) nullptr. ```. Thus, the final result of the initial call to `Cppyy::SizeOf(vtype)` is `0`. This means that cppyy thinks that the size of these types (including `const char *`, `const int *` and so on) is zero, thus the attribute is never pythonized. In upstream cppyy, this is fixed by calling `SizeOf` with the original type, instead of the resolved one: https://github.com/wlav/CPyCppyy/blob/master/src/Pythonize.cxx#L1789-L1802. So this should be done in our cppyy too. Reassigning the issue to me, it's not related to cling but cppyy itself",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11596
https://github.com/root-project/root/issues/11596:859,modifiability,bind,bindings,859,"The issue seems to be with [this line in particular](https://github.com/root-project/root/blob/07932d78211d0ac5fdb198ac2260c35530cb9647/bindings/pyroot/cppyy/CPyCppyy/src/Pythonize.cxx#L1152):. ```cpp. const std::string& vtype = Cppyy::ResolveName(name+""::value_type"");. size_t typesz = Cppyy::SizeOf(vtype);. ```. In the reproducer case, this is equivalent to calling `Cppyy::SizeOf(""const char *"")`. This will call [`SizeOf(const std::string &)`](https://github.com/root-project/root/blob/e6fcad7d14d6a7ffa0b59e4557005d88b05ce948/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx#L626). In turn, this first calls `gROOT->GetType(""const char *"")`, which fails, then falls back to calling `SizeOf(GetScope(type_name))`. In `GetScope`, we reach [this part](https://github.com/root-project/root/blob/e6fcad7d14d6a7ffa0b59e4557005d88b05ce948/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx#L531-L536) that calls `TClass::GetClass`. As we can see, this returns nullptr:. ```cpp. root [0] auto cl = TClass::GetClass(""const char *"", true, true);. root [1] cl. (TClass *) nullptr. ```. Thus, the final result of the initial call to `Cppyy::SizeOf(vtype)` is `0`. This means that cppyy thinks that the size of these types (including `const char *`, `const int *` and so on) is zero, thus the attribute is never pythonized. In upstream cppyy, this is fixed by calling `SizeOf` with the original type, instead of the resolved one: https://github.com/wlav/CPyCppyy/blob/master/src/Pythonize.cxx#L1789-L1802. So this should be done in our cppyy too. Reassigning the issue to me, it's not related to cling but cppyy itself",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11596
https://github.com/root-project/root/issues/11596:675,reliability,fail,fails,675,"The issue seems to be with [this line in particular](https://github.com/root-project/root/blob/07932d78211d0ac5fdb198ac2260c35530cb9647/bindings/pyroot/cppyy/CPyCppyy/src/Pythonize.cxx#L1152):. ```cpp. const std::string& vtype = Cppyy::ResolveName(name+""::value_type"");. size_t typesz = Cppyy::SizeOf(vtype);. ```. In the reproducer case, this is equivalent to calling `Cppyy::SizeOf(""const char *"")`. This will call [`SizeOf(const std::string &)`](https://github.com/root-project/root/blob/e6fcad7d14d6a7ffa0b59e4557005d88b05ce948/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx#L626). In turn, this first calls `gROOT->GetType(""const char *"")`, which fails, then falls back to calling `SizeOf(GetScope(type_name))`. In `GetScope`, we reach [this part](https://github.com/root-project/root/blob/e6fcad7d14d6a7ffa0b59e4557005d88b05ce948/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/src/clingwrapper.cxx#L531-L536) that calls `TClass::GetClass`. As we can see, this returns nullptr:. ```cpp. root [0] auto cl = TClass::GetClass(""const char *"", true, true);. root [1] cl. (TClass *) nullptr. ```. Thus, the final result of the initial call to `Cppyy::SizeOf(vtype)` is `0`. This means that cppyy thinks that the size of these types (including `const char *`, `const int *` and so on) is zero, thus the attribute is never pythonized. In upstream cppyy, this is fixed by calling `SizeOf` with the original type, instead of the resolved one: https://github.com/wlav/CPyCppyy/blob/master/src/Pythonize.cxx#L1789-L1802. So this should be done in our cppyy too. Reassigning the issue to me, it's not related to cling but cppyy itself",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11596
https://github.com/root-project/root/pull/11597:124,deployability,patch,patch,124,"Thank you for the solution! Just a question, will this be backported to ROOT 6.26 or is it indeed too big of a change for a patch release?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11597
https://github.com/root-project/root/pull/11597:130,deployability,releas,release,130,"Thank you for the solution! Just a question, will this be backported to ROOT 6.26 or is it indeed too big of a change for a patch release?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11597
https://github.com/root-project/root/pull/11597:124,safety,patch,patch,124,"Thank you for the solution! Just a question, will this be backported to ROOT 6.26 or is it indeed too big of a change for a patch release?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11597
https://github.com/root-project/root/pull/11597:124,security,patch,patch,124,"Thank you for the solution! Just a question, will this be backported to ROOT 6.26 or is it indeed too big of a change for a patch release?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11597
https://github.com/root-project/root/pull/11597:140,deployability,releas,release,140,"It's not a good to backport such a fundamental change to the `RooRealIntegral` constructor, especially not now that we are late in the 6.26 release cycle already. Patch releases become rarer, and if this change causes other bugs if would take months before another patch release could come out with the patches for these potential bugs. I'm afraid in 6.26 we have to live now with this limitation of the batch mode! But maybe you could just use ROOT `master`? The ROOT master nightlies are even on cvmfs:. https://root.cern/install/nightlies/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11597
https://github.com/root-project/root/pull/11597:163,deployability,Patch,Patch,163,"It's not a good to backport such a fundamental change to the `RooRealIntegral` constructor, especially not now that we are late in the 6.26 release cycle already. Patch releases become rarer, and if this change causes other bugs if would take months before another patch release could come out with the patches for these potential bugs. I'm afraid in 6.26 we have to live now with this limitation of the batch mode! But maybe you could just use ROOT `master`? The ROOT master nightlies are even on cvmfs:. https://root.cern/install/nightlies/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11597
https://github.com/root-project/root/pull/11597:169,deployability,releas,releases,169,"It's not a good to backport such a fundamental change to the `RooRealIntegral` constructor, especially not now that we are late in the 6.26 release cycle already. Patch releases become rarer, and if this change causes other bugs if would take months before another patch release could come out with the patches for these potential bugs. I'm afraid in 6.26 we have to live now with this limitation of the batch mode! But maybe you could just use ROOT `master`? The ROOT master nightlies are even on cvmfs:. https://root.cern/install/nightlies/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11597
https://github.com/root-project/root/pull/11597:265,deployability,patch,patch,265,"It's not a good to backport such a fundamental change to the `RooRealIntegral` constructor, especially not now that we are late in the 6.26 release cycle already. Patch releases become rarer, and if this change causes other bugs if would take months before another patch release could come out with the patches for these potential bugs. I'm afraid in 6.26 we have to live now with this limitation of the batch mode! But maybe you could just use ROOT `master`? The ROOT master nightlies are even on cvmfs:. https://root.cern/install/nightlies/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11597
https://github.com/root-project/root/pull/11597:271,deployability,releas,release,271,"It's not a good to backport such a fundamental change to the `RooRealIntegral` constructor, especially not now that we are late in the 6.26 release cycle already. Patch releases become rarer, and if this change causes other bugs if would take months before another patch release could come out with the patches for these potential bugs. I'm afraid in 6.26 we have to live now with this limitation of the batch mode! But maybe you could just use ROOT `master`? The ROOT master nightlies are even on cvmfs:. https://root.cern/install/nightlies/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11597
https://github.com/root-project/root/pull/11597:303,deployability,patch,patches,303,"It's not a good to backport such a fundamental change to the `RooRealIntegral` constructor, especially not now that we are late in the 6.26 release cycle already. Patch releases become rarer, and if this change causes other bugs if would take months before another patch release could come out with the patches for these potential bugs. I'm afraid in 6.26 we have to live now with this limitation of the batch mode! But maybe you could just use ROOT `master`? The ROOT master nightlies are even on cvmfs:. https://root.cern/install/nightlies/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11597
https://github.com/root-project/root/pull/11597:524,deployability,instal,install,524,"It's not a good to backport such a fundamental change to the `RooRealIntegral` constructor, especially not now that we are late in the 6.26 release cycle already. Patch releases become rarer, and if this change causes other bugs if would take months before another patch release could come out with the patches for these potential bugs. I'm afraid in 6.26 we have to live now with this limitation of the batch mode! But maybe you could just use ROOT `master`? The ROOT master nightlies are even on cvmfs:. https://root.cern/install/nightlies/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11597
https://github.com/root-project/root/pull/11597:404,integrability,batch,batch,404,"It's not a good to backport such a fundamental change to the `RooRealIntegral` constructor, especially not now that we are late in the 6.26 release cycle already. Patch releases become rarer, and if this change causes other bugs if would take months before another patch release could come out with the patches for these potential bugs. I'm afraid in 6.26 we have to live now with this limitation of the batch mode! But maybe you could just use ROOT `master`? The ROOT master nightlies are even on cvmfs:. https://root.cern/install/nightlies/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11597
https://github.com/root-project/root/pull/11597:404,performance,batch,batch,404,"It's not a good to backport such a fundamental change to the `RooRealIntegral` constructor, especially not now that we are late in the 6.26 release cycle already. Patch releases become rarer, and if this change causes other bugs if would take months before another patch release could come out with the patches for these potential bugs. I'm afraid in 6.26 we have to live now with this limitation of the batch mode! But maybe you could just use ROOT `master`? The ROOT master nightlies are even on cvmfs:. https://root.cern/install/nightlies/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11597
https://github.com/root-project/root/pull/11597:163,safety,Patch,Patch,163,"It's not a good to backport such a fundamental change to the `RooRealIntegral` constructor, especially not now that we are late in the 6.26 release cycle already. Patch releases become rarer, and if this change causes other bugs if would take months before another patch release could come out with the patches for these potential bugs. I'm afraid in 6.26 we have to live now with this limitation of the batch mode! But maybe you could just use ROOT `master`? The ROOT master nightlies are even on cvmfs:. https://root.cern/install/nightlies/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11597
https://github.com/root-project/root/pull/11597:265,safety,patch,patch,265,"It's not a good to backport such a fundamental change to the `RooRealIntegral` constructor, especially not now that we are late in the 6.26 release cycle already. Patch releases become rarer, and if this change causes other bugs if would take months before another patch release could come out with the patches for these potential bugs. I'm afraid in 6.26 we have to live now with this limitation of the batch mode! But maybe you could just use ROOT `master`? The ROOT master nightlies are even on cvmfs:. https://root.cern/install/nightlies/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11597
https://github.com/root-project/root/pull/11597:303,safety,patch,patches,303,"It's not a good to backport such a fundamental change to the `RooRealIntegral` constructor, especially not now that we are late in the 6.26 release cycle already. Patch releases become rarer, and if this change causes other bugs if would take months before another patch release could come out with the patches for these potential bugs. I'm afraid in 6.26 we have to live now with this limitation of the batch mode! But maybe you could just use ROOT `master`? The ROOT master nightlies are even on cvmfs:. https://root.cern/install/nightlies/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11597
https://github.com/root-project/root/pull/11597:163,security,Patch,Patch,163,"It's not a good to backport such a fundamental change to the `RooRealIntegral` constructor, especially not now that we are late in the 6.26 release cycle already. Patch releases become rarer, and if this change causes other bugs if would take months before another patch release could come out with the patches for these potential bugs. I'm afraid in 6.26 we have to live now with this limitation of the batch mode! But maybe you could just use ROOT `master`? The ROOT master nightlies are even on cvmfs:. https://root.cern/install/nightlies/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11597
https://github.com/root-project/root/pull/11597:265,security,patch,patch,265,"It's not a good to backport such a fundamental change to the `RooRealIntegral` constructor, especially not now that we are late in the 6.26 release cycle already. Patch releases become rarer, and if this change causes other bugs if would take months before another patch release could come out with the patches for these potential bugs. I'm afraid in 6.26 we have to live now with this limitation of the batch mode! But maybe you could just use ROOT `master`? The ROOT master nightlies are even on cvmfs:. https://root.cern/install/nightlies/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11597
https://github.com/root-project/root/pull/11597:303,security,patch,patches,303,"It's not a good to backport such a fundamental change to the `RooRealIntegral` constructor, especially not now that we are late in the 6.26 release cycle already. Patch releases become rarer, and if this change causes other bugs if would take months before another patch release could come out with the patches for these potential bugs. I'm afraid in 6.26 we have to live now with this limitation of the batch mode! But maybe you could just use ROOT `master`? The ROOT master nightlies are even on cvmfs:. https://root.cern/install/nightlies/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11597
https://github.com/root-project/root/pull/11597:127,availability,avail,available,127,"Yes, I can try to switch to the dev3 LCG view, which should have ROOT master. I'll check in a few days, when the fix should be available in the builds",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11597
https://github.com/root-project/root/pull/11597:144,deployability,build,builds,144,"Yes, I can try to switch to the dev3 LCG view, which should have ROOT master. I'll check in a few days, when the fix should be available in the builds",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11597
https://github.com/root-project/root/pull/11597:127,reliability,availab,available,127,"Yes, I can try to switch to the dev3 LCG view, which should have ROOT master. I'll check in a few days, when the fix should be available in the builds",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11597
https://github.com/root-project/root/pull/11597:127,safety,avail,available,127,"Yes, I can try to switch to the dev3 LCG view, which should have ROOT master. I'll check in a few days, when the fix should be available in the builds",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11597
https://github.com/root-project/root/pull/11597:127,security,availab,available,127,"Yes, I can try to switch to the dev3 LCG view, which should have ROOT master. I'll check in a few days, when the fix should be available in the builds",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11597
https://github.com/root-project/root/pull/11600:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2004/default, ROOT-ubuntu18.04/nortcxxmod",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11600
https://github.com/root-project/root/pull/11600:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2004/default, ROOT-ubuntu18.04/nortcxxmod",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11600
https://github.com/root-project/root/issues/11601:17,availability,failur,failures,17,"FWIW many of the failures are due to. ```. root [0] std::string_view sv;. root [1] (std::string) sv;. IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE12__sv_wrapperC1ESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper::__sv_wrapper(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE17_S_to_string_viewESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_S_to_string_view(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEC1ENS4_12__sv_wrapperERKS3_' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper, std::allocator<char> const&). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11601
https://github.com/root-project/root/issues/11601:17,deployability,fail,failures,17,"FWIW many of the failures are due to. ```. root [0] std::string_view sv;. root [1] (std::string) sv;. IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE12__sv_wrapperC1ESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper::__sv_wrapper(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE17_S_to_string_viewESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_S_to_string_view(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEC1ENS4_12__sv_wrapperERKS3_' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper, std::allocator<char> const&). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11601
https://github.com/root-project/root/issues/11601:405,energy efficiency,alloc,allocator,405,"FWIW many of the failures are due to. ```. root [0] std::string_view sv;. root [1] (std::string) sv;. IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE12__sv_wrapperC1ESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper::__sv_wrapper(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE17_S_to_string_viewESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_S_to_string_view(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEC1ENS4_12__sv_wrapperERKS3_' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper, std::allocator<char> const&). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11601
https://github.com/root-project/root/issues/11601:525,energy efficiency,load,load,525,"FWIW many of the failures are due to. ```. root [0] std::string_view sv;. root [1] (std::string) sv;. IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE12__sv_wrapperC1ESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper::__sv_wrapper(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE17_S_to_string_viewESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_S_to_string_view(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEC1ENS4_12__sv_wrapperERKS3_' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper, std::allocator<char> const&). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11601
https://github.com/root-project/root/issues/11601:870,energy efficiency,alloc,allocator,870,"FWIW many of the failures are due to. ```. root [0] std::string_view sv;. root [1] (std::string) sv;. IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE12__sv_wrapperC1ESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper::__sv_wrapper(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE17_S_to_string_viewESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_S_to_string_view(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEC1ENS4_12__sv_wrapperERKS3_' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper, std::allocator<char> const&). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11601
https://github.com/root-project/root/issues/11601:981,energy efficiency,load,load,981,"FWIW many of the failures are due to. ```. root [0] std::string_view sv;. root [1] (std::string) sv;. IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE12__sv_wrapperC1ESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper::__sv_wrapper(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE17_S_to_string_viewESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_S_to_string_view(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEC1ENS4_12__sv_wrapperERKS3_' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper, std::allocator<char> const&). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11601
https://github.com/root-project/root/issues/11601:1306,energy efficiency,alloc,allocator,1306,"FWIW many of the failures are due to. ```. root [0] std::string_view sv;. root [1] (std::string) sv;. IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE12__sv_wrapperC1ESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper::__sv_wrapper(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE17_S_to_string_viewESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_S_to_string_view(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEC1ENS4_12__sv_wrapperERKS3_' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper, std::allocator<char> const&). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11601
https://github.com/root-project/root/issues/11601:1400,energy efficiency,alloc,allocator,1400,"FWIW many of the failures are due to. ```. root [0] std::string_view sv;. root [1] (std::string) sv;. IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE12__sv_wrapperC1ESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper::__sv_wrapper(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE17_S_to_string_viewESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_S_to_string_view(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEC1ENS4_12__sv_wrapperERKS3_' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper, std::allocator<char> const&). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11601
https://github.com/root-project/root/issues/11601:1438,energy efficiency,alloc,allocator,1438,"FWIW many of the failures are due to. ```. root [0] std::string_view sv;. root [1] (std::string) sv;. IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE12__sv_wrapperC1ESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper::__sv_wrapper(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE17_S_to_string_viewESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_S_to_string_view(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEC1ENS4_12__sv_wrapperERKS3_' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper, std::allocator<char> const&). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11601
https://github.com/root-project/root/issues/11601:1481,energy efficiency,load,load,1481,"FWIW many of the failures are due to. ```. root [0] std::string_view sv;. root [1] (std::string) sv;. IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE12__sv_wrapperC1ESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper::__sv_wrapper(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE17_S_to_string_viewESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_S_to_string_view(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEC1ENS4_12__sv_wrapperERKS3_' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper, std::allocator<char> const&). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11601
https://github.com/root-project/root/issues/11601:279,integrability,interfac,interface,279,"FWIW many of the failures are due to. ```. root [0] std::string_view sv;. root [1] (std::string) sv;. IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE12__sv_wrapperC1ESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper::__sv_wrapper(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE17_S_to_string_viewESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_S_to_string_view(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEC1ENS4_12__sv_wrapperERKS3_' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper, std::allocator<char> const&). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11601
https://github.com/root-project/root/issues/11601:744,integrability,interfac,interface,744,"FWIW many of the failures are due to. ```. root [0] std::string_view sv;. root [1] (std::string) sv;. IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE12__sv_wrapperC1ESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper::__sv_wrapper(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE17_S_to_string_viewESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_S_to_string_view(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEC1ENS4_12__sv_wrapperERKS3_' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper, std::allocator<char> const&). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11601
https://github.com/root-project/root/issues/11601:1180,integrability,interfac,interface,1180,"FWIW many of the failures are due to. ```. root [0] std::string_view sv;. root [1] (std::string) sv;. IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE12__sv_wrapperC1ESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper::__sv_wrapper(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE17_S_to_string_viewESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_S_to_string_view(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEC1ENS4_12__sv_wrapperERKS3_' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper, std::allocator<char> const&). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11601
https://github.com/root-project/root/issues/11601:279,interoperability,interfac,interface,279,"FWIW many of the failures are due to. ```. root [0] std::string_view sv;. root [1] (std::string) sv;. IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE12__sv_wrapperC1ESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper::__sv_wrapper(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE17_S_to_string_viewESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_S_to_string_view(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEC1ENS4_12__sv_wrapperERKS3_' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper, std::allocator<char> const&). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11601
https://github.com/root-project/root/issues/11601:548,interoperability,share,shared,548,"FWIW many of the failures are due to. ```. root [0] std::string_view sv;. root [1] (std::string) sv;. IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE12__sv_wrapperC1ESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper::__sv_wrapper(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE17_S_to_string_viewESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_S_to_string_view(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEC1ENS4_12__sv_wrapperERKS3_' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper, std::allocator<char> const&). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11601
https://github.com/root-project/root/issues/11601:744,interoperability,interfac,interface,744,"FWIW many of the failures are due to. ```. root [0] std::string_view sv;. root [1] (std::string) sv;. IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE12__sv_wrapperC1ESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper::__sv_wrapper(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE17_S_to_string_viewESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_S_to_string_view(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEC1ENS4_12__sv_wrapperERKS3_' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper, std::allocator<char> const&). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11601
https://github.com/root-project/root/issues/11601:1004,interoperability,share,shared,1004,"FWIW many of the failures are due to. ```. root [0] std::string_view sv;. root [1] (std::string) sv;. IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE12__sv_wrapperC1ESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper::__sv_wrapper(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE17_S_to_string_viewESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_S_to_string_view(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEC1ENS4_12__sv_wrapperERKS3_' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper, std::allocator<char> const&). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11601
https://github.com/root-project/root/issues/11601:1180,interoperability,interfac,interface,1180,"FWIW many of the failures are due to. ```. root [0] std::string_view sv;. root [1] (std::string) sv;. IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE12__sv_wrapperC1ESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper::__sv_wrapper(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE17_S_to_string_viewESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_S_to_string_view(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEC1ENS4_12__sv_wrapperERKS3_' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper, std::allocator<char> const&). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11601
https://github.com/root-project/root/issues/11601:1504,interoperability,share,shared,1504,"FWIW many of the failures are due to. ```. root [0] std::string_view sv;. root [1] (std::string) sv;. IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE12__sv_wrapperC1ESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper::__sv_wrapper(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE17_S_to_string_viewESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_S_to_string_view(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEC1ENS4_12__sv_wrapperERKS3_' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper, std::allocator<char> const&). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11601
https://github.com/root-project/root/issues/11601:279,modifiability,interfac,interface,279,"FWIW many of the failures are due to. ```. root [0] std::string_view sv;. root [1] (std::string) sv;. IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE12__sv_wrapperC1ESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper::__sv_wrapper(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE17_S_to_string_viewESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_S_to_string_view(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEC1ENS4_12__sv_wrapperERKS3_' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper, std::allocator<char> const&). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11601
https://github.com/root-project/root/issues/11601:744,modifiability,interfac,interface,744,"FWIW many of the failures are due to. ```. root [0] std::string_view sv;. root [1] (std::string) sv;. IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE12__sv_wrapperC1ESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper::__sv_wrapper(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE17_S_to_string_viewESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_S_to_string_view(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEC1ENS4_12__sv_wrapperERKS3_' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper, std::allocator<char> const&). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11601
https://github.com/root-project/root/issues/11601:1180,modifiability,interfac,interface,1180,"FWIW many of the failures are due to. ```. root [0] std::string_view sv;. root [1] (std::string) sv;. IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE12__sv_wrapperC1ESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper::__sv_wrapper(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE17_S_to_string_viewESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_S_to_string_view(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEC1ENS4_12__sv_wrapperERKS3_' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper, std::allocator<char> const&). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11601
https://github.com/root-project/root/issues/11601:17,performance,failur,failures,17,"FWIW many of the failures are due to. ```. root [0] std::string_view sv;. root [1] (std::string) sv;. IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE12__sv_wrapperC1ESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper::__sv_wrapper(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE17_S_to_string_viewESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_S_to_string_view(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEC1ENS4_12__sv_wrapperERKS3_' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper, std::allocator<char> const&). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11601
https://github.com/root-project/root/issues/11601:525,performance,load,load,525,"FWIW many of the failures are due to. ```. root [0] std::string_view sv;. root [1] (std::string) sv;. IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE12__sv_wrapperC1ESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper::__sv_wrapper(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE17_S_to_string_viewESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_S_to_string_view(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEC1ENS4_12__sv_wrapperERKS3_' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper, std::allocator<char> const&). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11601
https://github.com/root-project/root/issues/11601:981,performance,load,load,981,"FWIW many of the failures are due to. ```. root [0] std::string_view sv;. root [1] (std::string) sv;. IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE12__sv_wrapperC1ESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper::__sv_wrapper(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE17_S_to_string_viewESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_S_to_string_view(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEC1ENS4_12__sv_wrapperERKS3_' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper, std::allocator<char> const&). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11601
https://github.com/root-project/root/issues/11601:1481,performance,load,load,1481,"FWIW many of the failures are due to. ```. root [0] std::string_view sv;. root [1] (std::string) sv;. IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE12__sv_wrapperC1ESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper::__sv_wrapper(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE17_S_to_string_viewESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_S_to_string_view(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEC1ENS4_12__sv_wrapperERKS3_' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper, std::allocator<char> const&). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11601
https://github.com/root-project/root/issues/11601:17,reliability,fail,failures,17,"FWIW many of the failures are due to. ```. root [0] std::string_view sv;. root [1] (std::string) sv;. IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE12__sv_wrapperC1ESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper::__sv_wrapper(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE17_S_to_string_viewESt17basic_string_viewIcS2_E' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::_S_to_string_view(std::basic_string_view<char, std::char_traits<char> >). Maybe you need to load the corresponding shared library? IncrementalExecutor::executeFunction: symbol '_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEC1ENS4_12__sv_wrapperERKS3_' unresolved while linking [cling interface function]! You are probably missing the definition of std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::__sv_wrapper, std::allocator<char> const&). Maybe you need to load the corresponding shared library? ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11601
https://github.com/root-project/root/issues/11601:119,deployability,build,build,119,"As a workaround, `cmake -DCLING_CXX_PATH=/usr/bin/g++` seems to work. I would have loved to add this as a tweak to the build system, but we have to address https://github.com/root-project/root/issues/11612 first...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11601
https://github.com/root-project/root/issues/11601:50,deployability,build,builds,50,"Yes, the workaround is still needed for all Clang builds on EL8 (see for example also the ASan build configuration)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11601
https://github.com/root-project/root/issues/11601:95,deployability,build,build,95,"Yes, the workaround is still needed for all Clang builds on EL8 (see for example also the ASan build configuration)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11601
https://github.com/root-project/root/issues/11601:101,deployability,configurat,configuration,101,"Yes, the workaround is still needed for all Clang builds on EL8 (see for example also the ASan build configuration)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11601
https://github.com/root-project/root/issues/11601:101,integrability,configur,configuration,101,"Yes, the workaround is still needed for all Clang builds on EL8 (see for example also the ASan build configuration)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11601
https://github.com/root-project/root/issues/11601:101,modifiability,configur,configuration,101,"Yes, the workaround is still needed for all Clang builds on EL8 (see for example also the ASan build configuration)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11601
https://github.com/root-project/root/issues/11601:101,security,configur,configuration,101,"Yes, the workaround is still needed for all Clang builds on EL8 (see for example also the ASan build configuration)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11601
https://github.com/root-project/root/issues/11602:137,interoperability,share,share,137,"Hi @ianna , . it's quite weird that this is only visible inside `pytest`, I am not sure this is a bug in `Snapshot`. In any case, please share a recipe to reproduce this on our side so we can take a look! :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11602
https://github.com/root-project/root/issues/11602:492,availability,slo,slots,492,"Hi @eguiraud,. Yes, it's puzzling. Here is the closest I came up with to reproduce it in the prompt - I haven't run it in `pytest` yet: . ```python. >>> compiler(. ... """""". ... struct TwoPtrs {. ... int* b;. ... int* a;. ... };. ... """"""). True. >>> df = ROOT.RDataFrame(1).Define(""x"", ""return TwoPtrs{new int(3), new int(4)}""). >>> df.Describe().Print(). Empty dataframe filling 1 row. Property Value. -------- -----. Columns in total 1. Columns from defines 1. Event loops run 0. Processing slots 1. Column Type Origin. ------ ---- ------. x TwoPtrs Define>>> . >>> df.Snapshot(""X"", ""xxx.root"", (""x"",)). Error in <TStreamerInfo::Build>: TwoPtrs, discarding: int* b, no [dimension]. Error in <TStreamerInfo::Build>: TwoPtrs, discarding: int* a, no [dimension]. <cppyy.gbl.ROOT.RDF.RResultPtr<ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void> > object at 0x7fca1e796710>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11602
https://github.com/root-project/root/issues/11602:605,availability,Error,Error,605,"Hi @eguiraud,. Yes, it's puzzling. Here is the closest I came up with to reproduce it in the prompt - I haven't run it in `pytest` yet: . ```python. >>> compiler(. ... """""". ... struct TwoPtrs {. ... int* b;. ... int* a;. ... };. ... """"""). True. >>> df = ROOT.RDataFrame(1).Define(""x"", ""return TwoPtrs{new int(3), new int(4)}""). >>> df.Describe().Print(). Empty dataframe filling 1 row. Property Value. -------- -----. Columns in total 1. Columns from defines 1. Event loops run 0. Processing slots 1. Column Type Origin. ------ ---- ------. x TwoPtrs Define>>> . >>> df.Snapshot(""X"", ""xxx.root"", (""x"",)). Error in <TStreamerInfo::Build>: TwoPtrs, discarding: int* b, no [dimension]. Error in <TStreamerInfo::Build>: TwoPtrs, discarding: int* a, no [dimension]. <cppyy.gbl.ROOT.RDF.RResultPtr<ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void> > object at 0x7fca1e796710>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11602
https://github.com/root-project/root/issues/11602:683,availability,Error,Error,683,"Hi @eguiraud,. Yes, it's puzzling. Here is the closest I came up with to reproduce it in the prompt - I haven't run it in `pytest` yet: . ```python. >>> compiler(. ... """""". ... struct TwoPtrs {. ... int* b;. ... int* a;. ... };. ... """"""). True. >>> df = ROOT.RDataFrame(1).Define(""x"", ""return TwoPtrs{new int(3), new int(4)}""). >>> df.Describe().Print(). Empty dataframe filling 1 row. Property Value. -------- -----. Columns in total 1. Columns from defines 1. Event loops run 0. Processing slots 1. Column Type Origin. ------ ---- ------. x TwoPtrs Define>>> . >>> df.Snapshot(""X"", ""xxx.root"", (""x"",)). Error in <TStreamerInfo::Build>: TwoPtrs, discarding: int* b, no [dimension]. Error in <TStreamerInfo::Build>: TwoPtrs, discarding: int* a, no [dimension]. <cppyy.gbl.ROOT.RDF.RResultPtr<ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void> > object at 0x7fca1e796710>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11602
https://github.com/root-project/root/issues/11602:630,deployability,Build,Build,630,"Hi @eguiraud,. Yes, it's puzzling. Here is the closest I came up with to reproduce it in the prompt - I haven't run it in `pytest` yet: . ```python. >>> compiler(. ... """""". ... struct TwoPtrs {. ... int* b;. ... int* a;. ... };. ... """"""). True. >>> df = ROOT.RDataFrame(1).Define(""x"", ""return TwoPtrs{new int(3), new int(4)}""). >>> df.Describe().Print(). Empty dataframe filling 1 row. Property Value. -------- -----. Columns in total 1. Columns from defines 1. Event loops run 0. Processing slots 1. Column Type Origin. ------ ---- ------. x TwoPtrs Define>>> . >>> df.Snapshot(""X"", ""xxx.root"", (""x"",)). Error in <TStreamerInfo::Build>: TwoPtrs, discarding: int* b, no [dimension]. Error in <TStreamerInfo::Build>: TwoPtrs, discarding: int* a, no [dimension]. <cppyy.gbl.ROOT.RDF.RResultPtr<ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void> > object at 0x7fca1e796710>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11602
https://github.com/root-project/root/issues/11602:708,deployability,Build,Build,708,"Hi @eguiraud,. Yes, it's puzzling. Here is the closest I came up with to reproduce it in the prompt - I haven't run it in `pytest` yet: . ```python. >>> compiler(. ... """""". ... struct TwoPtrs {. ... int* b;. ... int* a;. ... };. ... """"""). True. >>> df = ROOT.RDataFrame(1).Define(""x"", ""return TwoPtrs{new int(3), new int(4)}""). >>> df.Describe().Print(). Empty dataframe filling 1 row. Property Value. -------- -----. Columns in total 1. Columns from defines 1. Event loops run 0. Processing slots 1. Column Type Origin. ------ ---- ------. x TwoPtrs Define>>> . >>> df.Snapshot(""X"", ""xxx.root"", (""x"",)). Error in <TStreamerInfo::Build>: TwoPtrs, discarding: int* b, no [dimension]. Error in <TStreamerInfo::Build>: TwoPtrs, discarding: int* a, no [dimension]. <cppyy.gbl.ROOT.RDF.RResultPtr<ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void> > object at 0x7fca1e796710>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11602
https://github.com/root-project/root/issues/11602:462,integrability,Event,Event,462,"Hi @eguiraud,. Yes, it's puzzling. Here is the closest I came up with to reproduce it in the prompt - I haven't run it in `pytest` yet: . ```python. >>> compiler(. ... """""". ... struct TwoPtrs {. ... int* b;. ... int* a;. ... };. ... """"""). True. >>> df = ROOT.RDataFrame(1).Define(""x"", ""return TwoPtrs{new int(3), new int(4)}""). >>> df.Describe().Print(). Empty dataframe filling 1 row. Property Value. -------- -----. Columns in total 1. Columns from defines 1. Event loops run 0. Processing slots 1. Column Type Origin. ------ ---- ------. x TwoPtrs Define>>> . >>> df.Snapshot(""X"", ""xxx.root"", (""x"",)). Error in <TStreamerInfo::Build>: TwoPtrs, discarding: int* b, no [dimension]. Error in <TStreamerInfo::Build>: TwoPtrs, discarding: int* a, no [dimension]. <cppyy.gbl.ROOT.RDF.RResultPtr<ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void> > object at 0x7fca1e796710>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11602
https://github.com/root-project/root/issues/11602:605,performance,Error,Error,605,"Hi @eguiraud,. Yes, it's puzzling. Here is the closest I came up with to reproduce it in the prompt - I haven't run it in `pytest` yet: . ```python. >>> compiler(. ... """""". ... struct TwoPtrs {. ... int* b;. ... int* a;. ... };. ... """"""). True. >>> df = ROOT.RDataFrame(1).Define(""x"", ""return TwoPtrs{new int(3), new int(4)}""). >>> df.Describe().Print(). Empty dataframe filling 1 row. Property Value. -------- -----. Columns in total 1. Columns from defines 1. Event loops run 0. Processing slots 1. Column Type Origin. ------ ---- ------. x TwoPtrs Define>>> . >>> df.Snapshot(""X"", ""xxx.root"", (""x"",)). Error in <TStreamerInfo::Build>: TwoPtrs, discarding: int* b, no [dimension]. Error in <TStreamerInfo::Build>: TwoPtrs, discarding: int* a, no [dimension]. <cppyy.gbl.ROOT.RDF.RResultPtr<ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void> > object at 0x7fca1e796710>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11602
https://github.com/root-project/root/issues/11602:683,performance,Error,Error,683,"Hi @eguiraud,. Yes, it's puzzling. Here is the closest I came up with to reproduce it in the prompt - I haven't run it in `pytest` yet: . ```python. >>> compiler(. ... """""". ... struct TwoPtrs {. ... int* b;. ... int* a;. ... };. ... """"""). True. >>> df = ROOT.RDataFrame(1).Define(""x"", ""return TwoPtrs{new int(3), new int(4)}""). >>> df.Describe().Print(). Empty dataframe filling 1 row. Property Value. -------- -----. Columns in total 1. Columns from defines 1. Event loops run 0. Processing slots 1. Column Type Origin. ------ ---- ------. x TwoPtrs Define>>> . >>> df.Snapshot(""X"", ""xxx.root"", (""x"",)). Error in <TStreamerInfo::Build>: TwoPtrs, discarding: int* b, no [dimension]. Error in <TStreamerInfo::Build>: TwoPtrs, discarding: int* a, no [dimension]. <cppyy.gbl.ROOT.RDF.RResultPtr<ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void> > object at 0x7fca1e796710>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11602
https://github.com/root-project/root/issues/11602:492,reliability,slo,slots,492,"Hi @eguiraud,. Yes, it's puzzling. Here is the closest I came up with to reproduce it in the prompt - I haven't run it in `pytest` yet: . ```python. >>> compiler(. ... """""". ... struct TwoPtrs {. ... int* b;. ... int* a;. ... };. ... """"""). True. >>> df = ROOT.RDataFrame(1).Define(""x"", ""return TwoPtrs{new int(3), new int(4)}""). >>> df.Describe().Print(). Empty dataframe filling 1 row. Property Value. -------- -----. Columns in total 1. Columns from defines 1. Event loops run 0. Processing slots 1. Column Type Origin. ------ ---- ------. x TwoPtrs Define>>> . >>> df.Snapshot(""X"", ""xxx.root"", (""x"",)). Error in <TStreamerInfo::Build>: TwoPtrs, discarding: int* b, no [dimension]. Error in <TStreamerInfo::Build>: TwoPtrs, discarding: int* a, no [dimension]. <cppyy.gbl.ROOT.RDF.RResultPtr<ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void> > object at 0x7fca1e796710>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11602
https://github.com/root-project/root/issues/11602:605,safety,Error,Error,605,"Hi @eguiraud,. Yes, it's puzzling. Here is the closest I came up with to reproduce it in the prompt - I haven't run it in `pytest` yet: . ```python. >>> compiler(. ... """""". ... struct TwoPtrs {. ... int* b;. ... int* a;. ... };. ... """"""). True. >>> df = ROOT.RDataFrame(1).Define(""x"", ""return TwoPtrs{new int(3), new int(4)}""). >>> df.Describe().Print(). Empty dataframe filling 1 row. Property Value. -------- -----. Columns in total 1. Columns from defines 1. Event loops run 0. Processing slots 1. Column Type Origin. ------ ---- ------. x TwoPtrs Define>>> . >>> df.Snapshot(""X"", ""xxx.root"", (""x"",)). Error in <TStreamerInfo::Build>: TwoPtrs, discarding: int* b, no [dimension]. Error in <TStreamerInfo::Build>: TwoPtrs, discarding: int* a, no [dimension]. <cppyy.gbl.ROOT.RDF.RResultPtr<ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void> > object at 0x7fca1e796710>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11602
https://github.com/root-project/root/issues/11602:683,safety,Error,Error,683,"Hi @eguiraud,. Yes, it's puzzling. Here is the closest I came up with to reproduce it in the prompt - I haven't run it in `pytest` yet: . ```python. >>> compiler(. ... """""". ... struct TwoPtrs {. ... int* b;. ... int* a;. ... };. ... """"""). True. >>> df = ROOT.RDataFrame(1).Define(""x"", ""return TwoPtrs{new int(3), new int(4)}""). >>> df.Describe().Print(). Empty dataframe filling 1 row. Property Value. -------- -----. Columns in total 1. Columns from defines 1. Event loops run 0. Processing slots 1. Column Type Origin. ------ ---- ------. x TwoPtrs Define>>> . >>> df.Snapshot(""X"", ""xxx.root"", (""x"",)). Error in <TStreamerInfo::Build>: TwoPtrs, discarding: int* b, no [dimension]. Error in <TStreamerInfo::Build>: TwoPtrs, discarding: int* a, no [dimension]. <cppyy.gbl.ROOT.RDF.RResultPtr<ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void> > object at 0x7fca1e796710>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11602
https://github.com/root-project/root/issues/11602:47,usability,close,closest,47,"Hi @eguiraud,. Yes, it's puzzling. Here is the closest I came up with to reproduce it in the prompt - I haven't run it in `pytest` yet: . ```python. >>> compiler(. ... """""". ... struct TwoPtrs {. ... int* b;. ... int* a;. ... };. ... """"""). True. >>> df = ROOT.RDataFrame(1).Define(""x"", ""return TwoPtrs{new int(3), new int(4)}""). >>> df.Describe().Print(). Empty dataframe filling 1 row. Property Value. -------- -----. Columns in total 1. Columns from defines 1. Event loops run 0. Processing slots 1. Column Type Origin. ------ ---- ------. x TwoPtrs Define>>> . >>> df.Snapshot(""X"", ""xxx.root"", (""x"",)). Error in <TStreamerInfo::Build>: TwoPtrs, discarding: int* b, no [dimension]. Error in <TStreamerInfo::Build>: TwoPtrs, discarding: int* a, no [dimension]. <cppyy.gbl.ROOT.RDF.RResultPtr<ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void> > object at 0x7fca1e796710>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11602
https://github.com/root-project/root/issues/11602:605,usability,Error,Error,605,"Hi @eguiraud,. Yes, it's puzzling. Here is the closest I came up with to reproduce it in the prompt - I haven't run it in `pytest` yet: . ```python. >>> compiler(. ... """""". ... struct TwoPtrs {. ... int* b;. ... int* a;. ... };. ... """"""). True. >>> df = ROOT.RDataFrame(1).Define(""x"", ""return TwoPtrs{new int(3), new int(4)}""). >>> df.Describe().Print(). Empty dataframe filling 1 row. Property Value. -------- -----. Columns in total 1. Columns from defines 1. Event loops run 0. Processing slots 1. Column Type Origin. ------ ---- ------. x TwoPtrs Define>>> . >>> df.Snapshot(""X"", ""xxx.root"", (""x"",)). Error in <TStreamerInfo::Build>: TwoPtrs, discarding: int* b, no [dimension]. Error in <TStreamerInfo::Build>: TwoPtrs, discarding: int* a, no [dimension]. <cppyy.gbl.ROOT.RDF.RResultPtr<ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void> > object at 0x7fca1e796710>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11602
https://github.com/root-project/root/issues/11602:683,usability,Error,Error,683,"Hi @eguiraud,. Yes, it's puzzling. Here is the closest I came up with to reproduce it in the prompt - I haven't run it in `pytest` yet: . ```python. >>> compiler(. ... """""". ... struct TwoPtrs {. ... int* b;. ... int* a;. ... };. ... """"""). True. >>> df = ROOT.RDataFrame(1).Define(""x"", ""return TwoPtrs{new int(3), new int(4)}""). >>> df.Describe().Print(). Empty dataframe filling 1 row. Property Value. -------- -----. Columns in total 1. Columns from defines 1. Event loops run 0. Processing slots 1. Column Type Origin. ------ ---- ------. x TwoPtrs Define>>> . >>> df.Snapshot(""X"", ""xxx.root"", (""x"",)). Error in <TStreamerInfo::Build>: TwoPtrs, discarding: int* b, no [dimension]. Error in <TStreamerInfo::Build>: TwoPtrs, discarding: int* a, no [dimension]. <cppyy.gbl.ROOT.RDF.RResultPtr<ROOT::RDF::RInterface<ROOT::Detail::RDF::RLoopManager,void> > object at 0x7fca1e796710>. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11602
https://github.com/root-project/root/issues/11602:172,safety,test,test,172,"@vepadulano - FYI, I can confirm that the issue is still present in the latest maser branch built with Python 3.12. However, I cannot reproduce a `SystemError` running the test case with pytest. I'm closing the issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11602
https://github.com/root-project/root/issues/11602:172,testability,test,test,172,"@vepadulano - FYI, I can confirm that the issue is still present in the latest maser branch built with Python 3.12. However, I cannot reproduce a `SystemError` running the test case with pytest. I'm closing the issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11602
https://github.com/root-project/root/issues/11602:25,usability,confirm,confirm,25,"@vepadulano - FYI, I can confirm that the issue is still present in the latest maser branch built with Python 3.12. However, I cannot reproduce a `SystemError` running the test case with pytest. I'm closing the issue.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11602
https://github.com/root-project/root/issues/11603:98,energy efficiency,current,current,98,"So we could introduce such option (e.g `check_connectivity`), set it `ON` by default (to keep the current behavior), and set the `NO_CONNECTION` to `TRUE` if it is disabled. Would that fit your need? And maybe @Axel-Naumann can also comment on this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:106,usability,behavi,behavior,106,"So we could introduce such option (e.g `check_connectivity`), set it `ON` by default (to keep the current behavior), and set the `NO_CONNECTION` to `TRUE` if it is disabled. Would that fit your need? And maybe @Axel-Naumann can also comment on this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:419,availability,failur,failure,419,"Hi @wdconinc and @bellenot! It would be nice if we could fix the issue without the added complexity of an additional flag. Wouter, you're probably using the `fail-on-missing` option to build ROOT, right? The flag to make sure that the features don't get quietly disabled at configuration time. The connectivity check doesn't make sense with `fail-on-missing=ON`, because a missing dependency will cause a configuration failure either way. More on this in the description of the PR that I opened:. * https://github.com/root-project/root/pull/15467. Would that PR fix your issue?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:158,deployability,fail,fail-on-missing,158,"Hi @wdconinc and @bellenot! It would be nice if we could fix the issue without the added complexity of an additional flag. Wouter, you're probably using the `fail-on-missing` option to build ROOT, right? The flag to make sure that the features don't get quietly disabled at configuration time. The connectivity check doesn't make sense with `fail-on-missing=ON`, because a missing dependency will cause a configuration failure either way. More on this in the description of the PR that I opened:. * https://github.com/root-project/root/pull/15467. Would that PR fix your issue?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:185,deployability,build,build,185,"Hi @wdconinc and @bellenot! It would be nice if we could fix the issue without the added complexity of an additional flag. Wouter, you're probably using the `fail-on-missing` option to build ROOT, right? The flag to make sure that the features don't get quietly disabled at configuration time. The connectivity check doesn't make sense with `fail-on-missing=ON`, because a missing dependency will cause a configuration failure either way. More on this in the description of the PR that I opened:. * https://github.com/root-project/root/pull/15467. Would that PR fix your issue?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:274,deployability,configurat,configuration,274,"Hi @wdconinc and @bellenot! It would be nice if we could fix the issue without the added complexity of an additional flag. Wouter, you're probably using the `fail-on-missing` option to build ROOT, right? The flag to make sure that the features don't get quietly disabled at configuration time. The connectivity check doesn't make sense with `fail-on-missing=ON`, because a missing dependency will cause a configuration failure either way. More on this in the description of the PR that I opened:. * https://github.com/root-project/root/pull/15467. Would that PR fix your issue?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:342,deployability,fail,fail-on-missing,342,"Hi @wdconinc and @bellenot! It would be nice if we could fix the issue without the added complexity of an additional flag. Wouter, you're probably using the `fail-on-missing` option to build ROOT, right? The flag to make sure that the features don't get quietly disabled at configuration time. The connectivity check doesn't make sense with `fail-on-missing=ON`, because a missing dependency will cause a configuration failure either way. More on this in the description of the PR that I opened:. * https://github.com/root-project/root/pull/15467. Would that PR fix your issue?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:381,deployability,depend,dependency,381,"Hi @wdconinc and @bellenot! It would be nice if we could fix the issue without the added complexity of an additional flag. Wouter, you're probably using the `fail-on-missing` option to build ROOT, right? The flag to make sure that the features don't get quietly disabled at configuration time. The connectivity check doesn't make sense with `fail-on-missing=ON`, because a missing dependency will cause a configuration failure either way. More on this in the description of the PR that I opened:. * https://github.com/root-project/root/pull/15467. Would that PR fix your issue?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:405,deployability,configurat,configuration,405,"Hi @wdconinc and @bellenot! It would be nice if we could fix the issue without the added complexity of an additional flag. Wouter, you're probably using the `fail-on-missing` option to build ROOT, right? The flag to make sure that the features don't get quietly disabled at configuration time. The connectivity check doesn't make sense with `fail-on-missing=ON`, because a missing dependency will cause a configuration failure either way. More on this in the description of the PR that I opened:. * https://github.com/root-project/root/pull/15467. Would that PR fix your issue?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:419,deployability,fail,failure,419,"Hi @wdconinc and @bellenot! It would be nice if we could fix the issue without the added complexity of an additional flag. Wouter, you're probably using the `fail-on-missing` option to build ROOT, right? The flag to make sure that the features don't get quietly disabled at configuration time. The connectivity check doesn't make sense with `fail-on-missing=ON`, because a missing dependency will cause a configuration failure either way. More on this in the description of the PR that I opened:. * https://github.com/root-project/root/pull/15467. Would that PR fix your issue?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:274,integrability,configur,configuration,274,"Hi @wdconinc and @bellenot! It would be nice if we could fix the issue without the added complexity of an additional flag. Wouter, you're probably using the `fail-on-missing` option to build ROOT, right? The flag to make sure that the features don't get quietly disabled at configuration time. The connectivity check doesn't make sense with `fail-on-missing=ON`, because a missing dependency will cause a configuration failure either way. More on this in the description of the PR that I opened:. * https://github.com/root-project/root/pull/15467. Would that PR fix your issue?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:381,integrability,depend,dependency,381,"Hi @wdconinc and @bellenot! It would be nice if we could fix the issue without the added complexity of an additional flag. Wouter, you're probably using the `fail-on-missing` option to build ROOT, right? The flag to make sure that the features don't get quietly disabled at configuration time. The connectivity check doesn't make sense with `fail-on-missing=ON`, because a missing dependency will cause a configuration failure either way. More on this in the description of the PR that I opened:. * https://github.com/root-project/root/pull/15467. Would that PR fix your issue?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:405,integrability,configur,configuration,405,"Hi @wdconinc and @bellenot! It would be nice if we could fix the issue without the added complexity of an additional flag. Wouter, you're probably using the `fail-on-missing` option to build ROOT, right? The flag to make sure that the features don't get quietly disabled at configuration time. The connectivity check doesn't make sense with `fail-on-missing=ON`, because a missing dependency will cause a configuration failure either way. More on this in the description of the PR that I opened:. * https://github.com/root-project/root/pull/15467. Would that PR fix your issue?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:274,modifiability,configur,configuration,274,"Hi @wdconinc and @bellenot! It would be nice if we could fix the issue without the added complexity of an additional flag. Wouter, you're probably using the `fail-on-missing` option to build ROOT, right? The flag to make sure that the features don't get quietly disabled at configuration time. The connectivity check doesn't make sense with `fail-on-missing=ON`, because a missing dependency will cause a configuration failure either way. More on this in the description of the PR that I opened:. * https://github.com/root-project/root/pull/15467. Would that PR fix your issue?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:381,modifiability,depend,dependency,381,"Hi @wdconinc and @bellenot! It would be nice if we could fix the issue without the added complexity of an additional flag. Wouter, you're probably using the `fail-on-missing` option to build ROOT, right? The flag to make sure that the features don't get quietly disabled at configuration time. The connectivity check doesn't make sense with `fail-on-missing=ON`, because a missing dependency will cause a configuration failure either way. More on this in the description of the PR that I opened:. * https://github.com/root-project/root/pull/15467. Would that PR fix your issue?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:405,modifiability,configur,configuration,405,"Hi @wdconinc and @bellenot! It would be nice if we could fix the issue without the added complexity of an additional flag. Wouter, you're probably using the `fail-on-missing` option to build ROOT, right? The flag to make sure that the features don't get quietly disabled at configuration time. The connectivity check doesn't make sense with `fail-on-missing=ON`, because a missing dependency will cause a configuration failure either way. More on this in the description of the PR that I opened:. * https://github.com/root-project/root/pull/15467. Would that PR fix your issue?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:288,performance,time,time,288,"Hi @wdconinc and @bellenot! It would be nice if we could fix the issue without the added complexity of an additional flag. Wouter, you're probably using the `fail-on-missing` option to build ROOT, right? The flag to make sure that the features don't get quietly disabled at configuration time. The connectivity check doesn't make sense with `fail-on-missing=ON`, because a missing dependency will cause a configuration failure either way. More on this in the description of the PR that I opened:. * https://github.com/root-project/root/pull/15467. Would that PR fix your issue?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:419,performance,failur,failure,419,"Hi @wdconinc and @bellenot! It would be nice if we could fix the issue without the added complexity of an additional flag. Wouter, you're probably using the `fail-on-missing` option to build ROOT, right? The flag to make sure that the features don't get quietly disabled at configuration time. The connectivity check doesn't make sense with `fail-on-missing=ON`, because a missing dependency will cause a configuration failure either way. More on this in the description of the PR that I opened:. * https://github.com/root-project/root/pull/15467. Would that PR fix your issue?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:158,reliability,fail,fail-on-missing,158,"Hi @wdconinc and @bellenot! It would be nice if we could fix the issue without the added complexity of an additional flag. Wouter, you're probably using the `fail-on-missing` option to build ROOT, right? The flag to make sure that the features don't get quietly disabled at configuration time. The connectivity check doesn't make sense with `fail-on-missing=ON`, because a missing dependency will cause a configuration failure either way. More on this in the description of the PR that I opened:. * https://github.com/root-project/root/pull/15467. Would that PR fix your issue?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:317,reliability,doe,doesn,317,"Hi @wdconinc and @bellenot! It would be nice if we could fix the issue without the added complexity of an additional flag. Wouter, you're probably using the `fail-on-missing` option to build ROOT, right? The flag to make sure that the features don't get quietly disabled at configuration time. The connectivity check doesn't make sense with `fail-on-missing=ON`, because a missing dependency will cause a configuration failure either way. More on this in the description of the PR that I opened:. * https://github.com/root-project/root/pull/15467. Would that PR fix your issue?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:342,reliability,fail,fail-on-missing,342,"Hi @wdconinc and @bellenot! It would be nice if we could fix the issue without the added complexity of an additional flag. Wouter, you're probably using the `fail-on-missing` option to build ROOT, right? The flag to make sure that the features don't get quietly disabled at configuration time. The connectivity check doesn't make sense with `fail-on-missing=ON`, because a missing dependency will cause a configuration failure either way. More on this in the description of the PR that I opened:. * https://github.com/root-project/root/pull/15467. Would that PR fix your issue?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:419,reliability,fail,failure,419,"Hi @wdconinc and @bellenot! It would be nice if we could fix the issue without the added complexity of an additional flag. Wouter, you're probably using the `fail-on-missing` option to build ROOT, right? The flag to make sure that the features don't get quietly disabled at configuration time. The connectivity check doesn't make sense with `fail-on-missing=ON`, because a missing dependency will cause a configuration failure either way. More on this in the description of the PR that I opened:. * https://github.com/root-project/root/pull/15467. Would that PR fix your issue?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:89,safety,compl,complexity,89,"Hi @wdconinc and @bellenot! It would be nice if we could fix the issue without the added complexity of an additional flag. Wouter, you're probably using the `fail-on-missing` option to build ROOT, right? The flag to make sure that the features don't get quietly disabled at configuration time. The connectivity check doesn't make sense with `fail-on-missing=ON`, because a missing dependency will cause a configuration failure either way. More on this in the description of the PR that I opened:. * https://github.com/root-project/root/pull/15467. Would that PR fix your issue?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:381,safety,depend,dependency,381,"Hi @wdconinc and @bellenot! It would be nice if we could fix the issue without the added complexity of an additional flag. Wouter, you're probably using the `fail-on-missing` option to build ROOT, right? The flag to make sure that the features don't get quietly disabled at configuration time. The connectivity check doesn't make sense with `fail-on-missing=ON`, because a missing dependency will cause a configuration failure either way. More on this in the description of the PR that I opened:. * https://github.com/root-project/root/pull/15467. Would that PR fix your issue?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:89,security,compl,complexity,89,"Hi @wdconinc and @bellenot! It would be nice if we could fix the issue without the added complexity of an additional flag. Wouter, you're probably using the `fail-on-missing` option to build ROOT, right? The flag to make sure that the features don't get quietly disabled at configuration time. The connectivity check doesn't make sense with `fail-on-missing=ON`, because a missing dependency will cause a configuration failure either way. More on this in the description of the PR that I opened:. * https://github.com/root-project/root/pull/15467. Would that PR fix your issue?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:274,security,configur,configuration,274,"Hi @wdconinc and @bellenot! It would be nice if we could fix the issue without the added complexity of an additional flag. Wouter, you're probably using the `fail-on-missing` option to build ROOT, right? The flag to make sure that the features don't get quietly disabled at configuration time. The connectivity check doesn't make sense with `fail-on-missing=ON`, because a missing dependency will cause a configuration failure either way. More on this in the description of the PR that I opened:. * https://github.com/root-project/root/pull/15467. Would that PR fix your issue?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:405,security,configur,configuration,405,"Hi @wdconinc and @bellenot! It would be nice if we could fix the issue without the added complexity of an additional flag. Wouter, you're probably using the `fail-on-missing` option to build ROOT, right? The flag to make sure that the features don't get quietly disabled at configuration time. The connectivity check doesn't make sense with `fail-on-missing=ON`, because a missing dependency will cause a configuration failure either way. More on this in the description of the PR that I opened:. * https://github.com/root-project/root/pull/15467. Would that PR fix your issue?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:381,testability,depend,dependency,381,"Hi @wdconinc and @bellenot! It would be nice if we could fix the issue without the added complexity of an additional flag. Wouter, you're probably using the `fail-on-missing` option to build ROOT, right? The flag to make sure that the features don't get quietly disabled at configuration time. The connectivity check doesn't make sense with `fail-on-missing=ON`, because a missing dependency will cause a configuration failure either way. More on this in the description of the PR that I opened:. * https://github.com/root-project/root/pull/15467. Would that PR fix your issue?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:41,deployability,fail,fail-on-missing,41,"The fix seems fine (we are indeed using `fail-on-missing` by default through the spack package). It is still not entirely clear in advance which features require connectivity, and which don't (or even what to do in advance in order to pre-populate the FetchContent locations). There is also confusion with the names of the features: `builtin_` would lead one to think it's provided with the source tree but it isn't, except for `builtin_openui5` where it is the opposite.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:87,modifiability,pac,package,87,"The fix seems fine (we are indeed using `fail-on-missing` by default through the spack package). It is still not entirely clear in advance which features require connectivity, and which don't (or even what to do in advance in order to pre-populate the FetchContent locations). There is also confusion with the names of the features: `builtin_` would lead one to think it's provided with the source tree but it isn't, except for `builtin_openui5` where it is the opposite.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:41,reliability,fail,fail-on-missing,41,"The fix seems fine (we are indeed using `fail-on-missing` by default through the spack package). It is still not entirely clear in advance which features require connectivity, and which don't (or even what to do in advance in order to pre-populate the FetchContent locations). There is also confusion with the names of the features: `builtin_` would lead one to think it's provided with the source tree but it isn't, except for `builtin_openui5` where it is the opposite.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:417,safety,except,except,417,"The fix seems fine (we are indeed using `fail-on-missing` by default through the spack package). It is still not entirely clear in advance which features require connectivity, and which don't (or even what to do in advance in order to pre-populate the FetchContent locations). There is also confusion with the names of the features: `builtin_` would lead one to think it's provided with the source tree but it isn't, except for `builtin_openui5` where it is the opposite.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:122,usability,clear,clear,122,"The fix seems fine (we are indeed using `fail-on-missing` by default through the spack package). It is still not entirely clear in advance which features require connectivity, and which don't (or even what to do in advance in order to pre-populate the FetchContent locations). There is also confusion with the names of the features: `builtin_` would lead one to think it's provided with the source tree but it isn't, except for `builtin_openui5` where it is the opposite.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:248,deployability,instal,install,248,"Cool, good to hear that the PR goes in the right direction then! > It is still not entirely clear in advance which features require connectivity. All features of builtins that do require network note this in their description:. * https://root.cern/install/build_from_source/#all-build-options. * https://github.com/root-project/root/blob/master/cmake/modules/RootBuildOptions.cmake#L87. I agree that `builtin_openui5` should explicitly say that it requires network if `OFF`. For the confusing name with `builtin_`, do you have a suggestion to make this clearer? I don't think there are many options there, we meant of course builtin to the ROOT build, not the source tree :slightly_smiling_face: . About the pre-populating of FetchContent locations: I was facing the same problem recently for nix packages. I fixed it in the end by patching the CMake code of ROOT:. https://github.com/NixOS/nixpkgs/pull/308497",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:279,deployability,build,build-options,279,"Cool, good to hear that the PR goes in the right direction then! > It is still not entirely clear in advance which features require connectivity. All features of builtins that do require network note this in their description:. * https://root.cern/install/build_from_source/#all-build-options. * https://github.com/root-project/root/blob/master/cmake/modules/RootBuildOptions.cmake#L87. I agree that `builtin_openui5` should explicitly say that it requires network if `OFF`. For the confusing name with `builtin_`, do you have a suggestion to make this clearer? I don't think there are many options there, we meant of course builtin to the ROOT build, not the source tree :slightly_smiling_face: . About the pre-populating of FetchContent locations: I was facing the same problem recently for nix packages. I fixed it in the end by patching the CMake code of ROOT:. https://github.com/NixOS/nixpkgs/pull/308497",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:351,deployability,modul,modules,351,"Cool, good to hear that the PR goes in the right direction then! > It is still not entirely clear in advance which features require connectivity. All features of builtins that do require network note this in their description:. * https://root.cern/install/build_from_source/#all-build-options. * https://github.com/root-project/root/blob/master/cmake/modules/RootBuildOptions.cmake#L87. I agree that `builtin_openui5` should explicitly say that it requires network if `OFF`. For the confusing name with `builtin_`, do you have a suggestion to make this clearer? I don't think there are many options there, we meant of course builtin to the ROOT build, not the source tree :slightly_smiling_face: . About the pre-populating of FetchContent locations: I was facing the same problem recently for nix packages. I fixed it in the end by patching the CMake code of ROOT:. https://github.com/NixOS/nixpkgs/pull/308497",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:645,deployability,build,build,645,"Cool, good to hear that the PR goes in the right direction then! > It is still not entirely clear in advance which features require connectivity. All features of builtins that do require network note this in their description:. * https://root.cern/install/build_from_source/#all-build-options. * https://github.com/root-project/root/blob/master/cmake/modules/RootBuildOptions.cmake#L87. I agree that `builtin_openui5` should explicitly say that it requires network if `OFF`. For the confusing name with `builtin_`, do you have a suggestion to make this clearer? I don't think there are many options there, we meant of course builtin to the ROOT build, not the source tree :slightly_smiling_face: . About the pre-populating of FetchContent locations: I was facing the same problem recently for nix packages. I fixed it in the end by patching the CMake code of ROOT:. https://github.com/NixOS/nixpkgs/pull/308497",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:832,deployability,patch,patching,832,"Cool, good to hear that the PR goes in the right direction then! > It is still not entirely clear in advance which features require connectivity. All features of builtins that do require network note this in their description:. * https://root.cern/install/build_from_source/#all-build-options. * https://github.com/root-project/root/blob/master/cmake/modules/RootBuildOptions.cmake#L87. I agree that `builtin_openui5` should explicitly say that it requires network if `OFF`. For the confusing name with `builtin_`, do you have a suggestion to make this clearer? I don't think there are many options there, we meant of course builtin to the ROOT build, not the source tree :slightly_smiling_face: . About the pre-populating of FetchContent locations: I was facing the same problem recently for nix packages. I fixed it in the end by patching the CMake code of ROOT:. https://github.com/NixOS/nixpkgs/pull/308497",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:0,energy efficiency,Cool,Cool,0,"Cool, good to hear that the PR goes in the right direction then! > It is still not entirely clear in advance which features require connectivity. All features of builtins that do require network note this in their description:. * https://root.cern/install/build_from_source/#all-build-options. * https://github.com/root-project/root/blob/master/cmake/modules/RootBuildOptions.cmake#L87. I agree that `builtin_openui5` should explicitly say that it requires network if `OFF`. For the confusing name with `builtin_`, do you have a suggestion to make this clearer? I don't think there are many options there, we meant of course builtin to the ROOT build, not the source tree :slightly_smiling_face: . About the pre-populating of FetchContent locations: I was facing the same problem recently for nix packages. I fixed it in the end by patching the CMake code of ROOT:. https://github.com/NixOS/nixpkgs/pull/308497",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:351,modifiability,modul,modules,351,"Cool, good to hear that the PR goes in the right direction then! > It is still not entirely clear in advance which features require connectivity. All features of builtins that do require network note this in their description:. * https://root.cern/install/build_from_source/#all-build-options. * https://github.com/root-project/root/blob/master/cmake/modules/RootBuildOptions.cmake#L87. I agree that `builtin_openui5` should explicitly say that it requires network if `OFF`. For the confusing name with `builtin_`, do you have a suggestion to make this clearer? I don't think there are many options there, we meant of course builtin to the ROOT build, not the source tree :slightly_smiling_face: . About the pre-populating of FetchContent locations: I was facing the same problem recently for nix packages. I fixed it in the end by patching the CMake code of ROOT:. https://github.com/NixOS/nixpkgs/pull/308497",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:797,modifiability,pac,packages,797,"Cool, good to hear that the PR goes in the right direction then! > It is still not entirely clear in advance which features require connectivity. All features of builtins that do require network note this in their description:. * https://root.cern/install/build_from_source/#all-build-options. * https://github.com/root-project/root/blob/master/cmake/modules/RootBuildOptions.cmake#L87. I agree that `builtin_openui5` should explicitly say that it requires network if `OFF`. For the confusing name with `builtin_`, do you have a suggestion to make this clearer? I don't think there are many options there, we meant of course builtin to the ROOT build, not the source tree :slightly_smiling_face: . About the pre-populating of FetchContent locations: I was facing the same problem recently for nix packages. I fixed it in the end by patching the CMake code of ROOT:. https://github.com/NixOS/nixpkgs/pull/308497",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:187,performance,network,network,187,"Cool, good to hear that the PR goes in the right direction then! > It is still not entirely clear in advance which features require connectivity. All features of builtins that do require network note this in their description:. * https://root.cern/install/build_from_source/#all-build-options. * https://github.com/root-project/root/blob/master/cmake/modules/RootBuildOptions.cmake#L87. I agree that `builtin_openui5` should explicitly say that it requires network if `OFF`. For the confusing name with `builtin_`, do you have a suggestion to make this clearer? I don't think there are many options there, we meant of course builtin to the ROOT build, not the source tree :slightly_smiling_face: . About the pre-populating of FetchContent locations: I was facing the same problem recently for nix packages. I fixed it in the end by patching the CMake code of ROOT:. https://github.com/NixOS/nixpkgs/pull/308497",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:457,performance,network,network,457,"Cool, good to hear that the PR goes in the right direction then! > It is still not entirely clear in advance which features require connectivity. All features of builtins that do require network note this in their description:. * https://root.cern/install/build_from_source/#all-build-options. * https://github.com/root-project/root/blob/master/cmake/modules/RootBuildOptions.cmake#L87. I agree that `builtin_openui5` should explicitly say that it requires network if `OFF`. For the confusing name with `builtin_`, do you have a suggestion to make this clearer? I don't think there are many options there, we meant of course builtin to the ROOT build, not the source tree :slightly_smiling_face: . About the pre-populating of FetchContent locations: I was facing the same problem recently for nix packages. I fixed it in the end by patching the CMake code of ROOT:. https://github.com/NixOS/nixpkgs/pull/308497",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:351,safety,modul,modules,351,"Cool, good to hear that the PR goes in the right direction then! > It is still not entirely clear in advance which features require connectivity. All features of builtins that do require network note this in their description:. * https://root.cern/install/build_from_source/#all-build-options. * https://github.com/root-project/root/blob/master/cmake/modules/RootBuildOptions.cmake#L87. I agree that `builtin_openui5` should explicitly say that it requires network if `OFF`. For the confusing name with `builtin_`, do you have a suggestion to make this clearer? I don't think there are many options there, we meant of course builtin to the ROOT build, not the source tree :slightly_smiling_face: . About the pre-populating of FetchContent locations: I was facing the same problem recently for nix packages. I fixed it in the end by patching the CMake code of ROOT:. https://github.com/NixOS/nixpkgs/pull/308497",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:832,safety,patch,patching,832,"Cool, good to hear that the PR goes in the right direction then! > It is still not entirely clear in advance which features require connectivity. All features of builtins that do require network note this in their description:. * https://root.cern/install/build_from_source/#all-build-options. * https://github.com/root-project/root/blob/master/cmake/modules/RootBuildOptions.cmake#L87. I agree that `builtin_openui5` should explicitly say that it requires network if `OFF`. For the confusing name with `builtin_`, do you have a suggestion to make this clearer? I don't think there are many options there, we meant of course builtin to the ROOT build, not the source tree :slightly_smiling_face: . About the pre-populating of FetchContent locations: I was facing the same problem recently for nix packages. I fixed it in the end by patching the CMake code of ROOT:. https://github.com/NixOS/nixpkgs/pull/308497",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:187,security,network,network,187,"Cool, good to hear that the PR goes in the right direction then! > It is still not entirely clear in advance which features require connectivity. All features of builtins that do require network note this in their description:. * https://root.cern/install/build_from_source/#all-build-options. * https://github.com/root-project/root/blob/master/cmake/modules/RootBuildOptions.cmake#L87. I agree that `builtin_openui5` should explicitly say that it requires network if `OFF`. For the confusing name with `builtin_`, do you have a suggestion to make this clearer? I don't think there are many options there, we meant of course builtin to the ROOT build, not the source tree :slightly_smiling_face: . About the pre-populating of FetchContent locations: I was facing the same problem recently for nix packages. I fixed it in the end by patching the CMake code of ROOT:. https://github.com/NixOS/nixpkgs/pull/308497",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:457,security,network,network,457,"Cool, good to hear that the PR goes in the right direction then! > It is still not entirely clear in advance which features require connectivity. All features of builtins that do require network note this in their description:. * https://root.cern/install/build_from_source/#all-build-options. * https://github.com/root-project/root/blob/master/cmake/modules/RootBuildOptions.cmake#L87. I agree that `builtin_openui5` should explicitly say that it requires network if `OFF`. For the confusing name with `builtin_`, do you have a suggestion to make this clearer? I don't think there are many options there, we meant of course builtin to the ROOT build, not the source tree :slightly_smiling_face: . About the pre-populating of FetchContent locations: I was facing the same problem recently for nix packages. I fixed it in the end by patching the CMake code of ROOT:. https://github.com/NixOS/nixpkgs/pull/308497",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:832,security,patch,patching,832,"Cool, good to hear that the PR goes in the right direction then! > It is still not entirely clear in advance which features require connectivity. All features of builtins that do require network note this in their description:. * https://root.cern/install/build_from_source/#all-build-options. * https://github.com/root-project/root/blob/master/cmake/modules/RootBuildOptions.cmake#L87. I agree that `builtin_openui5` should explicitly say that it requires network if `OFF`. For the confusing name with `builtin_`, do you have a suggestion to make this clearer? I don't think there are many options there, we meant of course builtin to the ROOT build, not the source tree :slightly_smiling_face: . About the pre-populating of FetchContent locations: I was facing the same problem recently for nix packages. I fixed it in the end by patching the CMake code of ROOT:. https://github.com/NixOS/nixpkgs/pull/308497",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:92,usability,clear,clear,92,"Cool, good to hear that the PR goes in the right direction then! > It is still not entirely clear in advance which features require connectivity. All features of builtins that do require network note this in their description:. * https://root.cern/install/build_from_source/#all-build-options. * https://github.com/root-project/root/blob/master/cmake/modules/RootBuildOptions.cmake#L87. I agree that `builtin_openui5` should explicitly say that it requires network if `OFF`. For the confusing name with `builtin_`, do you have a suggestion to make this clearer? I don't think there are many options there, we meant of course builtin to the ROOT build, not the source tree :slightly_smiling_face: . About the pre-populating of FetchContent locations: I was facing the same problem recently for nix packages. I fixed it in the end by patching the CMake code of ROOT:. https://github.com/NixOS/nixpkgs/pull/308497",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:553,usability,clear,clearer,553,"Cool, good to hear that the PR goes in the right direction then! > It is still not entirely clear in advance which features require connectivity. All features of builtins that do require network note this in their description:. * https://root.cern/install/build_from_source/#all-build-options. * https://github.com/root-project/root/blob/master/cmake/modules/RootBuildOptions.cmake#L87. I agree that `builtin_openui5` should explicitly say that it requires network if `OFF`. For the confusing name with `builtin_`, do you have a suggestion to make this clearer? I don't think there are many options there, we meant of course builtin to the ROOT build, not the source tree :slightly_smiling_face: . About the pre-populating of FetchContent locations: I was facing the same problem recently for nix packages. I fixed it in the end by patching the CMake code of ROOT:. https://github.com/NixOS/nixpkgs/pull/308497",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:17,deployability,patch,patch,17,"Since you had to patch it in nix, you'll also appreciate the fragility of such an approach. In fact, it will already break with #15467... (`substituteInPlace CMakeLists.txt --replace 'if(NO_CONNECTION)' 'if(FALSE)'` will fail to match anything) . I don't want to suggest changing well-established config option names like `builtin_*`, but I think fetching external content should be a default-off option. Is it reasonable to have `builtin_openui5`, which looks for an openui5 tree in _deps (or wherever FetchContent places it), and a separate `fetch_openui5` which enables the fetching itself? That way, we can have `builtin_openui5=ON` and `fetch_openui5=ON` for automatic fetching, and `builtin_openui5=ON` and `fetch_openui5=OFF` when we provide openui5 ourselves. This could extend to other keywords, potentially allowing the default to be seamless with current defaults.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:221,deployability,fail,fail,221,"Since you had to patch it in nix, you'll also appreciate the fragility of such an approach. In fact, it will already break with #15467... (`substituteInPlace CMakeLists.txt --replace 'if(NO_CONNECTION)' 'if(FALSE)'` will fail to match anything) . I don't want to suggest changing well-established config option names like `builtin_*`, but I think fetching external content should be a default-off option. Is it reasonable to have `builtin_openui5`, which looks for an openui5 tree in _deps (or wherever FetchContent places it), and a separate `fetch_openui5` which enables the fetching itself? That way, we can have `builtin_openui5=ON` and `fetch_openui5=ON` for automatic fetching, and `builtin_openui5=ON` and `fetch_openui5=OFF` when we provide openui5 ourselves. This could extend to other keywords, potentially allowing the default to be seamless with current defaults.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:664,deployability,automat,automatic,664,"Since you had to patch it in nix, you'll also appreciate the fragility of such an approach. In fact, it will already break with #15467... (`substituteInPlace CMakeLists.txt --replace 'if(NO_CONNECTION)' 'if(FALSE)'` will fail to match anything) . I don't want to suggest changing well-established config option names like `builtin_*`, but I think fetching external content should be a default-off option. Is it reasonable to have `builtin_openui5`, which looks for an openui5 tree in _deps (or wherever FetchContent places it), and a separate `fetch_openui5` which enables the fetching itself? That way, we can have `builtin_openui5=ON` and `fetch_openui5=ON` for automatic fetching, and `builtin_openui5=ON` and `fetch_openui5=OFF` when we provide openui5 ourselves. This could extend to other keywords, potentially allowing the default to be seamless with current defaults.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:858,energy efficiency,current,current,858,"Since you had to patch it in nix, you'll also appreciate the fragility of such an approach. In fact, it will already break with #15467... (`substituteInPlace CMakeLists.txt --replace 'if(NO_CONNECTION)' 'if(FALSE)'` will fail to match anything) . I don't want to suggest changing well-established config option names like `builtin_*`, but I think fetching external content should be a default-off option. Is it reasonable to have `builtin_openui5`, which looks for an openui5 tree in _deps (or wherever FetchContent places it), and a separate `fetch_openui5` which enables the fetching itself? That way, we can have `builtin_openui5=ON` and `fetch_openui5=ON` for automatic fetching, and `builtin_openui5=ON` and `fetch_openui5=OFF` when we provide openui5 ourselves. This could extend to other keywords, potentially allowing the default to be seamless with current defaults.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:140,integrability,sub,substituteInPlace,140,"Since you had to patch it in nix, you'll also appreciate the fragility of such an approach. In fact, it will already break with #15467... (`substituteInPlace CMakeLists.txt --replace 'if(NO_CONNECTION)' 'if(FALSE)'` will fail to match anything) . I don't want to suggest changing well-established config option names like `builtin_*`, but I think fetching external content should be a default-off option. Is it reasonable to have `builtin_openui5`, which looks for an openui5 tree in _deps (or wherever FetchContent places it), and a separate `fetch_openui5` which enables the fetching itself? That way, we can have `builtin_openui5=ON` and `fetch_openui5=ON` for automatic fetching, and `builtin_openui5=ON` and `fetch_openui5=OFF` when we provide openui5 ourselves. This could extend to other keywords, potentially allowing the default to be seamless with current defaults.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:779,modifiability,exten,extend,779,"Since you had to patch it in nix, you'll also appreciate the fragility of such an approach. In fact, it will already break with #15467... (`substituteInPlace CMakeLists.txt --replace 'if(NO_CONNECTION)' 'if(FALSE)'` will fail to match anything) . I don't want to suggest changing well-established config option names like `builtin_*`, but I think fetching external content should be a default-off option. Is it reasonable to have `builtin_openui5`, which looks for an openui5 tree in _deps (or wherever FetchContent places it), and a separate `fetch_openui5` which enables the fetching itself? That way, we can have `builtin_openui5=ON` and `fetch_openui5=ON` for automatic fetching, and `builtin_openui5=ON` and `fetch_openui5=OFF` when we provide openui5 ourselves. This could extend to other keywords, potentially allowing the default to be seamless with current defaults.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:365,performance,content,content,365,"Since you had to patch it in nix, you'll also appreciate the fragility of such an approach. In fact, it will already break with #15467... (`substituteInPlace CMakeLists.txt --replace 'if(NO_CONNECTION)' 'if(FALSE)'` will fail to match anything) . I don't want to suggest changing well-established config option names like `builtin_*`, but I think fetching external content should be a default-off option. Is it reasonable to have `builtin_openui5`, which looks for an openui5 tree in _deps (or wherever FetchContent places it), and a separate `fetch_openui5` which enables the fetching itself? That way, we can have `builtin_openui5=ON` and `fetch_openui5=ON` for automatic fetching, and `builtin_openui5=ON` and `fetch_openui5=OFF` when we provide openui5 ourselves. This could extend to other keywords, potentially allowing the default to be seamless with current defaults.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:221,reliability,fail,fail,221,"Since you had to patch it in nix, you'll also appreciate the fragility of such an approach. In fact, it will already break with #15467... (`substituteInPlace CMakeLists.txt --replace 'if(NO_CONNECTION)' 'if(FALSE)'` will fail to match anything) . I don't want to suggest changing well-established config option names like `builtin_*`, but I think fetching external content should be a default-off option. Is it reasonable to have `builtin_openui5`, which looks for an openui5 tree in _deps (or wherever FetchContent places it), and a separate `fetch_openui5` which enables the fetching itself? That way, we can have `builtin_openui5=ON` and `fetch_openui5=ON` for automatic fetching, and `builtin_openui5=ON` and `fetch_openui5=OFF` when we provide openui5 ourselves. This could extend to other keywords, potentially allowing the default to be seamless with current defaults.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:17,safety,patch,patch,17,"Since you had to patch it in nix, you'll also appreciate the fragility of such an approach. In fact, it will already break with #15467... (`substituteInPlace CMakeLists.txt --replace 'if(NO_CONNECTION)' 'if(FALSE)'` will fail to match anything) . I don't want to suggest changing well-established config option names like `builtin_*`, but I think fetching external content should be a default-off option. Is it reasonable to have `builtin_openui5`, which looks for an openui5 tree in _deps (or wherever FetchContent places it), and a separate `fetch_openui5` which enables the fetching itself? That way, we can have `builtin_openui5=ON` and `fetch_openui5=ON` for automatic fetching, and `builtin_openui5=ON` and `fetch_openui5=OFF` when we provide openui5 ourselves. This could extend to other keywords, potentially allowing the default to be seamless with current defaults.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:17,security,patch,patch,17,"Since you had to patch it in nix, you'll also appreciate the fragility of such an approach. In fact, it will already break with #15467... (`substituteInPlace CMakeLists.txt --replace 'if(NO_CONNECTION)' 'if(FALSE)'` will fail to match anything) . I don't want to suggest changing well-established config option names like `builtin_*`, but I think fetching external content should be a default-off option. Is it reasonable to have `builtin_openui5`, which looks for an openui5 tree in _deps (or wherever FetchContent places it), and a separate `fetch_openui5` which enables the fetching itself? That way, we can have `builtin_openui5=ON` and `fetch_openui5=ON` for automatic fetching, and `builtin_openui5=ON` and `fetch_openui5=OFF` when we provide openui5 ourselves. This could extend to other keywords, potentially allowing the default to be seamless with current defaults.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/issues/11603:664,testability,automat,automatic,664,"Since you had to patch it in nix, you'll also appreciate the fragility of such an approach. In fact, it will already break with #15467... (`substituteInPlace CMakeLists.txt --replace 'if(NO_CONNECTION)' 'if(FALSE)'` will fail to match anything) . I don't want to suggest changing well-established config option names like `builtin_*`, but I think fetching external content should be a default-off option. Is it reasonable to have `builtin_openui5`, which looks for an openui5 tree in _deps (or wherever FetchContent places it), and a separate `fetch_openui5` which enables the fetching itself? That way, we can have `builtin_openui5=ON` and `fetch_openui5=ON` for automatic fetching, and `builtin_openui5=ON` and `fetch_openui5=OFF` when we provide openui5 ourselves. This could extend to other keywords, potentially allowing the default to be seamless with current defaults.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11603
https://github.com/root-project/root/pull/11604:11,deployability,build,build,11,@phsft-bot build with flags -Droofit_multiprocess=ON -Dbuiltin_zeromq=ON -Dbuiltin_cppzmq=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11604
https://github.com/root-project/root/pull/11607:16,deployability,build,build,16,"I cancelled the build on `mac1015`, the queue is still long...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11607
https://github.com/root-project/root/pull/11607:40,integrability,queue,queue,40,"I cancelled the build on `mac1015`, the queue is still long...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11607
https://github.com/root-project/root/pull/11607:40,performance,queue,queue,40,"I cancelled the build on `mac1015`, the queue is still long...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11607
https://github.com/root-project/root/pull/11607:2,usability,cancel,cancelled,2,"I cancelled the build on `mac1015`, the queue is still long...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11607
https://github.com/root-project/root/pull/11608:153,availability,operat,operator,153,"![image](https://user-images.githubusercontent.com/84740927/200298744-ca666d14-14f6-4b73-8091-5c8cab3892a7.png). Hello @lmoneta I implemented the expand operator but am facing issue with `RModelParser_ONNX.cxx` , can you help me with what can be the possible solution to resolve it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11608
https://github.com/root-project/root/pull/11608:17,usability,user,user-images,17,"![image](https://user-images.githubusercontent.com/84740927/200298744-ca666d14-14f6-4b73-8091-5c8cab3892a7.png). Hello @lmoneta I implemented the expand operator but am facing issue with `RModelParser_ONNX.cxx` , can you help me with what can be the possible solution to resolve it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11608
https://github.com/root-project/root/pull/11608:221,usability,help,help,221,"![image](https://user-images.githubusercontent.com/84740927/200298744-ca666d14-14f6-4b73-8091-5c8cab3892a7.png). Hello @lmoneta I implemented the expand operator but am facing issue with `RModelParser_ONNX.cxx` , can you help me with what can be the possible solution to resolve it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11608
https://github.com/root-project/root/pull/11608:154,availability,operat,operator,154,"> ![image](https://user-images.githubusercontent.com/84740927/200298744-ca666d14-14f6-4b73-8091-5c8cab3892a7.png) Hello @lmoneta I implemented the expand operator but am facing issue with `RModelParser_ONNX.cxx` , can you help me with what can be the possible solution to resolve it? Hi @Neel-Shah-29, You need to add `ParseExpand.cxx` to the cmake file `root/tmva/sofie_parsers/CMakeLists.txt`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11608
https://github.com/root-project/root/pull/11608:19,usability,user,user-images,19,"> ![image](https://user-images.githubusercontent.com/84740927/200298744-ca666d14-14f6-4b73-8091-5c8cab3892a7.png) Hello @lmoneta I implemented the expand operator but am facing issue with `RModelParser_ONNX.cxx` , can you help me with what can be the possible solution to resolve it? Hi @Neel-Shah-29, You need to add `ParseExpand.cxx` to the cmake file `root/tmva/sofie_parsers/CMakeLists.txt`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11608
https://github.com/root-project/root/pull/11608:222,usability,help,help,222,"> ![image](https://user-images.githubusercontent.com/84740927/200298744-ca666d14-14f6-4b73-8091-5c8cab3892a7.png) Hello @lmoneta I implemented the expand operator but am facing issue with `RModelParser_ONNX.cxx` , can you help me with what can be the possible solution to resolve it? Hi @Neel-Shah-29, You need to add `ParseExpand.cxx` to the cmake file `root/tmva/sofie_parsers/CMakeLists.txt`.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11608
https://github.com/root-project/root/pull/11608:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2204/cxx17, ROOT-ubuntu2004/default, ROOT-ubuntu18.04/nortcxxmod",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11608
https://github.com/root-project/root/pull/11608:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu2204/cxx17, ROOT-ubuntu2004/default, ROOT-ubuntu18.04/nortcxxmod",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11608
https://github.com/root-project/root/pull/11609:11,deployability,build,build,11,@phsft-bot build just on ROOT-performance-centos8-multicore/default with flags -DCTEST_TEST_EXCLUDE_NONE=On -Droofit=OFF,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11609
https://github.com/root-project/root/pull/11609:30,performance,perform,performance-,30,@phsft-bot build just on ROOT-performance-centos8-multicore/default with flags -DCTEST_TEST_EXCLUDE_NONE=On -Droofit=OFF,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11609
https://github.com/root-project/root/pull/11609:30,usability,perform,performance-,30,@phsft-bot build just on ROOT-performance-centos8-multicore/default with flags -DCTEST_TEST_EXCLUDE_NONE=On -Droofit=OFF,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11609
https://github.com/root-project/root/pull/11613:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11613
https://github.com/root-project/root/pull/11613:11,deployability,build,build,11,@phsft-bot build just on mac1015/cxx17,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11613
https://github.com/root-project/root/pull/11613:56,availability,servic,services,56,I asked for a rebuild as the last build (https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-handler/23894/) seemed to be stuck / skipped there. ![build-stuck](https://user-images.githubusercontent.com/5142394/196799114-794d59e3-b3d5-44d6-901f-29876bab9314.png).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11613
https://github.com/root-project/root/pull/11613:34,deployability,build,build,34,I asked for a rebuild as the last build (https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-handler/23894/) seemed to be stuck / skipped there. ![build-stuck](https://user-images.githubusercontent.com/5142394/196799114-794d59e3-b3d5-44d6-901f-29876bab9314.png).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11613
https://github.com/root-project/root/pull/11613:56,deployability,servic,services,56,I asked for a rebuild as the last build (https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-handler/23894/) seemed to be stuck / skipped there. ![build-stuck](https://user-images.githubusercontent.com/5142394/196799114-794d59e3-b3d5-44d6-901f-29876bab9314.png).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11613
https://github.com/root-project/root/pull/11613:162,deployability,build,build-stuck,162,I asked for a rebuild as the last build (https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-handler/23894/) seemed to be stuck / skipped there. ![build-stuck](https://user-images.githubusercontent.com/5142394/196799114-794d59e3-b3d5-44d6-901f-29876bab9314.png).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11613
https://github.com/root-project/root/pull/11613:56,integrability,servic,services,56,I asked for a rebuild as the last build (https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-handler/23894/) seemed to be stuck / skipped there. ![build-stuck](https://user-images.githubusercontent.com/5142394/196799114-794d59e3-b3d5-44d6-901f-29876bab9314.png).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11613
https://github.com/root-project/root/pull/11613:56,modifiability,servic,services,56,I asked for a rebuild as the last build (https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-handler/23894/) seemed to be stuck / skipped there. ![build-stuck](https://user-images.githubusercontent.com/5142394/196799114-794d59e3-b3d5-44d6-901f-29876bab9314.png).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11613
https://github.com/root-project/root/pull/11613:183,usability,user,user-images,183,I asked for a rebuild as the last build (https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-handler/23894/) seemed to be stuck / skipped there. ![build-stuck](https://user-images.githubusercontent.com/5142394/196799114-794d59e3-b3d5-44d6-901f-29876bab9314.png).,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11613
https://github.com/root-project/root/pull/11613:36,safety,review,review,36,@bellenot this is finally ready for review as the CI has passed. :+1:,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11613
https://github.com/root-project/root/pull/11613:36,testability,review,review,36,@bellenot this is finally ready for review as the CI has passed. :+1:,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11613
https://github.com/root-project/root/pull/11613:83,interoperability,platform,platforms,83,"@matthewfeickert OK, thanks, but why just on mac1015/cxx17? Can I try again on all platforms?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11613
https://github.com/root-project/root/pull/11613:323,deployability,build,build,323,"> @matthewfeickert OK, thanks, but why just on mac1015/cxx17? Can I try again on all platforms? I did run on all the platforms. c.f. https://github.com/root-project/root/pull/11613#issuecomment-1284287593. The macos jobs got stuck https://github.com/root-project/root/pull/11613#issuecomment-1284546005 so I re-triggered a build for them https://github.com/root-project/root/pull/11613#issuecomment-1284545221.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11613
https://github.com/root-project/root/pull/11613:85,interoperability,platform,platforms,85,"> @matthewfeickert OK, thanks, but why just on mac1015/cxx17? Can I try again on all platforms? I did run on all the platforms. c.f. https://github.com/root-project/root/pull/11613#issuecomment-1284287593. The macos jobs got stuck https://github.com/root-project/root/pull/11613#issuecomment-1284546005 so I re-triggered a build for them https://github.com/root-project/root/pull/11613#issuecomment-1284545221.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11613
https://github.com/root-project/root/pull/11613:117,interoperability,platform,platforms,117,"> @matthewfeickert OK, thanks, but why just on mac1015/cxx17? Can I try again on all platforms? I did run on all the platforms. c.f. https://github.com/root-project/root/pull/11613#issuecomment-1284287593. The macos jobs got stuck https://github.com/root-project/root/pull/11613#issuecomment-1284546005 so I re-triggered a build for them https://github.com/root-project/root/pull/11613#issuecomment-1284545221.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11613
https://github.com/root-project/root/pull/11613:39,safety,review,review,39,Likewise thanks very much for the fast review! :),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11613
https://github.com/root-project/root/pull/11613:39,testability,review,review,39,Likewise thanks very much for the fast review! :),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11613
https://github.com/root-project/root/pull/11614:83,deployability,build,build,83,The `grep` is quite long to perform.. it adds 1 minute. Well compared to the whole build it is only a small %.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:28,performance,perform,perform,28,The `grep` is quite long to perform.. it adds 1 minute. Well compared to the whole build it is only a small %.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:28,usability,perform,perform,28,The `grep` is quite long to perform.. it adds 1 minute. Well compared to the whole build it is only a small %.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:118,integrability,repositor,repository,118,You are looking only for `macro_image`. This is used only in the tutorials. So you do not need to grep the whole ROOT repository as you do. You need to grep only the tutorials folder.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:118,interoperability,repositor,repository,118,You are looking only for `macro_image`. This is used only in the tutorials. So you do not need to grep the whole ROOT repository as you do. You need to grep only the tutorials folder.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:326,deployability,log,log-ouput,326,"And by the way, I cannot reproduce locally these warnings. For example:. ```. ... Info in <TCanvas::Print>: SVG file mathsymb.svg has been created. Info in <TCanvas::Print>: png file /Users/couet/rootdoc/html/pict1_latex5.C.png has been created. Info in <TCanvas::Print>: ps file mathsymb.ps has been created. ... ```. On the log-ouput you pointed we can see a warning about `latex5.C` but locally, with a fresh build, it is fine. No warning.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:412,deployability,build,build,412,"And by the way, I cannot reproduce locally these warnings. For example:. ```. ... Info in <TCanvas::Print>: SVG file mathsymb.svg has been created. Info in <TCanvas::Print>: png file /Users/couet/rootdoc/html/pict1_latex5.C.png has been created. Info in <TCanvas::Print>: ps file mathsymb.ps has been created. ... ```. On the log-ouput you pointed we can see a warning about `latex5.C` but locally, with a fresh build, it is fine. No warning.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:326,safety,log,log-ouput,326,"And by the way, I cannot reproduce locally these warnings. For example:. ```. ... Info in <TCanvas::Print>: SVG file mathsymb.svg has been created. Info in <TCanvas::Print>: png file /Users/couet/rootdoc/html/pict1_latex5.C.png has been created. Info in <TCanvas::Print>: ps file mathsymb.ps has been created. ... ```. On the log-ouput you pointed we can see a warning about `latex5.C` but locally, with a fresh build, it is fine. No warning.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:326,security,log,log-ouput,326,"And by the way, I cannot reproduce locally these warnings. For example:. ```. ... Info in <TCanvas::Print>: SVG file mathsymb.svg has been created. Info in <TCanvas::Print>: png file /Users/couet/rootdoc/html/pict1_latex5.C.png has been created. Info in <TCanvas::Print>: ps file mathsymb.ps has been created. ... ```. On the log-ouput you pointed we can see a warning about `latex5.C` but locally, with a fresh build, it is fine. No warning.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:326,testability,log,log-ouput,326,"And by the way, I cannot reproduce locally these warnings. For example:. ```. ... Info in <TCanvas::Print>: SVG file mathsymb.svg has been created. Info in <TCanvas::Print>: png file /Users/couet/rootdoc/html/pict1_latex5.C.png has been created. Info in <TCanvas::Print>: ps file mathsymb.ps has been created. ... ```. On the log-ouput you pointed we can see a warning about `latex5.C` but locally, with a fresh build, it is fine. No warning.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:184,usability,User,Users,184,"And by the way, I cannot reproduce locally these warnings. For example:. ```. ... Info in <TCanvas::Print>: SVG file mathsymb.svg has been created. Info in <TCanvas::Print>: png file /Users/couet/rootdoc/html/pict1_latex5.C.png has been created. Info in <TCanvas::Print>: ps file mathsymb.ps has been created. ... ```. On the log-ouput you pointed we can see a warning about `latex5.C` but locally, with a fresh build, it is fine. No warning.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:120,integrability,repositor,repository,120,> You are looking only for `macro_image`. This is used only in the tutorials. So you do not need to grep the whole ROOT repository as you do. You need to grep only the tutorials folder. Good point. Changed.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:120,interoperability,repositor,repository,120,> You are looking only for `macro_image`. This is used only in the tutorials. So you do not need to grep the whole ROOT repository as you do. You need to grep only the tutorials folder. Good point. Changed.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:352,deployability,log,log-ouput,352,"> And by the way, I cannot reproduce locally these warnings. For example:. > . > ```. > ... > Info in <TCanvas::Print>: SVG file mathsymb.svg has been created. > Info in <TCanvas::Print>: png file /Users/couet/rootdoc/html/pict1_latex5.C.png has been created. > Info in <TCanvas::Print>: ps file mathsymb.ps has been created. > ... > ```. > . > On the log-ouput you pointed we can see a warning about `latex5.C` but locally, with a fresh build, it is fine. No warning. Maybe it would be useful to add to the Jenkins build a step that cleans the git repository on sftnight before starting the build? To get fresh builds there too?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:438,deployability,build,build,438,"> And by the way, I cannot reproduce locally these warnings. For example:. > . > ```. > ... > Info in <TCanvas::Print>: SVG file mathsymb.svg has been created. > Info in <TCanvas::Print>: png file /Users/couet/rootdoc/html/pict1_latex5.C.png has been created. > Info in <TCanvas::Print>: ps file mathsymb.ps has been created. > ... > ```. > . > On the log-ouput you pointed we can see a warning about `latex5.C` but locally, with a fresh build, it is fine. No warning. Maybe it would be useful to add to the Jenkins build a step that cleans the git repository on sftnight before starting the build? To get fresh builds there too?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:516,deployability,build,build,516,"> And by the way, I cannot reproduce locally these warnings. For example:. > . > ```. > ... > Info in <TCanvas::Print>: SVG file mathsymb.svg has been created. > Info in <TCanvas::Print>: png file /Users/couet/rootdoc/html/pict1_latex5.C.png has been created. > Info in <TCanvas::Print>: ps file mathsymb.ps has been created. > ... > ```. > . > On the log-ouput you pointed we can see a warning about `latex5.C` but locally, with a fresh build, it is fine. No warning. Maybe it would be useful to add to the Jenkins build a step that cleans the git repository on sftnight before starting the build? To get fresh builds there too?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:592,deployability,build,build,592,"> And by the way, I cannot reproduce locally these warnings. For example:. > . > ```. > ... > Info in <TCanvas::Print>: SVG file mathsymb.svg has been created. > Info in <TCanvas::Print>: png file /Users/couet/rootdoc/html/pict1_latex5.C.png has been created. > Info in <TCanvas::Print>: ps file mathsymb.ps has been created. > ... > ```. > . > On the log-ouput you pointed we can see a warning about `latex5.C` but locally, with a fresh build, it is fine. No warning. Maybe it would be useful to add to the Jenkins build a step that cleans the git repository on sftnight before starting the build? To get fresh builds there too?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:612,deployability,build,builds,612,"> And by the way, I cannot reproduce locally these warnings. For example:. > . > ```. > ... > Info in <TCanvas::Print>: SVG file mathsymb.svg has been created. > Info in <TCanvas::Print>: png file /Users/couet/rootdoc/html/pict1_latex5.C.png has been created. > Info in <TCanvas::Print>: ps file mathsymb.ps has been created. > ... > ```. > . > On the log-ouput you pointed we can see a warning about `latex5.C` but locally, with a fresh build, it is fine. No warning. Maybe it would be useful to add to the Jenkins build a step that cleans the git repository on sftnight before starting the build? To get fresh builds there too?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:549,integrability,repositor,repository,549,"> And by the way, I cannot reproduce locally these warnings. For example:. > . > ```. > ... > Info in <TCanvas::Print>: SVG file mathsymb.svg has been created. > Info in <TCanvas::Print>: png file /Users/couet/rootdoc/html/pict1_latex5.C.png has been created. > Info in <TCanvas::Print>: ps file mathsymb.ps has been created. > ... > ```. > . > On the log-ouput you pointed we can see a warning about `latex5.C` but locally, with a fresh build, it is fine. No warning. Maybe it would be useful to add to the Jenkins build a step that cleans the git repository on sftnight before starting the build? To get fresh builds there too?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:549,interoperability,repositor,repository,549,"> And by the way, I cannot reproduce locally these warnings. For example:. > . > ```. > ... > Info in <TCanvas::Print>: SVG file mathsymb.svg has been created. > Info in <TCanvas::Print>: png file /Users/couet/rootdoc/html/pict1_latex5.C.png has been created. > Info in <TCanvas::Print>: ps file mathsymb.ps has been created. > ... > ```. > . > On the log-ouput you pointed we can see a warning about `latex5.C` but locally, with a fresh build, it is fine. No warning. Maybe it would be useful to add to the Jenkins build a step that cleans the git repository on sftnight before starting the build? To get fresh builds there too?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:352,safety,log,log-ouput,352,"> And by the way, I cannot reproduce locally these warnings. For example:. > . > ```. > ... > Info in <TCanvas::Print>: SVG file mathsymb.svg has been created. > Info in <TCanvas::Print>: png file /Users/couet/rootdoc/html/pict1_latex5.C.png has been created. > Info in <TCanvas::Print>: ps file mathsymb.ps has been created. > ... > ```. > . > On the log-ouput you pointed we can see a warning about `latex5.C` but locally, with a fresh build, it is fine. No warning. Maybe it would be useful to add to the Jenkins build a step that cleans the git repository on sftnight before starting the build? To get fresh builds there too?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:352,security,log,log-ouput,352,"> And by the way, I cannot reproduce locally these warnings. For example:. > . > ```. > ... > Info in <TCanvas::Print>: SVG file mathsymb.svg has been created. > Info in <TCanvas::Print>: png file /Users/couet/rootdoc/html/pict1_latex5.C.png has been created. > Info in <TCanvas::Print>: ps file mathsymb.ps has been created. > ... > ```. > . > On the log-ouput you pointed we can see a warning about `latex5.C` but locally, with a fresh build, it is fine. No warning. Maybe it would be useful to add to the Jenkins build a step that cleans the git repository on sftnight before starting the build? To get fresh builds there too?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:352,testability,log,log-ouput,352,"> And by the way, I cannot reproduce locally these warnings. For example:. > . > ```. > ... > Info in <TCanvas::Print>: SVG file mathsymb.svg has been created. > Info in <TCanvas::Print>: png file /Users/couet/rootdoc/html/pict1_latex5.C.png has been created. > Info in <TCanvas::Print>: ps file mathsymb.ps has been created. > ... > ```. > . > On the log-ouput you pointed we can see a warning about `latex5.C` but locally, with a fresh build, it is fine. No warning. Maybe it would be useful to add to the Jenkins build a step that cleans the git repository on sftnight before starting the build? To get fresh builds there too?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:198,usability,User,Users,198,"> And by the way, I cannot reproduce locally these warnings. For example:. > . > ```. > ... > Info in <TCanvas::Print>: SVG file mathsymb.svg has been created. > Info in <TCanvas::Print>: png file /Users/couet/rootdoc/html/pict1_latex5.C.png has been created. > Info in <TCanvas::Print>: ps file mathsymb.ps has been created. > ... > ```. > . > On the log-ouput you pointed we can see a warning about `latex5.C` but locally, with a fresh build, it is fine. No warning. Maybe it would be useful to add to the Jenkins build a step that cleans the git repository on sftnight before starting the build? To get fresh builds there too?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:49,deployability,build,build,49,> Maybe it would be useful to add to the Jenkins build a step that cleans the git repository on sftnight before starting the build? To get fresh builds there too? For example using the git clean command within https://github.com/root-project/rootspi/blob/master/rdoc/preparesource.sh:. https://www.geeksforgeeks.org/git-clean/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:125,deployability,build,build,125,> Maybe it would be useful to add to the Jenkins build a step that cleans the git repository on sftnight before starting the build? To get fresh builds there too? For example using the git clean command within https://github.com/root-project/rootspi/blob/master/rdoc/preparesource.sh:. https://www.geeksforgeeks.org/git-clean/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:145,deployability,build,builds,145,> Maybe it would be useful to add to the Jenkins build a step that cleans the git repository on sftnight before starting the build? To get fresh builds there too? For example using the git clean command within https://github.com/root-project/rootspi/blob/master/rdoc/preparesource.sh:. https://www.geeksforgeeks.org/git-clean/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:82,integrability,repositor,repository,82,> Maybe it would be useful to add to the Jenkins build a step that cleans the git repository on sftnight before starting the build? To get fresh builds there too? For example using the git clean command within https://github.com/root-project/rootspi/blob/master/rdoc/preparesource.sh:. https://www.geeksforgeeks.org/git-clean/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:82,interoperability,repositor,repository,82,> Maybe it would be useful to add to the Jenkins build a step that cleans the git repository on sftnight before starting the build? To get fresh builds there too? For example using the git clean command within https://github.com/root-project/rootspi/blob/master/rdoc/preparesource.sh:. https://www.geeksforgeeks.org/git-clean/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:195,usability,command,command,195,> Maybe it would be useful to add to the Jenkins build a step that cleans the git repository on sftnight before starting the build? To get fresh builds there too? For example using the git clean command within https://github.com/root-project/rootspi/blob/master/rdoc/preparesource.sh:. https://www.geeksforgeeks.org/git-clean/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:53,availability,error,error,53,"It is more tricky than I thought. Actually I see the error ""sometimes"" on fresh builds only. That's not clear yet ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:80,deployability,build,builds,80,"It is more tricky than I thought. Actually I see the error ""sometimes"" on fresh builds only. That's not clear yet ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:53,performance,error,error,53,"It is more tricky than I thought. Actually I see the error ""sometimes"" on fresh builds only. That's not clear yet ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:53,safety,error,error,53,"It is more tricky than I thought. Actually I see the error ""sometimes"" on fresh builds only. That's not clear yet ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:53,usability,error,error,53,"It is more tricky than I thought. Actually I see the error ""sometimes"" on fresh builds only. That's not clear yet ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:104,usability,clear,clear,104,"It is more tricky than I thought. Actually I see the error ""sometimes"" on fresh builds only. That's not clear yet ...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:267,deployability,build,build,267,"Maybe it's just a multi-threading thing? The output lines are ordered differently each time because the threads write to stdout in different order. If you Search for ""latex5.C"", don't you see always a warning line (every time in different position):. `/home/sftnight/build/workspace/root-makedoc-master/rootspi/rdoc/src/master/tutorials/graphics/latex5.C:8: warning: image file pict1_latex5.C.png is not found in IMAGE_PATH: assuming external image.`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:18,performance,multi-thread,multi-threading,18,"Maybe it's just a multi-threading thing? The output lines are ordered differently each time because the threads write to stdout in different order. If you Search for ""latex5.C"", don't you see always a warning line (every time in different position):. `/home/sftnight/build/workspace/root-makedoc-master/rootspi/rdoc/src/master/tutorials/graphics/latex5.C:8: warning: image file pict1_latex5.C.png is not found in IMAGE_PATH: assuming external image.`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:87,performance,time,time,87,"Maybe it's just a multi-threading thing? The output lines are ordered differently each time because the threads write to stdout in different order. If you Search for ""latex5.C"", don't you see always a warning line (every time in different position):. `/home/sftnight/build/workspace/root-makedoc-master/rootspi/rdoc/src/master/tutorials/graphics/latex5.C:8: warning: image file pict1_latex5.C.png is not found in IMAGE_PATH: assuming external image.`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:221,performance,time,time,221,"Maybe it's just a multi-threading thing? The output lines are ordered differently each time because the threads write to stdout in different order. If you Search for ""latex5.C"", don't you see always a warning line (every time in different position):. `/home/sftnight/build/workspace/root-makedoc-master/rootspi/rdoc/src/master/tutorials/graphics/latex5.C:8: warning: image file pict1_latex5.C.png is not found in IMAGE_PATH: assuming external image.`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:26,reliability,doe,does,26,Do we still want this? It does not seem really safe...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11614:47,safety,safe,safe,47,Do we still want this? It does not seem really safe...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11614
https://github.com/root-project/root/pull/11615:99,deployability,releas,release,99,"@matthewfeickert FYI, it's fine with me, but I'll wait for Axel next week to ask the status of the release before backporting it",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11615
https://github.com/root-project/root/pull/11615:85,usability,statu,status,85,"@matthewfeickert FYI, it's fine with me, but I'll wait for Axel next week to ask the status of the release before backporting it",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11615
https://github.com/root-project/root/pull/11615:11,deployability,build,build,11,@phsft-bot build just on windows10/cxx14,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11615
https://github.com/root-project/root/issues/11616:98,deployability,updat,update,98,"Yes, https://github.com/root-project/root/pull/16039 takes care of `Long_t`, but we still need to update `RProxiedCollectionField` to remove the hard-coded fixed width integer types.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11616
https://github.com/root-project/root/issues/11616:98,safety,updat,update,98,"Yes, https://github.com/root-project/root/pull/16039 takes care of `Long_t`, but we still need to update `RProxiedCollectionField` to remove the hard-coded fixed width integer types.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11616
https://github.com/root-project/root/issues/11616:98,security,updat,update,98,"Yes, https://github.com/root-project/root/pull/16039 takes care of `Long_t`, but we still need to update `RProxiedCollectionField` to remove the hard-coded fixed width integer types.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11616
https://github.com/root-project/root/pull/11623:38,availability,failur,failures,38,"The changes of this PR cause new test failures which are related to the iteration of `std::vector`. Possibly the `value_type` and `value_size` fields are linked to the iteration too, and some additional changes are required there. Needs investigation.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11623
https://github.com/root-project/root/pull/11623:38,deployability,fail,failures,38,"The changes of this PR cause new test failures which are related to the iteration of `std::vector`. Possibly the `value_type` and `value_size` fields are linked to the iteration too, and some additional changes are required there. Needs investigation.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11623
https://github.com/root-project/root/pull/11623:38,performance,failur,failures,38,"The changes of this PR cause new test failures which are related to the iteration of `std::vector`. Possibly the `value_type` and `value_size` fields are linked to the iteration too, and some additional changes are required there. Needs investigation.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11623
https://github.com/root-project/root/pull/11623:38,reliability,fail,failures,38,"The changes of this PR cause new test failures which are related to the iteration of `std::vector`. Possibly the `value_type` and `value_size` fields are linked to the iteration too, and some additional changes are required there. Needs investigation.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11623
https://github.com/root-project/root/pull/11623:33,safety,test,test,33,"The changes of this PR cause new test failures which are related to the iteration of `std::vector`. Possibly the `value_type` and `value_size` fields are linked to the iteration too, and some additional changes are required there. Needs investigation.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11623
https://github.com/root-project/root/pull/11623:33,testability,test,test,33,"The changes of this PR cause new test failures which are related to the iteration of `std::vector`. Possibly the `value_type` and `value_size` fields are linked to the iteration too, and some additional changes are required there. Needs investigation.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11623
https://github.com/root-project/root/pull/11623:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11623
https://github.com/root-project/root/issues/11624:157,integrability,Event,Events,157,"> Any ideas? Looks doable. I didn't notice anything that's missing on 1st read. I was only wondering how you do this:. ```json. ""sample_a"":{. ""treenames"": [""Events"", ""ADifferentName""],. ""files"": [""fa*.root"", ""TheWeirdFileWithTheDifferentName""],. # ... },. ```. What would you expect to happen in this case?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:355,energy efficiency,current,current,355,"> > Any ideas? > . > Looks doable. I didn't notice anything that's missing on 1st read. > . > I was only wondering how you do this:. > . > ```json. > ""sample_a"":{. > ""treenames"": [""Events"", ""ADifferentName""],. > ""files"": [""fa*.root"", ""TheWeirdFileWithTheDifferentName""],. > # ... > },. > ```. > . > What would you expect to happen in this case? As of the current implementation - map the first file glob to the first tree name (so every tree in ""fa*.root"" is expected to be called ""Events""). And then, the next file(glob) has tree(s) with the name ""ADifferentName"". This however, requires the user to be careful to do the matching between treename and glob. Alternative, that I recall from the PPP discussion was to instead specify tree and file together - I imagine [""fa*.root?#Events"", ""ADifferentName?#TheWeirdFileWithTheDifferentName""]. Is this what you are asking, @hageboeck ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:181,integrability,Event,Events,181,"> > Any ideas? > . > Looks doable. I didn't notice anything that's missing on 1st read. > . > I was only wondering how you do this:. > . > ```json. > ""sample_a"":{. > ""treenames"": [""Events"", ""ADifferentName""],. > ""files"": [""fa*.root"", ""TheWeirdFileWithTheDifferentName""],. > # ... > },. > ```. > . > What would you expect to happen in this case? As of the current implementation - map the first file glob to the first tree name (so every tree in ""fa*.root"" is expected to be called ""Events""). And then, the next file(glob) has tree(s) with the name ""ADifferentName"". This however, requires the user to be careful to do the matching between treename and glob. Alternative, that I recall from the PPP discussion was to instead specify tree and file together - I imagine [""fa*.root?#Events"", ""ADifferentName?#TheWeirdFileWithTheDifferentName""]. Is this what you are asking, @hageboeck ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:482,integrability,Event,Events,482,"> > Any ideas? > . > Looks doable. I didn't notice anything that's missing on 1st read. > . > I was only wondering how you do this:. > . > ```json. > ""sample_a"":{. > ""treenames"": [""Events"", ""ADifferentName""],. > ""files"": [""fa*.root"", ""TheWeirdFileWithTheDifferentName""],. > # ... > },. > ```. > . > What would you expect to happen in this case? As of the current implementation - map the first file glob to the first tree name (so every tree in ""fa*.root"" is expected to be called ""Events""). And then, the next file(glob) has tree(s) with the name ""ADifferentName"". This however, requires the user to be careful to do the matching between treename and glob. Alternative, that I recall from the PPP discussion was to instead specify tree and file together - I imagine [""fa*.root?#Events"", ""ADifferentName?#TheWeirdFileWithTheDifferentName""]. Is this what you are asking, @hageboeck ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:779,integrability,Event,Events,779,"> > Any ideas? > . > Looks doable. I didn't notice anything that's missing on 1st read. > . > I was only wondering how you do this:. > . > ```json. > ""sample_a"":{. > ""treenames"": [""Events"", ""ADifferentName""],. > ""files"": [""fa*.root"", ""TheWeirdFileWithTheDifferentName""],. > # ... > },. > ```. > . > What would you expect to happen in this case? As of the current implementation - map the first file glob to the first tree name (so every tree in ""fa*.root"" is expected to be called ""Events""). And then, the next file(glob) has tree(s) with the name ""ADifferentName"". This however, requires the user to be careful to do the matching between treename and glob. Alternative, that I recall from the PPP discussion was to instead specify tree and file together - I imagine [""fa*.root?#Events"", ""ADifferentName?#TheWeirdFileWithTheDifferentName""]. Is this what you are asking, @hageboeck ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:724,interoperability,specif,specify,724,"> > Any ideas? > . > Looks doable. I didn't notice anything that's missing on 1st read. > . > I was only wondering how you do this:. > . > ```json. > ""sample_a"":{. > ""treenames"": [""Events"", ""ADifferentName""],. > ""files"": [""fa*.root"", ""TheWeirdFileWithTheDifferentName""],. > # ... > },. > ```. > . > What would you expect to happen in this case? As of the current implementation - map the first file glob to the first tree name (so every tree in ""fa*.root"" is expected to be called ""Events""). And then, the next file(glob) has tree(s) with the name ""ADifferentName"". This however, requires the user to be careful to do the matching between treename and glob. Alternative, that I recall from the PPP discussion was to instead specify tree and file together - I imagine [""fa*.root?#Events"", ""ADifferentName?#TheWeirdFileWithTheDifferentName""]. Is this what you are asking, @hageboeck ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:593,usability,user,user,593,"> > Any ideas? > . > Looks doable. I didn't notice anything that's missing on 1st read. > . > I was only wondering how you do this:. > . > ```json. > ""sample_a"":{. > ""treenames"": [""Events"", ""ADifferentName""],. > ""files"": [""fa*.root"", ""TheWeirdFileWithTheDifferentName""],. > # ... > },. > ```. > . > What would you expect to happen in this case? As of the current implementation - map the first file glob to the first tree name (so every tree in ""fa*.root"" is expected to be called ""Events""). And then, the next file(glob) has tree(s) with the name ""ADifferentName"". This however, requires the user to be careful to do the matching between treename and glob. Alternative, that I recall from the PPP discussion was to instead specify tree and file together - I imagine [""fa*.root?#Events"", ""ADifferentName?#TheWeirdFileWithTheDifferentName""]. Is this what you are asking, @hageboeck ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:1596,availability,operat,operational,1596," [""some"", ""list"", ""of"", ""files""], ...}. # and. fileset = { ""dataset"": { ""files"": [""file1"", ""file2"", ...], ""treename"": ""Events"", ""metadata"": { ""stuff"": ""about stuff""}, ...}, { .... } }. ```. depending on user need. I think optional and union types are very convenient here since not every user will need or want to specify all components of the full schema on each use (but uniformizing the description when needed is very important). . To repeat from above here is the suggested metadata requirements (with annotations). """""". This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata. * Decide what term to use instead of ""groups"" (dataset is probably best). * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a standard. As to files - it is not very common but people do use parquet or hdf5 in analysis. Removing those formats as concepts to describe a dataset is rather limiting. Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This can make things much easier in the case that, for instance, some random machine learning tool cannot output root files but can produce some other usefully structured data format. . *** - The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of frien",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:3210,availability,error,error,3210,"ncluding mixed modes and joins across rather heterogenous datasets. This can make things much easier in the case that, for instance, some random machine learning tool cannot output root files but can produce some other usefully structured data format. . *** - The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple, which is limiting in scope for what is possible for dataset augmentation. Moreover, this allows the definition of left/right/inner/outer joins at the metadata level which is extremely useful for understanding how that additional data is intended to be used (are you just augmenting the number of columns in the dataset, are you x-referencing two datasets, etc.). It is then up to the system ingesting this data to implement the join specified by the user correctly (which can be tested for). For the second *** reference, this is also a restriction of your program, not the metadata, an error should be thrown by whatever is executing and cannot handle a case rather than restricting concepts for describing a dataset. Furthermore, going to joins as a metadata concept allows the user to specify an entire dataset for a join rather than individual files, resulting in significant reduction of doubly-bookkept data. . Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user (since it is often the case they will want to run over a limited piece of the data to test things and then run over the full dataset). Re-writing the metadata on each run would get cumbersome quickly. To take all this and mutate your original suggestion (I haven't defined all the types but hopefully it's intelligible):. ```. {. ""datasets"":{. ""dataset"":{. ""treenames"": Union[List[String], String],. ""files"": List[String],. ""friends"":{. ""treenames"": Union[List[String], String],. ""files"": List[String],. ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:792,deployability,depend,depending,792,"Hi - this is an excellent start but I'd like to offer a few considerations given that not everyone uses root files these days. Specifically, friend trees are not a widely accepted concept outside of TTrees and RNtuple. It is, however, easy to abstract away from this so that this metadata specification is more universal. In coffea, we didn't go all the way to formalizing it in a schema since there are many details but you can see the basic validation we do here:. https://github.com/CoffeaTeam/coffea/blob/master/coffea/processor/executor.py#L1353. We allow forms like:. ```. fileset = { ""dataset"" : [""some"", ""list"", ""of"", ""files""], ...}. # and. fileset = { ""dataset"": { ""files"": [""file1"", ""file2"", ...], ""treename"": ""Events"", ""metadata"": { ""stuff"": ""about stuff""}, ...}, { .... } }. ```. depending on user need. I think optional and union types are very convenient here since not every user will need or want to specify all components of the full schema on each use (but uniformizing the description when needed is very important). . To repeat from above here is the suggested metadata requirements (with annotations). """""". This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata. * Decide what term to use instead of ""groups"" (dataset is probably best). * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a s",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:3503,energy efficiency,reduc,reduction,3503," a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple, which is limiting in scope for what is possible for dataset augmentation. Moreover, this allows the definition of left/right/inner/outer joins at the metadata level which is extremely useful for understanding how that additional data is intended to be used (are you just augmenting the number of columns in the dataset, are you x-referencing two datasets, etc.). It is then up to the system ingesting this data to implement the join specified by the user correctly (which can be tested for). For the second *** reference, this is also a restriction of your program, not the metadata, an error should be thrown by whatever is executing and cannot handle a case rather than restricting concepts for describing a dataset. Furthermore, going to joins as a metadata concept allows the user to specify an entire dataset for a join rather than individual files, resulting in significant reduction of doubly-bookkept data. . Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user (since it is often the case they will want to run over a limited piece of the data to test things and then run over the full dataset). Re-writing the metadata on each run would get cumbersome quickly. To take all this and mutate your original suggestion (I haven't defined all the types but hopefully it's intelligible):. ```. {. ""datasets"":{. ""dataset"":{. ""treenames"": Union[List[String], String],. ""files"": List[String],. ""friends"":{. ""treenames"": Union[List[String], String],. ""files"": List[String],. ""joinType"": OneOf[""inner"", ""outer"", ""left"", ""right"", ""cross""], #this should just be made into a type. } or List[Dict[As in Single Dict]],. ""metadata"": Optional[Dict[JsonSerialiableAny:JsonSerializableAny]]. },. # ... },. # other optional values from here on. ""metadata"": Optional[Dict[JsonSerial",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:243,integrability,abstract,abstract,243,"Hi - this is an excellent start but I'd like to offer a few considerations given that not everyone uses root files these days. Specifically, friend trees are not a widely accepted concept outside of TTrees and RNtuple. It is, however, easy to abstract away from this so that this metadata specification is more universal. In coffea, we didn't go all the way to formalizing it in a schema since there are many details but you can see the basic validation we do here:. https://github.com/CoffeaTeam/coffea/blob/master/coffea/processor/executor.py#L1353. We allow forms like:. ```. fileset = { ""dataset"" : [""some"", ""list"", ""of"", ""files""], ...}. # and. fileset = { ""dataset"": { ""files"": [""file1"", ""file2"", ...], ""treename"": ""Events"", ""metadata"": { ""stuff"": ""about stuff""}, ...}, { .... } }. ```. depending on user need. I think optional and union types are very convenient here since not every user will need or want to specify all components of the full schema on each use (but uniformizing the description when needed is very important). . To repeat from above here is the suggested metadata requirements (with annotations). """""". This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata. * Decide what term to use instead of ""groups"" (dataset is probably best). * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a s",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:381,integrability,schema,schema,381,"Hi - this is an excellent start but I'd like to offer a few considerations given that not everyone uses root files these days. Specifically, friend trees are not a widely accepted concept outside of TTrees and RNtuple. It is, however, easy to abstract away from this so that this metadata specification is more universal. In coffea, we didn't go all the way to formalizing it in a schema since there are many details but you can see the basic validation we do here:. https://github.com/CoffeaTeam/coffea/blob/master/coffea/processor/executor.py#L1353. We allow forms like:. ```. fileset = { ""dataset"" : [""some"", ""list"", ""of"", ""files""], ...}. # and. fileset = { ""dataset"": { ""files"": [""file1"", ""file2"", ...], ""treename"": ""Events"", ""metadata"": { ""stuff"": ""about stuff""}, ...}, { .... } }. ```. depending on user need. I think optional and union types are very convenient here since not every user will need or want to specify all components of the full schema on each use (but uniformizing the description when needed is very important). . To repeat from above here is the suggested metadata requirements (with annotations). """""". This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata. * Decide what term to use instead of ""groups"" (dataset is probably best). * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a s",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:721,integrability,Event,Events,721,"Hi - this is an excellent start but I'd like to offer a few considerations given that not everyone uses root files these days. Specifically, friend trees are not a widely accepted concept outside of TTrees and RNtuple. It is, however, easy to abstract away from this so that this metadata specification is more universal. In coffea, we didn't go all the way to formalizing it in a schema since there are many details but you can see the basic validation we do here:. https://github.com/CoffeaTeam/coffea/blob/master/coffea/processor/executor.py#L1353. We allow forms like:. ```. fileset = { ""dataset"" : [""some"", ""list"", ""of"", ""files""], ...}. # and. fileset = { ""dataset"": { ""files"": [""file1"", ""file2"", ...], ""treename"": ""Events"", ""metadata"": { ""stuff"": ""about stuff""}, ...}, { .... } }. ```. depending on user need. I think optional and union types are very convenient here since not every user will need or want to specify all components of the full schema on each use (but uniformizing the description when needed is very important). . To repeat from above here is the suggested metadata requirements (with annotations). """""". This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata. * Decide what term to use instead of ""groups"" (dataset is probably best). * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a s",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:792,integrability,depend,depending,792,"Hi - this is an excellent start but I'd like to offer a few considerations given that not everyone uses root files these days. Specifically, friend trees are not a widely accepted concept outside of TTrees and RNtuple. It is, however, easy to abstract away from this so that this metadata specification is more universal. In coffea, we didn't go all the way to formalizing it in a schema since there are many details but you can see the basic validation we do here:. https://github.com/CoffeaTeam/coffea/blob/master/coffea/processor/executor.py#L1353. We allow forms like:. ```. fileset = { ""dataset"" : [""some"", ""list"", ""of"", ""files""], ...}. # and. fileset = { ""dataset"": { ""files"": [""file1"", ""file2"", ...], ""treename"": ""Events"", ""metadata"": { ""stuff"": ""about stuff""}, ...}, { .... } }. ```. depending on user need. I think optional and union types are very convenient here since not every user will need or want to specify all components of the full schema on each use (but uniformizing the description when needed is very important). . To repeat from above here is the suggested metadata requirements (with annotations). """""". This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata. * Decide what term to use instead of ""groups"" (dataset is probably best). * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a s",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:928,integrability,compon,components,928,"Hi - this is an excellent start but I'd like to offer a few considerations given that not everyone uses root files these days. Specifically, friend trees are not a widely accepted concept outside of TTrees and RNtuple. It is, however, easy to abstract away from this so that this metadata specification is more universal. In coffea, we didn't go all the way to formalizing it in a schema since there are many details but you can see the basic validation we do here:. https://github.com/CoffeaTeam/coffea/blob/master/coffea/processor/executor.py#L1353. We allow forms like:. ```. fileset = { ""dataset"" : [""some"", ""list"", ""of"", ""files""], ...}. # and. fileset = { ""dataset"": { ""files"": [""file1"", ""file2"", ...], ""treename"": ""Events"", ""metadata"": { ""stuff"": ""about stuff""}, ...}, { .... } }. ```. depending on user need. I think optional and union types are very convenient here since not every user will need or want to specify all components of the full schema on each use (but uniformizing the description when needed is very important). . To repeat from above here is the suggested metadata requirements (with annotations). """""". This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata. * Decide what term to use instead of ""groups"" (dataset is probably best). * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a s",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:951,integrability,schema,schema,951,"Hi - this is an excellent start but I'd like to offer a few considerations given that not everyone uses root files these days. Specifically, friend trees are not a widely accepted concept outside of TTrees and RNtuple. It is, however, easy to abstract away from this so that this metadata specification is more universal. In coffea, we didn't go all the way to formalizing it in a schema since there are many details but you can see the basic validation we do here:. https://github.com/CoffeaTeam/coffea/blob/master/coffea/processor/executor.py#L1353. We allow forms like:. ```. fileset = { ""dataset"" : [""some"", ""list"", ""of"", ""files""], ...}. # and. fileset = { ""dataset"": { ""files"": [""file1"", ""file2"", ...], ""treename"": ""Events"", ""metadata"": { ""stuff"": ""about stuff""}, ...}, { .... } }. ```. depending on user need. I think optional and union types are very convenient here since not every user will need or want to specify all components of the full schema on each use (but uniformizing the description when needed is very important). . To repeat from above here is the suggested metadata requirements (with annotations). """""". This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata. * Decide what term to use instead of ""groups"" (dataset is probably best). * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a s",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:1146,integrability,schema,schema,1146,"rees are not a widely accepted concept outside of TTrees and RNtuple. It is, however, easy to abstract away from this so that this metadata specification is more universal. In coffea, we didn't go all the way to formalizing it in a schema since there are many details but you can see the basic validation we do here:. https://github.com/CoffeaTeam/coffea/blob/master/coffea/processor/executor.py#L1353. We allow forms like:. ```. fileset = { ""dataset"" : [""some"", ""list"", ""of"", ""files""], ...}. # and. fileset = { ""dataset"": { ""files"": [""file1"", ""file2"", ...], ""treename"": ""Events"", ""metadata"": { ""stuff"": ""about stuff""}, ...}, { .... } }. ```. depending on user need. I think optional and union types are very convenient here since not every user will need or want to specify all components of the full schema on each use (but uniformizing the description when needed is very important). . To repeat from above here is the suggested metadata requirements (with annotations). """""". This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata. * Decide what term to use instead of ""groups"" (dataset is probably best). * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a standard. As to files - it is not very common but people do use parquet or hdf5 in analysis. Removing those formats as concepts to describe a dataset ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:1861,integrability,schema,schema,1861,"ient here since not every user will need or want to specify all components of the full schema on each use (but uniformizing the description when needed is very important). . To repeat from above here is the suggested metadata requirements (with annotations). """""". This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata. * Decide what term to use instead of ""groups"" (dataset is probably best). * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a standard. As to files - it is not very common but people do use parquet or hdf5 in analysis. Removing those formats as concepts to describe a dataset is rather limiting. Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This can make things much easier in the case that, for instance, some random machine learning tool cannot output root files but can produce some other usefully structured data format. . *** - The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple, which is limiting in scope for what is possible for dataset augmentation. Moreover, this allows the definition of left/right/inner/outer joins at the metadata level which is extremely useful for understanding how that additional data is inte",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:1965,integrability,schema,schema,1965,"e (but uniformizing the description when needed is very important). . To repeat from above here is the suggested metadata requirements (with annotations). """""". This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata. * Decide what term to use instead of ""groups"" (dataset is probably best). * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a standard. As to files - it is not very common but people do use parquet or hdf5 in analysis. Removing those formats as concepts to describe a dataset is rather limiting. Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This can make things much easier in the case that, for instance, some random machine learning tool cannot output root files but can produce some other usefully structured data format. . *** - The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple, which is limiting in scope for what is possible for dataset augmentation. Moreover, this allows the definition of left/right/inner/outer joins at the metadata level which is extremely useful for understanding how that additional data is intended to be used (are you just augmenting the number of columns in the dataset, are you x-referencing two",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:127,interoperability,Specif,Specifically,127,"Hi - this is an excellent start but I'd like to offer a few considerations given that not everyone uses root files these days. Specifically, friend trees are not a widely accepted concept outside of TTrees and RNtuple. It is, however, easy to abstract away from this so that this metadata specification is more universal. In coffea, we didn't go all the way to formalizing it in a schema since there are many details but you can see the basic validation we do here:. https://github.com/CoffeaTeam/coffea/blob/master/coffea/processor/executor.py#L1353. We allow forms like:. ```. fileset = { ""dataset"" : [""some"", ""list"", ""of"", ""files""], ...}. # and. fileset = { ""dataset"": { ""files"": [""file1"", ""file2"", ...], ""treename"": ""Events"", ""metadata"": { ""stuff"": ""about stuff""}, ...}, { .... } }. ```. depending on user need. I think optional and union types are very convenient here since not every user will need or want to specify all components of the full schema on each use (but uniformizing the description when needed is very important). . To repeat from above here is the suggested metadata requirements (with annotations). """""". This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata. * Decide what term to use instead of ""groups"" (dataset is probably best). * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a s",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:289,interoperability,specif,specification,289,"Hi - this is an excellent start but I'd like to offer a few considerations given that not everyone uses root files these days. Specifically, friend trees are not a widely accepted concept outside of TTrees and RNtuple. It is, however, easy to abstract away from this so that this metadata specification is more universal. In coffea, we didn't go all the way to formalizing it in a schema since there are many details but you can see the basic validation we do here:. https://github.com/CoffeaTeam/coffea/blob/master/coffea/processor/executor.py#L1353. We allow forms like:. ```. fileset = { ""dataset"" : [""some"", ""list"", ""of"", ""files""], ...}. # and. fileset = { ""dataset"": { ""files"": [""file1"", ""file2"", ...], ""treename"": ""Events"", ""metadata"": { ""stuff"": ""about stuff""}, ...}, { .... } }. ```. depending on user need. I think optional and union types are very convenient here since not every user will need or want to specify all components of the full schema on each use (but uniformizing the description when needed is very important). . To repeat from above here is the suggested metadata requirements (with annotations). """""". This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata. * Decide what term to use instead of ""groups"" (dataset is probably best). * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a s",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:916,interoperability,specif,specify,916,"Hi - this is an excellent start but I'd like to offer a few considerations given that not everyone uses root files these days. Specifically, friend trees are not a widely accepted concept outside of TTrees and RNtuple. It is, however, easy to abstract away from this so that this metadata specification is more universal. In coffea, we didn't go all the way to formalizing it in a schema since there are many details but you can see the basic validation we do here:. https://github.com/CoffeaTeam/coffea/blob/master/coffea/processor/executor.py#L1353. We allow forms like:. ```. fileset = { ""dataset"" : [""some"", ""list"", ""of"", ""files""], ...}. # and. fileset = { ""dataset"": { ""files"": [""file1"", ""file2"", ...], ""treename"": ""Events"", ""metadata"": { ""stuff"": ""about stuff""}, ...}, { .... } }. ```. depending on user need. I think optional and union types are very convenient here since not every user will need or want to specify all components of the full schema on each use (but uniformizing the description when needed is very important). . To repeat from above here is the suggested metadata requirements (with annotations). """""". This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata. * Decide what term to use instead of ""groups"" (dataset is probably best). * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a s",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:928,interoperability,compon,components,928,"Hi - this is an excellent start but I'd like to offer a few considerations given that not everyone uses root files these days. Specifically, friend trees are not a widely accepted concept outside of TTrees and RNtuple. It is, however, easy to abstract away from this so that this metadata specification is more universal. In coffea, we didn't go all the way to formalizing it in a schema since there are many details but you can see the basic validation we do here:. https://github.com/CoffeaTeam/coffea/blob/master/coffea/processor/executor.py#L1353. We allow forms like:. ```. fileset = { ""dataset"" : [""some"", ""list"", ""of"", ""files""], ...}. # and. fileset = { ""dataset"": { ""files"": [""file1"", ""file2"", ...], ""treename"": ""Events"", ""metadata"": { ""stuff"": ""about stuff""}, ...}, { .... } }. ```. depending on user need. I think optional and union types are very convenient here since not every user will need or want to specify all components of the full schema on each use (but uniformizing the description when needed is very important). . To repeat from above here is the suggested metadata requirements (with annotations). """""". This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata. * Decide what term to use instead of ""groups"" (dataset is probably best). * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a s",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:1137,interoperability,standard,standard,1137,"friend trees are not a widely accepted concept outside of TTrees and RNtuple. It is, however, easy to abstract away from this so that this metadata specification is more universal. In coffea, we didn't go all the way to formalizing it in a schema since there are many details but you can see the basic validation we do here:. https://github.com/CoffeaTeam/coffea/blob/master/coffea/processor/executor.py#L1353. We allow forms like:. ```. fileset = { ""dataset"" : [""some"", ""list"", ""of"", ""files""], ...}. # and. fileset = { ""dataset"": { ""files"": [""file1"", ""file2"", ...], ""treename"": ""Events"", ""metadata"": { ""stuff"": ""about stuff""}, ...}, { .... } }. ```. depending on user need. I think optional and union types are very convenient here since not every user will need or want to specify all components of the full schema on each use (but uniformizing the description when needed is very important). . To repeat from above here is the suggested metadata requirements (with annotations). """""". This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata. * Decide what term to use instead of ""groups"" (dataset is probably best). * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a standard. As to files - it is not very common but people do use parquet or hdf5 in analysis. Removing those formats as concepts to describe a ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:1222,interoperability,Specif,Specify,1222,"however, easy to abstract away from this so that this metadata specification is more universal. In coffea, we didn't go all the way to formalizing it in a schema since there are many details but you can see the basic validation we do here:. https://github.com/CoffeaTeam/coffea/blob/master/coffea/processor/executor.py#L1353. We allow forms like:. ```. fileset = { ""dataset"" : [""some"", ""list"", ""of"", ""files""], ...}. # and. fileset = { ""dataset"": { ""files"": [""file1"", ""file2"", ...], ""treename"": ""Events"", ""metadata"": { ""stuff"": ""about stuff""}, ...}, { .... } }. ```. depending on user need. I think optional and union types are very convenient here since not every user will need or want to specify all components of the full schema on each use (but uniformizing the description when needed is very important). . To repeat from above here is the suggested metadata requirements (with annotations). """""". This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata. * Decide what term to use instead of ""groups"" (dataset is probably best). * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a standard. As to files - it is not very common but people do use parquet or hdf5 in analysis. Removing those formats as concepts to describe a dataset is rather limiting. Allowing them opens up many possibilities, including mixe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:1446,interoperability,format,formats,1446,"ion we do here:. https://github.com/CoffeaTeam/coffea/blob/master/coffea/processor/executor.py#L1353. We allow forms like:. ```. fileset = { ""dataset"" : [""some"", ""list"", ""of"", ""files""], ...}. # and. fileset = { ""dataset"": { ""files"": [""file1"", ""file2"", ...], ""treename"": ""Events"", ""metadata"": { ""stuff"": ""about stuff""}, ...}, { .... } }. ```. depending on user need. I think optional and union types are very convenient here since not every user will need or want to specify all components of the full schema on each use (but uniformizing the description when needed is very important). . To repeat from above here is the suggested metadata requirements (with annotations). """""". This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata. * Decide what term to use instead of ""groups"" (dataset is probably best). * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a standard. As to files - it is not very common but people do use parquet or hdf5 in analysis. Removing those formats as concepts to describe a dataset is rather limiting. Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This can make things much easier in the case that, for instance, some random machine learning tool cannot output root files but can produce some other usefully structure",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:1710,interoperability,specif,specification,1710,""": ""Events"", ""metadata"": { ""stuff"": ""about stuff""}, ...}, { .... } }. ```. depending on user need. I think optional and union types are very convenient here since not every user will need or want to specify all components of the full schema on each use (but uniformizing the description when needed is very important). . To repeat from above here is the suggested metadata requirements (with annotations). """""". This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata. * Decide what term to use instead of ""groups"" (dataset is probably best). * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a standard. As to files - it is not very common but people do use parquet or hdf5 in analysis. Removing those formats as concepts to describe a dataset is rather limiting. Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This can make things much easier in the case that, for instance, some random machine learning tool cannot output root files but can produce some other usefully structured data format. . *** - The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple, which is limiting in scope for what is possible for dataset augmentation. Moreover, this allow",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:1999,interoperability,standard,standard,1999," when needed is very important). . To repeat from above here is the suggested metadata requirements (with annotations). """""". This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata. * Decide what term to use instead of ""groups"" (dataset is probably best). * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a standard. As to files - it is not very common but people do use parquet or hdf5 in analysis. Removing those formats as concepts to describe a dataset is rather limiting. Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This can make things much easier in the case that, for instance, some random machine learning tool cannot output root files but can produce some other usefully structured data format. . *** - The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple, which is limiting in scope for what is possible for dataset augmentation. Moreover, this allows the definition of left/right/inner/outer joins at the metadata level which is extremely useful for understanding how that additional data is intended to be used (are you just augmenting the number of columns in the dataset, are you x-referencing two datasets, etc.). It is then up to ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:2107,interoperability,format,formats,2107,"notations). """""". This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata. * Decide what term to use instead of ""groups"" (dataset is probably best). * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a standard. As to files - it is not very common but people do use parquet or hdf5 in analysis. Removing those formats as concepts to describe a dataset is rather limiting. Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This can make things much easier in the case that, for instance, some random machine learning tool cannot output root files but can produce some other usefully structured data format. . *** - The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple, which is limiting in scope for what is possible for dataset augmentation. Moreover, this allows the definition of left/right/inner/outer joins at the metadata level which is extremely useful for understanding how that additional data is intended to be used (are you just augmenting the number of columns in the dataset, are you x-referencing two datasets, etc.). It is then up to the system ingesting this data to implement the join specified by the user correctly (which can be tested fo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:2258,interoperability,heterogen,heterogenous,2258,"h with associated metadata. * Decide what term to use instead of ""groups"" (dataset is probably best). * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a standard. As to files - it is not very common but people do use parquet or hdf5 in analysis. Removing those formats as concepts to describe a dataset is rather limiting. Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This can make things much easier in the case that, for instance, some random machine learning tool cannot output root files but can produce some other usefully structured data format. . *** - The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple, which is limiting in scope for what is possible for dataset augmentation. Moreover, this allows the definition of left/right/inner/outer joins at the metadata level which is extremely useful for understanding how that additional data is intended to be used (are you just augmenting the number of columns in the dataset, are you x-referencing two datasets, etc.). It is then up to the system ingesting this data to implement the join specified by the user correctly (which can be tested for). For the second *** reference, this is also a restriction of your program, not the metadata, an error should be thrown by whatever is executing and ca",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:2457,interoperability,format,format,2457,"program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a standard. As to files - it is not very common but people do use parquet or hdf5 in analysis. Removing those formats as concepts to describe a dataset is rather limiting. Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This can make things much easier in the case that, for instance, some random machine learning tool cannot output root files but can produce some other usefully structured data format. . *** - The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple, which is limiting in scope for what is possible for dataset augmentation. Moreover, this allows the definition of left/right/inner/outer joins at the metadata level which is extremely useful for understanding how that additional data is intended to be used (are you just augmenting the number of columns in the dataset, are you x-referencing two datasets, etc.). It is then up to the system ingesting this data to implement the join specified by the user correctly (which can be tested for). For the second *** reference, this is also a restriction of your program, not the metadata, an error should be thrown by whatever is executing and cannot handle a case rather than restricting concepts for describing a dataset. Furthermore, going to joins as a metadata concept allows the user to specify an entire dataset for a join rather than ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:3056,interoperability,specif,specified,3056,"e parquet or hdf5 in analysis. Removing those formats as concepts to describe a dataset is rather limiting. Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This can make things much easier in the case that, for instance, some random machine learning tool cannot output root files but can produce some other usefully structured data format. . *** - The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple, which is limiting in scope for what is possible for dataset augmentation. Moreover, this allows the definition of left/right/inner/outer joins at the metadata level which is extremely useful for understanding how that additional data is intended to be used (are you just augmenting the number of columns in the dataset, are you x-referencing two datasets, etc.). It is then up to the system ingesting this data to implement the join specified by the user correctly (which can be tested for). For the second *** reference, this is also a restriction of your program, not the metadata, an error should be thrown by whatever is executing and cannot handle a case rather than restricting concepts for describing a dataset. Furthermore, going to joins as a metadata concept allows the user to specify an entire dataset for a join rather than individual files, resulting in significant reduction of doubly-bookkept data. . Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user (since it is often the case they will want to run over a limited piece of the data to test things and then run over the full dataset). Re-writing the metadata on each run would get cumbersome quickly. To take all this and mutate your original suggestion (I haven't defined all the types but hopefully it's intelligible):. ```. {. ""datasets"":{. ""dataset",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:3411,interoperability,specif,specify,3411,"oduce some other usefully structured data format. . *** - The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple, which is limiting in scope for what is possible for dataset augmentation. Moreover, this allows the definition of left/right/inner/outer joins at the metadata level which is extremely useful for understanding how that additional data is intended to be used (are you just augmenting the number of columns in the dataset, are you x-referencing two datasets, etc.). It is then up to the system ingesting this data to implement the join specified by the user correctly (which can be tested for). For the second *** reference, this is also a restriction of your program, not the metadata, an error should be thrown by whatever is executing and cannot handle a case rather than restricting concepts for describing a dataset. Furthermore, going to joins as a metadata concept allows the user to specify an entire dataset for a join rather than individual files, resulting in significant reduction of doubly-bookkept data. . Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user (since it is often the case they will want to run over a limited piece of the data to test things and then run over the full dataset). Re-writing the metadata on each run would get cumbersome quickly. To take all this and mutate your original suggestion (I haven't defined all the types but hopefully it's intelligible):. ```. {. ""datasets"":{. ""dataset"":{. ""treenames"": Union[List[String], String],. ""files"": List[String],. ""friends"":{. ""treenames"": Union[List[String], String],. ""files"": List[String],. ""joinType"": OneOf[""inner"", ""outer"", ""left"", ""right"", ""cross""], #this should just be made into a type. } or List[Dict[As in Single Dict]],. ""metadata"": Optional[Dict[JsonSerialiableAny:JsonSerializableAn",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:3669,interoperability,specif,specified,3669,"at concept here rather than the precise concept of friends in TTree/RNtuple, which is limiting in scope for what is possible for dataset augmentation. Moreover, this allows the definition of left/right/inner/outer joins at the metadata level which is extremely useful for understanding how that additional data is intended to be used (are you just augmenting the number of columns in the dataset, are you x-referencing two datasets, etc.). It is then up to the system ingesting this data to implement the join specified by the user correctly (which can be tested for). For the second *** reference, this is also a restriction of your program, not the metadata, an error should be thrown by whatever is executing and cannot handle a case rather than restricting concepts for describing a dataset. Furthermore, going to joins as a metadata concept allows the user to specify an entire dataset for a join rather than individual files, resulting in significant reduction of doubly-bookkept data. . Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user (since it is often the case they will want to run over a limited piece of the data to test things and then run over the full dataset). Re-writing the metadata on each run would get cumbersome quickly. To take all this and mutate your original suggestion (I haven't defined all the types but hopefully it's intelligible):. ```. {. ""datasets"":{. ""dataset"":{. ""treenames"": Union[List[String], String],. ""files"": List[String],. ""friends"":{. ""treenames"": Union[List[String], String],. ""files"": List[String],. ""joinType"": OneOf[""inner"", ""outer"", ""left"", ""right"", ""cross""], #this should just be made into a type. } or List[Dict[As in Single Dict]],. ""metadata"": Optional[Dict[JsonSerialiableAny:JsonSerializableAny]]. },. # ... },. # other optional values from here on. ""metadata"": Optional[Dict[JsonSerialiableAny:JsonSerialiableAny]]. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:243,modifiability,abstract,abstract,243,"Hi - this is an excellent start but I'd like to offer a few considerations given that not everyone uses root files these days. Specifically, friend trees are not a widely accepted concept outside of TTrees and RNtuple. It is, however, easy to abstract away from this so that this metadata specification is more universal. In coffea, we didn't go all the way to formalizing it in a schema since there are many details but you can see the basic validation we do here:. https://github.com/CoffeaTeam/coffea/blob/master/coffea/processor/executor.py#L1353. We allow forms like:. ```. fileset = { ""dataset"" : [""some"", ""list"", ""of"", ""files""], ...}. # and. fileset = { ""dataset"": { ""files"": [""file1"", ""file2"", ...], ""treename"": ""Events"", ""metadata"": { ""stuff"": ""about stuff""}, ...}, { .... } }. ```. depending on user need. I think optional and union types are very convenient here since not every user will need or want to specify all components of the full schema on each use (but uniformizing the description when needed is very important). . To repeat from above here is the suggested metadata requirements (with annotations). """""". This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata. * Decide what term to use instead of ""groups"" (dataset is probably best). * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a s",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:792,modifiability,depend,depending,792,"Hi - this is an excellent start but I'd like to offer a few considerations given that not everyone uses root files these days. Specifically, friend trees are not a widely accepted concept outside of TTrees and RNtuple. It is, however, easy to abstract away from this so that this metadata specification is more universal. In coffea, we didn't go all the way to formalizing it in a schema since there are many details but you can see the basic validation we do here:. https://github.com/CoffeaTeam/coffea/blob/master/coffea/processor/executor.py#L1353. We allow forms like:. ```. fileset = { ""dataset"" : [""some"", ""list"", ""of"", ""files""], ...}. # and. fileset = { ""dataset"": { ""files"": [""file1"", ""file2"", ...], ""treename"": ""Events"", ""metadata"": { ""stuff"": ""about stuff""}, ...}, { .... } }. ```. depending on user need. I think optional and union types are very convenient here since not every user will need or want to specify all components of the full schema on each use (but uniformizing the description when needed is very important). . To repeat from above here is the suggested metadata requirements (with annotations). """""". This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata. * Decide what term to use instead of ""groups"" (dataset is probably best). * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a s",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:928,modifiability,compon,components,928,"Hi - this is an excellent start but I'd like to offer a few considerations given that not everyone uses root files these days. Specifically, friend trees are not a widely accepted concept outside of TTrees and RNtuple. It is, however, easy to abstract away from this so that this metadata specification is more universal. In coffea, we didn't go all the way to formalizing it in a schema since there are many details but you can see the basic validation we do here:. https://github.com/CoffeaTeam/coffea/blob/master/coffea/processor/executor.py#L1353. We allow forms like:. ```. fileset = { ""dataset"" : [""some"", ""list"", ""of"", ""files""], ...}. # and. fileset = { ""dataset"": { ""files"": [""file1"", ""file2"", ...], ""treename"": ""Events"", ""metadata"": { ""stuff"": ""about stuff""}, ...}, { .... } }. ```. depending on user need. I think optional and union types are very convenient here since not every user will need or want to specify all components of the full schema on each use (but uniformizing the description when needed is very important). . To repeat from above here is the suggested metadata requirements (with annotations). """""". This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata. * Decide what term to use instead of ""groups"" (dataset is probably best). * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a s",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:3210,performance,error,error,3210,"ncluding mixed modes and joins across rather heterogenous datasets. This can make things much easier in the case that, for instance, some random machine learning tool cannot output root files but can produce some other usefully structured data format. . *** - The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple, which is limiting in scope for what is possible for dataset augmentation. Moreover, this allows the definition of left/right/inner/outer joins at the metadata level which is extremely useful for understanding how that additional data is intended to be used (are you just augmenting the number of columns in the dataset, are you x-referencing two datasets, etc.). It is then up to the system ingesting this data to implement the join specified by the user correctly (which can be tested for). For the second *** reference, this is also a restriction of your program, not the metadata, an error should be thrown by whatever is executing and cannot handle a case rather than restricting concepts for describing a dataset. Furthermore, going to joins as a metadata concept allows the user to specify an entire dataset for a join rather than individual files, resulting in significant reduction of doubly-bookkept data. . Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user (since it is often the case they will want to run over a limited piece of the data to test things and then run over the full dataset). Re-writing the metadata on each run would get cumbersome quickly. To take all this and mutate your original suggestion (I haven't defined all the types but hopefully it's intelligible):. ```. {. ""datasets"":{. ""dataset"":{. ""treenames"": Union[List[String], String],. ""files"": List[String],. ""friends"":{. ""treenames"": Union[List[String], String],. ""files"": List[String],. ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:3682,performance,execution time,execution time,3682,"at concept here rather than the precise concept of friends in TTree/RNtuple, which is limiting in scope for what is possible for dataset augmentation. Moreover, this allows the definition of left/right/inner/outer joins at the metadata level which is extremely useful for understanding how that additional data is intended to be used (are you just augmenting the number of columns in the dataset, are you x-referencing two datasets, etc.). It is then up to the system ingesting this data to implement the join specified by the user correctly (which can be tested for). For the second *** reference, this is also a restriction of your program, not the metadata, an error should be thrown by whatever is executing and cannot handle a case rather than restricting concepts for describing a dataset. Furthermore, going to joins as a metadata concept allows the user to specify an entire dataset for a join rather than individual files, resulting in significant reduction of doubly-bookkept data. . Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user (since it is often the case they will want to run over a limited piece of the data to test things and then run over the full dataset). Re-writing the metadata on each run would get cumbersome quickly. To take all this and mutate your original suggestion (I haven't defined all the types but hopefully it's intelligible):. ```. {. ""datasets"":{. ""dataset"":{. ""treenames"": Union[List[String], String],. ""files"": List[String],. ""friends"":{. ""treenames"": Union[List[String], String],. ""files"": List[String],. ""joinType"": OneOf[""inner"", ""outer"", ""left"", ""right"", ""cross""], #this should just be made into a type. } or List[Dict[As in Single Dict]],. ""metadata"": Optional[Dict[JsonSerialiableAny:JsonSerializableAny]]. },. # ... },. # other optional values from here on. ""metadata"": Optional[Dict[JsonSerialiableAny:JsonSerialiableAny]]. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:1468,reliability,doe,does,1468,"ps://github.com/CoffeaTeam/coffea/blob/master/coffea/processor/executor.py#L1353. We allow forms like:. ```. fileset = { ""dataset"" : [""some"", ""list"", ""of"", ""files""], ...}. # and. fileset = { ""dataset"": { ""files"": [""file1"", ""file2"", ...], ""treename"": ""Events"", ""metadata"": { ""stuff"": ""about stuff""}, ...}, { .... } }. ```. depending on user need. I think optional and union types are very convenient here since not every user will need or want to specify all components of the full schema on each use (but uniformizing the description when needed is very important). . To repeat from above here is the suggested metadata requirements (with annotations). """""". This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata. * Decide what term to use instead of ""groups"" (dataset is probably best). * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a standard. As to files - it is not very common but people do use parquet or hdf5 in analysis. Removing those formats as concepts to describe a dataset is rather limiting. Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This can make things much easier in the case that, for instance, some random machine learning tool cannot output root files but can produce some other usefully structured data format. . ***",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:443,safety,valid,validation,443,"Hi - this is an excellent start but I'd like to offer a few considerations given that not everyone uses root files these days. Specifically, friend trees are not a widely accepted concept outside of TTrees and RNtuple. It is, however, easy to abstract away from this so that this metadata specification is more universal. In coffea, we didn't go all the way to formalizing it in a schema since there are many details but you can see the basic validation we do here:. https://github.com/CoffeaTeam/coffea/blob/master/coffea/processor/executor.py#L1353. We allow forms like:. ```. fileset = { ""dataset"" : [""some"", ""list"", ""of"", ""files""], ...}. # and. fileset = { ""dataset"": { ""files"": [""file1"", ""file2"", ...], ""treename"": ""Events"", ""metadata"": { ""stuff"": ""about stuff""}, ...}, { .... } }. ```. depending on user need. I think optional and union types are very convenient here since not every user will need or want to specify all components of the full schema on each use (but uniformizing the description when needed is very important). . To repeat from above here is the suggested metadata requirements (with annotations). """""". This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata. * Decide what term to use instead of ""groups"" (dataset is probably best). * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a s",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:792,safety,depend,depending,792,"Hi - this is an excellent start but I'd like to offer a few considerations given that not everyone uses root files these days. Specifically, friend trees are not a widely accepted concept outside of TTrees and RNtuple. It is, however, easy to abstract away from this so that this metadata specification is more universal. In coffea, we didn't go all the way to formalizing it in a schema since there are many details but you can see the basic validation we do here:. https://github.com/CoffeaTeam/coffea/blob/master/coffea/processor/executor.py#L1353. We allow forms like:. ```. fileset = { ""dataset"" : [""some"", ""list"", ""of"", ""files""], ...}. # and. fileset = { ""dataset"": { ""files"": [""file1"", ""file2"", ...], ""treename"": ""Events"", ""metadata"": { ""stuff"": ""about stuff""}, ...}, { .... } }. ```. depending on user need. I think optional and union types are very convenient here since not every user will need or want to specify all components of the full schema on each use (but uniformizing the description when needed is very important). . To repeat from above here is the suggested metadata requirements (with annotations). """""". This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata. * Decide what term to use instead of ""groups"" (dataset is probably best). * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a s",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:1248,safety,input,input,1248," away from this so that this metadata specification is more universal. In coffea, we didn't go all the way to formalizing it in a schema since there are many details but you can see the basic validation we do here:. https://github.com/CoffeaTeam/coffea/blob/master/coffea/processor/executor.py#L1353. We allow forms like:. ```. fileset = { ""dataset"" : [""some"", ""list"", ""of"", ""files""], ...}. # and. fileset = { ""dataset"": { ""files"": [""file1"", ""file2"", ...], ""treename"": ""Events"", ""metadata"": { ""stuff"": ""about stuff""}, ...}, { .... } }. ```. depending on user need. I think optional and union types are very convenient here since not every user will need or want to specify all components of the full schema on each use (but uniformizing the description when needed is very important). . To repeat from above here is the suggested metadata requirements (with annotations). """""". This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata. * Decide what term to use instead of ""groups"" (dataset is probably best). * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a standard. As to files - it is not very common but people do use parquet or hdf5 in analysis. Removing those formats as concepts to describe a dataset is rather limiting. Allowing them opens up many possibilities, including mixed modes and joins across ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:3102,safety,test,tested,3102,"e formats as concepts to describe a dataset is rather limiting. Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This can make things much easier in the case that, for instance, some random machine learning tool cannot output root files but can produce some other usefully structured data format. . *** - The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple, which is limiting in scope for what is possible for dataset augmentation. Moreover, this allows the definition of left/right/inner/outer joins at the metadata level which is extremely useful for understanding how that additional data is intended to be used (are you just augmenting the number of columns in the dataset, are you x-referencing two datasets, etc.). It is then up to the system ingesting this data to implement the join specified by the user correctly (which can be tested for). For the second *** reference, this is also a restriction of your program, not the metadata, an error should be thrown by whatever is executing and cannot handle a case rather than restricting concepts for describing a dataset. Furthermore, going to joins as a metadata concept allows the user to specify an entire dataset for a join rather than individual files, resulting in significant reduction of doubly-bookkept data. . Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user (since it is often the case they will want to run over a limited piece of the data to test things and then run over the full dataset). Re-writing the metadata on each run would get cumbersome quickly. To take all this and mutate your original suggestion (I haven't defined all the types but hopefully it's intelligible):. ```. {. ""datasets"":{. ""dataset"":{. ""treenames"": Union[List[String], String",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:3210,safety,error,error,3210,"ncluding mixed modes and joins across rather heterogenous datasets. This can make things much easier in the case that, for instance, some random machine learning tool cannot output root files but can produce some other usefully structured data format. . *** - The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple, which is limiting in scope for what is possible for dataset augmentation. Moreover, this allows the definition of left/right/inner/outer joins at the metadata level which is extremely useful for understanding how that additional data is intended to be used (are you just augmenting the number of columns in the dataset, are you x-referencing two datasets, etc.). It is then up to the system ingesting this data to implement the join specified by the user correctly (which can be tested for). For the second *** reference, this is also a restriction of your program, not the metadata, an error should be thrown by whatever is executing and cannot handle a case rather than restricting concepts for describing a dataset. Furthermore, going to joins as a metadata concept allows the user to specify an entire dataset for a join rather than individual files, resulting in significant reduction of doubly-bookkept data. . Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user (since it is often the case they will want to run over a limited piece of the data to test things and then run over the full dataset). Re-writing the metadata on each run would get cumbersome quickly. To take all this and mutate your original suggestion (I haven't defined all the types but hopefully it's intelligible):. ```. {. ""datasets"":{. ""dataset"":{. ""treenames"": Union[List[String], String],. ""files"": List[String],. ""friends"":{. ""treenames"": Union[List[String], String],. ""files"": List[String],. ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:3795,safety,test,test,3795,"at concept here rather than the precise concept of friends in TTree/RNtuple, which is limiting in scope for what is possible for dataset augmentation. Moreover, this allows the definition of left/right/inner/outer joins at the metadata level which is extremely useful for understanding how that additional data is intended to be used (are you just augmenting the number of columns in the dataset, are you x-referencing two datasets, etc.). It is then up to the system ingesting this data to implement the join specified by the user correctly (which can be tested for). For the second *** reference, this is also a restriction of your program, not the metadata, an error should be thrown by whatever is executing and cannot handle a case rather than restricting concepts for describing a dataset. Furthermore, going to joins as a metadata concept allows the user to specify an entire dataset for a join rather than individual files, resulting in significant reduction of doubly-bookkept data. . Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user (since it is often the case they will want to run over a limited piece of the data to test things and then run over the full dataset). Re-writing the metadata on each run would get cumbersome quickly. To take all this and mutate your original suggestion (I haven't defined all the types but hopefully it's intelligible):. ```. {. ""datasets"":{. ""dataset"":{. ""treenames"": Union[List[String], String],. ""files"": List[String],. ""friends"":{. ""treenames"": Union[List[String], String],. ""files"": List[String],. ""joinType"": OneOf[""inner"", ""outer"", ""left"", ""right"", ""cross""], #this should just be made into a type. } or List[Dict[As in Single Dict]],. ""metadata"": Optional[Dict[JsonSerialiableAny:JsonSerializableAny]]. },. # ... },. # other optional values from here on. ""metadata"": Optional[Dict[JsonSerialiableAny:JsonSerialiableAny]]. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:443,security,validat,validation,443,"Hi - this is an excellent start but I'd like to offer a few considerations given that not everyone uses root files these days. Specifically, friend trees are not a widely accepted concept outside of TTrees and RNtuple. It is, however, easy to abstract away from this so that this metadata specification is more universal. In coffea, we didn't go all the way to formalizing it in a schema since there are many details but you can see the basic validation we do here:. https://github.com/CoffeaTeam/coffea/blob/master/coffea/processor/executor.py#L1353. We allow forms like:. ```. fileset = { ""dataset"" : [""some"", ""list"", ""of"", ""files""], ...}. # and. fileset = { ""dataset"": { ""files"": [""file1"", ""file2"", ...], ""treename"": ""Events"", ""metadata"": { ""stuff"": ""about stuff""}, ...}, { .... } }. ```. depending on user need. I think optional and union types are very convenient here since not every user will need or want to specify all components of the full schema on each use (but uniformizing the description when needed is very important). . To repeat from above here is the suggested metadata requirements (with annotations). """""". This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata. * Decide what term to use instead of ""groups"" (dataset is probably best). * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a s",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:3491,security,sign,significant,3491,"r this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple, which is limiting in scope for what is possible for dataset augmentation. Moreover, this allows the definition of left/right/inner/outer joins at the metadata level which is extremely useful for understanding how that additional data is intended to be used (are you just augmenting the number of columns in the dataset, are you x-referencing two datasets, etc.). It is then up to the system ingesting this data to implement the join specified by the user correctly (which can be tested for). For the second *** reference, this is also a restriction of your program, not the metadata, an error should be thrown by whatever is executing and cannot handle a case rather than restricting concepts for describing a dataset. Furthermore, going to joins as a metadata concept allows the user to specify an entire dataset for a join rather than individual files, resulting in significant reduction of doubly-bookkept data. . Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user (since it is often the case they will want to run over a limited piece of the data to test things and then run over the full dataset). Re-writing the metadata on each run would get cumbersome quickly. To take all this and mutate your original suggestion (I haven't defined all the types but hopefully it's intelligible):. ```. {. ""datasets"":{. ""dataset"":{. ""treenames"": Union[List[String], String],. ""files"": List[String],. ""friends"":{. ""treenames"": Union[List[String], String],. ""files"": List[String],. ""joinType"": OneOf[""inner"", ""outer"", ""left"", ""right"", ""cross""], #this should just be made into a type. } or List[Dict[As in Single Dict]],. ""metadata"": Optional[Dict[JsonSerialiableAny:JsonSerializableAny]]. },. # ... },. # other optional values from here on. ""metadata"": Optional[Dict",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:792,testability,depend,depending,792,"Hi - this is an excellent start but I'd like to offer a few considerations given that not everyone uses root files these days. Specifically, friend trees are not a widely accepted concept outside of TTrees and RNtuple. It is, however, easy to abstract away from this so that this metadata specification is more universal. In coffea, we didn't go all the way to formalizing it in a schema since there are many details but you can see the basic validation we do here:. https://github.com/CoffeaTeam/coffea/blob/master/coffea/processor/executor.py#L1353. We allow forms like:. ```. fileset = { ""dataset"" : [""some"", ""list"", ""of"", ""files""], ...}. # and. fileset = { ""dataset"": { ""files"": [""file1"", ""file2"", ...], ""treename"": ""Events"", ""metadata"": { ""stuff"": ""about stuff""}, ...}, { .... } }. ```. depending on user need. I think optional and union types are very convenient here since not every user will need or want to specify all components of the full schema on each use (but uniformizing the description when needed is very important). . To repeat from above here is the suggested metadata requirements (with annotations). """""". This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata. * Decide what term to use instead of ""groups"" (dataset is probably best). * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a s",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:1384,testability,plan,plan,1384,"a since there are many details but you can see the basic validation we do here:. https://github.com/CoffeaTeam/coffea/blob/master/coffea/processor/executor.py#L1353. We allow forms like:. ```. fileset = { ""dataset"" : [""some"", ""list"", ""of"", ""files""], ...}. # and. fileset = { ""dataset"": { ""files"": [""file1"", ""file2"", ...], ""treename"": ""Events"", ""metadata"": { ""stuff"": ""about stuff""}, ...}, { .... } }. ```. depending on user need. I think optional and union types are very convenient here since not every user will need or want to specify all components of the full schema on each use (but uniformizing the description when needed is very important). . To repeat from above here is the suggested metadata requirements (with annotations). """""". This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata. * Decide what term to use instead of ""groups"" (dataset is probably best). * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a standard. As to files - it is not very common but people do use parquet or hdf5 in analysis. Removing those formats as concepts to describe a dataset is rather limiting. Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This can make things much easier in the case that, for instance, some random machine learning tool cannot",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:2818,testability,understand,understanding,2818,"thing in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a standard. As to files - it is not very common but people do use parquet or hdf5 in analysis. Removing those formats as concepts to describe a dataset is rather limiting. Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This can make things much easier in the case that, for instance, some random machine learning tool cannot output root files but can produce some other usefully structured data format. . *** - The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple, which is limiting in scope for what is possible for dataset augmentation. Moreover, this allows the definition of left/right/inner/outer joins at the metadata level which is extremely useful for understanding how that additional data is intended to be used (are you just augmenting the number of columns in the dataset, are you x-referencing two datasets, etc.). It is then up to the system ingesting this data to implement the join specified by the user correctly (which can be tested for). For the second *** reference, this is also a restriction of your program, not the metadata, an error should be thrown by whatever is executing and cannot handle a case rather than restricting concepts for describing a dataset. Furthermore, going to joins as a metadata concept allows the user to specify an entire dataset for a join rather than individual files, resulting in significant reduction of doubly-bookkept data. . Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user (since it is often the case they will want to run over a limited piece of the data to test things and then run over ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:3102,testability,test,tested,3102,"e formats as concepts to describe a dataset is rather limiting. Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This can make things much easier in the case that, for instance, some random machine learning tool cannot output root files but can produce some other usefully structured data format. . *** - The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple, which is limiting in scope for what is possible for dataset augmentation. Moreover, this allows the definition of left/right/inner/outer joins at the metadata level which is extremely useful for understanding how that additional data is intended to be used (are you just augmenting the number of columns in the dataset, are you x-referencing two datasets, etc.). It is then up to the system ingesting this data to implement the join specified by the user correctly (which can be tested for). For the second *** reference, this is also a restriction of your program, not the metadata, an error should be thrown by whatever is executing and cannot handle a case rather than restricting concepts for describing a dataset. Furthermore, going to joins as a metadata concept allows the user to specify an entire dataset for a join rather than individual files, resulting in significant reduction of doubly-bookkept data. . Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user (since it is often the case they will want to run over a limited piece of the data to test things and then run over the full dataset). Re-writing the metadata on each run would get cumbersome quickly. To take all this and mutate your original suggestion (I haven't defined all the types but hopefully it's intelligible):. ```. {. ""datasets"":{. ""dataset"":{. ""treenames"": Union[List[String], String",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:3795,testability,test,test,3795,"at concept here rather than the precise concept of friends in TTree/RNtuple, which is limiting in scope for what is possible for dataset augmentation. Moreover, this allows the definition of left/right/inner/outer joins at the metadata level which is extremely useful for understanding how that additional data is intended to be used (are you just augmenting the number of columns in the dataset, are you x-referencing two datasets, etc.). It is then up to the system ingesting this data to implement the join specified by the user correctly (which can be tested for). For the second *** reference, this is also a restriction of your program, not the metadata, an error should be thrown by whatever is executing and cannot handle a case rather than restricting concepts for describing a dataset. Furthermore, going to joins as a metadata concept allows the user to specify an entire dataset for a join rather than individual files, resulting in significant reduction of doubly-bookkept data. . Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user (since it is often the case they will want to run over a limited piece of the data to test things and then run over the full dataset). Re-writing the metadata on each run would get cumbersome quickly. To take all this and mutate your original suggestion (I haven't defined all the types but hopefully it's intelligible):. ```. {. ""datasets"":{. ""dataset"":{. ""treenames"": Union[List[String], String],. ""files"": List[String],. ""friends"":{. ""treenames"": Union[List[String], String],. ""files"": List[String],. ""joinType"": OneOf[""inner"", ""outer"", ""left"", ""right"", ""cross""], #this should just be made into a type. } or List[Dict[As in Single Dict]],. ""metadata"": Optional[Dict[JsonSerialiableAny:JsonSerializableAny]]. },. # ... },. # other optional values from here on. ""metadata"": Optional[Dict[JsonSerialiableAny:JsonSerialiableAny]]. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:805,usability,user,user,805,"Hi - this is an excellent start but I'd like to offer a few considerations given that not everyone uses root files these days. Specifically, friend trees are not a widely accepted concept outside of TTrees and RNtuple. It is, however, easy to abstract away from this so that this metadata specification is more universal. In coffea, we didn't go all the way to formalizing it in a schema since there are many details but you can see the basic validation we do here:. https://github.com/CoffeaTeam/coffea/blob/master/coffea/processor/executor.py#L1353. We allow forms like:. ```. fileset = { ""dataset"" : [""some"", ""list"", ""of"", ""files""], ...}. # and. fileset = { ""dataset"": { ""files"": [""file1"", ""file2"", ...], ""treename"": ""Events"", ""metadata"": { ""stuff"": ""about stuff""}, ...}, { .... } }. ```. depending on user need. I think optional and union types are very convenient here since not every user will need or want to specify all components of the full schema on each use (but uniformizing the description when needed is very important). . To repeat from above here is the suggested metadata requirements (with annotations). """""". This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata. * Decide what term to use instead of ""groups"" (dataset is probably best). * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a s",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:890,usability,user,user,890,"Hi - this is an excellent start but I'd like to offer a few considerations given that not everyone uses root files these days. Specifically, friend trees are not a widely accepted concept outside of TTrees and RNtuple. It is, however, easy to abstract away from this so that this metadata specification is more universal. In coffea, we didn't go all the way to formalizing it in a schema since there are many details but you can see the basic validation we do here:. https://github.com/CoffeaTeam/coffea/blob/master/coffea/processor/executor.py#L1353. We allow forms like:. ```. fileset = { ""dataset"" : [""some"", ""list"", ""of"", ""files""], ...}. # and. fileset = { ""dataset"": { ""files"": [""file1"", ""file2"", ...], ""treename"": ""Events"", ""metadata"": { ""stuff"": ""about stuff""}, ...}, { .... } }. ```. depending on user need. I think optional and union types are very convenient here since not every user will need or want to specify all components of the full schema on each use (but uniformizing the description when needed is very important). . To repeat from above here is the suggested metadata requirements (with annotations). """""". This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata. * Decide what term to use instead of ""groups"" (dataset is probably best). * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a s",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:1160,usability,support,support,1160,"widely accepted concept outside of TTrees and RNtuple. It is, however, easy to abstract away from this so that this metadata specification is more universal. In coffea, we didn't go all the way to formalizing it in a schema since there are many details but you can see the basic validation we do here:. https://github.com/CoffeaTeam/coffea/blob/master/coffea/processor/executor.py#L1353. We allow forms like:. ```. fileset = { ""dataset"" : [""some"", ""list"", ""of"", ""files""], ...}. # and. fileset = { ""dataset"": { ""files"": [""file1"", ""file2"", ...], ""treename"": ""Events"", ""metadata"": { ""stuff"": ""about stuff""}, ...}, { .... } }. ```. depending on user need. I think optional and union types are very convenient here since not every user will need or want to specify all components of the full schema on each use (but uniformizing the description when needed is very important). . To repeat from above here is the suggested metadata requirements (with annotations). """""". This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata. * Decide what term to use instead of ""groups"" (dataset is probably best). * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a standard. As to files - it is not very common but people do use parquet or hdf5 in analysis. Removing those formats as concepts to describe a dataset is rather limit",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:1248,usability,input,input,1248," away from this so that this metadata specification is more universal. In coffea, we didn't go all the way to formalizing it in a schema since there are many details but you can see the basic validation we do here:. https://github.com/CoffeaTeam/coffea/blob/master/coffea/processor/executor.py#L1353. We allow forms like:. ```. fileset = { ""dataset"" : [""some"", ""list"", ""of"", ""files""], ...}. # and. fileset = { ""dataset"": { ""files"": [""file1"", ""file2"", ...], ""treename"": ""Events"", ""metadata"": { ""stuff"": ""about stuff""}, ...}, { .... } }. ```. depending on user need. I think optional and union types are very convenient here since not every user will need or want to specify all components of the full schema on each use (but uniformizing the description when needed is very important). . To repeat from above here is the suggested metadata requirements (with annotations). """""". This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata. * Decide what term to use instead of ""groups"" (dataset is probably best). * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a standard. As to files - it is not very common but people do use parquet or hdf5 in analysis. Removing those formats as concepts to describe a dataset is rather limiting. Allowing them opens up many possibilities, including mixed modes and joins across ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:1401,usability,support,support,1401,"any details but you can see the basic validation we do here:. https://github.com/CoffeaTeam/coffea/blob/master/coffea/processor/executor.py#L1353. We allow forms like:. ```. fileset = { ""dataset"" : [""some"", ""list"", ""of"", ""files""], ...}. # and. fileset = { ""dataset"": { ""files"": [""file1"", ""file2"", ...], ""treename"": ""Events"", ""metadata"": { ""stuff"": ""about stuff""}, ...}, { .... } }. ```. depending on user need. I think optional and union types are very convenient here since not every user will need or want to specify all components of the full schema on each use (but uniformizing the description when needed is very important). . To repeat from above here is the suggested metadata requirements (with annotations). """""". This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata. * Decide what term to use instead of ""groups"" (dataset is probably best). * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a standard. As to files - it is not very common but people do use parquet or hdf5 in analysis. Removing those formats as concepts to describe a dataset is rather limiting. Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This can make things much easier in the case that, for instance, some random machine learning tool cannot output root files ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:1484,usability,support,support,1484,"ffeaTeam/coffea/blob/master/coffea/processor/executor.py#L1353. We allow forms like:. ```. fileset = { ""dataset"" : [""some"", ""list"", ""of"", ""files""], ...}. # and. fileset = { ""dataset"": { ""files"": [""file1"", ""file2"", ...], ""treename"": ""Events"", ""metadata"": { ""stuff"": ""about stuff""}, ...}, { .... } }. ```. depending on user need. I think optional and union types are very convenient here since not every user will need or want to specify all components of the full schema on each use (but uniformizing the description when needed is very important). . To repeat from above here is the suggested metadata requirements (with annotations). """""". This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata. * Decide what term to use instead of ""groups"" (dataset is probably best). * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a standard. As to files - it is not very common but people do use parquet or hdf5 in analysis. Removing those formats as concepts to describe a dataset is rather limiting. Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This can make things much easier in the case that, for instance, some random machine learning tool cannot output root files but can produce some other usefully structured data format. . *** - The more genera",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:1541,usability,support,support,1541,"L1353. We allow forms like:. ```. fileset = { ""dataset"" : [""some"", ""list"", ""of"", ""files""], ...}. # and. fileset = { ""dataset"": { ""files"": [""file1"", ""file2"", ...], ""treename"": ""Events"", ""metadata"": { ""stuff"": ""about stuff""}, ...}, { .... } }. ```. depending on user need. I think optional and union types are very convenient here since not every user will need or want to specify all components of the full schema on each use (but uniformizing the description when needed is very important). . To repeat from above here is the suggested metadata requirements (with annotations). """""". This new standard schema should support a few key features of the definition of a dataset:. * Specify groups of several input files, each with associated metadata. * Decide what term to use instead of ""groups"" (dataset is probably best). * Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a standard. As to files - it is not very common but people do use parquet or hdf5 in analysis. Removing those formats as concepts to describe a dataset is rather limiting. Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This can make things much easier in the case that, for instance, some random machine learning tool cannot output root files but can produce some other usefully structured data format. . *** - The more general term for this is a a join, and I think you should use t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:2366,usability,learn,learning,2366,"ver TTree but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a standard. As to files - it is not very common but people do use parquet or hdf5 in analysis. Removing those formats as concepts to describe a dataset is rather limiting. Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This can make things much easier in the case that, for instance, some random machine learning tool cannot output root files but can produce some other usefully structured data format. . *** - The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple, which is limiting in scope for what is possible for dataset augmentation. Moreover, this allows the definition of left/right/inner/outer joins at the metadata level which is extremely useful for understanding how that additional data is intended to be used (are you just augmenting the number of columns in the dataset, are you x-referencing two datasets, etc.). It is then up to the system ingesting this data to implement the join specified by the user correctly (which can be tested for). For the second *** reference, this is also a restriction of your program, not the metadata, an error should be thrown by whatever is executing and cannot handle a case rather than restricting concepts for describing a dataset. Furthermore, going to joins ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:2375,usability,tool,tool,2375,"ee but plan for RNTuple support (metadata should not care about file formats, your program does). * Should support friend trees per group *** (see below). * Should support entry ranges per group (why? this makes little operational sense from the POV of an analyst). * No indexed friend trees (at least for now) *** (also). """""". This specification of requirements mixes things that are describing the data (metadata) and and how to react to it (something in a program, not part of the schema). I believe a clean factorization along these lines is very important to creating a well-adopted schema if you intend to develop a standard. As to files - it is not very common but people do use parquet or hdf5 in analysis. Removing those formats as concepts to describe a dataset is rather limiting. Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This can make things much easier in the case that, for instance, some random machine learning tool cannot output root files but can produce some other usefully structured data format. . *** - The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple, which is limiting in scope for what is possible for dataset augmentation. Moreover, this allows the definition of left/right/inner/outer joins at the metadata level which is extremely useful for understanding how that additional data is intended to be used (are you just augmenting the number of columns in the dataset, are you x-referencing two datasets, etc.). It is then up to the system ingesting this data to implement the join specified by the user correctly (which can be tested for). For the second *** reference, this is also a restriction of your program, not the metadata, an error should be thrown by whatever is executing and cannot handle a case rather than restricting concepts for describing a dataset. Furthermore, going to joins as a me",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:3073,usability,user,user,3073,"df5 in analysis. Removing those formats as concepts to describe a dataset is rather limiting. Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This can make things much easier in the case that, for instance, some random machine learning tool cannot output root files but can produce some other usefully structured data format. . *** - The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple, which is limiting in scope for what is possible for dataset augmentation. Moreover, this allows the definition of left/right/inner/outer joins at the metadata level which is extremely useful for understanding how that additional data is intended to be used (are you just augmenting the number of columns in the dataset, are you x-referencing two datasets, etc.). It is then up to the system ingesting this data to implement the join specified by the user correctly (which can be tested for). For the second *** reference, this is also a restriction of your program, not the metadata, an error should be thrown by whatever is executing and cannot handle a case rather than restricting concepts for describing a dataset. Furthermore, going to joins as a metadata concept allows the user to specify an entire dataset for a join rather than individual files, resulting in significant reduction of doubly-bookkept data. . Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user (since it is often the case they will want to run over a limited piece of the data to test things and then run over the full dataset). Re-writing the metadata on each run would get cumbersome quickly. To take all this and mutate your original suggestion (I haven't defined all the types but hopefully it's intelligible):. ```. {. ""datasets"":{. ""dataset"":{. ""treename",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:3210,usability,error,error,3210,"ncluding mixed modes and joins across rather heterogenous datasets. This can make things much easier in the case that, for instance, some random machine learning tool cannot output root files but can produce some other usefully structured data format. . *** - The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple, which is limiting in scope for what is possible for dataset augmentation. Moreover, this allows the definition of left/right/inner/outer joins at the metadata level which is extremely useful for understanding how that additional data is intended to be used (are you just augmenting the number of columns in the dataset, are you x-referencing two datasets, etc.). It is then up to the system ingesting this data to implement the join specified by the user correctly (which can be tested for). For the second *** reference, this is also a restriction of your program, not the metadata, an error should be thrown by whatever is executing and cannot handle a case rather than restricting concepts for describing a dataset. Furthermore, going to joins as a metadata concept allows the user to specify an entire dataset for a join rather than individual files, resulting in significant reduction of doubly-bookkept data. . Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user (since it is often the case they will want to run over a limited piece of the data to test things and then run over the full dataset). Re-writing the metadata on each run would get cumbersome quickly. To take all this and mutate your original suggestion (I haven't defined all the types but hopefully it's intelligible):. ```. {. ""datasets"":{. ""dataset"":{. ""treenames"": Union[List[String], String],. ""files"": List[String],. ""friends"":{. ""treenames"": Union[List[String], String],. ""files"": List[String],. ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:3403,usability,user,user,3403,"but can produce some other usefully structured data format. . *** - The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple, which is limiting in scope for what is possible for dataset augmentation. Moreover, this allows the definition of left/right/inner/outer joins at the metadata level which is extremely useful for understanding how that additional data is intended to be used (are you just augmenting the number of columns in the dataset, are you x-referencing two datasets, etc.). It is then up to the system ingesting this data to implement the join specified by the user correctly (which can be tested for). For the second *** reference, this is also a restriction of your program, not the metadata, an error should be thrown by whatever is executing and cannot handle a case rather than restricting concepts for describing a dataset. Furthermore, going to joins as a metadata concept allows the user to specify an entire dataset for a join rather than individual files, resulting in significant reduction of doubly-bookkept data. . Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user (since it is often the case they will want to run over a limited piece of the data to test things and then run over the full dataset). Re-writing the metadata on each run would get cumbersome quickly. To take all this and mutate your original suggestion (I haven't defined all the types but hopefully it's intelligible):. ```. {. ""datasets"":{. ""dataset"":{. ""treenames"": Union[List[String], String],. ""files"": List[String],. ""friends"":{. ""treenames"": Union[List[String], String],. ""files"": List[String],. ""joinType"": OneOf[""inner"", ""outer"", ""left"", ""right"", ""cross""], #this should just be made into a type. } or List[Dict[As in Single Dict]],. ""metadata"": Optional[Dict[JsonSerialiableAny:JsonSeri",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:3704,usability,user,user,3704,"at concept here rather than the precise concept of friends in TTree/RNtuple, which is limiting in scope for what is possible for dataset augmentation. Moreover, this allows the definition of left/right/inner/outer joins at the metadata level which is extremely useful for understanding how that additional data is intended to be used (are you just augmenting the number of columns in the dataset, are you x-referencing two datasets, etc.). It is then up to the system ingesting this data to implement the join specified by the user correctly (which can be tested for). For the second *** reference, this is also a restriction of your program, not the metadata, an error should be thrown by whatever is executing and cannot handle a case rather than restricting concepts for describing a dataset. Furthermore, going to joins as a metadata concept allows the user to specify an entire dataset for a join rather than individual files, resulting in significant reduction of doubly-bookkept data. . Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user (since it is often the case they will want to run over a limited piece of the data to test things and then run over the full dataset). Re-writing the metadata on each run would get cumbersome quickly. To take all this and mutate your original suggestion (I haven't defined all the types but hopefully it's intelligible):. ```. {. ""datasets"":{. ""dataset"":{. ""treenames"": Union[List[String], String],. ""files"": List[String],. ""friends"":{. ""treenames"": Union[List[String], String],. ""files"": List[String],. ""joinType"": OneOf[""inner"", ""outer"", ""left"", ""right"", ""cross""], #this should just be made into a type. } or List[Dict[As in Single Dict]],. ""metadata"": Optional[Dict[JsonSerialiableAny:JsonSerializableAny]]. },. # ... },. # other optional values from here on. ""metadata"": Optional[Dict[JsonSerialiableAny:JsonSerialiableAny]]. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:352,energy efficiency,current,currently,352,"Dear @hageboeck,. That specification would translate to. ```cpp. TChain c;. c.Add(""fa*.root?#Events"");. c.Add(""TheWeirdFileWithTheDifferentName.root?#ADifferentName"");. ```. For that particular ""dataset/sample"" and ""sample_a"" would just be retrievable as part of the metadata during the event loop. RDataFrame just processes the events in that TChain, currently you can distinguish the different file by calling a `DefinePerSample` and checking whether you are processing entries from that particular file and act accordingly. Probably it is not the most common case, but we have seen it happen and since it is supported by TChain, RDF needs to support it as well. I wonder if, by creating the possibility of adding different ""datasets/samples"", we are now practically removing the need for this case, or if it still holds. If not, we could think about allowing only a single ""dataset name"" (i.e. treename) per ""dataset"", although I'm not sure that this would be generic enough.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:43,integrability,translat,translate,43,"Dear @hageboeck,. That specification would translate to. ```cpp. TChain c;. c.Add(""fa*.root?#Events"");. c.Add(""TheWeirdFileWithTheDifferentName.root?#ADifferentName"");. ```. For that particular ""dataset/sample"" and ""sample_a"" would just be retrievable as part of the metadata during the event loop. RDataFrame just processes the events in that TChain, currently you can distinguish the different file by calling a `DefinePerSample` and checking whether you are processing entries from that particular file and act accordingly. Probably it is not the most common case, but we have seen it happen and since it is supported by TChain, RDF needs to support it as well. I wonder if, by creating the possibility of adding different ""datasets/samples"", we are now practically removing the need for this case, or if it still holds. If not, we could think about allowing only a single ""dataset name"" (i.e. treename) per ""dataset"", although I'm not sure that this would be generic enough.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:93,integrability,Event,Events,93,"Dear @hageboeck,. That specification would translate to. ```cpp. TChain c;. c.Add(""fa*.root?#Events"");. c.Add(""TheWeirdFileWithTheDifferentName.root?#ADifferentName"");. ```. For that particular ""dataset/sample"" and ""sample_a"" would just be retrievable as part of the metadata during the event loop. RDataFrame just processes the events in that TChain, currently you can distinguish the different file by calling a `DefinePerSample` and checking whether you are processing entries from that particular file and act accordingly. Probably it is not the most common case, but we have seen it happen and since it is supported by TChain, RDF needs to support it as well. I wonder if, by creating the possibility of adding different ""datasets/samples"", we are now practically removing the need for this case, or if it still holds. If not, we could think about allowing only a single ""dataset name"" (i.e. treename) per ""dataset"", although I'm not sure that this would be generic enough.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:287,integrability,event,event,287,"Dear @hageboeck,. That specification would translate to. ```cpp. TChain c;. c.Add(""fa*.root?#Events"");. c.Add(""TheWeirdFileWithTheDifferentName.root?#ADifferentName"");. ```. For that particular ""dataset/sample"" and ""sample_a"" would just be retrievable as part of the metadata during the event loop. RDataFrame just processes the events in that TChain, currently you can distinguish the different file by calling a `DefinePerSample` and checking whether you are processing entries from that particular file and act accordingly. Probably it is not the most common case, but we have seen it happen and since it is supported by TChain, RDF needs to support it as well. I wonder if, by creating the possibility of adding different ""datasets/samples"", we are now practically removing the need for this case, or if it still holds. If not, we could think about allowing only a single ""dataset name"" (i.e. treename) per ""dataset"", although I'm not sure that this would be generic enough.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:329,integrability,event,events,329,"Dear @hageboeck,. That specification would translate to. ```cpp. TChain c;. c.Add(""fa*.root?#Events"");. c.Add(""TheWeirdFileWithTheDifferentName.root?#ADifferentName"");. ```. For that particular ""dataset/sample"" and ""sample_a"" would just be retrievable as part of the metadata during the event loop. RDataFrame just processes the events in that TChain, currently you can distinguish the different file by calling a `DefinePerSample` and checking whether you are processing entries from that particular file and act accordingly. Probably it is not the most common case, but we have seen it happen and since it is supported by TChain, RDF needs to support it as well. I wonder if, by creating the possibility of adding different ""datasets/samples"", we are now practically removing the need for this case, or if it still holds. If not, we could think about allowing only a single ""dataset name"" (i.e. treename) per ""dataset"", although I'm not sure that this would be generic enough.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:23,interoperability,specif,specification,23,"Dear @hageboeck,. That specification would translate to. ```cpp. TChain c;. c.Add(""fa*.root?#Events"");. c.Add(""TheWeirdFileWithTheDifferentName.root?#ADifferentName"");. ```. For that particular ""dataset/sample"" and ""sample_a"" would just be retrievable as part of the metadata during the event loop. RDataFrame just processes the events in that TChain, currently you can distinguish the different file by calling a `DefinePerSample` and checking whether you are processing entries from that particular file and act accordingly. Probably it is not the most common case, but we have seen it happen and since it is supported by TChain, RDF needs to support it as well. I wonder if, by creating the possibility of adding different ""datasets/samples"", we are now practically removing the need for this case, or if it still holds. If not, we could think about allowing only a single ""dataset name"" (i.e. treename) per ""dataset"", although I'm not sure that this would be generic enough.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:43,interoperability,translat,translate,43,"Dear @hageboeck,. That specification would translate to. ```cpp. TChain c;. c.Add(""fa*.root?#Events"");. c.Add(""TheWeirdFileWithTheDifferentName.root?#ADifferentName"");. ```. For that particular ""dataset/sample"" and ""sample_a"" would just be retrievable as part of the metadata during the event loop. RDataFrame just processes the events in that TChain, currently you can distinguish the different file by calling a `DefinePerSample` and checking whether you are processing entries from that particular file and act accordingly. Probably it is not the most common case, but we have seen it happen and since it is supported by TChain, RDF needs to support it as well. I wonder if, by creating the possibility of adding different ""datasets/samples"", we are now practically removing the need for this case, or if it still holds. If not, we could think about allowing only a single ""dataset name"" (i.e. treename) per ""dataset"", although I'm not sure that this would be generic enough.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:757,reliability,pra,practically,757,"Dear @hageboeck,. That specification would translate to. ```cpp. TChain c;. c.Add(""fa*.root?#Events"");. c.Add(""TheWeirdFileWithTheDifferentName.root?#ADifferentName"");. ```. For that particular ""dataset/sample"" and ""sample_a"" would just be retrievable as part of the metadata during the event loop. RDataFrame just processes the events in that TChain, currently you can distinguish the different file by calling a `DefinePerSample` and checking whether you are processing entries from that particular file and act accordingly. Probably it is not the most common case, but we have seen it happen and since it is supported by TChain, RDF needs to support it as well. I wonder if, by creating the possibility of adding different ""datasets/samples"", we are now practically removing the need for this case, or if it still holds. If not, we could think about allowing only a single ""dataset name"" (i.e. treename) per ""dataset"", although I'm not sure that this would be generic enough.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:611,usability,support,supported,611,"Dear @hageboeck,. That specification would translate to. ```cpp. TChain c;. c.Add(""fa*.root?#Events"");. c.Add(""TheWeirdFileWithTheDifferentName.root?#ADifferentName"");. ```. For that particular ""dataset/sample"" and ""sample_a"" would just be retrievable as part of the metadata during the event loop. RDataFrame just processes the events in that TChain, currently you can distinguish the different file by calling a `DefinePerSample` and checking whether you are processing entries from that particular file and act accordingly. Probably it is not the most common case, but we have seen it happen and since it is supported by TChain, RDF needs to support it as well. I wonder if, by creating the possibility of adding different ""datasets/samples"", we are now practically removing the need for this case, or if it still holds. If not, we could think about allowing only a single ""dataset name"" (i.e. treename) per ""dataset"", although I'm not sure that this would be generic enough.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:645,usability,support,support,645,"Dear @hageboeck,. That specification would translate to. ```cpp. TChain c;. c.Add(""fa*.root?#Events"");. c.Add(""TheWeirdFileWithTheDifferentName.root?#ADifferentName"");. ```. For that particular ""dataset/sample"" and ""sample_a"" would just be retrievable as part of the metadata during the event loop. RDataFrame just processes the events in that TChain, currently you can distinguish the different file by calling a `DefinePerSample` and checking whether you are processing entries from that particular file and act accordingly. Probably it is not the most common case, but we have seen it happen and since it is supported by TChain, RDF needs to support it as well. I wonder if, by creating the possibility of adding different ""datasets/samples"", we are now practically removing the need for this case, or if it still holds. If not, we could think about allowing only a single ""dataset name"" (i.e. treename) per ""dataset"", although I'm not sure that this would be generic enough.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:2177,availability,operat,operation,2177,"ht into. I think that it is much related with the other comment regarding joins. Mixed modes sounds intriguing although I can't see a clear path for its implementation in the I/O layer, rather we may be better off doing this at the analysis tool layer directly. In general, the usecase of reading the output of some ML pipeline during the execution of the analysis is definitely something we want to address. For what concerns this specification, the easy part is just deciding for something more generic than ""treenames"" when specifying these other data formats; the trickier part is deciding how these other input data should be read. See the next comment for more discussion about this. > The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple. Yes I agree we can describe adding more columns to the main dataset as a join, with the implicit but crucial clarification that it is a view on the join operation and not a concrete join operation that would involve copying the two operands. With this sense, a friend TTree is equivalent to a left join where both unique IDs correspond to the event index and are the same number. I completely agree that this is a limit, indexed friends only extend it a little bit by allowing different sets of event indexes in the two tables. The idea of an heterogeneous dataset layout, with some datasets/samples having to be left-joined and others having to be inner-joined (for example), involves some design work and I would like to discuss it further, although I'd like to get a better idea of the use cases that need any joins other than left join. > Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user. During the meeting a few weeks ago there was quite a large consensus on this information being useful when written at the datasets/samples level.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:2211,availability,operat,operation,2211,"elated with the other comment regarding joins. Mixed modes sounds intriguing although I can't see a clear path for its implementation in the I/O layer, rather we may be better off doing this at the analysis tool layer directly. In general, the usecase of reading the output of some ML pipeline during the execution of the analysis is definitely something we want to address. For what concerns this specification, the easy part is just deciding for something more generic than ""treenames"" when specifying these other data formats; the trickier part is deciding how these other input data should be read. See the next comment for more discussion about this. > The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple. Yes I agree we can describe adding more columns to the main dataset as a join, with the implicit but crucial clarification that it is a view on the join operation and not a concrete join operation that would involve copying the two operands. With this sense, a friend TTree is equivalent to a left join where both unique IDs correspond to the event index and are the same number. I completely agree that this is a limit, indexed friends only extend it a little bit by allowing different sets of event indexes in the two tables. The idea of an heterogeneous dataset layout, with some datasets/samples having to be left-joined and others having to be inner-joined (for example), involves some design work and I would like to discuss it further, although I'd like to get a better idea of the use cases that need any joins other than left join. > Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user. During the meeting a few weeks ago there was quite a large consensus on this information being useful when written at the datasets/samples level. I also agree with you that an ent",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:4040,availability,error,error,4040," the meeting a few weeks ago there was quite a large consensus on this information being useful when written at the datasets/samples level. I also agree with you that an entry range is usually specified when testing before running the full thing. Nonetheless, the important part of this feature was the ability to tie a specific entry range to a specific dataset/sample and not to the global dataset, so that even when testing at least N entries from each dataset/sample would be processed. If this is not specified when definining the dataset metadata, then I suppose we should expose some API like:. ```python. entry_ranges = [(0,1000), (50000, 60000)] # taken from my initial specification example. df = RDataFrame(...). df.SetEntryRanges(entry_ranges). ```. And similarly for coffea and other frameworks. What I don't like about this is that I need to remember how many datasets/samples I have in my specification so that `len(entry_ranges)` corresponds to that number. Of course the tool can error and say ""You have specified too many entry ranges, please use only N"", maybe that's good enough but I'm not sure. One other comment could be that we don't need to have exactly one entry range per dataset/sample, maybe some datasets just need to be processed fully. But the API from above would not be able to distinguish whether the user actually didn't want to provide an entry range for a certain dataset or just forgot how many datasets were there. How would you address this part? > To take all this and mutate your original suggestion. Thanks for taking the time to include this example. I am happy that you agree on having a single top-level key ""datasets"" in which all the various datasets can be defined. I think this opens possibilities to use the rest of the JSON file for describing more parts of the analysis while not touching the dataset specification. I just wanted to ask you a clarification regarding the type `List[Dict[As in Single Dict]]` mentioned in the ""friends"" key. This i",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:1501,deployability,pipelin,pipeline,1501,"ards one vs the other. Do you think we should poll the larger audience at some point, for this and probably other questions? One other option could be just accepting both ""datasets"" and ""samples"" as the top-level key in the JSON object. > Cover TTree but plan for RNTuple support (metadata should not care about file formats, your program does). Indeed, this point was more directed towards us developers rather than user-facing. Metadata will definitely be orthogonal to the data format. > Allowing them opens up many possibilities, including mixed modes and joins across rather heterogenous datasets. This is an interesting comment, something that I hadn't put too much thought into. I think that it is much related with the other comment regarding joins. Mixed modes sounds intriguing although I can't see a clear path for its implementation in the I/O layer, rather we may be better off doing this at the analysis tool layer directly. In general, the usecase of reading the output of some ML pipeline during the execution of the analysis is definitely something we want to address. For what concerns this specification, the easy part is just deciding for something more generic than ""treenames"" when specifying these other data formats; the trickier part is deciding how these other input data should be read. See the next comment for more discussion about this. > The more general term for this is a a join, and I think you should use that concept here rather than the precise concept of friends in TTree/RNtuple. Yes I agree we can describe adding more columns to the main dataset as a join, with the implicit but crucial clarification that it is a view on the join operation and not a concrete join operation that would involve copying the two operands. With this sense, a friend TTree is equivalent to a left join where both unique IDs correspond to the event index and are the same number. I completely agree that this is a limit, indexed friends only extend it a little bit by allowing diff",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
https://github.com/root-project/root/issues/11624:3634,deployability,API,API,3634," left-joined and others having to be inner-joined (for example), involves some design work and I would like to discuss it further, although I'd like to get a better idea of the use cases that need any joins other than left join. > Entry ranges: I don't think this is very useful data to record. This is either kept track of as a good-luminosity block list, or specified at execution time by the user. During the meeting a few weeks ago there was quite a large consensus on this information being useful when written at the datasets/samples level. I also agree with you that an entry range is usually specified when testing before running the full thing. Nonetheless, the important part of this feature was the ability to tie a specific entry range to a specific dataset/sample and not to the global dataset, so that even when testing at least N entries from each dataset/sample would be processed. If this is not specified when definining the dataset metadata, then I suppose we should expose some API like:. ```python. entry_ranges = [(0,1000), (50000, 60000)] # taken from my initial specification example. df = RDataFrame(...). df.SetEntryRanges(entry_ranges). ```. And similarly for coffea and other frameworks. What I don't like about this is that I need to remember how many datasets/samples I have in my specification so that `len(entry_ranges)` corresponds to that number. Of course the tool can error and say ""You have specified too many entry ranges, please use only N"", maybe that's good enough but I'm not sure. One other comment could be that we don't need to have exactly one entry range per dataset/sample, maybe some datasets just need to be processed fully. But the API from above would not be able to distinguish whether the user actually didn't want to provide an entry range for a certain dataset or just forgot how many datasets were there. How would you address this part? > To take all this and mutate your original suggestion. Thanks for taking the time to include this exampl",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11624
